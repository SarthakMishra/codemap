{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CodeMap: AI-Powered Developer Toolkit","text":"<p>Welcome to the CodeMap documentation!</p> <p>CodeMap is an AI-powered developer toolkit designed to enhance your development workflow. It offers features like token-optimized documentation generation, semantic code analysis, and streamlined Git operations with AI assistance.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Generate Documentation: Create optimized markdown documentation and visualize repository structures.</li> <li>Smart Commits: Get AI-generated commit messages based on semantic analysis of your changes.</li> <li>AI-Powered PRs: Streamline pull request creation and management with intelligent suggestions.</li> <li>Multi-LLM Support: Integrate with various LLM providers via LiteLLM.</li> </ul> <p>Explore the documentation sections to learn more:</p> <ul> <li>Installation</li> <li>Usage Guide</li> <li>Configuration</li> <li>Development Setup</li> <li>Contributing Guide</li> </ul>"},{"location":"acknowledgements/","title":"Acknowledgments","text":"<p>CodeMap relies on these excellent open-source libraries and models:</p>"},{"location":"acknowledgements/#core-dependencies","title":"Core Dependencies","text":"<ul> <li>LiteLLM (&gt;=1.67.0) - Unified interface for LLM providers</li> <li>NumPy (&gt;=2.2.5) - Numerical computing for vector operations</li> <li>Pygments (&gt;=2.19.1) - Syntax highlighting for code snippets</li> <li>Python-dotenv (&gt;=1.1.0) - Environment variable management</li> <li>PyYAML (&gt;=6.0.2) - YAML parsing and configuration management</li> <li>Questionary (&gt;=2.1.0) - Interactive user prompts</li> <li>Requests (&gt;=2.32.3) - HTTP library for API interactions</li> <li>Rich (&gt;=14.0.0) - Beautiful terminal formatting and output</li> <li>Typer (&gt;=0.15.2) - Modern CLI framework for Python</li> <li>Typing Extensions (&gt;=4.13.2) - Backported typing features</li> <li>Sentence-Transformers (&gt;=4.1.0) - Text embeddings for semantic code analysis</li> </ul>"},{"location":"acknowledgements/#development-tools","title":"Development Tools","text":"<ul> <li>isort (&gt;=6.0.1) - Import sorting</li> <li>pylint (&gt;=3.3.6) - Code analysis</li> <li>pyright (&gt;=1.1.399) - Static type checking</li> <li>pytest (&gt;=8.3.5) - Testing framework</li> <li>pytest-cov (&gt;=6.1.1) - Test coverage reporting</li> <li>ruff (&gt;=0.11.6) - Fast Python linter</li> </ul>"},{"location":"acknowledgements/#models","title":"Models","text":"<ul> <li>Code Embeddings: Qodo/Qodo-Embed-1-1.5B - State-of-the-art embedding model optimized for code retrieval tasks.</li> <li>LLM Support: Compatible with various providers through LiteLLM including:</li> <li>OpenAI models</li> <li>Anthropic Claude models</li> <li>Groq models</li> <li>Mistral models</li> <li>Cohere models</li> <li>Together AI models</li> <li>OpenRouter providers</li> </ul>"},{"location":"acknowledgements/#special-thanks","title":"Special Thanks","text":"<ul> <li>Cursor</li> <li>OpenHands</li> <li>GitHub Actions</li> <li>Img Shields</li> <li>Codecov </li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>Warning</p> <p>CodeMap currently only supports Unix-based platforms (macOS, Linux). For Windows users, we recommend using Windows Subsystem for Linux (WSL).</p> <p>Tip</p> <p>After installation, you can use either <code>codemap</code> or the shorter alias <code>cm</code> to run the commands.</p>"},{"location":"installation/#installation-using-pipx-recommended","title":"Installation using pipx (Recommended)","text":"<p>Using <code>pipx</code> is recommended as it installs the package in an isolated environment and automatically manages the PATH.</p> <pre><code># Ensure pipx is installed (install it if you haven't)\n# python3 -m pip install --user pipx\n# python3 -m pipx ensurepath\n\n# Install codemap from PyPI\npipx install codemap\n</code></pre>"},{"location":"installation/#alternative-manual-installation-using-pip","title":"Alternative: Manual Installation using pip","text":"<p>If you prefer not to use <code>pipx</code>, you can install using <code>pip</code> directly:</p> <pre><code># Install with pip (user installation)\npip install --user codemap\n\n# Make sure your PATH includes the user bin directory\n# Add the following to your shell profile (e.g., ~/.bashrc, ~/.zshrc):\n# export PATH=\"$HOME/.local/bin:$PATH\"\n# Or find the correct path using: python3 -m site --user-base\n</code></pre>"},{"location":"installation/#development-version-latest-github","title":"Development Version (Latest GitHub)","text":"<p>If you want to try the latest development version with unreleased features:</p> <pre><code># Using pipx\npipx install git+https://github.com/SarthakMishra/codemap.git\n\n# Or using pip\npip install --user git+https://github.com/SarthakMishra/codemap.git\n</code></pre>"},{"location":"installation/#updating-codemap","title":"Updating CodeMap","text":"<p>To update CodeMap to the latest version:</p> <pre><code># If installed with pipx from PyPI\npipx upgrade codemap\n\n# If installed with pip from PyPI\npip install --user --upgrade codemap\n\n# If installed from GitHub\npipx upgrade codemap  # or\npip install --user --upgrade git+https://github.com/SarthakMishra/codemap.git\n</code></pre>"},{"location":"installation/#uninstalling","title":"Uninstalling","text":"<pre><code># If installed with pipx\npipx uninstall codemap\n\n# If installed with pip\npip uninstall codemap\n</code></pre>"},{"location":"api/","title":"API Reference","text":"<p>CodeMap - AI-powered developer toolkit.</p>"},{"location":"api/#main-modules","title":"Main Modules","text":"<ul> <li>Cli - Command-line interface package for CodeMap.</li> <li>Config - Default configuration settings for the codemap tool.</li> <li>Gen - Code documentation generation package for CodeMap.</li> <li>Git - Git utilities for CodeMap.</li> <li>Llm - LLM module for CodeMap.</li> <li>Processor - CodeMap processor module.</li> <li>Utils - Utility module for CodeMap package.</li> </ul>"},{"location":"api/config/","title":"Config","text":"<p>Default configuration settings for the codemap tool.</p>"},{"location":"api/config/#codemap.config.DEFAULT_CONFIG","title":"DEFAULT_CONFIG  <code>module-attribute</code>","text":"<pre><code>DEFAULT_CONFIG = {\n\t\"llm\": {\n\t\t\"model\": \"openai/gpt-4o-mini\",\n\t\t\"api_base\": None,\n\t},\n\t\"gen\": {\n\t\t\"max_content_length\": 5000,\n\t\t\"use_gitignore\": True,\n\t\t\"output_dir\": \"documentation\",\n\t\t\"include_tree\": True,\n\t\t\"include_entity_graph\": True,\n\t\t\"semantic_analysis\": True,\n\t\t\"lod_level\": \"docs\",\n\t\t\"mermaid_entities\": [\n\t\t\t\"module\",\n\t\t\t\"class\",\n\t\t\t\"function\",\n\t\t\t\"method\",\n\t\t\t\"constant\",\n\t\t\t\"variable\",\n\t\t\t\"import\",\n\t\t],\n\t\t\"mermaid_relationships\": [\n\t\t\t\"declares\",\n\t\t\t\"imports\",\n\t\t\t\"calls\",\n\t\t],\n\t\t\"mermaid_show_legend\": True,\n\t\t\"mermaid_remove_unconnected\": False,\n\t},\n\t\"processor\": {\n\t\t\"enabled\": True,\n\t\t\"max_workers\": 4,\n\t\t\"ignored_patterns\": [\n\t\t\t\"**/.git/**\",\n\t\t\t\"**/__pycache__/**\",\n\t\t\t\"**/.venv/**\",\n\t\t\t\"**/node_modules/**\",\n\t\t\t\"**/*.pyc\",\n\t\t\t\"**/dist/**\",\n\t\t\t\"**/build/**\",\n\t\t],\n\t\t\"default_lod_level\": \"signatures\",\n\t},\n\t\"commit\": {\n\t\t\"strategy\": \"file\",\n\t\t\"bypass_hooks\": False,\n\t\t\"convention\": {\n\t\t\t\"types\": [\n\t\t\t\t\"feat\",\n\t\t\t\t\"fix\",\n\t\t\t\t\"docs\",\n\t\t\t\t\"style\",\n\t\t\t\t\"refactor\",\n\t\t\t\t\"perf\",\n\t\t\t\t\"test\",\n\t\t\t\t\"build\",\n\t\t\t\t\"ci\",\n\t\t\t\t\"chore\",\n\t\t\t],\n\t\t\t\"scopes\": [],\n\t\t\t\"max_length\": 72,\n\t\t},\n\t\t\"lint\": {\n\t\t\t\"header_max_length\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"always\",\n\t\t\t\t\"value\": 100,\n\t\t\t},\n\t\t\t\"header_case\": {\n\t\t\t\t\"level\": \"DISABLED\",\n\t\t\t\t\"rule\": \"always\",\n\t\t\t\t\"value\": \"lower-case\",\n\t\t\t},\n\t\t\t\"header_full_stop\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"never\",\n\t\t\t\t\"value\": \".\",\n\t\t\t},\n\t\t\t\"type_enum\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"always\",\n\t\t\t},\n\t\t\t\"type_case\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"always\",\n\t\t\t\t\"value\": \"lower-case\",\n\t\t\t},\n\t\t\t\"type_empty\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"never\",\n\t\t\t},\n\t\t\t\"scope_case\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"always\",\n\t\t\t\t\"value\": \"lower-case\",\n\t\t\t},\n\t\t\t\"scope_empty\": {\n\t\t\t\t\"level\": \"DISABLED\",\n\t\t\t\t\"rule\": \"never\",\n\t\t\t},\n\t\t\t\"scope_enum\": {\n\t\t\t\t\"level\": \"DISABLED\",\n\t\t\t\t\"rule\": \"always\",\n\t\t\t},\n\t\t\t\"subject_case\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"never\",\n\t\t\t\t\"value\": [\n\t\t\t\t\t\"sentence-case\",\n\t\t\t\t\t\"start-case\",\n\t\t\t\t\t\"pascal-case\",\n\t\t\t\t\t\"upper-case\",\n\t\t\t\t],\n\t\t\t},\n\t\t\t\"subject_empty\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"never\",\n\t\t\t},\n\t\t\t\"subject_full_stop\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"never\",\n\t\t\t\t\"value\": \".\",\n\t\t\t},\n\t\t\t\"subject_exclamation_mark\": {\n\t\t\t\t\"level\": \"DISABLED\",\n\t\t\t\t\"rule\": \"never\",\n\t\t\t},\n\t\t\t\"body_leading_blank\": {\n\t\t\t\t\"level\": \"WARNING\",\n\t\t\t\t\"rule\": \"always\",\n\t\t\t},\n\t\t\t\"body_empty\": {\n\t\t\t\t\"level\": \"DISABLED\",\n\t\t\t\t\"rule\": \"never\",\n\t\t\t},\n\t\t\t\"body_max_line_length\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"always\",\n\t\t\t\t\"value\": 100,\n\t\t\t},\n\t\t\t\"footer_leading_blank\": {\n\t\t\t\t\"level\": \"WARNING\",\n\t\t\t\t\"rule\": \"always\",\n\t\t\t},\n\t\t\t\"footer_empty\": {\n\t\t\t\t\"level\": \"DISABLED\",\n\t\t\t\t\"rule\": \"never\",\n\t\t\t},\n\t\t\t\"footer_max_line_length\": {\n\t\t\t\t\"level\": \"ERROR\",\n\t\t\t\t\"rule\": \"always\",\n\t\t\t\t\"value\": 100,\n\t\t\t},\n\t\t},\n\t},\n\t\"pr\": {\n\t\t\"defaults\": {\n\t\t\t\"base_branch\": None,\n\t\t\t\"feature_prefix\": \"feature/\",\n\t\t},\n\t\t\"strategy\": \"github-flow\",\n\t\t\"branch_mapping\": {\n\t\t\t\"feature\": {\n\t\t\t\t\"base\": \"develop\",\n\t\t\t\t\"prefix\": \"feature/\",\n\t\t\t},\n\t\t\t\"release\": {\n\t\t\t\t\"base\": \"main\",\n\t\t\t\t\"prefix\": \"release/\",\n\t\t\t},\n\t\t\t\"hotfix\": {\"base\": \"main\", \"prefix\": \"hotfix/\"},\n\t\t\t\"bugfix\": {\n\t\t\t\t\"base\": \"develop\",\n\t\t\t\t\"prefix\": \"bugfix/\",\n\t\t\t},\n\t\t},\n\t\t\"generate\": {\n\t\t\t\"title_strategy\": \"commits\",\n\t\t\t\"description_strategy\": \"commits\",\n\t\t\t\"description_template\": dedent(\n\t\t\t\t\"\\t\\t\\t## Changes\\n\\t\\t\\t{changes}\\n\\n\\t\\t\\t## Testing\\n\\t\\t\\t{testing_instructions}\\n\\n\\t\\t\\t## Screenshots\\n\\t\\t\\t{screenshots}\\n\\t\\t\\t\"\n\t\t\t),\n\t\t\t\"use_workflow_templates\": True,\n\t\t},\n\t},\n}\n</code></pre>"},{"location":"api/cli/","title":"Cli Overview","text":"<p>Command-line interface package for CodeMap.</p> <ul> <li>Commit Cmd - Command for generating conventional commit messages from Git diffs.</li> <li>Gen Cmd - Implementation of the gen command for code documentation generation.</li> <li>Pr Cmd - Command for generating and managing pull requests.</li> </ul>"},{"location":"api/cli/commit_cmd/","title":"Commit Cmd","text":"<p>Command for generating conventional commit messages from Git diffs.</p>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.MAX_PREVIEW_LINES","title":"MAX_PREVIEW_LINES  <code>module-attribute</code>","text":"<pre><code>MAX_PREVIEW_LINES = 10\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.env_local","title":"env_local  <code>module-attribute</code>","text":"<pre><code>env_local = Path('.env.local')\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.env_file","title":"env_file  <code>module-attribute</code>","text":"<pre><code>env_file = Path('.env')\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.GenerationMode","title":"GenerationMode","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>LLM message generation mode.</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>class GenerationMode(str, Enum):\n\t\"\"\"LLM message generation mode.\"\"\"\n\n\tSMART = \"smart\"  # Use LLM-based generation\n\tSIMPLE = \"simple\"  # Use simple rule-based generation\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.GenerationMode.SMART","title":"SMART  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SMART = 'smart'\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.GenerationMode.SIMPLE","title":"SIMPLE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SIMPLE = 'simple'\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.CommitOptions","title":"CommitOptions  <code>dataclass</code>","text":"<p>Options for the commit command.</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>@dataclass\nclass CommitOptions:\n\t\"\"\"Options for the commit command.\"\"\"\n\n\trepo_path: Path\n\tgeneration_mode: GenerationMode = field(default=GenerationMode.SMART)\n\tmodel: str = field(default=\"openai/gpt-4o-mini\")\n\tapi_base: str | None = field(default=None)\n\tcommit: bool = field(default=True)\n\tprompt_template: str | None = field(default=None)\n\tapi_key: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.CommitOptions.__init__","title":"__init__","text":"<pre><code>__init__(\n\trepo_path: Path,\n\tgeneration_mode: GenerationMode = SMART,\n\tmodel: str = \"openai/gpt-4o-mini\",\n\tapi_base: str | None = None,\n\tcommit: bool = True,\n\tprompt_template: str | None = None,\n\tapi_key: str | None = None,\n) -&gt; None\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.CommitOptions.repo_path","title":"repo_path  <code>instance-attribute</code>","text":"<pre><code>repo_path: Path\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.CommitOptions.generation_mode","title":"generation_mode  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>generation_mode: GenerationMode = field(default=SMART)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.CommitOptions.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model: str = field(default='openai/gpt-4o-mini')\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.CommitOptions.api_base","title":"api_base  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_base: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.CommitOptions.commit","title":"commit  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>commit: bool = field(default=True)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.CommitOptions.prompt_template","title":"prompt_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>prompt_template: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.CommitOptions.api_key","title":"api_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_key: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.create_universal_generator","title":"create_universal_generator","text":"<pre><code>create_universal_generator(\n\trepo_path: Path,\n\tmodel: str | None = None,\n\tapi_key: str | None = None,\n\tapi_base: str | None = None,\n\tprompt_template: str | None = None,\n) -&gt; CommitMessageGenerator\n</code></pre> <p>Create a universal message generator with the provided options.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>Path</code> <p>Repository path</p> required <code>model</code> <code>str | None</code> <p>Model name to use</p> <code>None</code> <code>api_key</code> <code>str | None</code> <p>API key to use</p> <code>None</code> <code>api_base</code> <code>str | None</code> <p>API base URL to use</p> <code>None</code> <code>prompt_template</code> <code>str | None</code> <p>Custom prompt template</p> <code>None</code> <p>Returns:</p> Type Description <code>CommitMessageGenerator</code> <p>Configured CommitMessageGenerator</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>def create_universal_generator(\n\trepo_path: Path,\n\tmodel: str | None = None,\n\tapi_key: str | None = None,\n\tapi_base: str | None = None,\n\tprompt_template: str | None = None,\n) -&gt; CommitMessageGenerator:\n\t\"\"\"\n\tCreate a universal message generator with the provided options.\n\n\tArgs:\n\t    repo_path: Repository path\n\t    model: Model name to use\n\t    api_key: API key to use\n\t    api_base: API base URL to use\n\t    prompt_template: Custom prompt template\n\n\tReturns:\n\t    Configured CommitMessageGenerator\n\n\t\"\"\"\n\tfrom codemap.git.commit_generator import CommitMessageGenerator\n\tfrom codemap.llm import create_client\n\tfrom codemap.utils.config_loader import ConfigLoader\n\n\t# Create LLM client\n\tllm_client = create_client(\n\t\trepo_path=repo_path,\n\t\tmodel=model,\n\t\tapi_key=api_key,\n\t\tapi_base=api_base,\n\t)\n\n\t# Create config loader\n\tconfig_loader = ConfigLoader(repo_root=repo_path)\n\n\t# Get default prompt template if not provided\n\tif not prompt_template:\n\t\tfrom codemap.git.commit_generator.prompts import DEFAULT_PROMPT_TEMPLATE\n\n\t\tprompt_template = DEFAULT_PROMPT_TEMPLATE\n\n\t# Create and return generator\n\treturn CommitMessageGenerator(\n\t\trepo_root=repo_path,\n\t\tllm_client=llm_client,\n\t\tprompt_template=prompt_template,\n\t\tconfig_loader=config_loader,\n\t)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.setup_message_generator","title":"setup_message_generator","text":"<pre><code>setup_message_generator(\n\toptions: CommitOptions,\n) -&gt; CommitMessageGenerator\n</code></pre> <p>Set up a message generator with the provided options.</p> <p>Parameters:</p> Name Type Description Default <code>options</code> <code>CommitOptions</code> <p>Command options</p> required <p>Returns:</p> Type Description <code>CommitMessageGenerator</code> <p>Configured message generator</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>def setup_message_generator(options: CommitOptions) -&gt; CommitMessageGenerator:\n\t\"\"\"\n\tSet up a message generator with the provided options.\n\n\tArgs:\n\t    options: Command options\n\n\tReturns:\n\t    Configured message generator\n\n\t\"\"\"\n\t# Use the universal generator for simplified setup\n\treturn create_universal_generator(\n\t\trepo_path=options.repo_path,\n\t\tmodel=options.model,\n\t\tapi_key=options.api_key,\n\t\tapi_base=options.api_base,\n\t\tprompt_template=_load_prompt_template(options.prompt_template),\n\t)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.generate_message","title":"generate_message","text":"<pre><code>generate_message(\n\tchunk: DiffChunk,\n\tmessage_generator: CommitMessageGenerator,\n\tuse_simple_mode: bool = False,\n\tenable_linting: bool = True,\n) -&gt; tuple[str, bool]\n</code></pre> <p>Generate a commit message for a diff chunk.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk</code> <p>Diff chunk to generate message for</p> required <code>message_generator</code> <code>CommitMessageGenerator</code> <p>Message generator to use</p> required <code>use_simple_mode</code> <code>bool</code> <p>Whether to use simple mode</p> <code>False</code> <code>enable_linting</code> <code>bool</code> <p>Whether to enable linting</p> <code>True</code> <p>Returns:</p> Type Description <code>tuple[str, bool]</code> <p>Tuple of (message, whether LLM was used)</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>def generate_message(\n\tchunk: DiffChunk,\n\tmessage_generator: CommitMessageGenerator,\n\tuse_simple_mode: bool = False,\n\tenable_linting: bool = True,\n) -&gt; tuple[str, bool]:\n\t\"\"\"\n\tGenerate a commit message for a diff chunk.\n\n\tArgs:\n\t    chunk: Diff chunk to generate message for\n\t    message_generator: Message generator to use\n\t    use_simple_mode: Whether to use simple mode\n\t    enable_linting: Whether to enable linting\n\n\tReturns:\n\t    Tuple of (message, whether LLM was used)\n\n\t\"\"\"\n\tif use_simple_mode:\n\t\t# Use fallback generation without LLM\n\t\tmessage = message_generator.fallback_generation(chunk)\n\t\treturn message, False\n\n\tif enable_linting:\n\t\t# Use lint-capable generation\n\t\tfrom codemap.git.commit_generator.utils import generate_message_with_linting\n\n\t\tmessage, used_llm, _ = generate_message_with_linting(\n\t\t\tchunk=chunk,\n\t\t\tgenerator=message_generator,\n\t\t\trepo_root=message_generator.repo_root,\n\t\t)\n\t\treturn message, used_llm\n\n\t# Use regular generation without linting\n\tmessage, used_llm = message_generator.generate_message(chunk)\n\treturn message, used_llm\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.generate_commit_message","title":"generate_commit_message","text":"<pre><code>generate_commit_message(\n\tchunk: DiffChunk,\n\tgenerator: CommitMessageGenerator,\n\tmode: GenerationMode,\n) -&gt; tuple[str, bool]\n</code></pre> <p>Generate a commit message for a diff chunk.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk</code> <p>Diff chunk to generate message for</p> required <code>generator</code> <code>CommitMessageGenerator</code> <p>Message generator to use</p> required <code>mode</code> <code>GenerationMode</code> <p>Generation mode</p> required <p>Returns:</p> Type Description <code>tuple[str, bool]</code> <p>Tuple of (message, whether LLM was used)</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>def generate_commit_message(\n\tchunk: DiffChunk,\n\tgenerator: CommitMessageGenerator,\n\tmode: GenerationMode,\n) -&gt; tuple[str, bool]:\n\t\"\"\"\n\tGenerate a commit message for a diff chunk.\n\n\tArgs:\n\t    chunk: Diff chunk to generate message for\n\t    generator: Message generator to use\n\t    mode: Generation mode\n\n\tReturns:\n\t    Tuple of (message, whether LLM was used)\n\n\t\"\"\"\n\t# Handle simple mode directly\n\tif mode == GenerationMode.SIMPLE:\n\t\tfrom codemap.git.commit_generator.schemas import DiffChunkData\n\n\t\t# Convert DiffChunk to DiffChunkData\n\t\tchunk_dict = DiffChunkData(files=chunk.files, content=chunk.content)\n\t\t# Add description if it exists\n\t\tif chunk.description is not None:\n\t\t\tchunk_dict[\"description\"] = chunk.description\n\t\tmessage = generator.fallback_generation(chunk_dict)\n\t\treturn message, False\n\n\t# Use the universal generate_message function for SMART mode\n\ttry:\n\t\tmessage, used_llm = generate_message(\n\t\t\tchunk=chunk, message_generator=generator, use_simple_mode=False, enable_linting=True\n\t\t)\n\t\treturn message, used_llm\n\texcept (ValueError, RuntimeError, LLMError) as e:\n\t\tshow_error(f\"Error generating message: {e}\")\n\t\t# Still try to generate a fallback message\n\t\tfrom codemap.git.commit_generator.schemas import DiffChunkData\n\n\t\t# Convert DiffChunk to DiffChunkData\n\t\tchunk_dict = DiffChunkData(files=chunk.files, content=chunk.content)\n\t\t# Add description if it exists\n\t\tif chunk.description is not None:\n\t\t\tchunk_dict[\"description\"] = chunk.description\n\t\tmessage = generator.fallback_generation(chunk_dict)\n\t\treturn message, False\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.print_chunk_summary","title":"print_chunk_summary","text":"<pre><code>print_chunk_summary(chunk: DiffChunk, index: int) -&gt; None\n</code></pre> <p>Print a summary of the chunk.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk</code> <p>DiffChunk to summarize</p> required <code>index</code> <code>int</code> <p>Index of the chunk (1-based for display)</p> required Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>def print_chunk_summary(chunk: DiffChunk, index: int) -&gt; None:\n\t\"\"\"\n\tPrint a summary of the chunk.\n\n\tArgs:\n\t    chunk: DiffChunk to summarize\n\t    index: Index of the chunk (1-based for display)\n\n\t\"\"\"\n\t# Print header\n\tconsole.print(f\"\\nCommit {index + 1} of {index + 1}\")\n\n\t# Print chunk information in a panel\n\n\t# Create a content string with the files and changes\n\tcontent = \"**Files:** \" + \", \".join(chunk.files) + \"\\n\"\n\n\t# Calculate line counts from the diff content\n\tadded = len([line for line in chunk.content.splitlines() if line.startswith(\"+\") and not line.startswith(\"+++\")])\n\tremoved = len([line for line in chunk.content.splitlines() if line.startswith(\"-\") and not line.startswith(\"---\")])\n\n\t# Add line counts\n\tcontent += \"**Changes:** \"\n\tif added &gt; 0:\n\t\tcontent += f\"{added} added\"\n\tif removed &gt; 0:\n\t\tif added &gt; 0:\n\t\t\tcontent += \", \"\n\t\tcontent += f\"{removed} removed\"\n\tcontent += \"\\n\"\n\n\t# Add a preview of the diff content\n\tif chunk.content:\n\t\tcontent_lines = chunk.content.splitlines()\n\t\tif len(content_lines) &gt; MAX_PREVIEW_LINES:\n\t\t\tcontent += (\n\t\t\t\t\"\\n```diff\\n\"\n\t\t\t\t+ \"\\n\".join(content_lines[:MAX_PREVIEW_LINES])\n\t\t\t\t+ f\"\\n... ({len(content_lines) - MAX_PREVIEW_LINES} more lines)\\n```\"\n\t\t\t)\n\t\telse:\n\t\t\tcontent += \"\\n```diff\\n\" + chunk.content + \"\\n```\"\n\n\t# Create the panel with the content\n\tpanel = Panel(\n\t\tMarkdown(content),\n\t\ttitle=f\"Chunk {index + 1}\",\n\t\tborder_style=\"blue\",\n\t\texpand=False,\n\t\tpadding=(1, 2),\n\t)\n\tconsole.print(panel)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.ChunkContext","title":"ChunkContext  <code>dataclass</code>","text":"<p>Context for processing a chunk.</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>@dataclass\nclass ChunkContext:\n\t\"\"\"Context for processing a chunk.\"\"\"\n\n\tchunk: DiffChunk\n\tindex: int\n\ttotal: int\n\tgenerator: CommitMessageGenerator\n\tmode: GenerationMode\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.ChunkContext.__init__","title":"__init__","text":"<pre><code>__init__(\n\tchunk: DiffChunk,\n\tindex: int,\n\ttotal: int,\n\tgenerator: CommitMessageGenerator,\n\tmode: GenerationMode,\n) -&gt; None\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.ChunkContext.chunk","title":"chunk  <code>instance-attribute</code>","text":"<pre><code>chunk: DiffChunk\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.ChunkContext.index","title":"index  <code>instance-attribute</code>","text":"<pre><code>index: int\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.ChunkContext.total","title":"total  <code>instance-attribute</code>","text":"<pre><code>total: int\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.ChunkContext.generator","title":"generator  <code>instance-attribute</code>","text":"<pre><code>generator: CommitMessageGenerator\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.ChunkContext.mode","title":"mode  <code>instance-attribute</code>","text":"<pre><code>mode: GenerationMode\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.process_chunk_interactively","title":"process_chunk_interactively","text":"<pre><code>process_chunk_interactively(context: ChunkContext) -&gt; str\n</code></pre> <p>Process a diff chunk interactively.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>ChunkContext</code> <p>Context for processing the chunk</p> required <p>Returns:</p> Type Description <code>str</code> <p>Action to take (\"continue\", \"exit\")</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>def process_chunk_interactively(context: ChunkContext) -&gt; str:\n\t\"\"\"\n\tProcess a diff chunk interactively.\n\n\tArgs:\n\t    context: Context for processing the chunk\n\n\tReturns:\n\t    Action to take (\"continue\", \"exit\")\n\n\t\"\"\"\n\tconsole.print(f\"\\n[bold]Commit {context.index + 1} of {context.total}[/bold]\")\n\tprint_chunk_summary(context.chunk, context.index)\n\n\t# Generate commit message\n\tmessage, used_llm = generate_commit_message(context.chunk, context.generator, context.mode)\n\n\t# Display proposed message in a panel\n\ttag = \"AI\" if used_llm else \"Simple\"\n\tmessage_panel = Panel(\n\t\tText(message, style=\"green\"),\n\t\ttitle=f\"[bold blue]Proposed message ({tag})[/]\",\n\t\tborder_style=\"blue\" if used_llm else \"yellow\",\n\t\texpand=False,\n\t\tpadding=(1, 2),\n\t)\n\tconsole.print(message_panel)\n\n\t# Ask user what to do\n\tchoices = [\n\t\t{\"value\": \"commit\", \"name\": \"Commit with this message\"},\n\t\t{\"value\": \"edit\", \"name\": \"Edit message and commit\"},\n\t\t{\"value\": \"regenerate\", \"name\": \"Regenerate message\"},\n\t\t{\"value\": \"skip\", \"name\": \"Skip this chunk\"},\n\t\t{\"value\": \"exit\", \"name\": \"Exit without committing\"},\n\t]\n\n\taction = questionary.select(\"What would you like to do?\", choices=choices).ask()\n\n\tif action == \"commit\":\n\t\t_commit_with_message(context.chunk, message)\n\telif action == \"edit\":\n\t\t_commit_with_user_input(context.chunk, message)\n\telif action == \"regenerate\":\n\t\t# Just loop back for this chunk with smart generation\n\t\treturn process_chunk_interactively(\n\t\t\tChunkContext(\n\t\t\t\tchunk=context.chunk,\n\t\t\t\tindex=context.index,\n\t\t\t\ttotal=context.total,\n\t\t\t\tgenerator=context.generator,\n\t\t\t\tmode=GenerationMode.SMART,\n\t\t\t),\n\t\t)\n\telif action == \"skip\":\n\t\tconsole.print(\"[yellow]Skipped commit.[/yellow]\")\n\telif action == \"exit\":\n\t\tconsole.print(\"[yellow]Exiting commit process[/yellow]\")\n\t\treturn \"exit\"\n\n\treturn \"continue\"\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.display_suggested_messages","title":"display_suggested_messages","text":"<pre><code>display_suggested_messages(\n\toptions: CommitOptions,\n\tchunks: Sequence[DiffChunk],\n\tgenerator: CommitMessageGenerator,\n) -&gt; None\n</code></pre> <p>Display suggested commit messages without committing.</p> <p>Parameters:</p> Name Type Description Default <code>options</code> <code>CommitOptions</code> <p>Commit options</p> required <code>chunks</code> <code>Sequence[DiffChunk]</code> <p>List of diff chunks</p> required <code>generator</code> <code>CommitMessageGenerator</code> <p>Message generator to use</p> required Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>def display_suggested_messages(\n\toptions: CommitOptions, chunks: Sequence[DiffChunk], generator: CommitMessageGenerator\n) -&gt; None:\n\t\"\"\"\n\tDisplay suggested commit messages without committing.\n\n\tArgs:\n\t    options: Commit options\n\t    chunks: List of diff chunks\n\t    generator: Message generator to use\n\n\t\"\"\"\n\tconsole.print(\"Suggested commit messages (not committing):\")\n\n\tfor i, chunk in enumerate(chunks):\n\t\tprint_chunk_summary(chunk, i)\n\t\tmessage, used_llm = generate_commit_message(chunk, generator, options.generation_mode)\n\n\t\t# Display the message in a panel\n\t\ttag = \"AI\" if used_llm else \"Simple\"\n\t\tmessage_panel = Panel(\n\t\t\tText(message, style=\"green\"),\n\t\t\ttitle=f\"[bold blue]{tag}[/]\",\n\t\t\tborder_style=\"blue\" if used_llm else \"yellow\",\n\t\t\texpand=False,\n\t\t\tpadding=(1, 2),\n\t\t)\n\t\tconsole.print(message_panel)\n\t\tconsole.print()\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.process_all_chunks","title":"process_all_chunks","text":"<pre><code>process_all_chunks(\n\toptions: CommitOptions,\n\tchunks: Sequence[DiffChunk],\n\tgenerator: CommitMessageGenerator,\n) -&gt; int\n</code></pre> <p>Process all diff chunks.</p> <p>Parameters:</p> Name Type Description Default <code>options</code> <code>CommitOptions</code> <p>Commit options</p> required <code>chunks</code> <code>Sequence[DiffChunk]</code> <p>List of diff chunks</p> required <code>generator</code> <code>CommitMessageGenerator</code> <p>CommitMessageGenerator instance</p> required <p>Returns:</p> Type Description <code>int</code> <p>Exit code (0 for success, 1 for failure)</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>def process_all_chunks(\n\toptions: CommitOptions,\n\tchunks: Sequence[DiffChunk],\n\tgenerator: CommitMessageGenerator,\n) -&gt; int:\n\t\"\"\"\n\tProcess all diff chunks.\n\n\tArgs:\n\t    options: Commit options\n\t    chunks: List of diff chunks\n\t    generator: CommitMessageGenerator instance\n\n\tReturns:\n\t    Exit code (0 for success, 1 for failure)\n\n\t\"\"\"\n\t# Short circuit if there aren't any chunks\n\tif not chunks:\n\t\tlogger.debug(\"No chunks to process\")\n\t\treturn 0\n\n\t# If not interactive or we only have one chunk, process non-interactively\n\tif len(chunks) == 1:\n\t\tchunk = chunks[0]\n\t\tprint_chunk_summary(chunk, 0)\n\t\tmessage, is_valid = generate_commit_message(chunk, generator, options.generation_mode)\n\n\t\tif not is_valid:\n\t\t\tshow_error(\"Generated commit message is not valid\")\n\t\t\treturn 1\n\n\t\tconsole.print(f\"Generated message: {message}\")\n\n\t\tif options.commit:\n\t\t\t_commit_with_message(chunk, message)\n\t\telse:\n\t\t\tconsole.print(\"[yellow]Skipping commit (commit=False)[/yellow]\")\n\telse:\n\t\t# Process multiple chunks in interactive mode\n\t\tfor i, chunk in enumerate(chunks):\n\t\t\tcontext = ChunkContext(\n\t\t\t\tchunk=chunk,\n\t\t\t\tindex=i,\n\t\t\t\ttotal=len(chunks),\n\t\t\t\tgenerator=generator,\n\t\t\t\tmode=options.generation_mode,\n\t\t\t)\n\n\t\t\tif process_chunk_interactively(context) == \"exit\":\n\t\t\t\treturn 0\n\n\treturn 0\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig","title":"RunConfig  <code>dataclass</code>","text":"<p>Configuration options for running the commit command.</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>@dataclass\nclass RunConfig:\n\t\"\"\"Configuration options for running the commit command.\"\"\"\n\n\trepo_path: Path | None = None\n\tforce_simple: bool = False\n\tapi_key: str | None = None\n\tmodel: str = \"openai/gpt-4o-mini\"\n\tapi_base: str | None = None\n\tcommit: bool = True\n\tprompt_template: str | None = None\n\tstaged_only: bool = False  # Only process staged changes\n\tbypass_hooks: bool = False  # Whether to bypass git hooks (--no-verify)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig.__init__","title":"__init__","text":"<pre><code>__init__(\n\trepo_path: Path | None = None,\n\tforce_simple: bool = False,\n\tapi_key: str | None = None,\n\tmodel: str = \"openai/gpt-4o-mini\",\n\tapi_base: str | None = None,\n\tcommit: bool = True,\n\tprompt_template: str | None = None,\n\tstaged_only: bool = False,\n\tbypass_hooks: bool = False,\n) -&gt; None\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig.repo_path","title":"repo_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>repo_path: Path | None = None\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig.force_simple","title":"force_simple  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>force_simple: bool = False\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig.api_key","title":"api_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_key: str | None = None\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model: str = 'openai/gpt-4o-mini'\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig.api_base","title":"api_base  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_base: str | None = None\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig.commit","title":"commit  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>commit: bool = True\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig.prompt_template","title":"prompt_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>prompt_template: str | None = None\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig.staged_only","title":"staged_only  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>staged_only: bool = False\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.RunConfig.bypass_hooks","title":"bypass_hooks  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bypass_hooks: bool = False\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.DEFAULT_RUN_CONFIG","title":"DEFAULT_RUN_CONFIG  <code>module-attribute</code>","text":"<pre><code>DEFAULT_RUN_CONFIG = RunConfig()\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.validate_and_process_commit","title":"validate_and_process_commit","text":"<pre><code>validate_and_process_commit(\n\tpath: Path | None,\n\tall_files: bool = False,\n\tmodel: str = \"gpt-4o-mini\",\n\tbypass_hooks: bool = False,\n) -&gt; None\n</code></pre> <p>Validate repository path and process commit.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | None</code> <p>Path to repository</p> required <code>all_files</code> <code>bool</code> <p>Whether to commit all files</p> <code>False</code> <code>model</code> <code>str</code> <p>Model to use for generation</p> <code>'gpt-4o-mini'</code> <code>bypass_hooks</code> <code>bool</code> <p>Whether to bypass git hooks with --no-verify</p> <code>False</code> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>def validate_and_process_commit(\n\tpath: Path | None,\n\tall_files: bool = False,\n\tmodel: str = \"gpt-4o-mini\",\n\tbypass_hooks: bool = False,\n) -&gt; None:\n\t\"\"\"\n\tValidate repository path and process commit.\n\n\tArgs:\n\t    path: Path to repository\n\t    all_files: Whether to commit all files\n\t    model: Model to use for generation\n\t    bypass_hooks: Whether to bypass git hooks with --no-verify\n\n\t\"\"\"\n\ttry:\n\t\t# Load configuration from .codemap.yml if it exists\n\t\trepo_path = validate_repo_path(path)\n\t\tif repo_path:\n\t\t\tconfig_loader = ConfigLoader(repo_root=repo_path)\n\t\t\t# Get bypass_hooks from config if not explicitly set\n\t\t\tif not hasattr(bypass_hooks, \"_set_explicitly\"):\n\t\t\t\tbypass_hooks = config_loader.get_bypass_hooks()\n\n\t\t# Create the CommitCommand instance\n\t\tcommand = CommitCommand(\n\t\t\tpath=path,\n\t\t\tmodel=model,\n\t\t\tbypass_hooks=bypass_hooks,\n\t\t)\n\n\t\t# Stage files if all_files flag is set\n\t\tif all_files:\n\t\t\trun_git_command([\"git\", \"add\", \".\"])\n\n\t\t# Run the command (message will be prompted during the interactive process)\n\t\tresult = command.run()\n\n\t\t# If command completed but returned False and it wasn't an intentional abort,\n\t\t# raise an error\n\t\tif not result and command.error_state != \"aborted\":\n\t\t\t_raise_command_failed_error()\n\n\texcept typer.Exit:\n\t\t# Let typer.Exit propagate for clean CLI exit\n\t\traise\n\texcept Exception as e:\n\t\tlogger.exception(\"Error processing commit\")\n\t\texit_with_error(f\"Error: {e}\", exception=e)\n</code></pre>"},{"location":"api/cli/commit_cmd/#codemap.cli.commit_cmd.commit_command","title":"commit_command","text":"<pre><code>commit_command(\n\tpath: Annotated[\n\t\tPath | None,\n\t\tArgument(\n\t\t\thelp=\"Path to repository or file to commit\",\n\t\t\texists=True,\n\t\t),\n\t] = None,\n\tmessage: Annotated[\n\t\tstr | None,\n\t\tOption(\"--message\", \"-m\", help=\"Commit message\"),\n\t] = None,\n\tall_files: Annotated[\n\t\tbool,\n\t\tOption(\"--all\", \"-a\", help=\"Commit all changes\"),\n\t] = False,\n\tmodel: Annotated[\n\t\tstr,\n\t\tOption(\n\t\t\t\"--model\",\n\t\t\thelp=\"LLM model to use for message generation\",\n\t\t),\n\t] = \"gpt-4o-mini\",\n\tstrategy: Annotated[\n\t\tstr,\n\t\tOption(\n\t\t\t\"--strategy\",\n\t\t\t\"-s\",\n\t\t\thelp=\"Strategy for splitting diffs\",\n\t\t),\n\t] = \"semantic\",\n\tnon_interactive: Annotated[\n\t\tbool,\n\t\tOption(\n\t\t\t\"--non-interactive\",\n\t\t\thelp=\"Run in non-interactive mode\",\n\t\t),\n\t] = False,\n\tbypass_hooks: Annotated[\n\t\tbool,\n\t\tOption(\n\t\t\t\"--bypass-hooks\",\n\t\t\thelp=\"Bypass git hooks with --no-verify\",\n\t\t),\n\t] = False,\n\tis_verbose: Annotated[\n\t\tbool,\n\t\tOption(\n\t\t\t\"--verbose\", \"-v\", help=\"Enable verbose logging\"\n\t\t),\n\t] = False,\n) -&gt; None\n</code></pre> <p>Generate AI-assisted commit messages for staged changes.</p> <p>This command analyzes your staged changes and generates commit messages using an LLM.</p> Source code in <code>src/codemap/cli/commit_cmd.py</code> <pre><code>def commit_command(\n\tpath: Annotated[\n\t\tPath | None,\n\t\ttyper.Argument(\n\t\t\thelp=\"Path to repository or file to commit\",\n\t\t\texists=True,\n\t\t),\n\t] = None,\n\tmessage: Annotated[str | None, typer.Option(\"--message\", \"-m\", help=\"Commit message\")] = None,\n\tall_files: Annotated[bool, typer.Option(\"--all\", \"-a\", help=\"Commit all changes\")] = False,\n\tmodel: Annotated[\n\t\tstr,\n\t\ttyper.Option(\n\t\t\t\"--model\",\n\t\t\thelp=\"LLM model to use for message generation\",\n\t\t),\n\t] = \"gpt-4o-mini\",\n\tstrategy: Annotated[str, typer.Option(\"--strategy\", \"-s\", help=\"Strategy for splitting diffs\")] = \"semantic\",\n\tnon_interactive: Annotated[bool, typer.Option(\"--non-interactive\", help=\"Run in non-interactive mode\")] = False,\n\tbypass_hooks: Annotated[bool, typer.Option(\"--bypass-hooks\", help=\"Bypass git hooks with --no-verify\")] = False,\n\tis_verbose: Annotated[bool, typer.Option(\"--verbose\", \"-v\", help=\"Enable verbose logging\")] = False,\n) -&gt; None:\n\t\"\"\"\n\tGenerate AI-assisted commit messages for staged changes.\n\n\tThis command analyzes your staged changes and generates commit messages\n\tusing an LLM.\n\n\t\"\"\"\n\tsetup_logging(is_verbose=is_verbose)\n\n\t# Log environment setup and key configuration\n\tif is_verbose:\n\t\t# Log Python and environment details\n\t\tlogger.debug(\"Python Path: %s\", sys.executable)\n\t\tlogger.debug(\"Python Version: %s\", sys.version)\n\n\t\t# Log model information\n\t\tlogger.debug(\"Using model: %s\", model)\n\n\t\t# Log command parameters\n\t\tlogger.debug(\"Message: %s\", message)\n\t\tlogger.debug(\"Strategy: %s\", strategy)\n\t\tlogger.debug(\"Non-interactive mode: %s\", non_interactive)\n\t\tlogger.debug(\"Bypass git hooks: %s\", bypass_hooks)\n\n\t\t# Check sentence_transformers\n\t\ttry:\n\t\t\timport sentence_transformers\n\n\t\t\tlogger.debug(\"sentence_transformers version: %s\", sentence_transformers.__version__)\n\t\texcept ImportError:\n\t\t\tlogger.debug(\"sentence_transformers is not installed or importable\")\n\t\texcept (AttributeError, RuntimeError) as e:\n\t\t\tlogger.debug(\"Error checking sentence_transformers: %s\", e)\n\n\t\t# Log important environment variables (without revealing API keys)\n\t\tprovider_prefixes = [\"OPENAI\", \"GROQ\", \"ANTHROPIC\", \"MISTRAL\", \"COHERE\", \"TOGETHER\", \"OPENROUTER\"]\n\t\tfor prefix in provider_prefixes:\n\t\t\tkey_var = f\"{prefix}_API_KEY\"\n\t\t\tif key_var in os.environ:\n\t\t\t\t# Log presence but not the actual key\n\t\t\t\tlogger.debug(\"%s is set in environment (length: %d)\", key_var, len(os.environ[key_var]))\n\n\t# Continue with normal command execution - typer.Exit exceptions will propagate normally\n\tvalidate_and_process_commit(\n\t\tpath=path,\n\t\tall_files=all_files,\n\t\tmodel=model,\n\t\tbypass_hooks=bypass_hooks,\n\t)\n</code></pre>"},{"location":"api/cli/gen_cmd/","title":"Gen Cmd","text":"<p>Implementation of the gen command for code documentation generation.</p> <p>This module implements the enhanced 'gen' command, which can generate human-readable documentation in Markdown format.</p>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.PathArg","title":"PathArg  <code>module-attribute</code>","text":"<pre><code>PathArg = Annotated[\n\tPath,\n\tArgument(\n\t\texists=True,\n\t\thelp=\"Path to the codebase to analyze\",\n\t\tshow_default=True,\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.OutputOpt","title":"OutputOpt  <code>module-attribute</code>","text":"<pre><code>OutputOpt = Annotated[\n\tPath | None,\n\tOption(\n\t\t\"--output\",\n\t\t\"-o\",\n\t\thelp=\"Output file path (overrides config)\",\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.ConfigOpt","title":"ConfigOpt  <code>module-attribute</code>","text":"<pre><code>ConfigOpt = Annotated[\n\tPath | None,\n\tOption(\"--config\", \"-c\", help=\"Path to config file\"),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.MaxContentLengthOpt","title":"MaxContentLengthOpt  <code>module-attribute</code>","text":"<pre><code>MaxContentLengthOpt = Annotated[\n\tint | None,\n\tOption(\n\t\t\"--max-content-length\",\n\t\thelp=\"Maximum content length for file display (set to 0 for unlimited)\",\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.TreeFlag","title":"TreeFlag  <code>module-attribute</code>","text":"<pre><code>TreeFlag = Annotated[\n\tbool,\n\tOption(\n\t\t\"--tree\",\n\t\t\"-t\",\n\t\thelp=\"Include directory tree in output\",\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.VerboseFlag","title":"VerboseFlag  <code>module-attribute</code>","text":"<pre><code>VerboseFlag = Annotated[\n\tbool,\n\tOption(\n\t\t\"--verbose\", \"-v\", help=\"Enable verbose logging\"\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.ProcessingFlag","title":"ProcessingFlag  <code>module-attribute</code>","text":"<pre><code>ProcessingFlag = Annotated[\n\tbool,\n\tOption(\n\t\t\"--process/--no-process\",\n\t\thelp=\"Process the codebase before generation\",\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.EntityGraphFlag","title":"EntityGraphFlag  <code>module-attribute</code>","text":"<pre><code>EntityGraphFlag = Annotated[\n\tbool | None,\n\tOption(\n\t\t\"--entity-graph/--no-entity-graph\",\n\t\t\"-e\",\n\t\thelp=\"Include entity relationship graph in output\",\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.LODLevelOpt","title":"LODLevelOpt  <code>module-attribute</code>","text":"<pre><code>LODLevelOpt = Annotated[\n\tstr,\n\tOption(\n\t\t\"--lod\",\n\t\thelp=\"Level of Detail for code analysis (e.g., 'full', 'docs', 'signatures')\",\n\t\tcase_sensitive=False,\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.MermaidEntitiesOpt","title":"MermaidEntitiesOpt  <code>module-attribute</code>","text":"<pre><code>MermaidEntitiesOpt = Annotated[\n\tstr | None,\n\tOption(\n\t\t\"--mermaid-entities\",\n\t\thelp=\"Comma-separated list of entity types to include in Mermaid graph (e.g., 'module,class,function')\",\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.MermaidRelationshipsOpt","title":"MermaidRelationshipsOpt  <code>module-attribute</code>","text":"<pre><code>MermaidRelationshipsOpt = Annotated[\n\tstr | None,\n\tOption(\n\t\t\"--mermaid-relationships\",\n\t\thelp=\"Comma-separated list of relationship types to include in Mermaid graph (e.g., 'declares,imports,calls')\",\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.MermaidLegendFlag","title":"MermaidLegendFlag  <code>module-attribute</code>","text":"<pre><code>MermaidLegendFlag = Annotated[\n\tbool | None,\n\tOption(\n\t\t\"--mermaid-legend/--no-mermaid-legend\",\n\t\thelp=\"Show/hide the legend in the Mermaid diagram\",\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.MermaidUnconnectedFlag","title":"MermaidUnconnectedFlag  <code>module-attribute</code>","text":"<pre><code>MermaidUnconnectedFlag = Annotated[\n\tbool | None,\n\tOption(\n\t\t\"--mermaid-unconnected/--no-mermaid-unconnected\",\n\t\thelp=\"Remove/keep nodes with no connections in the Mermaid diagram\",\n\t),\n]\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.initialize_processor","title":"initialize_processor","text":"<pre><code>initialize_processor(\n\trepo_path: Path, config_data: dict\n) -&gt; None\n</code></pre> <p>Initialize the processor for code analysis.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>Path</code> <p>Path to the repository</p> required <code>config_data</code> <code>dict</code> <p>Configuration data</p> required Source code in <code>src/codemap/cli/gen_cmd.py</code> <pre><code>def initialize_processor(repo_path: Path, config_data: dict) -&gt; None:\n\t\"\"\"\n\tInitialize the processor for code analysis.\n\n\tArgs:\n\t    repo_path: Path to the repository\n\t    config_data: Configuration data\n\n\t\"\"\"\n\tfrom codemap.utils.cli_utils import console\n\n\t# Extract processor configuration\n\tprocessor_config = config_data.get(\"processor\", {})\n\n\t# Get ignored patterns\n\tignored_patterns = set(processor_config.get(\"ignored_patterns\", []))\n\tignored_patterns.update(\n\t\t[\n\t\t\t\"**/.git/**\",\n\t\t\t\"**/__pycache__/**\",\n\t\t\t\"**/.venv/**\",\n\t\t\t\"**/node_modules/**\",\n\t\t\t\"**/.codemap_cache/**\",\n\t\t\t\"**/*.pyc\",\n\t\t\t\"**/dist/**\",\n\t\t\t\"**/build/**\",\n\t\t]\n\t)\n\n\t# Initialize processor with LOD support\n\ttry:\n\t\tprocessor = create_processor(repo_path=repo_path)\n\t\tconsole.print(\"[green]Processor initialized successfully[/green]\")\n\t\tprocessor.stop()\n\texcept Exception as e:\n\t\tconsole.print(f\"[red]Failed to initialize processor: {e}[/red]\")\n\t\traise\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.gen_command","title":"gen_command","text":"<pre><code>gen_command(\n\tpath: PathArg = Path(),\n\toutput: OutputOpt = None,\n\tconfig: ConfigOpt = None,\n\tmax_content_length: MaxContentLengthOpt = None,\n\tlod_level_str: LODLevelOpt = \"docs\",\n\tsemantic_analysis: Annotated[\n\t\tbool,\n\t\tOption(\n\t\t\t\"--semantic/--no-semantic\",\n\t\t\thelp=\"Enable/disable semantic analysis\",\n\t\t),\n\t] = True,\n\ttree: Annotated[\n\t\tbool | None,\n\t\tOption(\n\t\t\t\"--tree/--no-tree\",\n\t\t\t\"-t\",\n\t\t\thelp=\"Include directory tree in output\",\n\t\t),\n\t] = None,\n\tis_verbose: Annotated[\n\t\tbool,\n\t\tOption(\n\t\t\t\"--verbose\", \"-v\", help=\"Enable verbose logging\"\n\t\t),\n\t] = False,\n\tprocess: ProcessingFlag = True,\n\tentity_graph: EntityGraphFlag = None,\n\tmermaid_entities_str: MermaidEntitiesOpt = None,\n\tmermaid_relationships_str: MermaidRelationshipsOpt = None,\n\tmermaid_show_legend_flag: MermaidLegendFlag = None,\n\tmermaid_remove_unconnected_flag: MermaidUnconnectedFlag = None,\n) -&gt; None\n</code></pre> <p>Generate code documentation.</p> <p>This command processes a codebase and generates Markdown documentation with configurable level of detail.</p> <p>Examples:</p> <p>codemap gen                      # Generate docs for current directory codemap gen --lod full           # Generate full implementation docs codemap gen --lod signatures     # Generate docs with signatures only codemap gen --no-semantic        # Generate without semantic analysis</p> Source code in <code>src/codemap/cli/gen_cmd.py</code> <pre><code>def gen_command(\n\tpath: PathArg = Path(),\n\toutput: OutputOpt = None,\n\tconfig: ConfigOpt = None,\n\tmax_content_length: MaxContentLengthOpt = None,\n\tlod_level_str: LODLevelOpt = \"docs\",\n\tsemantic_analysis: Annotated[\n\t\tbool,\n\t\ttyper.Option(\n\t\t\t\"--semantic/--no-semantic\",\n\t\t\thelp=\"Enable/disable semantic analysis\",\n\t\t),\n\t] = True,\n\ttree: Annotated[\n\t\tbool | None,\n\t\ttyper.Option(\n\t\t\t\"--tree/--no-tree\",\n\t\t\t\"-t\",\n\t\t\thelp=\"Include directory tree in output\",\n\t\t),\n\t] = None,\n\tis_verbose: Annotated[\n\t\tbool,\n\t\ttyper.Option(\n\t\t\t\"--verbose\",\n\t\t\t\"-v\",\n\t\t\thelp=\"Enable verbose logging\",\n\t\t),\n\t] = False,\n\tprocess: ProcessingFlag = True,\n\tentity_graph: EntityGraphFlag = None,\n\tmermaid_entities_str: MermaidEntitiesOpt = None,\n\tmermaid_relationships_str: MermaidRelationshipsOpt = None,\n\tmermaid_show_legend_flag: MermaidLegendFlag = None,\n\tmermaid_remove_unconnected_flag: MermaidUnconnectedFlag = None,\n) -&gt; None:\n\t\"\"\"\n\tGenerate code documentation.\n\n\tThis command processes a codebase and generates Markdown documentation\n\twith configurable level of detail.\n\n\tExamples:\n\t        codemap gen                      # Generate docs for current directory\n\t        codemap gen --lod full           # Generate full implementation docs\n\t        codemap gen --lod signatures     # Generate docs with signatures only\n\t        codemap gen --no-semantic        # Generate without semantic analysis\n\n\t\"\"\"\n\tsetup_logging(is_verbose=is_verbose)\n\n\ttry:\n\t\ttarget_path = path.resolve()\n\t\tproject_root = Path.cwd()\n\n\t\t# Load config\n\t\tconfig_loader = ConfigLoader(str(config) if config else None)\n\t\tconfig_data = config_loader.config\n\n\t\t# Get gen-specific config with defaults\n\t\tgen_config_data = config_data.get(\"gen\", {})\n\n\t\t# Process the codebase if requested\n\t\tif process:\n\t\t\tfrom codemap.utils.cli_utils import console\n\n\t\t\tconsole.print(\"[yellow]Initializing processor...[/yellow]\")\n\t\t\tinitialize_processor(target_path, config_data)\n\t\t\tconsole.print(\"[green]Processor initialization completed successfully[/green]\")\n\n\t\t# Command line arguments override config file\n\t\tcontent_length = (\n\t\t\tmax_content_length if max_content_length is not None else gen_config_data.get(\"max_content_length\", 5000)\n\t\t)\n\n\t\t# Handle boolean flags - default to config values if not provided\n\t\tinclude_tree = tree if tree is not None else gen_config_data.get(\"include_tree\", False)\n\t\tenable_semantic = (\n\t\t\tsemantic_analysis if semantic_analysis is not None else gen_config_data.get(\"semantic_analysis\", True)\n\t\t)\n\t\tinclude_entity_graph = (\n\t\t\tentity_graph if entity_graph is not None else gen_config_data.get(\"include_entity_graph\", True)\n\t\t)\n\n\t\t# Initialize lod_level to a default before the try block\n\t\tlod_level: LODLevel = LODLevel.DOCS  # Default if conversion fails somehow\n\n\t\t# Get LOD level from config if not specified\n\t\tconfig_lod_str = str(gen_config_data.get(\"lod_level\", LODLevel.DOCS.name.lower()))  # Default to 'docs'\n\n\t\t# Determine the final LOD level string (CLI &gt; Config &gt; Default)\n\t\tfinal_lod_str = lod_level_str if lod_level_str != LODLevel.DOCS.name.lower() else config_lod_str\n\n\t\t# Convert the final string to the LODLevel enum\n\t\ttry:\n\t\t\t# Look up enum member by name (uppercase) instead of value\n\t\t\tlod_level = LODLevel[final_lod_str.upper()]\n\t\texcept (ValueError, KeyError) as e:  # Catch KeyError for invalid names\n\t\t\t# Provide a more helpful error message if conversion fails\n\t\t\t# Get valid names (lowercase) for the error message\n\t\t\tvalid_names = [name.lower() for name in LODLevel.__members__]\n\t\t\texit_with_error(\n\t\t\t\tf\"Invalid LOD level '{final_lod_str}'. Valid levels are: {', '.join(valid_names)}\", exception=e\n\t\t\t)\n\n\t\t# Handle Mermaid config (CLI &gt; Config &gt; Default)\n\t\tdefault_mermaid_entities = gen_config_data.get(\"mermaid_entities\", [])\n\t\tmermaid_entities = (\n\t\t\t[e.strip().lower() for e in mermaid_entities_str.split(\",\")]\n\t\t\tif mermaid_entities_str\n\t\t\telse default_mermaid_entities\n\t\t)\n\n\t\tdefault_mermaid_relationships = gen_config_data.get(\"mermaid_relationships\", [])\n\t\tmermaid_relationships = (\n\t\t\t[r.strip().lower() for r in mermaid_relationships_str.split(\",\")]\n\t\t\tif mermaid_relationships_str\n\t\t\telse default_mermaid_relationships\n\t\t)\n\n\t\t# Handle Mermaid legend visibility (CLI &gt; Config &gt; Default)\n\t\tmermaid_show_legend = (\n\t\t\tmermaid_show_legend_flag\n\t\t\tif mermaid_show_legend_flag is not None\n\t\t\telse gen_config_data.get(\"mermaid_show_legend\", True)  # Default to True\n\t\t)\n\n\t\t# Handle Mermaid unconnected node removal (CLI &gt; Config &gt; Default)\n\t\tmermaid_remove_unconnected = (\n\t\t\tmermaid_remove_unconnected_flag\n\t\t\tif mermaid_remove_unconnected_flag is not None\n\t\t\telse gen_config_data.get(\"mermaid_remove_unconnected\", False)  # Default to False\n\t\t)\n\n\t\t# Create generation config\n\t\tgen_config = GenConfig(\n\t\t\tlod_level=lod_level,\n\t\t\tmax_content_length=content_length,\n\t\t\tinclude_tree=include_tree,\n\t\t\tsemantic_analysis=enable_semantic,\n\t\t\tinclude_entity_graph=include_entity_graph,\n\t\t\tuse_gitignore=gen_config_data.get(\"use_gitignore\", True),\n\t\t\toutput_dir=Path(gen_config_data.get(\"output_dir\", \"documentation\")),\n\t\t\tmermaid_entities=mermaid_entities,\n\t\t\tmermaid_relationships=mermaid_relationships,\n\t\t\tmermaid_show_legend=mermaid_show_legend,\n\t\t\tmermaid_remove_unconnected=mermaid_remove_unconnected,\n\t\t)\n\n\t\t# Determine output path\n\t\tfrom codemap.gen.utils import determine_output_path\n\n\t\t# --- DIAGNOSTIC PRINT --- #\n\t\tlogger.debug(\"Gen config data being passed to determine_output_path: %s\", gen_config_data)\n\t\t# ---------------------- #\n\n\t\toutput_path = determine_output_path(project_root, output, gen_config_data)\n\n\t\t# Create and execute the gen command\n\t\tcommand = GenCommand(gen_config)\n\t\tsuccess = command.execute(target_path, output_path)\n\n\t\tif not success:\n\t\t\texit_with_error(\"Generation failed\")\n\n\texcept (FileNotFoundError, PermissionError, OSError) as e:\n\t\texit_with_error(f\"File system error: {e!s}\", exception=e)\n\texcept ValueError as e:\n\t\texit_with_error(f\"Configuration error: {e!s}\", exception=e)\n</code></pre>"},{"location":"api/cli/gen_cmd/#codemap.cli.gen_cmd.generate_command","title":"generate_command  <code>module-attribute</code>","text":"<pre><code>generate_command = gen_command\n</code></pre>"},{"location":"api/cli/pr_cmd/","title":"Pr Cmd","text":"<p>Command for generating and managing pull requests.</p>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.MAX_PREVIEW_LINES","title":"MAX_PREVIEW_LINES  <code>module-attribute</code>","text":"<pre><code>MAX_PREVIEW_LINES = 10\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.MAX_DESCRIPTION_LENGTH","title":"MAX_DESCRIPTION_LENGTH  <code>module-attribute</code>","text":"<pre><code>MAX_DESCRIPTION_LENGTH = 100\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.generate_message","title":"generate_message","text":"<pre><code>generate_message(\n\tchunk: DiffChunk,\n\tgenerator: CommitMessageGenerator,\n\tuse_simple_mode: bool = False,\n) -&gt; tuple[str, bool]\n</code></pre> <p>Generate a commit message for a diff chunk.</p> <p>This is a placeholder and should be properly imported from the appropriate module.</p> Source code in <code>src/codemap/cli/pr_cmd.py</code> <pre><code>def generate_message(\n\tchunk: DiffChunk, generator: CommitMessageGenerator, use_simple_mode: bool = False\n) -&gt; tuple[str, bool]:\n\t\"\"\"\n\tGenerate a commit message for a diff chunk.\n\n\tThis is a placeholder and should be properly imported from the\n\tappropriate module.\n\n\t\"\"\"\n\tif hasattr(generator, \"generate_message_with_linting\") and not use_simple_mode:\n\t\tmessage, used_llm, _ = generator.generate_message_with_linting(chunk)\n\telse:\n\t\tmessage, used_llm = generator.generate_message(chunk)\n\treturn message, used_llm\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.generate_release_pr_content","title":"generate_release_pr_content","text":"<pre><code>generate_release_pr_content(\n\tbase_branch: str, branch_name: str\n) -&gt; dict[str, str]\n</code></pre> <p>Generate PR content for a release.</p> <p>This is a placeholder and should be properly imported from the appropriate module.</p> <p>Parameters:</p> Name Type Description Default <code>base_branch</code> <code>str</code> <p>The branch to merge into (e.g. main)</p> required <code>branch_name</code> <code>str</code> <p>The release branch name (e.g. release/1.0.0)</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary with title and description</p> Source code in <code>src/codemap/cli/pr_cmd.py</code> <pre><code>def generate_release_pr_content(base_branch: str, branch_name: str) -&gt; dict[str, str]:\n\t\"\"\"\n\tGenerate PR content for a release.\n\n\tThis is a placeholder and should be properly imported from the appropriate module.\n\n\tArgs:\n\t        base_branch: The branch to merge into (e.g. main)\n\t        branch_name: The release branch name (e.g. release/1.0.0)\n\n\tReturns:\n\t        Dictionary with title and description\n\n\t\"\"\"\n\t# Extract version from branch name\n\tversion = branch_name.replace(\"release/\", \"\")\n\ttitle = f\"Release {version}\"\n\t# Include base branch information in the description\n\tdescription = f\"# Release {version}\\n\\nThis pull request merges release {version} into {base_branch}.\"\n\treturn {\"title\": title, \"description\": description}\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.console","title":"console  <code>module-attribute</code>","text":"<pre><code>console = Console()\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PRAction","title":"PRAction","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Actions for PR command.</p> Source code in <code>src/codemap/cli/pr_cmd.py</code> <pre><code>class PRAction(str, Enum):\n\t\"\"\"Actions for PR command.\"\"\"\n\n\tCREATE = \"create\"\n\tUPDATE = \"update\"\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PRAction.CREATE","title":"CREATE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CREATE = 'create'\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PRAction.UPDATE","title":"UPDATE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UPDATE = 'update'\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions","title":"PROptions  <code>dataclass</code>","text":"<p>Options for the PR command.</p> Source code in <code>src/codemap/cli/pr_cmd.py</code> <pre><code>@dataclass\nclass PROptions:\n\t\"\"\"Options for the PR command.\"\"\"\n\n\trepo_path: Path | None\n\tbranch_name: str | None = field(default=None)\n\tbase_branch: str | None = field(default=None)\n\ttitle: str | None = field(default=None)\n\tdescription: str | None = field(default=None)\n\tcommit_first: bool = field(default=True)\n\tforce_push: bool = field(default=False)\n\tpr_number: int | None = field(default=None)\n\tinteractive: bool = field(default=True)\n\tmodel: str | None = field(default=None)\n\tapi_base: str | None = field(default=None)\n\tapi_key: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.__init__","title":"__init__","text":"<pre><code>__init__(\n\trepo_path: Path | None,\n\tbranch_name: str | None = None,\n\tbase_branch: str | None = None,\n\ttitle: str | None = None,\n\tdescription: str | None = None,\n\tcommit_first: bool = True,\n\tforce_push: bool = False,\n\tpr_number: int | None = None,\n\tinteractive: bool = True,\n\tmodel: str | None = None,\n\tapi_base: str | None = None,\n\tapi_key: str | None = None,\n) -&gt; None\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.repo_path","title":"repo_path  <code>instance-attribute</code>","text":"<pre><code>repo_path: Path | None\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.branch_name","title":"branch_name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>branch_name: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.base_branch","title":"base_branch  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>base_branch: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.title","title":"title  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>title: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.commit_first","title":"commit_first  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>commit_first: bool = field(default=True)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.force_push","title":"force_push  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>force_push: bool = field(default=False)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.pr_number","title":"pr_number  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pr_number: int | None = field(default=None)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.interactive","title":"interactive  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>interactive: bool = field(default=True)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.api_base","title":"api_base  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_base: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.PROptions.api_key","title":"api_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_key: str | None = field(default=None)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.validate_workflow_strategy","title":"validate_workflow_strategy","text":"<pre><code>validate_workflow_strategy(value: str | None) -&gt; str | None\n</code></pre> <p>Validate workflow strategy.</p> Source code in <code>src/codemap/cli/pr_cmd.py</code> <pre><code>def validate_workflow_strategy(value: str | None) -&gt; str | None:\n\t\"\"\"Validate workflow strategy.\"\"\"\n\tvalid_strategies = [\"github-flow\", \"gitflow\", \"trunk-based\"]\n\tif value is None or value in valid_strategies:\n\t\treturn value\n\tconsole.print(f\"[red]Invalid workflow strategy: {value}. Must be one of: {', '.join(valid_strategies)}[/red]\")\n\tmsg = f\"Must be one of: {', '.join(valid_strategies)}\"\n\traise typer.BadParameter(msg)\n</code></pre>"},{"location":"api/cli/pr_cmd/#codemap.cli.pr_cmd.pr_command","title":"pr_command","text":"<pre><code>pr_command(\n\tpath: Annotated[\n\t\tPath,\n\t\tArgument(\n\t\t\texists=True,\n\t\t\thelp=\"Path to the codebase to analyze\",\n\t\t\tshow_default=True,\n\t\t),\n\t] = Path(),\n\taction: Annotated[\n\t\tPRAction,\n\t\tArgument(\n\t\t\thelp=\"Action to perform: create or update\"\n\t\t),\n\t] = CREATE,\n\tbranch_name: Annotated[\n\t\tstr | None,\n\t\tOption(\"--branch\", \"-b\", help=\"Target branch name\"),\n\t] = None,\n\tbranch_type: Annotated[\n\t\tstr | None,\n\t\tOption(\n\t\t\t\"--type\",\n\t\t\t\"-t\",\n\t\t\thelp=\"Branch type (feature, release, hotfix, bugfix)\",\n\t\t),\n\t] = None,\n\tbase_branch: Annotated[\n\t\tstr | None,\n\t\tOption(\n\t\t\t\"--base\",\n\t\t\thelp=\"Base branch for the PR (defaults to repo default)\",\n\t\t),\n\t] = None,\n\ttitle: Annotated[\n\t\tstr | None,\n\t\tOption(\"--title\", help=\"Pull request title\"),\n\t] = None,\n\tdescription: Annotated[\n\t\tstr | None,\n\t\tOption(\n\t\t\t\"--desc\",\n\t\t\t\"-d\",\n\t\t\thelp=\"Pull request description (file path or text)\",\n\t\t),\n\t] = None,\n\tno_commit: Annotated[\n\t\tbool,\n\t\tOption(\n\t\t\t\"--no-commit\",\n\t\t\thelp=\"Skip the commit process before creating PR\",\n\t\t),\n\t] = False,\n\tforce_push: Annotated[\n\t\tbool,\n\t\tOption(\n\t\t\t\"--force-push\",\n\t\t\t\"-f\",\n\t\t\thelp=\"Force push the branch\",\n\t\t),\n\t] = False,\n\tpr_number: Annotated[\n\t\tint | None,\n\t\tOption(\n\t\t\t\"--pr\",\n\t\t\thelp=\"PR number to update (required for update action)\",\n\t\t),\n\t] = None,\n\tworkflow: Annotated[\n\t\tstr | None,\n\t\tOption(\n\t\t\t\"--workflow\",\n\t\t\t\"-w\",\n\t\t\thelp=\"Git workflow strategy (github-flow, gitflow, trunk-based)\",\n\t\t\tcallback=validate_workflow_strategy,\n\t\t),\n\t] = None,\n\tnon_interactive: Annotated[\n\t\tbool,\n\t\tOption(\n\t\t\t\"--non-interactive\",\n\t\t\thelp=\"Run in non-interactive mode\",\n\t\t),\n\t] = False,\n\tmodel: Annotated[\n\t\tstr | None,\n\t\tOption(\n\t\t\t\"--model\",\n\t\t\t\"-m\",\n\t\t\thelp=\"LLM model for content generation\",\n\t\t),\n\t] = None,\n\tapi_base: Annotated[\n\t\tstr | None,\n\t\tOption(\"--api-base\", help=\"API base URL for LLM\"),\n\t] = None,\n\tapi_key: Annotated[\n\t\tstr | None,\n\t\tOption(\"--api-key\", help=\"API key for LLM\"),\n\t] = None,\n\tis_verbose: Annotated[\n\t\tbool,\n\t\tOption(\n\t\t\t\"--verbose\", \"-v\", help=\"Enable verbose logging\"\n\t\t),\n\t] = False,\n) -&gt; None\n</code></pre> <p>Create or update a pull request.</p> Source code in <code>src/codemap/cli/pr_cmd.py</code> <pre><code>def pr_command(\n\tpath: Annotated[\n\t\tPath,\n\t\ttyper.Argument(\n\t\t\texists=True,\n\t\t\thelp=\"Path to the codebase to analyze\",\n\t\t\tshow_default=True,\n\t\t),\n\t] = Path(),\n\taction: Annotated[PRAction, typer.Argument(help=\"Action to perform: create or update\")] = PRAction.CREATE,\n\tbranch_name: Annotated[str | None, typer.Option(\"--branch\", \"-b\", help=\"Target branch name\")] = None,\n\tbranch_type: Annotated[\n\t\tstr | None, typer.Option(\"--type\", \"-t\", help=\"Branch type (feature, release, hotfix, bugfix)\")\n\t] = None,\n\tbase_branch: Annotated[\n\t\tstr | None,\n\t\ttyper.Option(\"--base\", help=\"Base branch for the PR (defaults to repo default)\"),\n\t] = None,\n\ttitle: Annotated[str | None, typer.Option(\"--title\", help=\"Pull request title\")] = None,\n\tdescription: Annotated[\n\t\tstr | None,\n\t\ttyper.Option(\"--desc\", \"-d\", help=\"Pull request description (file path or text)\"),\n\t] = None,\n\tno_commit: Annotated[\n\t\tbool,\n\t\ttyper.Option(\"--no-commit\", help=\"Skip the commit process before creating PR\"),\n\t] = False,\n\tforce_push: Annotated[bool, typer.Option(\"--force-push\", \"-f\", help=\"Force push the branch\")] = False,\n\tpr_number: Annotated[\n\t\tint | None,\n\t\ttyper.Option(\"--pr\", help=\"PR number to update (required for update action)\"),\n\t] = None,\n\tworkflow: Annotated[\n\t\tstr | None,\n\t\ttyper.Option(\n\t\t\t\"--workflow\",\n\t\t\t\"-w\",\n\t\t\thelp=\"Git workflow strategy (github-flow, gitflow, trunk-based)\",\n\t\t\tcallback=validate_workflow_strategy,\n\t\t),\n\t] = None,\n\tnon_interactive: Annotated[bool, typer.Option(\"--non-interactive\", help=\"Run in non-interactive mode\")] = False,\n\tmodel: Annotated[\n\t\tstr | None,\n\t\ttyper.Option(\"--model\", \"-m\", help=\"LLM model for content generation\"),\n\t] = None,\n\tapi_base: Annotated[str | None, typer.Option(\"--api-base\", help=\"API base URL for LLM\")] = None,\n\tapi_key: Annotated[str | None, typer.Option(\"--api-key\", help=\"API key for LLM\")] = None,\n\tis_verbose: Annotated[\n\t\tbool,\n\t\ttyper.Option(\n\t\t\t\"--verbose\",\n\t\t\t\"-v\",\n\t\t\thelp=\"Enable verbose logging\",\n\t\t),\n\t] = False,\n) -&gt; None:\n\t\"\"\"Create or update a pull request.\"\"\"\n\t# Configure logging\n\tsetup_logging(is_verbose=is_verbose)\n\n\t# Helper function to raise typer.Exit with proper context\n\tdef exit_command(code: int = 1) -&gt; None:\n\t\traise typer.Exit(code) from None\n\n\ttry:\n\t\t# Get absolute path to repo\n\t\trepo_path = validate_repo_path(path)\n\n\t\t# Get PR configuration from config loader\n\t\tconfig_loader = ConfigLoader(repo_root=repo_path)\n\t\tconfig_loader.get_pr_config()\n\n\t\t# Set workflow strategy from command line or config - use ternary operator\n\t\tworkflow_strategy = workflow if workflow else config_loader.get_workflow_strategy()\n\n\t\t# Create workflow strategy instance\n\t\tstrategy = create_strategy(workflow_strategy)\n\n\t\t# Set up PR options\n\t\toptions = PROptions(\n\t\t\trepo_path=repo_path,\n\t\t\tbranch_name=branch_name,\n\t\t\tbase_branch=base_branch,\n\t\t\ttitle=title,\n\t\t\tdescription=description,\n\t\t\tcommit_first=not no_commit,\n\t\t\tforce_push=force_push,\n\t\t\tpr_number=pr_number,\n\t\t\tinteractive=not non_interactive,\n\t\t\tmodel=model,\n\t\t\tapi_base=api_base,\n\t\t\tapi_key=api_key,\n\t\t)\n\n\t\t# Load LLM config from file if not provided via CLI\n\t\tif not options.model or not options.api_key or not options.api_base:\n\t\t\tllm_config = _load_llm_config(repo_path)\n\t\t\toptions.model = options.model or llm_config.get(\"model\")\n\t\t\toptions.api_key = options.api_key or llm_config.get(\"api_key\")\n\t\t\toptions.api_base = options.api_base or llm_config.get(\"api_base\")\n\n\t\t# Perform requested action\n\t\tif action == PRAction.CREATE:\n\t\t\t# Configure branch type if provided\n\t\t\tif branch_type:\n\t\t\t\t# Validate branch type against workflow strategy\n\t\t\t\tvalid_types = strategy.get_branch_types()\n\t\t\t\tif branch_type not in valid_types:\n\t\t\t\t\tconsole.print(f\"[red]Invalid branch type for {workflow_strategy}: {branch_type}[/red]\")\n\t\t\t\t\tconsole.print(f\"[red]Valid types: {', '.join(valid_types)}[/red]\")\n\t\t\t\t\texit_command(1)\n\n\t\t\t\t# If branch name is provided, ensure it has the right prefix\n\t\t\t\tif options.branch_name:\n\t\t\t\t\tprefix = strategy.get_branch_prefix(branch_type)\n\t\t\t\t\tif prefix and not options.branch_name.startswith(prefix):\n\t\t\t\t\t\toptions.branch_name = f\"{prefix}{options.branch_name}\"\n\n\t\t\t# Handle branch creation/selection first\n\t\t\tbranch_name = _handle_branch_creation(options)\n\t\t\tif not branch_name:\n\t\t\t\treturn\n\n\t\t\t# Handle commits if needed (after branch is created/selected)\n\t\t\tif options.commit_first:\n\t\t\t\tcommit_success = _handle_commits(options)\n\t\t\t\tif not commit_success:\n\t\t\t\t\treturn\n\n\t\t\t# Handle push\n\t\t\tpush_success = _handle_push(options, branch_name)\n\t\t\tif not push_success:\n\t\t\t\treturn\n\n\t\t\t# Handle PR creation\n\t\t\tpr = _handle_pr_creation(options, branch_name)\n\t\t\tif not pr:\n\t\t\t\treturn\n\t\telse:  # update\n\t\t\t# If PR number is not provided, get existing PR for current branch\n\t\t\tif not options.pr_number:\n\t\t\t\tcurrent_branch = get_current_branch()\n\t\t\t\texisting_pr = get_existing_pr(current_branch)\n\t\t\t\tif existing_pr:\n\t\t\t\t\toptions.pr_number = existing_pr.number\n\t\t\t\telse:\n\t\t\t\t\tconsole.print(\"[red]No PR found for current branch. Please specify a PR number.[/red]\")\n\t\t\t\t\texit_command(1)\n\n\t\t\t# Handle PR update\n\t\t\tpr = _handle_pr_update(options, None)\n\t\t\tif not pr:\n\t\t\t\treturn\n\texcept (GitError, ValueError) as e:\n\t\t_exit_with_error(f\"Error: {e}\", exception=e)\n\texcept typer.Exit:\n\t\traise\n\texcept KeyboardInterrupt:\n\t\tconsole.print(\"\\n[yellow]Operation cancelled by user.[/yellow]\")\n\t\texit_command(130)\n\texcept Exception as e:\n\t\tlogger.exception(\"Unexpected error in PR command\")\n\t\t_exit_with_error(f\"Unexpected error: {e}\", exception=e)\n</code></pre>"},{"location":"api/gen/","title":"Gen Overview","text":"<p>Code documentation generation package for CodeMap.</p> <ul> <li>Command - Command implementation for code documentation generation.</li> <li>Generator - Code documentation generator implementation.</li> <li>Models - Models for the code generation module.</li> <li>Utils - Utility functions for the gen command.</li> </ul>"},{"location":"api/gen/command/","title":"Command","text":"<p>Command implementation for code documentation generation.</p>"},{"location":"api/gen/command/#codemap.gen.command.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/gen/command/#codemap.gen.command.process_codebase","title":"process_codebase","text":"<pre><code>process_codebase(\n\ttarget_path: Path,\n\tconfig: GenConfig,\n\tprogress: Progress,\n\ttask_id: TaskID,\n) -&gt; tuple[list[LODEntity], dict]\n</code></pre> <p>Process a codebase using the LOD pipeline architecture.</p> <p>Parameters:</p> Name Type Description Default <code>target_path</code> <code>Path</code> <p>Path to the target codebase</p> required <code>config</code> <code>GenConfig</code> <p>Generation configuration</p> required <code>progress</code> <code>Progress</code> <p>Progress indicator</p> required <code>task_id</code> <code>TaskID</code> <p>Task ID for progress reporting</p> required <p>Returns:</p> Type Description <code>tuple[list[LODEntity], dict]</code> <p>Tuple of (list of LOD entities, metadata dict)</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If initialization fails</p> Source code in <code>src/codemap/gen/command.py</code> <pre><code>def process_codebase(\n\ttarget_path: Path,\n\tconfig: GenConfig,\n\tprogress: Progress,\n\ttask_id: TaskID,\n) -&gt; tuple[list[LODEntity], dict]:\n\t\"\"\"\n\tProcess a codebase using the LOD pipeline architecture.\n\n\tArgs:\n\t    target_path: Path to the target codebase\n\t    config: Generation configuration\n\t    progress: Progress indicator\n\t    task_id: Task ID for progress reporting\n\n\tReturns:\n\t    Tuple of (list of LOD entities, metadata dict)\n\n\tRaises:\n\t    RuntimeError: If initialization fails\n\n\t\"\"\"\n\tlogger.info(\"Starting codebase processing for: %s\", target_path)\n\tprogress.update(task_id, description=\"Initializing processor...\")\n\n\ttry:\n\t\t# Initialize processor pipeline with LOD support\n\t\tpipeline = create_processor(\n\t\t\trepo_path=target_path,\n\t\t\tdefault_lod_level=config.lod_level,\n\t\t)\n\texcept RuntimeError as e:\n\t\tlogger.exception(\"Error initializing processor\")\n\t\terror_msg = f\"Processor initialization failed: {e}\"\n\t\tshow_error(error_msg)\n\t\traise RuntimeError(error_msg) from e\n\n\t# Scan target path for files to process\n\tprogress.update(task_id, description=\"Scanning files...\")\n\t# Need project root to correctly locate .gitignore\n\tproject_root = Path.cwd()  # Assuming CWD is project root\n\tall_paths = list(target_path.rglob(\"*\"))\n\n\t# Filter paths based on .gitignore patterns found in project_root\n\tfiltered_paths = filter_paths_by_gitignore(all_paths, project_root)\n\t# Count only non-binary files that will actually be processed\n\ttotal_files = sum(1 for p in filtered_paths if p.is_file() and is_text_file(p))\n\n\t# Update progress information\n\tprogress.update(task_id, total=total_files)\n\tprogress.update(task_id, description=f\"Processing {total_files} files...\")\n\n\t# Process files asynchronously\n\tfor path in filtered_paths:\n\t\tif path.is_file():\n\t\t\t# Submit async processing task\n\t\t\tpipeline.process_file(path, config.lod_level)\n\n\t# Wait for all submitted tasks to complete\n\tprogress.update(task_id, description=\"Waiting for processing tasks to finish...\")\n\tif not pipeline.wait_for_completion():\n\t\tlogger.warning(\"Processing tasks did not complete within the expected time.\")\n\t\t# Decide if we should continue or raise an error\n\t\t# For now, let's continue with potentially partial results\n\n\t# Retrieve results directly from the pipeline's cache after waiting\n\t# The cache should be populated by the worker threads\n\tentities = [pipeline.processed_files[p] for p in filtered_paths if p.is_file() and p in pipeline.processed_files]\n\tprocessed_files = len(entities)\n\tlogger.info(f\"Retrieved {processed_files} processed entities from pipeline cache.\")\n\n\t# Update progress one last time after collecting all results\n\tprogress.update(task_id, completed=processed_files, description=f\"Collected {processed_files} results.\")\n\n\t# Clean up\n\tpipeline.stop()\n\n\t# Generate repository metadata\n\tlanguages = {entity.language for entity in entities if entity.language}\n\n\tmetadata: dict[str, Any] = {\n\t\t\"name\": target_path.name,\n\t\t\"stats\": {\n\t\t\t\"total_files\": total_files,\n\t\t\t\"total_lines\": sum(entity.end_line - entity.start_line + 1 for entity in entities),\n\t\t\t\"languages\": list(languages),\n\t\t},\n\t}\n\n\t# Generate directory tree if requested\n\tif config.include_tree:\n\t\tmetadata[\"tree\"] = generate_tree(target_path, filtered_paths)\n\n\treturn entities, metadata\n</code></pre>"},{"location":"api/gen/command/#codemap.gen.command.GenCommand","title":"GenCommand","text":"<p>Main implementation of the gen command.</p> Source code in <code>src/codemap/gen/command.py</code> <pre><code>class GenCommand:\n\t\"\"\"Main implementation of the gen command.\"\"\"\n\n\tdef __init__(self, config: GenConfig) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the gen command.\n\n\t\tArgs:\n\t\t    config: Generation configuration\n\n\t\t\"\"\"\n\t\tself.config = config\n\n\tdef execute(self, target_path: Path, output_path: Path) -&gt; bool:\n\t\t\"\"\"\n\t\tExecute the gen command.\n\n\t\tArgs:\n\t\t    target_path: Path to the target codebase\n\t\t    output_path: Path to write the output\n\n\t\tReturns:\n\t\t    True if successful, False otherwise\n\n\t\t\"\"\"\n\t\tfrom rich.progress import BarColumn, Progress, TextColumn, TimeElapsedColumn\n\n\t\tfrom .generator import CodeMapGenerator\n\t\tfrom .utils import write_documentation\n\n\t\tstart_time = time.time()\n\n\t\ttry:\n\t\t\t# Create generator\n\t\t\tgenerator = CodeMapGenerator(self.config, output_path)\n\n\t\t\t# Process codebase with progress tracking\n\t\t\twith Progress(\n\t\t\t\tTextColumn(\"[progress.description]{task.description}\"),\n\t\t\t\tBarColumn(),\n\t\t\t\tTextColumn(\"{task.completed}/{task.total}\"),\n\t\t\t\tTimeElapsedColumn(),\n\t\t\t) as progress:\n\t\t\t\ttask_id = progress.add_task(\"Processing codebase...\", total=None)\n\t\t\t\tentities, metadata = process_codebase(target_path, self.config, progress, task_id)\n\n\t\t\t# Generate documentation\n\t\t\tconsole.print(\"[green]Processing complete. Generating documentation...\")\n\t\t\tcontent = generator.generate_documentation(entities, metadata)\n\n\t\t\t# Write documentation to output file\n\t\t\twrite_documentation(output_path, content)\n\n\t\t\t# Show completion message with timing\n\t\t\telapsed = time.time() - start_time\n\t\t\tconsole.print(f\"[green]Generation completed in {elapsed:.2f} seconds.\")\n\n\t\t\treturn True\n\n\t\texcept Exception as e:\n\t\t\tlogger.exception(\"Error during gen command execution\")\n\t\t\t# Show a clean error message to the user\n\t\t\terror_msg = f\"Generation failed: {e!s}\"\n\t\t\tshow_error(error_msg)\n\t\t\treturn False\n</code></pre>"},{"location":"api/gen/command/#codemap.gen.command.GenCommand.__init__","title":"__init__","text":"<pre><code>__init__(config: GenConfig) -&gt; None\n</code></pre> <p>Initialize the gen command.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>GenConfig</code> <p>Generation configuration</p> required Source code in <code>src/codemap/gen/command.py</code> <pre><code>def __init__(self, config: GenConfig) -&gt; None:\n\t\"\"\"\n\tInitialize the gen command.\n\n\tArgs:\n\t    config: Generation configuration\n\n\t\"\"\"\n\tself.config = config\n</code></pre>"},{"location":"api/gen/command/#codemap.gen.command.GenCommand.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config\n</code></pre>"},{"location":"api/gen/command/#codemap.gen.command.GenCommand.execute","title":"execute","text":"<pre><code>execute(target_path: Path, output_path: Path) -&gt; bool\n</code></pre> <p>Execute the gen command.</p> <p>Parameters:</p> Name Type Description Default <code>target_path</code> <code>Path</code> <p>Path to the target codebase</p> required <code>output_path</code> <code>Path</code> <p>Path to write the output</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise</p> Source code in <code>src/codemap/gen/command.py</code> <pre><code>def execute(self, target_path: Path, output_path: Path) -&gt; bool:\n\t\"\"\"\n\tExecute the gen command.\n\n\tArgs:\n\t    target_path: Path to the target codebase\n\t    output_path: Path to write the output\n\n\tReturns:\n\t    True if successful, False otherwise\n\n\t\"\"\"\n\tfrom rich.progress import BarColumn, Progress, TextColumn, TimeElapsedColumn\n\n\tfrom .generator import CodeMapGenerator\n\tfrom .utils import write_documentation\n\n\tstart_time = time.time()\n\n\ttry:\n\t\t# Create generator\n\t\tgenerator = CodeMapGenerator(self.config, output_path)\n\n\t\t# Process codebase with progress tracking\n\t\twith Progress(\n\t\t\tTextColumn(\"[progress.description]{task.description}\"),\n\t\t\tBarColumn(),\n\t\t\tTextColumn(\"{task.completed}/{task.total}\"),\n\t\t\tTimeElapsedColumn(),\n\t\t) as progress:\n\t\t\ttask_id = progress.add_task(\"Processing codebase...\", total=None)\n\t\t\tentities, metadata = process_codebase(target_path, self.config, progress, task_id)\n\n\t\t# Generate documentation\n\t\tconsole.print(\"[green]Processing complete. Generating documentation...\")\n\t\tcontent = generator.generate_documentation(entities, metadata)\n\n\t\t# Write documentation to output file\n\t\twrite_documentation(output_path, content)\n\n\t\t# Show completion message with timing\n\t\telapsed = time.time() - start_time\n\t\tconsole.print(f\"[green]Generation completed in {elapsed:.2f} seconds.\")\n\n\t\treturn True\n\n\texcept Exception as e:\n\t\tlogger.exception(\"Error during gen command execution\")\n\t\t# Show a clean error message to the user\n\t\terror_msg = f\"Generation failed: {e!s}\"\n\t\tshow_error(error_msg)\n\t\treturn False\n</code></pre>"},{"location":"api/gen/generator/","title":"Generator","text":"<p>Code documentation generator implementation.</p>"},{"location":"api/gen/generator/#codemap.gen.generator.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/gen/generator/#codemap.gen.generator.CodeMapGenerator","title":"CodeMapGenerator","text":"<p>Generates code documentation based on LOD (Level of Detail).</p> Source code in <code>src/codemap/gen/generator.py</code> <pre><code>class CodeMapGenerator:\n\t\"\"\"Generates code documentation based on LOD (Level of Detail).\"\"\"\n\n\tdef __init__(self, config: GenConfig, output_path: Path) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the code map generator.\n\n\t\tArgs:\n\t\t    config: Generation configuration settings\n\t\t    output_path: Path to write the output\n\n\t\t\"\"\"\n\t\tself.config = config\n\t\tself.output_path = output_path\n\n\tdef _generate_mermaid_diagram(self, entities: list[LODEntity]) -&gt; str:\n\t\t\"\"\"Generate a Mermaid diagram string for entity relationships using subgraphs.\"\"\"\n\t\t# Convert config strings to lower case for case-insensitive comparison\n\t\tallowed_entities = {e.lower() for e in self.config.mermaid_entities} if self.config.mermaid_entities else None\n\t\tallowed_relationships = (\n\t\t\t{r.lower() for r in self.config.mermaid_relationships} if self.config.mermaid_relationships else None\n\t\t)\n\n\t\t# Helper to check if an entity type should be included\n\t\tdef should_include_entity(entity_type: EntityType) -&gt; bool:\n\t\t\tif not allowed_entities:\n\t\t\t\treturn True  # Include all if not specified\n\t\t\treturn entity_type.name.lower() in allowed_entities\n\n\t\t# Helper to check if a relationship type should be included\n\t\tdef should_include_relationship(relationship_type: str) -&gt; bool:\n\t\t\tif not allowed_relationships:\n\t\t\t\treturn True  # Include all if not specified\n\t\t\treturn relationship_type.lower() in allowed_relationships\n\n\t\t# --- Data Structures --- #\n\t\t# node_id -&gt; (definition_line, class_name) for regular nodes\n\t\tnode_definitions: dict[str, tuple[str, str]] = {}\n\t\t# subgraph_id -&gt; (label, type, list_of_contained_node_ids)\n\t\tsubgraph_definitions: dict[str, tuple[str, str, list[str]]] = {}\n\t\t# subgraph_id -&gt; parent_subgraph_id (for nesting)\n\t\tsubgraph_hierarchy: dict[str, str] = {}\n\t\t# Edges (parent_id, child_id, label, type)\n\t\tedges: list[tuple[str, str, str, str]] = []\n\t\t# Track processed entities/subgraphs to avoid duplicates\n\t\tprocessed_ids = set()\n\t\t# Map entity ID to entity object\n\t\tentity_map: dict[str, LODEntity] = {}\n\t\t# Track which nodes/subgraphs are connected by edges\n\t\tconnected_ids = set()\n\t\t# Map simple function/method names to their full node IDs\n\t\tname_to_node_ids: dict[str, list[str]] = {}\n\t\t# Keep track of nodes defined outside any subgraph (like external imports)\n\t\tglobal_nodes: set[str] = set()\n\n\t\tinternal_paths = {str(e.metadata.get(\"file_path\")) for e in entities if e.metadata.get(\"file_path\")}\n\n\t\tdef get_node_id(entity: LODEntity) -&gt; str:\n\t\t\tfile_path_str = entity.metadata.get(\"file_path\", \"unknown_file\")\n\t\t\tbase_id = f\"{file_path_str}_{entity.start_line}_{entity.name or entity.entity_type.name}\"\n\t\t\t# Ensure Mermaid compatibility (alphanumeric + underscore)\n\t\t\treturn \"\".join(c if c.isalnum() else \"_\" for c in base_id)\n\n\t\tdef process_entity_recursive(entity: LODEntity, current_subgraph_id: str | None = None) -&gt; None:\n\t\t\tnonlocal processed_ids, connected_ids, global_nodes\n\n\t\t\tentity_node_id = get_node_id(entity)\n\n\t\t\tif entity.entity_type == EntityType.UNKNOWN or entity_node_id in processed_ids:\n\t\t\t\treturn\n\n\t\t\tprocessed_ids.add(entity_node_id)\n\t\t\tentity_map[entity_node_id] = entity\n\t\t\tinclude_this_entity = should_include_entity(entity.entity_type)\n\n\t\t\tnext_subgraph_id = current_subgraph_id\n\n\t\t\t# --- Handle Subgraphs (Module, Class) --- #\n\t\t\tif entity.entity_type in (EntityType.MODULE, EntityType.CLASS) and include_this_entity:\n\t\t\t\tsubgraph_label = _escape_mermaid_label(\n\t\t\t\t\tentity.name or Path(entity.metadata.get(\"file_path\", \"unknown\")).name\n\t\t\t\t)\n\t\t\t\tsubgraph_type = \"moduleSubgraph\" if entity.entity_type == EntityType.MODULE else \"classSubgraph\"\n\t\t\t\tif entity.entity_type == EntityType.MODULE and current_subgraph_id:  # Nested module\n\t\t\t\t\tsubgraph_type = \"submoduleSubgraph\"\n\n\t\t\t\tsubgraph_definitions[entity_node_id] = (subgraph_label, subgraph_type, [])\n\t\t\t\tif current_subgraph_id:\n\t\t\t\t\tsubgraph_hierarchy[entity_node_id] = current_subgraph_id\n\t\t\t\t# Mark the container as potentially connected if it has children or dependencies\n\t\t\t\tconnected_ids.add(entity_node_id)\n\t\t\t\tnext_subgraph_id = entity_node_id  # Children belong to this new subgraph\n\n\t\t\t# --- Handle Nodes (Functions, Methods, Vars, Consts, Imports) --- #\n\t\t\telif include_this_entity and entity.entity_type != EntityType.IMPORT:  # Imports handled separately\n\t\t\t\tnode_definition = \"\"\n\t\t\t\tnode_class = \"\"\n\t\t\t\tlabel = _escape_mermaid_label(entity.name or f\"({entity.entity_type.name.lower()})\")\n\n\t\t\t\tif entity.entity_type in (EntityType.FUNCTION, EntityType.METHOD):\n\t\t\t\t\tnode_definition = f'{entity_node_id}(\"{label}\")'\n\t\t\t\t\tnode_class = \"funcNode\"\n\t\t\t\telif entity.entity_type == EntityType.CONSTANT:\n\t\t\t\t\tnode_definition = f'{entity_node_id}[\"{label}\"]'\n\t\t\t\t\tnode_class = \"constNode\"\n\t\t\t\telif entity.entity_type == EntityType.VARIABLE:\n\t\t\t\t\tnode_definition = f'{entity_node_id}[\"{label}\"]'\n\t\t\t\t\tnode_class = \"varNode\"\n\t\t\t\t# Add other types if needed\n\n\t\t\t\tif node_definition and entity_node_id not in node_definitions:\n\t\t\t\t\tnode_definitions[entity_node_id] = (node_definition, node_class)\n\t\t\t\t\tif current_subgraph_id:\n\t\t\t\t\t\tsubgraph_definitions[current_subgraph_id][2].append(entity_node_id)\n\t\t\t\t\telse:\n\t\t\t\t\t\t# Should not happen often if root is module, but handle just in case\n\t\t\t\t\t\tglobal_nodes.add(entity_node_id)\n\n\t\t\t# --- Add to Name Map (for call edges) --- #\n\t\t\tif entity.entity_type in (EntityType.FUNCTION, EntityType.METHOD):\n\t\t\t\tname = entity.name\n\t\t\t\tif name:\n\t\t\t\t\tif name not in name_to_node_ids:\n\t\t\t\t\t\tname_to_node_ids[name] = []\n\t\t\t\t\tname_to_node_ids[name].append(entity_node_id)\n\n\t\t\t# --- Process Dependencies (Imports) --- #\n\t\t\tdependencies = entity.metadata.get(\"dependencies\", [])\n\t\t\t# Imports are associated with the module/class they are in, or globally if nowhere else\n\n\t\t\tif dependencies and should_include_relationship(\"imports\"):\n\t\t\t\tfor dep in dependencies:\n\t\t\t\t\tis_external = not dep.startswith(\".\") and not any(\n\t\t\t\t\t\tdep.startswith(str(p).replace(\"\\\\\", \"/\"))\n\t\t\t\t\t\tfor p in internal_paths\n\t\t\t\t\t\tif p  # Handle path separators\n\t\t\t\t\t)\n\t\t\t\t\tdep_id = \"dep_\" + \"\".join(c if c.isalnum() else \"_\" for c in dep)\n\t\t\t\t\tdep_label = _escape_mermaid_label(dep)\n\n\t\t\t\t\tif dep_id not in node_definitions and dep_id not in processed_ids:\n\t\t\t\t\t\tprocessed_ids.add(dep_id)  # Mark as processed to avoid duplicate definitions\n\t\t\t\t\t\tdep_class = \"externalImportNode\" if is_external else \"internalImportNode\"\n\t\t\t\t\t\tnode_shape = f'((\"{dep_label}\"))' if is_external else f'[\"{dep_label}\"]'\n\t\t\t\t\t\tnode_definitions[dep_id] = (f\"{dep_id}{node_shape}\", dep_class)\n\t\t\t\t\t\tglobal_nodes.add(dep_id)  # Imports are defined globally\n\n\t\t\t\t\t# Add edge from the importing *container* (subgraph) to the dependency\n\t\t\t\t\t# Use the entity_node_id of the *module* or *class* for the source of the import edge\n\t\t\t\t\tsource_node_id = (\n\t\t\t\t\t\tentity_node_id\n\t\t\t\t\t\tif entity.entity_type in (EntityType.MODULE, EntityType.CLASS)\n\t\t\t\t\t\telse current_subgraph_id\n\t\t\t\t\t)\n\t\t\t\t\tif source_node_id and source_node_id != dep_id:  # Check source_node_id validity\n\t\t\t\t\t\tedge_tuple = (source_node_id, dep_id, \"imports\", \"import\")\n\t\t\t\t\t\tif edge_tuple not in edges:\n\t\t\t\t\t\t\tedges.append(edge_tuple)\n\t\t\t\t\t\t\tconnected_ids.add(source_node_id)\n\t\t\t\t\t\t\tconnected_ids.add(dep_id)\n\n\t\t\t# --- Process Children Recursively --- #\n\t\t\tfor child in sorted(entity.children, key=lambda e: e.start_line):\n\t\t\t\tprocess_entity_recursive(child, next_subgraph_id)\n\n\t\t\t\t# --- Define Parent Edge (Declares) --- #\n\t\t\t\t# Edge from container (subgraph) to child node/subgraph\n\t\t\t\tchild_node_id = get_node_id(child)\n\t\t\t\tif (\n\t\t\t\t\tnext_subgraph_id  # Ensure there is a parent subgraph\n\t\t\t\t\tand child.entity_type != EntityType.UNKNOWN\n\t\t\t\t\tand child_node_id in processed_ids  # Ensure child was processed (not filtered out)\n\t\t\t\t\tand should_include_relationship(\"declares\")\n\t\t\t\t):\n\t\t\t\t\t# Only add edge if child is *directly* contained (node or subgraph)\n\t\t\t\t\tis_child_node = child_node_id in node_definitions\n\t\t\t\t\tis_child_subgraph = child_node_id in subgraph_definitions\n\n\t\t\t\t\tif is_child_node or is_child_subgraph:\n\t\t\t\t\t\tedge_tuple = (next_subgraph_id, child_node_id, \"declares\", \"declare\")\n\t\t\t\t\t\tif edge_tuple not in edges:\n\t\t\t\t\t\t\tedges.append(edge_tuple)\n\t\t\t\t\t\t\tconnected_ids.add(next_subgraph_id)\n\t\t\t\t\t\t\tconnected_ids.add(child_node_id)\n\n\t\t# --- Main Processing Loop --- #\n\t\tfor entity in entities:\n\t\t\t# Start processing from top-level modules\n\t\t\tif entity.entity_type == EntityType.MODULE and entity.metadata.get(\"file_path\"):\n\t\t\t\tprocess_entity_recursive(entity, current_subgraph_id=None)\n\n\t\t# --- Define Call Edges --- #\n\t\tif should_include_relationship(\"calls\"):\n\t\t\tfor caller_node_id, caller_entity in entity_map.items():\n\t\t\t\t# Check if the caller is a function/method node that was actually defined\n\t\t\t\tif caller_node_id in node_definitions and caller_entity.entity_type in (\n\t\t\t\t\tEntityType.FUNCTION,\n\t\t\t\t\tEntityType.METHOD,\n\t\t\t\t):\n\t\t\t\t\tcalls = caller_entity.metadata.get(\"calls\", [])\n\t\t\t\t\tfor called_name in calls:\n\t\t\t\t\t\t# Try matching full name first, then simple name\n\t\t\t\t\t\tpossible_target_ids = []\n\t\t\t\t\t\tif (\n\t\t\t\t\t\t\tcalled_name in name_to_node_ids\n\t\t\t\t\t\t):  # Full name match? (e.g., class.method) - Less likely with simple parsing\n\t\t\t\t\t\t\tpossible_target_ids.extend(name_to_node_ids[called_name])\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tsimple_called_name = called_name.split(\".\")[-1]\n\t\t\t\t\t\t\tif simple_called_name in name_to_node_ids:\n\t\t\t\t\t\t\t\tpossible_target_ids.extend(name_to_node_ids[simple_called_name])\n\n\t\t\t\t\t\tfor target_node_id in possible_target_ids:\n\t\t\t\t\t\t\t# Ensure target is also a defined node and not the caller itself\n\t\t\t\t\t\t\tif target_node_id in node_definitions and caller_node_id != target_node_id:\n\t\t\t\t\t\t\t\tedge_tuple = (caller_node_id, target_node_id, \"calls\", \"call\")\n\t\t\t\t\t\t\t\tif edge_tuple not in edges:\n\t\t\t\t\t\t\t\t\tedges.append(edge_tuple)\n\t\t\t\t\t\t\t\t\tconnected_ids.add(caller_node_id)\n\t\t\t\t\t\t\t\t\tconnected_ids.add(target_node_id)\n\n\t\t# --- Assemble Final Mermaid String --- #\n\t\tmermaid_lines = [\"graph LR\"]  # Or TD for Top-Down if preferred\n\n\t\t# --- Define Style Strings (Instead of classDef) ---\n\t\tstyle_map = {\n\t\t\t# Node Styles\n\t\t\t\"funcNode\": \"fill:#007bff,stroke:#FFF,stroke-width:1px,color:white\",  # Blue\n\t\t\t\"constNode\": \"fill:#6f42c1,stroke:#FFF,stroke-width:1px,color:white\",  # Purple\n\t\t\t\"varNode\": \"fill:#fd7e14,stroke:#FFF,stroke-width:1px,color:white\",  # Orange\n\t\t\t\"internalImportNode\": \"fill:#20c997,stroke:#FFF,stroke-width:1px,color:white\",  # Teal\n\t\t\t\"externalImportNode\": \"fill:#ffc107,stroke:#333,stroke-width:1px,color:#333\",  # Yellow\n\t\t\t# Subgraph Styles\n\t\t\t\"moduleSubgraph\": \"fill:#121630,color:#FFF\",  # Dark Grey BG\n\t\t\t\"submoduleSubgraph\": \"fill:#2a122e,color:#FFF\",  # Lighter Grey BG\n\t\t\t\"classSubgraph\": \"fill:#100f5e,color:#FFF\",  # Light Green BG\n\t\t}\n\n\t\t# --- Render Logic --- #\n\t\trendered_elements = set()  # Track IDs of things actually rendered\n\t\toutput_lines = []\n\t\tstyle_lines = []  # Collect style commands separately\n\t\tused_style_keys = set()  # Track which styles (funcNode, classSubgraph etc.) are used\n\n\t\t# Function to recursively render subgraphs and their nodes\n\t\tdef render_subgraph(subgraph_id: str, indent: str = \"\") -&gt; None:\n\t\t\tif subgraph_id in rendered_elements:\n\t\t\t\treturn\n\t\t\trendered_elements.add(subgraph_id)\n\n\t\t\tlabel, sg_type, contained_node_ids = subgraph_definitions[subgraph_id]\n\t\t\toutput_lines.append(f'{indent}subgraph {subgraph_id}[\"{label}\"]')\n\t\t\toutput_lines.append(f\"{indent}  direction LR\")  # Or TD\n\n\t\t\t# Render nodes inside this subgraph\n\t\t\tfor node_id in contained_node_ids:\n\t\t\t\tif node_id in node_definitions:\n\t\t\t\t\t# Apply filtering if enabled\n\t\t\t\t\tif self.config.mermaid_remove_unconnected and node_id not in connected_ids:\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tif node_id in rendered_elements:\n\t\t\t\t\t\tcontinue  # Should not happen, but safeguard\n\t\t\t\t\trendered_elements.add(node_id)\n\n\t\t\t\t\tdefinition, node_class = node_definitions[node_id]\n\t\t\t\t\toutput_lines.append(f\"{indent}  {definition}\")\n\t\t\t\t\tif node_class in style_map:\n\t\t\t\t\t\tstyle_lines.append(f\"{indent}  style {node_id} {style_map[node_class]}\")\n\t\t\t\t\t\tused_style_keys.add(node_class)  # Track used style\n\n\t\t\t# Render nested subgraphs\n\t\t\tnested_subgraphs = [sid for sid, parent_id in subgraph_hierarchy.items() if parent_id == subgraph_id]\n\t\t\tfor nested_id in sorted(nested_subgraphs):  # Sort for consistent output\n\t\t\t\t# Apply filtering if enabled - check if the subgraph itself or any node inside it is connected\n\t\t\t\tis_nested_connected = subgraph_id in connected_ids or any(\n\t\t\t\t\tnid in connected_ids for nid in subgraph_definitions[nested_id][2]\n\t\t\t\t)\n\t\t\t\tif self.config.mermaid_remove_unconnected and not is_nested_connected:\n\t\t\t\t\tcontinue\n\t\t\t\trender_subgraph(nested_id, indent + \"  \")\n\n\t\t\toutput_lines.append(f\"{indent}end\")\n\t\t\t# Apply style definition to subgraph *after* end\n\t\t\tif sg_type in style_map:\n\t\t\t\tstyle_lines.append(f\"{indent}style {subgraph_id} {style_map[sg_type]}\")\n\t\t\t\tused_style_keys.add(sg_type)  # Track used style\n\n\t\t# --- Define Global Nodes (Imports primarily) ---\n\t\toutput_lines.append(\"\\n  %% Global Nodes\")\n\t\tfor node_id in sorted(global_nodes):\n\t\t\tif node_id in node_definitions:\n\t\t\t\t# Apply filtering if enabled\n\t\t\t\tif self.config.mermaid_remove_unconnected and node_id not in connected_ids:\n\t\t\t\t\tcontinue\n\t\t\t\tif node_id in rendered_elements:\n\t\t\t\t\tcontinue\n\t\t\t\trendered_elements.add(node_id)\n\n\t\t\t\tdefinition, node_class = node_definitions[node_id]\n\t\t\t\toutput_lines.append(f\"  {definition}\")\n\t\t\t\tif node_class in style_map:\n\t\t\t\t\tstyle_lines.append(f\"  style {node_id} {style_map[node_class]}\")\n\t\t\t\t\tused_style_keys.add(node_class)  # Track used style\n\n\t\t# --- Render Top-Level Subgraphs ---\n\t\toutput_lines.append(\"\\n  %% Subgraphs\")\n\t\ttop_level_subgraphs = [sg_id for sg_id in subgraph_definitions if sg_id not in subgraph_hierarchy]\n\t\tfor sg_id in sorted(top_level_subgraphs):\n\t\t\t# Apply filtering if enabled - check if the subgraph itself or any node inside it is connected\n\t\t\tis_sg_connected = sg_id in connected_ids or any(\n\t\t\t\tnid in connected_ids for nid in subgraph_definitions[sg_id][2]\n\t\t\t)\n\t\t\tif self.config.mermaid_remove_unconnected and not is_sg_connected:\n\t\t\t\tcontinue\n\t\t\trender_subgraph(sg_id)\n\n\t\t# --- Render Edges --- #\n\t\toutput_lines.append(\"\\n  %% Edges\")\n\t\tlink_styles = []\n\t\tcall_edge_indices = []\n\t\timport_edge_indices = []\n\t\tdeclare_edge_indices = []\n\n\t\tfiltered_edges = []\n\t\tfor _i, (source_id, target_id, label, edge_type) in enumerate(edges):\n\t\t\t# Ensure both source and target were actually rendered (or are subgraphs that contain rendered nodes)\n\t\t\tsource_exists = source_id in rendered_elements or source_id in subgraph_definitions\n\t\t\ttarget_exists = target_id in rendered_elements or target_id in subgraph_definitions\n\n\t\t\tif source_exists and target_exists:\n\t\t\t\tedge_str = \"\"\n\t\t\t\tif edge_type == \"import\":\n\t\t\t\t\tedge_str = f\"  {source_id} -.-&gt;|{label}| {target_id}\"\n\t\t\t\t\timport_edge_indices.append(len(filtered_edges))  # Index in the filtered list\n\t\t\t\telif edge_type == \"call\":\n\t\t\t\t\tedge_str = f\"  {source_id} --&gt;|{label}| {target_id}\"\n\t\t\t\t\tcall_edge_indices.append(len(filtered_edges))\n\t\t\t\telif edge_type == \"declare\":\n\t\t\t\t\t# Make declare edges less prominent\n\t\t\t\t\tedge_str = f\"  {source_id} --- {target_id}\"  # Simple line, no label needed visually\n\t\t\t\t\tdeclare_edge_indices.append(len(filtered_edges))\n\t\t\t\telse:  # Default or unknown edge type\n\t\t\t\t\tedge_str = f\"  {source_id} --&gt; {target_id}\"\n\n\t\t\t\tif edge_str:\n\t\t\t\t\tfiltered_edges.append(edge_str)\n\n\t\toutput_lines.extend(sorted(filtered_edges))  # Sort for consistency\n\n\t\t# --- Apply Link Styles --- #\n\t\tif call_edge_indices or import_edge_indices or declare_edge_indices:\n\t\t\toutput_lines.append(\"\\n  %% Link Styles\")\n\t\t\tlink_styles.extend(\n\t\t\t\t[f\"  linkStyle {idx} stroke:#28a745,stroke-width:2px;\" for idx in call_edge_indices]\n\t\t\t)  # Green\n\t\t\tlink_styles.extend(\n\t\t\t\t[\n\t\t\t\t\tf\"  linkStyle {idx} stroke:#ffc107,stroke-width:1px,stroke-dasharray: 5 5;\"\n\t\t\t\t\tfor idx in import_edge_indices\n\t\t\t\t]\n\t\t\t)  # Yellow dashed\n\t\t\tlink_styles.extend(\n\t\t\t\t[f\"  linkStyle {idx} stroke:#adb5bd,stroke-width:1px;\" for idx in declare_edge_indices]\n\t\t\t)  # Gray thin\n\n\t\t\toutput_lines.extend(link_styles)\n\n\t\t# --- Generate Dynamic Legend (if enabled) ---\n\t\tlegend_lines = []\n\t\tlegend_style_lines = []\n\t\tif self.config.mermaid_show_legend and used_style_keys:\n\t\t\tlegend_lines.append(\"\\n  %% Legend\")\n\t\t\tlegend_lines.append(\"  subgraph Legend\")\n\t\t\tlegend_lines.append(\"    direction LR\")\n\n\t\t\t# Define all possible legend items and their corresponding style keys\n\t\t\tlegend_item_definitions = {\n\t\t\t\t\"legend_module\": (\"moduleSubgraph\", '[\"Module/File\"]'),\n\t\t\t\t\"legend_submodule\": (\"submoduleSubgraph\", '[\"Sub-Module\"]'),\n\t\t\t\t\"legend_class\": (\"classSubgraph\", '[\"Class\"]'),\n\t\t\t\t\"legend_func\": (\"funcNode\", '(\"Function/Method\")'),\n\t\t\t\t\"legend_const\": (\"constNode\", '[\"Constant\"]'),\n\t\t\t\t\"legend_var\": (\"varNode\", '[\"Variable\"]'),\n\t\t\t\t\"legend_import_int\": (\"internalImportNode\", '[\"Internal Import\"]'),\n\t\t\t\t\"legend_import_ext\": (\"externalImportNode\", '((\"External Import\"))'),\n\t\t\t}\n\n\t\t\tfor legend_id, (style_key, definition) in legend_item_definitions.items():\n\t\t\t\t# Only add legend item if its corresponding style was actually used in the graph\n\t\t\t\tif style_key in used_style_keys:\n\t\t\t\t\tlegend_lines.append(f\"    {legend_id}{definition}\")\n\t\t\t\t\t# Also add its style command to the list of styles\n\t\t\t\t\tif style_key in style_map:\n\t\t\t\t\t\tlegend_style_lines.append(f\"  style {legend_id} {style_map[style_key]}\")\n\n\t\t\tlegend_lines.append(\"  end\")\n\t\t\tlegend_lines.append(\"\")  # Add a blank line after legend\n\n\t\t# --- Assemble Final Output --- #\n\t\tmermaid_lines.extend(legend_lines)  # Add legend definitions (if any)\n\t\tmermaid_lines.extend(output_lines)  # Add main graph structure and edges\n\n\t\t# Append all collected style commands at the end\n\t\tall_style_lines = style_lines + legend_style_lines\n\t\tif all_style_lines:\n\t\t\tmermaid_lines.append(\"\\n  %% Styles\")\n\t\t\tmermaid_lines.extend(sorted(all_style_lines))\n\n\t\treturn \"\\n\".join(mermaid_lines)\n\n\tdef generate_documentation(self, entities: list[LODEntity], metadata: dict) -&gt; str:\n\t\t\"\"\"\n\t\tGenerate markdown documentation from the processed LOD entities.\n\n\t\tArgs:\n\t\t    entities: List of LOD entities\n\t\t    metadata: Repository metadata\n\n\t\tReturns:\n\t\t    Generated documentation as string\n\n\t\t\"\"\"\n\t\tcontent = []\n\n\t\t# Add header with repository information\n\t\trepo_name = metadata.get(\"name\", \"Repository\")\n\t\tcontent.append(f\"# {repo_name} Documentation\")\n\t\tcontent.append(f\"\\nGenerated on: {datetime.now(UTC).strftime('%Y-%m-%d %H:%M:%S')}\")\n\n\t\tif \"description\" in metadata:\n\t\t\tcontent.append(\"\\n\" + metadata.get(\"description\", \"\"))\n\n\t\t# Add repository statistics\n\t\tif \"stats\" in metadata:\n\t\t\tstats = metadata[\"stats\"]\n\t\t\tcontent.append(\"\\n## Repository Statistics\")\n\t\t\tcontent.append(f\"- Total files: {stats.get('total_files', 0)}\")\n\t\t\tcontent.append(f\"- Total lines of code: {stats.get('total_lines', 0)}\")\n\t\t\tcontent.append(f\"- Languages: {', '.join(stats.get('languages', []))}\")\n\n\t\t# Add directory structure if requested\n\t\tif self.config.include_tree and \"tree\" in metadata:\n\t\t\tcontent.append(\"\\n## Directory Structure\")\n\t\t\tcontent.append(\"```\")\n\t\t\tcontent.append(metadata[\"tree\"])\n\t\t\tcontent.append(\"```\")\n\n\t\t# Add Mermaid diagram if entities exist and config enables it\n\t\tif entities and self.config.include_entity_graph:\n\t\t\tcontent.append(\"\\n## Entity Relationships\")\n\t\t\tcontent.append(\"```mermaid\")\n\t\t\tmermaid_diagram = self._generate_mermaid_diagram(entities)\n\t\t\tcontent.append(mermaid_diagram)\n\t\t\tcontent.append(\"```\")\n\n\t\t# Add table of contents\n\t\tcontent.append(\"\\n## Table of Contents\")\n\n\t\t# Group entities by file\n\t\tfiles: dict[Path, list[LODEntity]] = {}\n\t\tfor entity in entities:\n\t\t\tfile_path = Path(entity.metadata.get(\"file_path\", \"\"))\n\t\t\tif not file_path.name:\n\t\t\t\tcontinue\n\n\t\t\tif file_path not in files:\n\t\t\t\tfiles[file_path] = []\n\t\t\tfiles[file_path].append(entity)\n\n\t\t# Create TOC entries\n\t\tfor file_path in sorted(files.keys()):\n\t\t\trel_path = file_path.name\n\t\t\tcontent.append(f\"- [{rel_path}](#{rel_path.replace('.', '-')})\")\n\n\t\t# Add code documentation grouped by file\n\t\tcontent.append(\"\\n## Code Documentation\")\n\n\t\t# Helper function to format a single entity recursively\n\t\tdef format_entity_recursive(entity: LODEntity, level: int) -&gt; list[str]:\n\t\t\tentity_content = []\n\t\t\tindent = \"  \" * level\n\t\t\tlist_prefix = f\"{indent}- \"\n\n\t\t\t# Basic entry: Type and Name/Signature\n\t\t\tentry_line = f\"{list_prefix}**{entity.entity_type.name.capitalize()}**: `{entity.name}`\"\n\t\t\tif self.config.lod_level.value &gt;= LODLevel.STRUCTURE.value and entity.signature:\n\t\t\t\tentry_line = f\"{list_prefix}**{entity.entity_type.name.capitalize()}**: `{entity.signature}`\"\n\t\t\t# Special handling for comments\n\t\t\telif entity.entity_type == EntityType.COMMENT and entity.content:\n\t\t\t\tcomment_lines = entity.content.strip().split(\"\\n\")\n\t\t\t\t# Format as italicized blockquote\n\t\t\t\tentity_content.extend([f\"{indent}&gt; *{line.strip()}*\" for line in comment_lines])\n\t\t\t\tentry_line = None  # Don't print the default entry line\n\t\t\telif not entity.name and entity.entity_type == EntityType.MODULE:\n\t\t\t\t# Skip module node if it has no name (handled by file heading)\n\t\t\t\t# Don't add the list item itself\n\t\t\t\tentry_line = None  # Don't print the default entry line\n\n\t\t\t# Add the generated entry line if it wasn't skipped\n\t\t\tif entry_line:\n\t\t\t\tentity_content.append(entry_line)\n\n\t\t\t# Add Docstring if level is DOCS or FULL (and not a comment)\n\t\t\tif (\n\t\t\t\tentity.entity_type != EntityType.COMMENT\n\t\t\t\tand self.config.lod_level.value &gt;= LODLevel.DOCS.value\n\t\t\t\tand entity.docstring\n\t\t\t):\n\t\t\t\tdocstring_lines = entity.docstring.strip().split(\"\\n\")\n\t\t\t\t# Indent docstring relative to the list item\n\t\t\t\tentity_content.extend([f\"{indent}  &gt; {line}\" for line in docstring_lines])\n\n\t\t\t# Add Content if level is FULL\n\t\t\tif self.config.lod_level.value &gt;= LODLevel.FULL.value and entity.content:\n\t\t\t\tcontent_lang = entity.language or \"\"\n\t\t\t\tentity_content.append(f\"{indent}  ```{content_lang}\")\n\t\t\t\t# Indent content lines as well\n\t\t\t\tcontent_lines = entity.content.strip().split(\"\\n\")\n\t\t\t\tentity_content.extend([f\"{indent}  {line}\" for line in content_lines])\n\t\t\t\tentity_content.append(f\"{indent}  ```\")\n\n\t\t\t# Recursively format children\n\t\t\tfor child in sorted(entity.children, key=lambda e: e.start_line):\n\t\t\t\t# Skip unknown children\n\t\t\t\tif child.entity_type != EntityType.UNKNOWN:\n\t\t\t\t\tentity_content.extend(format_entity_recursive(child, level + 1))\n\n\t\t\treturn entity_content\n\n\t\tfirst_file = True\n\t\tfor file_path, file_entities in sorted(files.items()):\n\t\t\t# Add a divider before each file section except the first one\n\t\t\tif not first_file:\n\t\t\t\tcontent.append(\"\\n---\")  # Horizontal rule\n\t\t\tfirst_file = False\n\n\t\t\trel_path = file_path.name\n\t\t\tcontent.append(f\"\\n### {rel_path}\")\n\n\t\t\t# Sort top-level entities by line number\n\t\t\tsorted_entities = sorted(file_entities, key=lambda e: e.start_line)\n\n\t\t\tif self.config.lod_level == LODLevel.SIGNATURES:\n\t\t\t\t# Level 1: Only top-level signatures\n\t\t\t\tfor entity in sorted_entities:\n\t\t\t\t\tif entity.entity_type in (\n\t\t\t\t\t\tEntityType.CLASS,\n\t\t\t\t\t\tEntityType.FUNCTION,\n\t\t\t\t\t\tEntityType.METHOD,\n\t\t\t\t\t\tEntityType.INTERFACE,\n\t\t\t\t\t\tEntityType.MODULE,\n\t\t\t\t\t):\n\t\t\t\t\t\tcontent.append(f\"\\n#### {entity.name or '(Module Level)'}\")\n\t\t\t\t\t\tif entity.signature:\n\t\t\t\t\t\t\tsig_lang = entity.language or \"\"\n\t\t\t\t\t\t\tcontent.append(f\"\\n```{sig_lang}\")\n\t\t\t\t\t\t\tcontent.append(entity.signature)\n\t\t\t\t\t\t\tcontent.append(\"```\")\n\t\t\telse:\n\t\t\t\t# Levels 2, 3, 4: Use recursive formatting\n\t\t\t\tfor entity in sorted_entities:\n\t\t\t\t\t# Process top-level entities (usually MODULE, but could be others if file has only one class/func)\n\t\t\t\t\tif entity.entity_type == EntityType.MODULE:\n\t\t\t\t\t\t# If it's the module, start recursion from its children\n\t\t\t\t\t\tfor child in sorted(entity.children, key=lambda e: e.start_line):\n\t\t\t\t\t\t\t# Skip unknown children\n\t\t\t\t\t\t\tif child.entity_type != EntityType.UNKNOWN:\n\t\t\t\t\t\t\t\tcontent.extend(format_entity_recursive(child, level=0))\n\t\t\t\t\t# Handle cases where the top-level entity isn't MODULE (e.g., a file with just one class)\n\t\t\t\t\t# Skip if unknown\n\t\t\t\t\telif entity.entity_type != EntityType.UNKNOWN:\n\t\t\t\t\t\tcontent.extend(format_entity_recursive(entity, level=0))\n\n\t\treturn \"\\n\".join(content)\n</code></pre>"},{"location":"api/gen/generator/#codemap.gen.generator.CodeMapGenerator.__init__","title":"__init__","text":"<pre><code>__init__(config: GenConfig, output_path: Path) -&gt; None\n</code></pre> <p>Initialize the code map generator.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>GenConfig</code> <p>Generation configuration settings</p> required <code>output_path</code> <code>Path</code> <p>Path to write the output</p> required Source code in <code>src/codemap/gen/generator.py</code> <pre><code>def __init__(self, config: GenConfig, output_path: Path) -&gt; None:\n\t\"\"\"\n\tInitialize the code map generator.\n\n\tArgs:\n\t    config: Generation configuration settings\n\t    output_path: Path to write the output\n\n\t\"\"\"\n\tself.config = config\n\tself.output_path = output_path\n</code></pre>"},{"location":"api/gen/generator/#codemap.gen.generator.CodeMapGenerator.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config\n</code></pre>"},{"location":"api/gen/generator/#codemap.gen.generator.CodeMapGenerator.output_path","title":"output_path  <code>instance-attribute</code>","text":"<pre><code>output_path = output_path\n</code></pre>"},{"location":"api/gen/generator/#codemap.gen.generator.CodeMapGenerator.generate_documentation","title":"generate_documentation","text":"<pre><code>generate_documentation(\n\tentities: list[LODEntity], metadata: dict\n) -&gt; str\n</code></pre> <p>Generate markdown documentation from the processed LOD entities.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>list[LODEntity]</code> <p>List of LOD entities</p> required <code>metadata</code> <code>dict</code> <p>Repository metadata</p> required <p>Returns:</p> Type Description <code>str</code> <p>Generated documentation as string</p> Source code in <code>src/codemap/gen/generator.py</code> <pre><code>def generate_documentation(self, entities: list[LODEntity], metadata: dict) -&gt; str:\n\t\"\"\"\n\tGenerate markdown documentation from the processed LOD entities.\n\n\tArgs:\n\t    entities: List of LOD entities\n\t    metadata: Repository metadata\n\n\tReturns:\n\t    Generated documentation as string\n\n\t\"\"\"\n\tcontent = []\n\n\t# Add header with repository information\n\trepo_name = metadata.get(\"name\", \"Repository\")\n\tcontent.append(f\"# {repo_name} Documentation\")\n\tcontent.append(f\"\\nGenerated on: {datetime.now(UTC).strftime('%Y-%m-%d %H:%M:%S')}\")\n\n\tif \"description\" in metadata:\n\t\tcontent.append(\"\\n\" + metadata.get(\"description\", \"\"))\n\n\t# Add repository statistics\n\tif \"stats\" in metadata:\n\t\tstats = metadata[\"stats\"]\n\t\tcontent.append(\"\\n## Repository Statistics\")\n\t\tcontent.append(f\"- Total files: {stats.get('total_files', 0)}\")\n\t\tcontent.append(f\"- Total lines of code: {stats.get('total_lines', 0)}\")\n\t\tcontent.append(f\"- Languages: {', '.join(stats.get('languages', []))}\")\n\n\t# Add directory structure if requested\n\tif self.config.include_tree and \"tree\" in metadata:\n\t\tcontent.append(\"\\n## Directory Structure\")\n\t\tcontent.append(\"```\")\n\t\tcontent.append(metadata[\"tree\"])\n\t\tcontent.append(\"```\")\n\n\t# Add Mermaid diagram if entities exist and config enables it\n\tif entities and self.config.include_entity_graph:\n\t\tcontent.append(\"\\n## Entity Relationships\")\n\t\tcontent.append(\"```mermaid\")\n\t\tmermaid_diagram = self._generate_mermaid_diagram(entities)\n\t\tcontent.append(mermaid_diagram)\n\t\tcontent.append(\"```\")\n\n\t# Add table of contents\n\tcontent.append(\"\\n## Table of Contents\")\n\n\t# Group entities by file\n\tfiles: dict[Path, list[LODEntity]] = {}\n\tfor entity in entities:\n\t\tfile_path = Path(entity.metadata.get(\"file_path\", \"\"))\n\t\tif not file_path.name:\n\t\t\tcontinue\n\n\t\tif file_path not in files:\n\t\t\tfiles[file_path] = []\n\t\tfiles[file_path].append(entity)\n\n\t# Create TOC entries\n\tfor file_path in sorted(files.keys()):\n\t\trel_path = file_path.name\n\t\tcontent.append(f\"- [{rel_path}](#{rel_path.replace('.', '-')})\")\n\n\t# Add code documentation grouped by file\n\tcontent.append(\"\\n## Code Documentation\")\n\n\t# Helper function to format a single entity recursively\n\tdef format_entity_recursive(entity: LODEntity, level: int) -&gt; list[str]:\n\t\tentity_content = []\n\t\tindent = \"  \" * level\n\t\tlist_prefix = f\"{indent}- \"\n\n\t\t# Basic entry: Type and Name/Signature\n\t\tentry_line = f\"{list_prefix}**{entity.entity_type.name.capitalize()}**: `{entity.name}`\"\n\t\tif self.config.lod_level.value &gt;= LODLevel.STRUCTURE.value and entity.signature:\n\t\t\tentry_line = f\"{list_prefix}**{entity.entity_type.name.capitalize()}**: `{entity.signature}`\"\n\t\t# Special handling for comments\n\t\telif entity.entity_type == EntityType.COMMENT and entity.content:\n\t\t\tcomment_lines = entity.content.strip().split(\"\\n\")\n\t\t\t# Format as italicized blockquote\n\t\t\tentity_content.extend([f\"{indent}&gt; *{line.strip()}*\" for line in comment_lines])\n\t\t\tentry_line = None  # Don't print the default entry line\n\t\telif not entity.name and entity.entity_type == EntityType.MODULE:\n\t\t\t# Skip module node if it has no name (handled by file heading)\n\t\t\t# Don't add the list item itself\n\t\t\tentry_line = None  # Don't print the default entry line\n\n\t\t# Add the generated entry line if it wasn't skipped\n\t\tif entry_line:\n\t\t\tentity_content.append(entry_line)\n\n\t\t# Add Docstring if level is DOCS or FULL (and not a comment)\n\t\tif (\n\t\t\tentity.entity_type != EntityType.COMMENT\n\t\t\tand self.config.lod_level.value &gt;= LODLevel.DOCS.value\n\t\t\tand entity.docstring\n\t\t):\n\t\t\tdocstring_lines = entity.docstring.strip().split(\"\\n\")\n\t\t\t# Indent docstring relative to the list item\n\t\t\tentity_content.extend([f\"{indent}  &gt; {line}\" for line in docstring_lines])\n\n\t\t# Add Content if level is FULL\n\t\tif self.config.lod_level.value &gt;= LODLevel.FULL.value and entity.content:\n\t\t\tcontent_lang = entity.language or \"\"\n\t\t\tentity_content.append(f\"{indent}  ```{content_lang}\")\n\t\t\t# Indent content lines as well\n\t\t\tcontent_lines = entity.content.strip().split(\"\\n\")\n\t\t\tentity_content.extend([f\"{indent}  {line}\" for line in content_lines])\n\t\t\tentity_content.append(f\"{indent}  ```\")\n\n\t\t# Recursively format children\n\t\tfor child in sorted(entity.children, key=lambda e: e.start_line):\n\t\t\t# Skip unknown children\n\t\t\tif child.entity_type != EntityType.UNKNOWN:\n\t\t\t\tentity_content.extend(format_entity_recursive(child, level + 1))\n\n\t\treturn entity_content\n\n\tfirst_file = True\n\tfor file_path, file_entities in sorted(files.items()):\n\t\t# Add a divider before each file section except the first one\n\t\tif not first_file:\n\t\t\tcontent.append(\"\\n---\")  # Horizontal rule\n\t\tfirst_file = False\n\n\t\trel_path = file_path.name\n\t\tcontent.append(f\"\\n### {rel_path}\")\n\n\t\t# Sort top-level entities by line number\n\t\tsorted_entities = sorted(file_entities, key=lambda e: e.start_line)\n\n\t\tif self.config.lod_level == LODLevel.SIGNATURES:\n\t\t\t# Level 1: Only top-level signatures\n\t\t\tfor entity in sorted_entities:\n\t\t\t\tif entity.entity_type in (\n\t\t\t\t\tEntityType.CLASS,\n\t\t\t\t\tEntityType.FUNCTION,\n\t\t\t\t\tEntityType.METHOD,\n\t\t\t\t\tEntityType.INTERFACE,\n\t\t\t\t\tEntityType.MODULE,\n\t\t\t\t):\n\t\t\t\t\tcontent.append(f\"\\n#### {entity.name or '(Module Level)'}\")\n\t\t\t\t\tif entity.signature:\n\t\t\t\t\t\tsig_lang = entity.language or \"\"\n\t\t\t\t\t\tcontent.append(f\"\\n```{sig_lang}\")\n\t\t\t\t\t\tcontent.append(entity.signature)\n\t\t\t\t\t\tcontent.append(\"```\")\n\t\telse:\n\t\t\t# Levels 2, 3, 4: Use recursive formatting\n\t\t\tfor entity in sorted_entities:\n\t\t\t\t# Process top-level entities (usually MODULE, but could be others if file has only one class/func)\n\t\t\t\tif entity.entity_type == EntityType.MODULE:\n\t\t\t\t\t# If it's the module, start recursion from its children\n\t\t\t\t\tfor child in sorted(entity.children, key=lambda e: e.start_line):\n\t\t\t\t\t\t# Skip unknown children\n\t\t\t\t\t\tif child.entity_type != EntityType.UNKNOWN:\n\t\t\t\t\t\t\tcontent.extend(format_entity_recursive(child, level=0))\n\t\t\t\t# Handle cases where the top-level entity isn't MODULE (e.g., a file with just one class)\n\t\t\t\t# Skip if unknown\n\t\t\t\telif entity.entity_type != EntityType.UNKNOWN:\n\t\t\t\t\tcontent.extend(format_entity_recursive(entity, level=0))\n\n\treturn \"\\n\".join(content)\n</code></pre>"},{"location":"api/gen/models/","title":"Models","text":"<p>Models for the code generation module.</p>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig","title":"GenConfig  <code>dataclass</code>","text":"<p>Configuration settings for the 'gen' command.</p> Source code in <code>src/codemap/gen/models.py</code> <pre><code>@dataclass\nclass GenConfig:\n\t\"\"\"Configuration settings for the 'gen' command.\"\"\"\n\n\t# Fields without default values\n\tmax_content_length: int\n\tuse_gitignore: bool\n\toutput_dir: Path\n\tsemantic_analysis: bool\n\tlod_level: LODLevel\n\n\t# Fields with default values\n\tinclude_tree: bool = True\n\tinclude_entity_graph: bool = True\n\tmermaid_entities: list[str] = field(default_factory=list)\n\tmermaid_relationships: list[str] = field(default_factory=list)\n\tmermaid_show_legend: bool = True\n\tmermaid_remove_unconnected: bool = False\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.__init__","title":"__init__","text":"<pre><code>__init__(\n\tmax_content_length: int,\n\tuse_gitignore: bool,\n\toutput_dir: Path,\n\tsemantic_analysis: bool,\n\tlod_level: LODLevel,\n\tinclude_tree: bool = True,\n\tinclude_entity_graph: bool = True,\n\tmermaid_entities: list[str] = list(),\n\tmermaid_relationships: list[str] = list(),\n\tmermaid_show_legend: bool = True,\n\tmermaid_remove_unconnected: bool = False,\n) -&gt; None\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.max_content_length","title":"max_content_length  <code>instance-attribute</code>","text":"<pre><code>max_content_length: int\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.use_gitignore","title":"use_gitignore  <code>instance-attribute</code>","text":"<pre><code>use_gitignore: bool\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.output_dir","title":"output_dir  <code>instance-attribute</code>","text":"<pre><code>output_dir: Path\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.semantic_analysis","title":"semantic_analysis  <code>instance-attribute</code>","text":"<pre><code>semantic_analysis: bool\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.lod_level","title":"lod_level  <code>instance-attribute</code>","text":"<pre><code>lod_level: LODLevel\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.include_tree","title":"include_tree  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>include_tree: bool = True\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.include_entity_graph","title":"include_entity_graph  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>include_entity_graph: bool = True\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.mermaid_entities","title":"mermaid_entities  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mermaid_entities: list[str] = field(default_factory=list)\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.mermaid_relationships","title":"mermaid_relationships  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mermaid_relationships: list[str] = field(\n\tdefault_factory=list\n)\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.mermaid_show_legend","title":"mermaid_show_legend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mermaid_show_legend: bool = True\n</code></pre>"},{"location":"api/gen/models/#codemap.gen.models.GenConfig.mermaid_remove_unconnected","title":"mermaid_remove_unconnected  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mermaid_remove_unconnected: bool = False\n</code></pre>"},{"location":"api/gen/utils/","title":"Utils","text":"<p>Utility functions for the gen command.</p>"},{"location":"api/gen/utils/#codemap.gen.utils.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/gen/utils/#codemap.gen.utils.generate_tree","title":"generate_tree","text":"<pre><code>generate_tree(\n\ttarget_path: Path, filtered_paths: Sequence[Path]\n) -&gt; str\n</code></pre> <p>Generate a directory tree representation.</p> <p>Parameters:</p> Name Type Description Default <code>target_path</code> <code>Path</code> <p>Root path</p> required <code>filtered_paths</code> <code>Sequence[Path]</code> <p>List of filtered absolute paths within target_path</p> required <p>Returns:</p> Type Description <code>str</code> <p>Tree representation as string</p> Source code in <code>src/codemap/gen/utils.py</code> <pre><code>def generate_tree(target_path: Path, filtered_paths: Sequence[Path]) -&gt; str:\n\t\"\"\"\n\tGenerate a directory tree representation.\n\n\tArgs:\n\t    target_path: Root path\n\t    filtered_paths: List of filtered **absolute** paths within target_path\n\n\tReturns:\n\t    Tree representation as string\n\n\t\"\"\"\n\t# Build a nested dictionary representing the file structure\n\ttree = {}\n\tfor abs_path in filtered_paths:\n\t\t# Ensure we only process paths within the target_path\n\t\ttry:\n\t\t\trel_path = abs_path.relative_to(target_path)\n\t\texcept ValueError:\n\t\t\tcontinue  # Skip paths not under target_path\n\n\t\tparts = rel_path.parts\n\t\tcurrent_level = tree\n\t\tfor i, part in enumerate(parts):\n\t\t\tif i == len(parts) - 1:  # Last part (file or final directory)\n\t\t\t\tcurrent_level[part] = \"file\" if abs_path.is_file() else \"dir\"\n\t\t\telse:\n\t\t\t\tif part not in current_level:\n\t\t\t\t\tcurrent_level[part] = {}\n\t\t\t\tcurrent_level = current_level[part]\n\t\t\t\t# Handle case where a file might exist with the same name as a directory part\n\t\t\t\tif not isinstance(current_level, dict):\n\t\t\t\t\tbreak  # Stop processing this path if structure is inconsistent\n\n\t# Recursive function to generate formatted tree lines\n\ttree_lines = []\n\n\tdef format_level(level: dict, prefix: str = \"\") -&gt; None:\n\t\titems = sorted(level.keys())\n\t\tfor i, name in enumerate(items):\n\t\t\tconnector = \"\u2514\u2500\u2500 \" if i == len(items) - 1 else \"\u251c\u2500\u2500 \"\n\t\t\titem_type = level[name]\n\n\t\t\tif isinstance(item_type, dict):  # It's a directory\n\t\t\t\ttree_lines.append(f\"{prefix}{connector}{name}/\")\n\t\t\t\tnew_prefix = prefix + (\"    \" if i == len(items) - 1 else \"\u2502   \")\n\t\t\t\tformat_level(item_type, new_prefix)\n\t\t\telse:  # It's a file\n\t\t\t\ttree_lines.append(f\"{prefix}{connector}{name}\")\n\n\t# Start formatting from the root\n\tformat_level(tree)\n\n\treturn \"\\n\".join(tree_lines)\n</code></pre>"},{"location":"api/gen/utils/#codemap.gen.utils.determine_output_path","title":"determine_output_path","text":"<pre><code>determine_output_path(\n\tproject_root: Path,\n\toutput: Path | None,\n\tconfig_data: dict,\n) -&gt; Path\n</code></pre> <p>Determine the output path for documentation.</p> <p>Parameters:</p> Name Type Description Default <code>project_root</code> <code>Path</code> <p>Root directory of the project</p> required <code>output</code> <code>Path | None</code> <p>Optional output path from command line</p> required <code>config_data</code> <code>dict</code> <p>Gen-specific configuration data</p> required <p>Returns:</p> Type Description <code>Path</code> <p>The determined output path</p> Source code in <code>src/codemap/gen/utils.py</code> <pre><code>def determine_output_path(project_root: Path, output: Path | None, config_data: dict) -&gt; Path:\n\t\"\"\"\n\tDetermine the output path for documentation.\n\n\tArgs:\n\t    project_root: Root directory of the project\n\t    output: Optional output path from command line\n\t    config_data: Gen-specific configuration data\n\n\tReturns:\n\t    The determined output path\n\n\t\"\"\"\n\tfrom datetime import UTC, datetime\n\n\t# If output is provided, use it directly\n\tif output:\n\t\treturn output.resolve()\n\n\t# Check for output file in config\n\tif \"output_file\" in config_data:\n\t\toutput_file = Path(config_data[\"output_file\"])\n\t\tif output_file.is_absolute():\n\t\t\treturn output_file\n\t\treturn project_root / output_file\n\n\t# Get output directory from config\n\toutput_dir = config_data.get(\"output_dir\", \"documentation\")\n\n\t# If output_dir is absolute, use it directly\n\toutput_dir_path = Path(output_dir)\n\tif not output_dir_path.is_absolute():\n\t\t# Otherwise, create the output directory in the project root\n\t\toutput_dir_path = project_root / output_dir\n\n\toutput_dir_path.mkdir(parents=True, exist_ok=True)\n\n\t# Generate a filename with timestamp\n\ttimestamp = datetime.now(UTC).strftime(\"%Y%m%d_%H%M%S\")\n\tfilename = f\"documentation_{timestamp}.md\"\n\n\treturn output_dir_path / filename\n</code></pre>"},{"location":"api/gen/utils/#codemap.gen.utils.write_documentation","title":"write_documentation","text":"<pre><code>write_documentation(\n\toutput_path: Path, documentation: str\n) -&gt; None\n</code></pre> <p>Write documentation to the specified output path.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>Path</code> <p>Path to write documentation to</p> required <code>documentation</code> <code>str</code> <p>Documentation content to write</p> required Source code in <code>src/codemap/gen/utils.py</code> <pre><code>def write_documentation(output_path: Path, documentation: str) -&gt; None:\n\t\"\"\"\n\tWrite documentation to the specified output path.\n\n\tArgs:\n\t    output_path: Path to write documentation to\n\t    documentation: Documentation content to write\n\n\t\"\"\"\n\tfrom codemap.utils.cli_utils import console, ensure_directory_exists, show_error\n\n\ttry:\n\t\t# Ensure parent directory exists\n\t\tensure_directory_exists(output_path.parent)\n\t\toutput_path.write_text(documentation)\n\t\tconsole.print(f\"[green]Documentation written to {output_path}\")\n\texcept (PermissionError, OSError) as e:\n\t\tshow_error(f\"Error writing documentation to {output_path}: {e!s}\")\n\t\traise\n</code></pre>"},{"location":"api/git/","title":"Git Overview","text":"<p>Git utilities for CodeMap.</p> <ul> <li>Commit Generator - Commit message generation package for CodeMap.</li> <li>Commit Linter - Commit linter package for validating git commit messages according to conventional commits.</li> <li>Diff Splitter - Diff splitting package for CodeMap.</li> <li>Interactive - Interactive commit interface for CodeMap.</li> <li>Pr Generator - PR generation package for CodeMap.</li> <li>Utils - Git utilities for CodeMap.</li> </ul>"},{"location":"api/git/interactive/","title":"Interactive","text":"<p>Interactive commit interface for CodeMap.</p>"},{"location":"api/git/interactive/#codemap.git.interactive.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.MAX_PREVIEW_LENGTH","title":"MAX_PREVIEW_LENGTH  <code>module-attribute</code>","text":"<pre><code>MAX_PREVIEW_LENGTH = 200\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.MAX_PREVIEW_LINES","title":"MAX_PREVIEW_LINES  <code>module-attribute</code>","text":"<pre><code>MAX_PREVIEW_LINES = 10\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.ChunkAction","title":"ChunkAction","text":"<p>               Bases: <code>Enum</code></p> <p>Possible actions for a diff chunk.</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>class ChunkAction(Enum):\n\t\"\"\"Possible actions for a diff chunk.\"\"\"\n\n\tACCEPT = auto()\n\tEDIT = auto()\n\tSKIP = auto()\n\tABORT = auto()\n\tREGENERATE = auto()\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.ChunkAction.ACCEPT","title":"ACCEPT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ACCEPT = auto()\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.ChunkAction.EDIT","title":"EDIT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>EDIT = auto()\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.ChunkAction.SKIP","title":"SKIP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SKIP = auto()\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.ChunkAction.ABORT","title":"ABORT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ABORT = auto()\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.ChunkAction.REGENERATE","title":"REGENERATE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>REGENERATE = auto()\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.ChunkResult","title":"ChunkResult  <code>dataclass</code>","text":"<p>Result of processing a diff chunk.</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>@dataclass\nclass ChunkResult:\n\t\"\"\"Result of processing a diff chunk.\"\"\"\n\n\taction: ChunkAction\n\tmessage: str | None = None\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.ChunkResult.__init__","title":"__init__","text":"<pre><code>__init__(\n\taction: ChunkAction, message: str | None = None\n) -&gt; None\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.ChunkResult.action","title":"action  <code>instance-attribute</code>","text":"<pre><code>action: ChunkAction\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.ChunkResult.message","title":"message  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>message: str | None = None\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI","title":"CommitUI","text":"<p>Interactive UI for the commit process.</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>class CommitUI:\n\t\"\"\"Interactive UI for the commit process.\"\"\"\n\n\tdef __init__(self) -&gt; None:\n\t\t\"\"\"Initialize the commit UI.\"\"\"\n\t\tself.console = Console()\n\n\tdef display_chunk(self, chunk: DiffChunk, index: int = 0, total: int = 1) -&gt; None:\n\t\t\"\"\"\n\t\tDisplay a diff chunk to the user.\n\n\t\tArgs:\n\t\t    chunk: DiffChunk to display\n\t\t    index: The 0-based index of the current chunk\n\t\t    total: The total number of chunks\n\n\t\t\"\"\"\n\t\t# Build file information\n\t\tfile_info = Text(\"Files: \", style=\"blue\")\n\t\tfile_info.append(\", \".join(chunk.files))\n\n\t\t# Calculate changes\n\t\tadded = len(\n\t\t\t[line for line in chunk.content.splitlines() if line.startswith(\"+\") and not line.startswith(\"+++\")]\n\t\t)\n\t\tremoved = len(\n\t\t\t[line for line in chunk.content.splitlines() if line.startswith(\"-\") and not line.startswith(\"---\")]\n\t\t)\n\t\tchanges_info = Text(\"\\nChanges: \", style=\"blue\")\n\t\tchanges_info.append(f\"{added} added, {removed} removed\")\n\n\t\t# Prepare diff content\n\t\tpanel_content = chunk.content\n\t\tif not panel_content.strip():\n\t\t\tpanel_content = \"No content diff available (e.g., new file or mode change)\"\n\n\t\t# Truncate to maximum of MAX_PREVIEW_LINES lines\n\t\tcontent_lines = panel_content.splitlines()\n\t\tif len(content_lines) &gt; MAX_PREVIEW_LINES:\n\t\t\tremaining_lines = len(content_lines) - MAX_PREVIEW_LINES\n\t\t\tpanel_content = \"\\n\".join(content_lines[:MAX_PREVIEW_LINES]) + f\"\\n... ({remaining_lines} more lines)\"\n\n\t\tdiff_content = Text(\"\\n\" + panel_content)\n\n\t\t# Determine title for the panel - use provided index and total\n\t\tpanel_title = f\"[bold]Commit {index + 1} of {total}[/bold]\"\n\n\t\t# Create content for the panel conditionally\n\t\tif getattr(chunk, \"description\", None):\n\t\t\t# If there's a description, create a combined panel\n\t\t\tif getattr(chunk, \"is_llm_generated\", False):\n\t\t\t\tmessage_title = \"[bold blue]Proposed message (AI)[/]\"\n\t\t\t\tmessage_style = \"blue\"\n\t\t\telse:\n\t\t\t\tmessage_title = \"[bold yellow]Proposed message (Simple)[/]\"\n\t\t\t\tmessage_style = \"yellow\"\n\n\t\t\t# Create separate panels and print them\n\t\t\t# First, print the diff panel\n\t\t\tdiff_panel = Panel(\n\t\t\t\tGroup(file_info, changes_info, diff_content),\n\t\t\t\ttitle=panel_title,\n\t\t\t\tborder_style=\"cyan\",\n\t\t\t\texpand=True,\n\t\t\t\twidth=self.console.width,\n\t\t\t\tpadding=(1, 2),\n\t\t\t)\n\t\t\tself.console.print(diff_panel)\n\n\t\t\t# Print divider\n\t\t\tself.console.print(Rule(style=\"dim\"))\n\n\t\t\t# Then print the message panel\n\t\t\tmessage_panel = Panel(\n\t\t\t\tText(str(chunk.description), style=\"green\"),\n\t\t\t\ttitle=message_title,\n\t\t\t\tborder_style=message_style,\n\t\t\t\texpand=True,\n\t\t\t\twidth=self.console.width,\n\t\t\t\tpadding=(1, 2),\n\t\t\t)\n\t\t\tself.console.print(message_panel)\n\t\telse:\n\t\t\t# If no description, just print the diff panel\n\t\t\tpanel = Panel(\n\t\t\t\tGroup(file_info, changes_info, diff_content),\n\t\t\t\ttitle=panel_title,\n\t\t\t\tborder_style=\"cyan\",\n\t\t\t\texpand=True,\n\t\t\t\twidth=self.console.width,\n\t\t\t\tpadding=(1, 2),\n\t\t\t)\n\t\t\tself.console.print()\n\t\t\tself.console.print(panel)\n\t\t\tself.console.print()\n\n\tdef display_message(self, message: str, is_llm_generated: bool = False) -&gt; None:\n\t\t\"\"\"\n\t\tDisplay a commit message to the user.\n\n\t\tArgs:\n\t\t    message: The commit message to display\n\t\t    is_llm_generated: Whether the message was generated by an LLM\n\n\t\t\"\"\"\n\t\ttag = \"AI\" if is_llm_generated else \"Simple\"\n\t\tmessage_panel = Panel(\n\t\t\tText(message, style=\"green\"),\n\t\t\ttitle=f\"[bold {'blue' if is_llm_generated else 'yellow'}]Proposed message ({tag})[/]\",\n\t\t\tborder_style=\"blue\" if is_llm_generated else \"yellow\",\n\t\t\texpand=False,\n\t\t\tpadding=(1, 2),\n\t\t)\n\t\tself.console.print(message_panel)\n\n\tdef get_user_action(self) -&gt; ChunkAction:\n\t\t\"\"\"\n\t\tGet the user's desired action for the current chunk.\n\n\t\tReturns:\n\t\t    ChunkAction indicating what to do with the chunk\n\n\t\t\"\"\"\n\t\t# Define options with their display text and corresponding action\n\t\toptions: list[tuple[str, ChunkAction]] = [\n\t\t\t(\"Commit with this message\", ChunkAction.ACCEPT),\n\t\t\t(\"Edit message and commit\", ChunkAction.EDIT),\n\t\t\t(\"Regenerate message\", ChunkAction.REGENERATE),\n\t\t\t(\"Skip this chunk\", ChunkAction.SKIP),\n\t\t\t(\"Exit without committing\", ChunkAction.ABORT),\n\t\t]\n\n\t\t# Use questionary to get the user's choice\n\t\tresult = questionary.select(\n\t\t\t\"What would you like to do?\",\n\t\t\tchoices=[option[0] for option in options],\n\t\t\tdefault=options[0][0],  # Set \"Commit with this message\" as default\n\t\t\tqmark=\"\u00bb\",\n\t\t\tuse_indicator=True,\n\t\t\tuse_arrow_keys=True,\n\t\t).ask()\n\n\t\t# Map the result back to the ChunkAction\n\t\tfor option, action in options:\n\t\t\tif option == result:\n\t\t\t\treturn action\n\n\t\t# Fallback (should never happen)\n\t\treturn ChunkAction.ABORT\n\n\tdef edit_message(self, current_message: str) -&gt; str:\n\t\t\"\"\"\n\t\tGet an edited commit message from the user.\n\n\t\tArgs:\n\t\t    current_message: Current commit message\n\n\t\tReturns:\n\t\t    Edited commit message\n\n\t\t\"\"\"\n\t\tself.console.print(\"\\n[bold blue]Edit commit message:[/]\")\n\t\tself.console.print(\"[dim]Press Enter to keep current message[/]\")\n\t\treturn Prompt.ask(\"Message\", default=current_message)\n\n\tdef process_chunk(self, chunk: DiffChunk, index: int = 0, total: int = 1) -&gt; ChunkResult:\n\t\t\"\"\"\n\t\tProcess a single diff chunk interactively.\n\n\t\tArgs:\n\t\t    chunk: DiffChunk to process\n\t\t    index: The 0-based index of the current chunk\n\t\t    total: The total number of chunks\n\n\t\tReturns:\n\t\t    ChunkResult with the user's action and any modified message\n\n\t\t\"\"\"\n\t\t# Display the combined diff and message panel\n\t\tself.display_chunk(chunk, index, total)\n\n\t\t# Now get the user's action through questionary (without displaying another message panel)\n\t\taction = self.get_user_action()\n\n\t\tif action == ChunkAction.EDIT:\n\t\t\tmessage = self.edit_message(chunk.description or \"\")\n\t\t\treturn ChunkResult(ChunkAction.ACCEPT, message)\n\n\t\tif action == ChunkAction.ACCEPT:\n\t\t\treturn ChunkResult(action, chunk.description)\n\n\t\treturn ChunkResult(action)\n\n\tdef confirm_abort(self) -&gt; bool:\n\t\t\"\"\"\n\t\tAsk the user to confirm aborting the commit process.\n\n\t\tReturns:\n\t\t    True if the user confirms, False otherwise\n\n\t\tRaises:\n\t\t    typer.Exit: When the user confirms exiting\n\n\t\t\"\"\"\n\t\tconfirmed = Confirm.ask(\n\t\t\t\"\\n[bold yellow]Are you sure you want to exit without committing?[/]\",\n\t\t\tdefault=False,\n\t\t)\n\n\t\tif confirmed:\n\t\t\tself.console.print(\"[yellow]Exiting commit process...[/yellow]\")\n\t\t\t# Use a zero exit code to indicate a successful (intended) exit\n\t\t\t# This prevents error messages from showing when exiting\n\t\t\traise typer.Exit(code=0)\n\n\t\treturn False\n\n\tdef confirm_bypass_hooks(self) -&gt; bool:\n\t\t\"\"\"\n\t\tAsk the user to confirm bypassing git hooks.\n\n\t\tReturns:\n\t\t    True if the user confirms, False otherwise\n\n\t\t\"\"\"\n\t\tself.console.print(\"\\n[bold yellow]Git hooks failed.[/]\")\n\t\tself.console.print(\"[yellow]This may be due to linting or other pre-commit checks.[/]\")\n\t\treturn Confirm.ask(\n\t\t\t\"\\n[bold yellow]Do you want to bypass git hooks and commit anyway?[/]\",\n\t\t\tdefault=False,\n\t\t)\n\n\tdef show_success(self, message: str) -&gt; None:\n\t\t\"\"\"\n\t\tShow a success message.\n\n\t\tArgs:\n\t\t    message: Message to display\n\n\t\t\"\"\"\n\t\tself.console.print(f\"\\n[bold green]\u2713[/] {message}\")\n\n\tdef show_error(self, message: str) -&gt; None:\n\t\t\"\"\"\n\t\tShow an error message to the user.\n\n\t\tArgs:\n\t\t    message: Error message to display\n\n\t\t\"\"\"\n\t\tif \"No changes to commit\" in message:\n\t\t\t# This is an informational message, not an error\n\t\t\tself.console.print(f\"[yellow]{message}[/yellow]\")\n\t\telse:\n\t\t\t# This is a real error\n\t\t\tself.console.print(f\"[red]Error:[/red] {message}\")\n\n\tdef show_skipped(self, files: list[str]) -&gt; None:\n\t\t\"\"\"\n\t\tShow which files were skipped.\n\n\t\tArgs:\n\t\t    files: List of skipped files\n\n\t\t\"\"\"\n\t\tif files:\n\t\t\tself.console.print(\"\\n[yellow]Skipped changes in:[/]\")\n\t\t\tfor file in files:\n\t\t\t\tself.console.print(f\"  \u2022 {file}\")\n\n\tdef show_regenerating(self) -&gt; None:\n\t\t\"\"\"Show message indicating message regeneration.\"\"\"\n\t\tself.console.print(\"\\n[yellow]Regenerating commit message...[/yellow]\")\n\n\tdef show_all_committed(self) -&gt; None:\n\t\t\"\"\"Show message indicating all changes are committed.\"\"\"\n\t\tself.console.print(\"[green]\u2713[/green] All changes committed!\")\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> <p>Initialize the commit UI.</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def __init__(self) -&gt; None:\n\t\"\"\"Initialize the commit UI.\"\"\"\n\tself.console = Console()\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.console","title":"console  <code>instance-attribute</code>","text":"<pre><code>console = Console()\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.display_chunk","title":"display_chunk","text":"<pre><code>display_chunk(\n\tchunk: DiffChunk, index: int = 0, total: int = 1\n) -&gt; None\n</code></pre> <p>Display a diff chunk to the user.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk</code> <p>DiffChunk to display</p> required <code>index</code> <code>int</code> <p>The 0-based index of the current chunk</p> <code>0</code> <code>total</code> <code>int</code> <p>The total number of chunks</p> <code>1</code> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def display_chunk(self, chunk: DiffChunk, index: int = 0, total: int = 1) -&gt; None:\n\t\"\"\"\n\tDisplay a diff chunk to the user.\n\n\tArgs:\n\t    chunk: DiffChunk to display\n\t    index: The 0-based index of the current chunk\n\t    total: The total number of chunks\n\n\t\"\"\"\n\t# Build file information\n\tfile_info = Text(\"Files: \", style=\"blue\")\n\tfile_info.append(\", \".join(chunk.files))\n\n\t# Calculate changes\n\tadded = len(\n\t\t[line for line in chunk.content.splitlines() if line.startswith(\"+\") and not line.startswith(\"+++\")]\n\t)\n\tremoved = len(\n\t\t[line for line in chunk.content.splitlines() if line.startswith(\"-\") and not line.startswith(\"---\")]\n\t)\n\tchanges_info = Text(\"\\nChanges: \", style=\"blue\")\n\tchanges_info.append(f\"{added} added, {removed} removed\")\n\n\t# Prepare diff content\n\tpanel_content = chunk.content\n\tif not panel_content.strip():\n\t\tpanel_content = \"No content diff available (e.g., new file or mode change)\"\n\n\t# Truncate to maximum of MAX_PREVIEW_LINES lines\n\tcontent_lines = panel_content.splitlines()\n\tif len(content_lines) &gt; MAX_PREVIEW_LINES:\n\t\tremaining_lines = len(content_lines) - MAX_PREVIEW_LINES\n\t\tpanel_content = \"\\n\".join(content_lines[:MAX_PREVIEW_LINES]) + f\"\\n... ({remaining_lines} more lines)\"\n\n\tdiff_content = Text(\"\\n\" + panel_content)\n\n\t# Determine title for the panel - use provided index and total\n\tpanel_title = f\"[bold]Commit {index + 1} of {total}[/bold]\"\n\n\t# Create content for the panel conditionally\n\tif getattr(chunk, \"description\", None):\n\t\t# If there's a description, create a combined panel\n\t\tif getattr(chunk, \"is_llm_generated\", False):\n\t\t\tmessage_title = \"[bold blue]Proposed message (AI)[/]\"\n\t\t\tmessage_style = \"blue\"\n\t\telse:\n\t\t\tmessage_title = \"[bold yellow]Proposed message (Simple)[/]\"\n\t\t\tmessage_style = \"yellow\"\n\n\t\t# Create separate panels and print them\n\t\t# First, print the diff panel\n\t\tdiff_panel = Panel(\n\t\t\tGroup(file_info, changes_info, diff_content),\n\t\t\ttitle=panel_title,\n\t\t\tborder_style=\"cyan\",\n\t\t\texpand=True,\n\t\t\twidth=self.console.width,\n\t\t\tpadding=(1, 2),\n\t\t)\n\t\tself.console.print(diff_panel)\n\n\t\t# Print divider\n\t\tself.console.print(Rule(style=\"dim\"))\n\n\t\t# Then print the message panel\n\t\tmessage_panel = Panel(\n\t\t\tText(str(chunk.description), style=\"green\"),\n\t\t\ttitle=message_title,\n\t\t\tborder_style=message_style,\n\t\t\texpand=True,\n\t\t\twidth=self.console.width,\n\t\t\tpadding=(1, 2),\n\t\t)\n\t\tself.console.print(message_panel)\n\telse:\n\t\t# If no description, just print the diff panel\n\t\tpanel = Panel(\n\t\t\tGroup(file_info, changes_info, diff_content),\n\t\t\ttitle=panel_title,\n\t\t\tborder_style=\"cyan\",\n\t\t\texpand=True,\n\t\t\twidth=self.console.width,\n\t\t\tpadding=(1, 2),\n\t\t)\n\t\tself.console.print()\n\t\tself.console.print(panel)\n\t\tself.console.print()\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.display_message","title":"display_message","text":"<pre><code>display_message(\n\tmessage: str, is_llm_generated: bool = False\n) -&gt; None\n</code></pre> <p>Display a commit message to the user.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The commit message to display</p> required <code>is_llm_generated</code> <code>bool</code> <p>Whether the message was generated by an LLM</p> <code>False</code> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def display_message(self, message: str, is_llm_generated: bool = False) -&gt; None:\n\t\"\"\"\n\tDisplay a commit message to the user.\n\n\tArgs:\n\t    message: The commit message to display\n\t    is_llm_generated: Whether the message was generated by an LLM\n\n\t\"\"\"\n\ttag = \"AI\" if is_llm_generated else \"Simple\"\n\tmessage_panel = Panel(\n\t\tText(message, style=\"green\"),\n\t\ttitle=f\"[bold {'blue' if is_llm_generated else 'yellow'}]Proposed message ({tag})[/]\",\n\t\tborder_style=\"blue\" if is_llm_generated else \"yellow\",\n\t\texpand=False,\n\t\tpadding=(1, 2),\n\t)\n\tself.console.print(message_panel)\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.get_user_action","title":"get_user_action","text":"<pre><code>get_user_action() -&gt; ChunkAction\n</code></pre> <p>Get the user's desired action for the current chunk.</p> <p>Returns:</p> Type Description <code>ChunkAction</code> <p>ChunkAction indicating what to do with the chunk</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def get_user_action(self) -&gt; ChunkAction:\n\t\"\"\"\n\tGet the user's desired action for the current chunk.\n\n\tReturns:\n\t    ChunkAction indicating what to do with the chunk\n\n\t\"\"\"\n\t# Define options with their display text and corresponding action\n\toptions: list[tuple[str, ChunkAction]] = [\n\t\t(\"Commit with this message\", ChunkAction.ACCEPT),\n\t\t(\"Edit message and commit\", ChunkAction.EDIT),\n\t\t(\"Regenerate message\", ChunkAction.REGENERATE),\n\t\t(\"Skip this chunk\", ChunkAction.SKIP),\n\t\t(\"Exit without committing\", ChunkAction.ABORT),\n\t]\n\n\t# Use questionary to get the user's choice\n\tresult = questionary.select(\n\t\t\"What would you like to do?\",\n\t\tchoices=[option[0] for option in options],\n\t\tdefault=options[0][0],  # Set \"Commit with this message\" as default\n\t\tqmark=\"\u00bb\",\n\t\tuse_indicator=True,\n\t\tuse_arrow_keys=True,\n\t).ask()\n\n\t# Map the result back to the ChunkAction\n\tfor option, action in options:\n\t\tif option == result:\n\t\t\treturn action\n\n\t# Fallback (should never happen)\n\treturn ChunkAction.ABORT\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.edit_message","title":"edit_message","text":"<pre><code>edit_message(current_message: str) -&gt; str\n</code></pre> <p>Get an edited commit message from the user.</p> <p>Parameters:</p> Name Type Description Default <code>current_message</code> <code>str</code> <p>Current commit message</p> required <p>Returns:</p> Type Description <code>str</code> <p>Edited commit message</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def edit_message(self, current_message: str) -&gt; str:\n\t\"\"\"\n\tGet an edited commit message from the user.\n\n\tArgs:\n\t    current_message: Current commit message\n\n\tReturns:\n\t    Edited commit message\n\n\t\"\"\"\n\tself.console.print(\"\\n[bold blue]Edit commit message:[/]\")\n\tself.console.print(\"[dim]Press Enter to keep current message[/]\")\n\treturn Prompt.ask(\"Message\", default=current_message)\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.process_chunk","title":"process_chunk","text":"<pre><code>process_chunk(\n\tchunk: DiffChunk, index: int = 0, total: int = 1\n) -&gt; ChunkResult\n</code></pre> <p>Process a single diff chunk interactively.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk</code> <p>DiffChunk to process</p> required <code>index</code> <code>int</code> <p>The 0-based index of the current chunk</p> <code>0</code> <code>total</code> <code>int</code> <p>The total number of chunks</p> <code>1</code> <p>Returns:</p> Type Description <code>ChunkResult</code> <p>ChunkResult with the user's action and any modified message</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def process_chunk(self, chunk: DiffChunk, index: int = 0, total: int = 1) -&gt; ChunkResult:\n\t\"\"\"\n\tProcess a single diff chunk interactively.\n\n\tArgs:\n\t    chunk: DiffChunk to process\n\t    index: The 0-based index of the current chunk\n\t    total: The total number of chunks\n\n\tReturns:\n\t    ChunkResult with the user's action and any modified message\n\n\t\"\"\"\n\t# Display the combined diff and message panel\n\tself.display_chunk(chunk, index, total)\n\n\t# Now get the user's action through questionary (without displaying another message panel)\n\taction = self.get_user_action()\n\n\tif action == ChunkAction.EDIT:\n\t\tmessage = self.edit_message(chunk.description or \"\")\n\t\treturn ChunkResult(ChunkAction.ACCEPT, message)\n\n\tif action == ChunkAction.ACCEPT:\n\t\treturn ChunkResult(action, chunk.description)\n\n\treturn ChunkResult(action)\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.confirm_abort","title":"confirm_abort","text":"<pre><code>confirm_abort() -&gt; bool\n</code></pre> <p>Ask the user to confirm aborting the commit process.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the user confirms, False otherwise</p> <p>Raises:</p> Type Description <code>Exit</code> <p>When the user confirms exiting</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def confirm_abort(self) -&gt; bool:\n\t\"\"\"\n\tAsk the user to confirm aborting the commit process.\n\n\tReturns:\n\t    True if the user confirms, False otherwise\n\n\tRaises:\n\t    typer.Exit: When the user confirms exiting\n\n\t\"\"\"\n\tconfirmed = Confirm.ask(\n\t\t\"\\n[bold yellow]Are you sure you want to exit without committing?[/]\",\n\t\tdefault=False,\n\t)\n\n\tif confirmed:\n\t\tself.console.print(\"[yellow]Exiting commit process...[/yellow]\")\n\t\t# Use a zero exit code to indicate a successful (intended) exit\n\t\t# This prevents error messages from showing when exiting\n\t\traise typer.Exit(code=0)\n\n\treturn False\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.confirm_bypass_hooks","title":"confirm_bypass_hooks","text":"<pre><code>confirm_bypass_hooks() -&gt; bool\n</code></pre> <p>Ask the user to confirm bypassing git hooks.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the user confirms, False otherwise</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def confirm_bypass_hooks(self) -&gt; bool:\n\t\"\"\"\n\tAsk the user to confirm bypassing git hooks.\n\n\tReturns:\n\t    True if the user confirms, False otherwise\n\n\t\"\"\"\n\tself.console.print(\"\\n[bold yellow]Git hooks failed.[/]\")\n\tself.console.print(\"[yellow]This may be due to linting or other pre-commit checks.[/]\")\n\treturn Confirm.ask(\n\t\t\"\\n[bold yellow]Do you want to bypass git hooks and commit anyway?[/]\",\n\t\tdefault=False,\n\t)\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.show_success","title":"show_success","text":"<pre><code>show_success(message: str) -&gt; None\n</code></pre> <p>Show a success message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to display</p> required Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def show_success(self, message: str) -&gt; None:\n\t\"\"\"\n\tShow a success message.\n\n\tArgs:\n\t    message: Message to display\n\n\t\"\"\"\n\tself.console.print(f\"\\n[bold green]\u2713[/] {message}\")\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.show_error","title":"show_error","text":"<pre><code>show_error(message: str) -&gt; None\n</code></pre> <p>Show an error message to the user.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message to display</p> required Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def show_error(self, message: str) -&gt; None:\n\t\"\"\"\n\tShow an error message to the user.\n\n\tArgs:\n\t    message: Error message to display\n\n\t\"\"\"\n\tif \"No changes to commit\" in message:\n\t\t# This is an informational message, not an error\n\t\tself.console.print(f\"[yellow]{message}[/yellow]\")\n\telse:\n\t\t# This is a real error\n\t\tself.console.print(f\"[red]Error:[/red] {message}\")\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.show_skipped","title":"show_skipped","text":"<pre><code>show_skipped(files: list[str]) -&gt; None\n</code></pre> <p>Show which files were skipped.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>list[str]</code> <p>List of skipped files</p> required Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def show_skipped(self, files: list[str]) -&gt; None:\n\t\"\"\"\n\tShow which files were skipped.\n\n\tArgs:\n\t    files: List of skipped files\n\n\t\"\"\"\n\tif files:\n\t\tself.console.print(\"\\n[yellow]Skipped changes in:[/]\")\n\t\tfor file in files:\n\t\t\tself.console.print(f\"  \u2022 {file}\")\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.show_regenerating","title":"show_regenerating","text":"<pre><code>show_regenerating() -&gt; None\n</code></pre> <p>Show message indicating message regeneration.</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def show_regenerating(self) -&gt; None:\n\t\"\"\"Show message indicating message regeneration.\"\"\"\n\tself.console.print(\"\\n[yellow]Regenerating commit message...[/yellow]\")\n</code></pre>"},{"location":"api/git/interactive/#codemap.git.interactive.CommitUI.show_all_committed","title":"show_all_committed","text":"<pre><code>show_all_committed() -&gt; None\n</code></pre> <p>Show message indicating all changes are committed.</p> Source code in <code>src/codemap/git/interactive.py</code> <pre><code>def show_all_committed(self) -&gt; None:\n\t\"\"\"Show message indicating all changes are committed.\"\"\"\n\tself.console.print(\"[green]\u2713[/green] All changes committed!\")\n</code></pre>"},{"location":"api/git/utils/","title":"Utils","text":"<p>Git utilities for CodeMap.</p>"},{"location":"api/git/utils/#codemap.git.utils.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.GitDiff","title":"GitDiff  <code>dataclass</code>","text":"<p>Represents a Git diff chunk.</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>@dataclass\nclass GitDiff:\n\t\"\"\"Represents a Git diff chunk.\"\"\"\n\n\tfiles: list[str]\n\tcontent: str\n\tis_staged: bool = False\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.GitDiff.__init__","title":"__init__","text":"<pre><code>__init__(\n\tfiles: list[str], content: str, is_staged: bool = False\n) -&gt; None\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.GitDiff.files","title":"files  <code>instance-attribute</code>","text":"<pre><code>files: list[str]\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.GitDiff.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: str\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.GitDiff.is_staged","title":"is_staged  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_staged: bool = False\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.GitError","title":"GitError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for Git-related errors.</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>class GitError(Exception):\n\t\"\"\"Custom exception for Git-related errors.\"\"\"\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.run_git_command","title":"run_git_command","text":"<pre><code>run_git_command(\n\tcommand: list[str],\n\tcwd: Path | str | None = None,\n\tcheck: bool = True,\n) -&gt; str\n</code></pre> <p>Run a git command and return its output.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>list[str]</code> <p>Git command as a list of strings</p> required <code>cwd</code> <code>Path | str | None</code> <p>Working directory</p> <code>None</code> <code>check</code> <code>bool</code> <p>Whether to check for errors</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Command output as a string</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If the command fails and check is True</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def run_git_command(command: list[str], cwd: Path | str | None = None, check: bool = True) -&gt; str:\n\t\"\"\"\n\tRun a git command and return its output.\n\n\tArgs:\n\t    command: Git command as a list of strings\n\t    cwd: Working directory\n\t    check: Whether to check for errors\n\n\tReturns:\n\t    Command output as a string\n\n\tRaises:\n\t    GitError: If the command fails and check is True\n\n\t\"\"\"\n\t# Constants to avoid magic numbers\n\tmin_cmd_len_for_merge_base = 3\n\tmerge_base_index = 1\n\tis_ancestor_index = 2\n\n\t# Check if command contains 'merge-base --is-ancestor' which is expected to sometimes fail\n\t# without it being a true error condition\n\tis_ancestor_check = (\n\t\tlen(command) &gt;= min_cmd_len_for_merge_base\n\t\tand command[merge_base_index] == \"merge-base\"\n\t\tand command[is_ancestor_index] == \"--is-ancestor\"\n\t)\n\n\ttry:\n\t\t# Using subprocess.run with a list of arguments is safe since we're not using shell=True\n\t\t# and the command is not being built from untrusted input\n\t\tresult = subprocess.run(  # noqa: S603\n\t\t\tcommand,\n\t\t\tcwd=cwd,\n\t\t\tcapture_output=True,\n\t\t\ttext=True,\n\t\t\tcheck=check,\n\t\t)\n\t\treturn result.stdout\n\texcept subprocess.CalledProcessError as e:\n\t\tstderr = e.stderr.strip() if e.stderr else \"\"\n\t\tstdout = e.stdout.strip() if e.stdout else \"\"\n\n\t\t# For merge-base --is-ancestor checks, log at debug level as this is expected to fail sometimes\n\t\tif is_ancestor_check:\n\t\t\tlogger.debug(\"Git command completed with non-zero status (expected for relationship check): %s\", command)\n\t\t\tif check:\n\t\t\t\terror_message = f\"Git command failed with exit code {e.returncode}: {stderr or stdout}\"\n\t\t\t\traise GitError(error_message) from e\n\t\telse:\n\t\t\t# For other commands, log the exception\n\t\t\tlogger.exception(\"Git command failed: %s\", \" \".join(command))\n\t\t\tif check:\n\t\t\t\terror_msg = f\"Git command failed: {stderr or stdout}\"\n\t\t\t\traise GitError(error_msg) from e\n\n\t\t# If we're not checking for errors, return an empty string\n\t\treturn \"\"\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.get_repo_root","title":"get_repo_root","text":"<pre><code>get_repo_root(path: Path | None = None) -&gt; Path\n</code></pre> <p>Get the root directory of the Git repository.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | None</code> <p>Optional path to start searching from</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to repository root</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If not in a Git repository</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def get_repo_root(path: Path | None = None) -&gt; Path:\n\t\"\"\"\n\tGet the root directory of the Git repository.\n\n\tArgs:\n\t    path: Optional path to start searching from\n\n\tReturns:\n\t    Path to repository root\n\n\tRaises:\n\t    GitError: If not in a Git repository\n\n\t\"\"\"\n\ttry:\n\t\tresult = run_git_command([\"git\", \"rev-parse\", \"--show-toplevel\"], path)\n\t\treturn Path(result.strip())\n\texcept GitError as e:\n\t\tmsg = \"Not in a Git repository\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.validate_repo_path","title":"validate_repo_path","text":"<pre><code>validate_repo_path(path: Path | None = None) -&gt; Path | None\n</code></pre> <p>Validate and return the repository path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | None</code> <p>Optional path to validate (defaults to current directory)</p> <code>None</code> <p>Returns:</p> Type Description <code>Path | None</code> <p>Path to the repository root if valid, None otherwise</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def validate_repo_path(path: Path | None = None) -&gt; Path | None:\n\t\"\"\"\n\tValidate and return the repository path.\n\n\tArgs:\n\t    path: Optional path to validate (defaults to current directory)\n\n\tReturns:\n\t    Path to the repository root if valid, None otherwise\n\n\t\"\"\"\n\ttry:\n\t\t# If no path provided, use current directory\n\t\tif path is None:\n\t\t\tpath = Path.cwd()\n\n\t\t# Get the repository root\n\t\treturn get_repo_root(path)\n\texcept GitError:\n\t\treturn None\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.get_staged_diff","title":"get_staged_diff","text":"<pre><code>get_staged_diff() -&gt; GitDiff\n</code></pre> <p>Get the diff of staged changes.</p> <p>Returns:</p> Type Description <code>GitDiff</code> <p>GitDiff object containing staged changes</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If git command fails</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def get_staged_diff() -&gt; GitDiff:\n\t\"\"\"\n\tGet the diff of staged changes.\n\n\tReturns:\n\t    GitDiff object containing staged changes\n\n\tRaises:\n\t    GitError: If git command fails\n\n\t\"\"\"\n\ttry:\n\t\t# Get list of staged files\n\t\tstaged_files = run_git_command([\"git\", \"diff\", \"--cached\", \"--name-only\"]).splitlines()\n\n\t\t# Get the actual diff\n\t\tdiff_content = run_git_command([\"git\", \"diff\", \"--cached\"])\n\n\t\treturn GitDiff(\n\t\t\tfiles=staged_files,\n\t\t\tcontent=diff_content,\n\t\t\tis_staged=True,\n\t\t)\n\texcept GitError as e:\n\t\tmsg = \"Failed to get staged changes\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.get_unstaged_diff","title":"get_unstaged_diff","text":"<pre><code>get_unstaged_diff() -&gt; GitDiff\n</code></pre> <p>Get the diff of unstaged changes.</p> <p>Returns:</p> Type Description <code>GitDiff</code> <p>GitDiff object containing unstaged changes</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If git command fails</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def get_unstaged_diff() -&gt; GitDiff:\n\t\"\"\"\n\tGet the diff of unstaged changes.\n\n\tReturns:\n\t    GitDiff object containing unstaged changes\n\n\tRaises:\n\t    GitError: If git command fails\n\n\t\"\"\"\n\ttry:\n\t\t# Get list of modified files\n\t\tmodified_files = run_git_command([\"git\", \"diff\", \"--name-only\"]).splitlines()\n\n\t\t# Get the actual diff\n\t\tdiff_content = run_git_command([\"git\", \"diff\"])\n\n\t\treturn GitDiff(\n\t\t\tfiles=modified_files,\n\t\t\tcontent=diff_content,\n\t\t\tis_staged=False,\n\t\t)\n\texcept GitError as e:\n\t\tmsg = \"Failed to get unstaged changes\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.stage_files","title":"stage_files","text":"<pre><code>stage_files(files: list[str]) -&gt; None\n</code></pre> <p>Stage the specified files.</p> <p>This function intelligently handles both existing and deleted files: - For existing files, it uses <code>git add</code> - For files that no longer exist but are tracked by git, it uses <code>git rm</code> - For files that no longer exist but are still in index, it uses <code>git rm --cached</code></p> <p>This prevents errors when trying to stage files that have been deleted but not yet tracked in git.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>list[str]</code> <p>List of files to stage</p> required <p>Raises:</p> Type Description <code>GitError</code> <p>If staging fails</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def stage_files(files: list[str]) -&gt; None:\n\t\"\"\"\n\tStage the specified files.\n\n\tThis function intelligently handles both existing and deleted files:\n\t- For existing files, it uses `git add`\n\t- For files that no longer exist but are tracked by git, it uses `git rm`\n\t- For files that no longer exist but are still in index, it uses `git rm --cached`\n\n\tThis prevents errors when trying to stage files that have been deleted\n\tbut not yet tracked in git.\n\n\tArgs:\n\t    files: List of files to stage\n\n\tRaises:\n\t    GitError: If staging fails\n\n\t\"\"\"\n\tif not files:\n\t\tlogger.warning(\"No files provided to stage_files\")\n\t\treturn\n\n\t# Keep track of all errors to report at the end\n\terrors = []\n\n\ttry:\n\t\t# 1. Get information about file status\n\t\t# ====================================\n\t\tgit_status_info = {}\n\t\ttracked_files = set()\n\t\tindex_files = set()\n\n\t\t# 1.1 Get git status information\n\t\ttry:\n\t\t\tstatus_output = run_git_command([\"git\", \"status\", \"--porcelain\"])\n\t\t\tfor line in status_output.splitlines():\n\t\t\t\t# Ensure line is a string, not bytes\n\t\t\t\tline_str = line if isinstance(line, str) else line.decode(\"utf-8\")\n\t\t\t\tif not line_str:\n\t\t\t\t\tcontinue\n\n\t\t\t\tstatus = line_str[:2]\n\t\t\t\tfile_path = line_str[3:].strip()\n\t\t\t\tgit_status_info[file_path] = status\n\t\texcept GitError:\n\t\t\terrors.append(\"Failed to get git status information\")\n\n\t\t# 1.2 Get tracked files\n\t\ttry:\n\t\t\ttracked_files_output = run_git_command([\"git\", \"ls-files\"])\n\t\t\ttracked_files = set(tracked_files_output.splitlines())\n\t\texcept GitError:\n\t\t\terrors.append(\"Failed to get list of tracked files\")\n\n\t\t# 1.3 Get index files\n\t\ttry:\n\t\t\tindex_files_output = run_git_command([\"git\", \"ls-files\", \"--stage\"])\n\t\t\tindex_files = {line.split()[-1] for line in index_files_output.splitlines() if line.strip()}\n\t\texcept GitError:\n\t\t\terrors.append(\"Failed to get list of files in git index\")\n\n\t\t# 2. Filter and categorize files\n\t\t# ==============================\n\t\t# Filter out invalid filenames\n\t\tvalid_files = [\n\t\t\tfile\n\t\t\tfor file in files\n\t\t\tif not (any(char in file for char in [\"*\", \"+\", \"{\", \"}\", \"\\\\\"]) or file.startswith('\"'))\n\t\t]\n\n\t\t# Skip any invalid filenames that were filtered out\n\t\tfor file in files:\n\t\t\tif file not in valid_files:\n\t\t\t\tlogger.warning(\"Skipping invalid filename: %s\", file)\n\n\t\t# Categorize files\n\t\texisting_files = []\n\t\tdeleted_tracked_files = []\n\t\tdeleted_index_files = []\n\t\tuntracked_nonexistent_files = []\n\n\t\tfor file in valid_files:\n\t\t\tpath = Path(file)\n\t\t\tif path.exists():\n\t\t\t\texisting_files.append(file)\n\t\t\telif file in tracked_files:\n\t\t\t\tdeleted_tracked_files.append(file)\n\t\t\telif file in index_files:\n\t\t\t\tdeleted_index_files.append(file)\n\t\t\telse:\n\t\t\t\tuntracked_nonexistent_files.append(file)\n\t\t\t\tlogger.warning(\"Skipping file %s: Does not exist and is not tracked by git\", file)\n\n\t\t# Log the categorized files\n\t\tlogger.debug(\"Existing files (%d): %s\", len(existing_files), existing_files)\n\t\tlogger.debug(\"Deleted tracked files (%d): %s\", len(deleted_tracked_files), deleted_tracked_files)\n\t\tlogger.debug(\"Deleted index files (%d): %s\", len(deleted_index_files), deleted_index_files)\n\n\t\t# 3. Process each file category\n\t\t# =============================\n\t\t# 3.1 Add existing files\n\t\tif existing_files:\n\t\t\ttry:\n\t\t\t\trun_git_command([\"git\", \"add\", *existing_files])\n\t\t\t\tlogger.debug(\"Added %d existing files\", len(existing_files))\n\t\t\texcept GitError as e:\n\t\t\t\terrors.append(f\"Failed to add existing files: {e!s}\")\n\n\t\t# 3.2 Remove deleted tracked files\n\t\tfor file in deleted_tracked_files:\n\t\t\tcmd = [\"git\", \"rm\", file]\n\t\t\ttry:\n\t\t\t\trun_git_command(cmd)\n\t\t\t\tlogger.debug(\"Removed deleted tracked file: %s\", file)\n\t\t\texcept GitError as e:\n\t\t\t\tif \"did not match any files\" in str(e):\n\t\t\t\t\t# File exists in tracked_files but can't be found, try with --cached\n\t\t\t\t\tdeleted_index_files.append(file)\n\t\t\t\telse:\n\t\t\t\t\terrors.append(f\"Failed to remove deleted tracked file {file}: {e!s}\")\n\n\t\t# 3.3 Remove files from index\n\t\tif deleted_index_files:\n\t\t\ttry:\n\t\t\t\trun_git_command([\"git\", \"rm\", \"--cached\", *deleted_index_files])\n\t\t\t\tlogger.debug(\"Removed %d files from index\", len(deleted_index_files))\n\t\t\texcept GitError as e:\n\t\t\t\terrors.append(f\"Failed to remove files from index: {e!s}\")\n\n\t\t# 4. Report errors if any occurred\n\t\t# ================================\n\t\tif errors:\n\t\t\terror_msg = \"; \".join(errors)\n\t\t\tmsg = f\"Errors while staging files: {error_msg}\"\n\t\t\tlogger.error(msg)\n\t\t\traise GitError(msg)  # noqa: TRY301\n\n\texcept GitError:\n\t\t# Pass through GitError exceptions\n\t\traise\n\texcept Exception as e:\n\t\t# Wrap other exceptions in GitError\n\t\tmsg = f\"Unexpected error staging files: {e}\"\n\t\tlogger.exception(msg)\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.commit","title":"commit","text":"<pre><code>commit(message: str) -&gt; None\n</code></pre> <p>Create a commit with the given message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Commit message</p> required <p>Raises:</p> Type Description <code>GitError</code> <p>If commit fails</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def commit(message: str) -&gt; None:\n\t\"\"\"\n\tCreate a commit with the given message.\n\n\tArgs:\n\t    message: Commit message\n\n\tRaises:\n\t    GitError: If commit fails\n\n\t\"\"\"\n\ttry:\n\t\t# For commit messages, we need to ensure they're properly quoted\n\t\t# Use a shell command directly to ensure proper quoting\n\t\timport shlex\n\n\t\tquoted_message = shlex.quote(message)\n\t\tshell_command = f\"git commit -m {quoted_message}\"\n\n\t\t# Using shell=True is necessary for proper handling of quoted commit messages\n\t\t# Security is maintained by using shlex.quote to escape user input\n\t\tsubprocess.run(  # noqa: S602\n\t\t\tshell_command,\n\t\t\tcwd=None,  # Use current dir\n\t\t\tcapture_output=True,\n\t\t\ttext=True,\n\t\t\tcheck=True,\n\t\t\tshell=True,  # Using shell=True for this operation\n\t\t)\n\texcept subprocess.CalledProcessError as e:\n\t\tmsg = f\"Failed to create commit: {e.stderr}\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.get_other_staged_files","title":"get_other_staged_files","text":"<pre><code>get_other_staged_files(\n\ttargeted_files: list[str],\n) -&gt; list[str]\n</code></pre> <p>Get staged files that are not part of the targeted files.</p> <p>Parameters:</p> Name Type Description Default <code>targeted_files</code> <code>list[str]</code> <p>List of files that are meant to be committed</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of other staged files that might be committed inadvertently</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If git command fails</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def get_other_staged_files(targeted_files: list[str]) -&gt; list[str]:\n\t\"\"\"\n\tGet staged files that are not part of the targeted files.\n\n\tArgs:\n\t    targeted_files: List of files that are meant to be committed\n\n\tReturns:\n\t    List of other staged files that might be committed inadvertently\n\n\tRaises:\n\t    GitError: If git command fails\n\n\t\"\"\"\n\ttry:\n\t\t# Get all staged files\n\t\tall_staged = run_git_command([\"git\", \"diff\", \"--cached\", \"--name-only\"]).splitlines()\n\n\t\t# Filter out the targeted files\n\t\treturn [f for f in all_staged if f not in targeted_files]\n\texcept GitError as e:\n\t\tmsg = \"Failed to check for other staged files\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.stash_staged_changes","title":"stash_staged_changes","text":"<pre><code>stash_staged_changes(exclude_files: list[str]) -&gt; bool\n</code></pre> <p>Temporarily stash staged changes except for specified files.</p> <p>This is used to ensure only specific files are committed when other files might be mistakenly staged.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_files</code> <code>list[str]</code> <p>Files to exclude from stashing (to keep staged)</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether stashing was performed</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If git operations fail</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def stash_staged_changes(exclude_files: list[str]) -&gt; bool:\n\t\"\"\"\n\tTemporarily stash staged changes except for specified files.\n\n\tThis is used to ensure only specific files are committed when other\n\tfiles might be mistakenly staged.\n\n\tArgs:\n\t    exclude_files: Files to exclude from stashing (to keep staged)\n\n\tReturns:\n\t    Whether stashing was performed\n\n\tRaises:\n\t    GitError: If git operations fail\n\n\t\"\"\"\n\ttry:\n\t\t# First check if there are any other staged files\n\t\tother_files = get_other_staged_files(exclude_files)\n\t\tif not other_files:\n\t\t\treturn False\n\n\t\t# Create a temporary index to save current state\n\t\trun_git_command([\"git\", \"stash\", \"push\", \"--keep-index\", \"--message\", \"CodeMap: temporary stash for commit\"])\n\texcept GitError as e:\n\t\tmsg = \"Failed to stash other staged changes\"\n\t\traise GitError(msg) from e\n\telse:\n\t\treturn True\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.unstash_changes","title":"unstash_changes","text":"<pre><code>unstash_changes() -&gt; None\n</code></pre> <p>Restore previously stashed changes.</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If git operations fail</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def unstash_changes() -&gt; None:\n\t\"\"\"\n\tRestore previously stashed changes.\n\n\tRaises:\n\t    GitError: If git operations fail\n\n\t\"\"\"\n\ttry:\n\t\tstash_list = run_git_command([\"git\", \"stash\", \"list\"])\n\t\tif \"CodeMap: temporary stash for commit\" in stash_list:\n\t\t\trun_git_command([\"git\", \"stash\", \"pop\"])\n\texcept GitError as e:\n\t\tmsg = \"Failed to restore stashed changes; you may need to manually run 'git stash pop'\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.commit_only_files","title":"commit_only_files","text":"<pre><code>commit_only_files(\n\tfiles: list[str],\n\tmessage: str,\n\t*,\n\tcommit_options: list[str] | None = None,\n\tignore_hooks: bool = False,\n) -&gt; list[str]\n</code></pre> <p>Commit only the specified files.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>list[str]</code> <p>List of files to commit</p> required <code>message</code> <code>str</code> <p>Commit message</p> required <code>commit_options</code> <code>list[str] | None</code> <p>Additional commit options</p> <code>None</code> <code>ignore_hooks</code> <code>bool</code> <p>Whether to ignore Git hooks</p> <code>False</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of other staged files that weren't committed</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def commit_only_files(\n\tfiles: list[str], message: str, *, commit_options: list[str] | None = None, ignore_hooks: bool = False\n) -&gt; list[str]:\n\t\"\"\"\n\tCommit only the specified files.\n\n\tArgs:\n\t    files: List of files to commit\n\t    message: Commit message\n\t    commit_options: Additional commit options\n\t    ignore_hooks: Whether to ignore Git hooks\n\n\tReturns:\n\t    List of other staged files that weren't committed\n\n\t\"\"\"\n\ttry:\n\t\t# Get status to check for deleted files\n\t\tstatus_cmd = [\"git\", \"status\", \"--porcelain\"]\n\t\tresult = subprocess.run(  # noqa: S603\n\t\t\tstatus_cmd,\n\t\t\tcapture_output=True,\n\t\t\ttext=True,\n\t\t\tcheck=True,\n\t\t\tshell=False,  # Explicitly set shell=False for security\n\t\t)\n\t\tstatus_output = result.stdout.strip()\n\n\t\t# Extract files from status output\n\t\tstatus_files = {}\n\t\tfor line in status_output.splitlines():\n\t\t\tif not line.strip():\n\t\t\t\tcontinue\n\t\t\tstatus = line[:2].strip()\n\t\t\tfile_path = line[3:].strip()\n\n\t\t\t# Handle renamed files\n\t\t\tif isinstance(file_path, bytes):\n\t\t\t\tfile_path = file_path.decode(\"utf-8\")\n\n\t\t\tif \" -&gt; \" in file_path:\n\t\t\t\tfile_path = file_path.split(\" -&gt; \")[1]\n\n\t\t\tstatus_files[file_path] = status\n\n\t\t# Stage all files - our improved stage_files function can handle both existing and deleted files\n\t\tstage_files(files)\n\n\t\t# Get other staged files\n\t\tother_staged = get_other_staged_files(files)\n\n\t\t# Commit the changes\n\t\tcommit_cmd = [\"git\", \"commit\", \"-m\", message]\n\n\t\tif commit_options:\n\t\t\tcommit_cmd.extend(commit_options)\n\n\t\tif ignore_hooks:\n\t\t\tcommit_cmd.append(\"--no-verify\")\n\n\t\ttry:\n\t\t\tsubprocess.run(  # noqa: S603\n\t\t\t\tcommit_cmd,\n\t\t\t\tcheck=True,\n\t\t\t\tcapture_output=True,\n\t\t\t\ttext=True,\n\t\t\t\tshell=False,  # Explicitly set shell=False for security\n\t\t\t)\n\t\t\tlogger.info(\"Created commit with message: %s\", message)\n\t\texcept subprocess.CalledProcessError as e:\n\t\t\t# Capture stderr and stdout for better error reporting\n\t\t\terror_msg = f\"Git commit command failed. Command: '{' '.join(commit_cmd)}'\"\n\n\t\t\tif e.stderr:\n\t\t\t\terror_msg += f\"\\n\\nGit Error Output:\\n{e.stderr.strip()}\"\n\t\t\tif e.stdout:\n\t\t\t\terror_msg += f\"\\n\\nCommand Output:\\n{e.stdout.strip()}\"\n\n\t\t\tlogger.exception(\"Failed to create commit: %s\", error_msg)\n\t\t\traise GitError(error_msg) from e\n\n\t\treturn other_staged\n\texcept GitError:\n\t\t# Re-raise GitErrors directly\n\t\traise\n\texcept Exception as e:\n\t\terror_msg = f\"Error in commit_only_files: {e!s}\"\n\t\tlogger.exception(error_msg)\n\t\traise GitError(error_msg) from e\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.get_untracked_files","title":"get_untracked_files","text":"<pre><code>get_untracked_files() -&gt; list[str]\n</code></pre> <p>Get a list of untracked files in the repository.</p> <p>These are files that are not yet tracked by Git (new files that haven't been staged).</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of untracked file paths</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If git command fails</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def get_untracked_files() -&gt; list[str]:\n\t\"\"\"\n\tGet a list of untracked files in the repository.\n\n\tThese are files that are not yet tracked by Git (new files that haven't been staged).\n\n\tReturns:\n\t    List of untracked file paths\n\n\tRaises:\n\t    GitError: If git command fails\n\n\t\"\"\"\n\ttry:\n\t\t# Use ls-files with --others to get untracked files and --exclude-standard to respect gitignore\n\t\treturn run_git_command([\"git\", \"ls-files\", \"--others\", \"--exclude-standard\"]).splitlines()\n\texcept GitError as e:\n\t\tmsg = \"Failed to get untracked files\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/utils/#codemap.git.utils.unstage_files","title":"unstage_files","text":"<pre><code>unstage_files(files: list[str]) -&gt; None\n</code></pre> <p>Unstage the specified files.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>list[str]</code> <p>List of files to unstage</p> required <p>Raises:</p> Type Description <code>GitError</code> <p>If unstaging fails</p> Source code in <code>src/codemap/git/utils.py</code> <pre><code>def unstage_files(files: list[str]) -&gt; None:\n\t\"\"\"\n\tUnstage the specified files.\n\n\tArgs:\n\t    files: List of files to unstage\n\n\tRaises:\n\t    GitError: If unstaging fails\n\n\t\"\"\"\n\ttry:\n\t\trun_git_command([\"git\", \"restore\", \"--staged\", *files])\n\texcept GitError as e:\n\t\tmsg = f\"Failed to unstage files: {', '.join(files)}\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/commit_generator/","title":"Commit Generator Overview","text":"<p>Commit message generation package for CodeMap.</p> <ul> <li>Command - Main commit command implementation for CodeMap.</li> <li>Generator - Generator module for commit messages.</li> <li>Prompts - Prompt templates for commit message generation.</li> <li>Schemas - Schemas and data structures for commit message generation.</li> <li>Utils - Linting functionality for commit messages.</li> </ul>"},{"location":"api/git/commit_generator/command/","title":"Command","text":"<p>Main commit command implementation for CodeMap.</p>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.MAX_FILES_BEFORE_BATCHING","title":"MAX_FILES_BEFORE_BATCHING  <code>module-attribute</code>","text":"<pre><code>MAX_FILES_BEFORE_BATCHING = 10\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand","title":"CommitCommand","text":"<p>Handles the commit command workflow.</p> Source code in <code>src/codemap/git/commit_generator/command.py</code> <pre><code>class CommitCommand:\n\t\"\"\"Handles the commit command workflow.\"\"\"\n\n\tdef __init__(self, path: Path | None = None, model: str = \"gpt-4o-mini\", bypass_hooks: bool = False) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the commit command.\n\n\t\tArgs:\n\t\t    path: Optional path to start from\n\t\t    model: LLM model to use for commit message generation\n\t\t    bypass_hooks: Whether to bypass git hooks with --no-verify\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\tself.repo_root = get_repo_root(path)\n\t\t\tself.ui: CommitUI = CommitUI()\n\t\t\tself.splitter = DiffSplitter(self.repo_root)\n\n\t\t\t# Store the current branch at initialization to ensure we don't switch branches unexpectedly\n\t\t\ttry:\n\t\t\t\tfrom codemap.git.pr_generator.utils import get_current_branch\n\n\t\t\t\tself.original_branch = get_current_branch()\n\t\t\texcept (ImportError, GitError):\n\t\t\t\tself.original_branch = None\n\n\t\t\t# Create LLM client and configs\n\t\t\tfrom codemap.llm import create_client\n\t\t\tfrom codemap.utils.config_loader import ConfigLoader\n\n\t\t\tconfig_loader = ConfigLoader(repo_root=self.repo_root)\n\t\t\tllm_client = create_client(repo_path=self.repo_root, model=model)\n\n\t\t\t# Create the commit message generator with required parameters\n\t\t\tself.message_generator = CommitMessageGenerator(\n\t\t\t\trepo_root=self.repo_root,\n\t\t\t\tllm_client=llm_client,\n\t\t\t\tprompt_template=DEFAULT_PROMPT_TEMPLATE,\n\t\t\t\tconfig_loader=config_loader,\n\t\t\t)\n\n\t\t\tself.error_state = None  # Tracks reason for failure: \"failed\", \"aborted\", etc.\n\t\t\tself.bypass_hooks = bypass_hooks  # Whether to bypass git hooks with --no-verify\n\t\texcept GitError as e:\n\t\t\traise RuntimeError(str(e)) from e\n\n\tdef _get_changes(self) -&gt; list[GitDiff]:\n\t\t\"\"\"\n\t\tGet staged, unstaged, and untracked changes separately.\n\n\t\tReturns:\n\t\t    List of GitDiff objects representing changes.\n\n\t\tRaises:\n\t\t    RuntimeError: If Git operations fail.\n\n\t\t\"\"\"\n\t\tchanges = []\n\t\ttry:\n\t\t\t# Get staged changes\n\t\t\tstaged = get_staged_diff()\n\t\t\tif staged and staged.files:\n\t\t\t\tchanges.append(staged)\n\t\t\t\tlogger.debug(\"Found %d staged files.\", len(staged.files))\n\n\t\t\t# Get unstaged changes\n\t\t\tunstaged = get_unstaged_diff()\n\t\t\tif unstaged and unstaged.files:\n\t\t\t\tchanges.append(unstaged)\n\t\t\t\tlogger.debug(\"Found %d unstaged files.\", len(unstaged.files))\n\n\t\t\t# Get untracked files\n\t\t\tuntracked_files = get_untracked_files()\n\t\t\tif untracked_files:\n\t\t\t\tuntracked_diff = GitDiff(files=untracked_files, content=\"\", is_staged=False)\n\t\t\t\tchanges.append(untracked_diff)\n\t\t\t\tlogger.debug(\"Found %d untracked files.\", len(untracked_files))\n\n\t\texcept GitError as e:\n\t\t\tmsg = f\"Failed to get repository changes: {e}\"\n\t\t\tlogger.exception(msg)\n\t\t\traise RuntimeError(msg) from e\n\n\t\treturn changes\n\n\tdef _generate_commit_message(self, chunk: DiffChunk) -&gt; None:\n\t\t\"\"\"\n\t\tGenerate a commit message for the chunk.\n\n\t\tArgs:\n\t\t    chunk: DiffChunk to generate message for\n\n\t\tRaises:\n\t\t    RuntimeError: If message generation fails\n\n\t\t\"\"\"\n\t\t# Constants to avoid magic numbers\n\t\tmax_log_message_length = 40\n\n\t\tlogger.debug(\"Starting commit message generation for %s\", chunk.files)\n\t\ttry:\n\t\t\twith loading_spinner(\"Generating commit message using LLM...\"):\n\t\t\t\t# Generate the message using the generator\n\t\t\t\tmessage, is_llm = self.message_generator.generate_message(chunk)\n\n\t\t\t\tlogger.debug(\n\t\t\t\t\t\"Got response - is_llm=%s, message=%s\",\n\t\t\t\t\tis_llm,\n\t\t\t\t\tmessage[:max_log_message_length] + \"...\"\n\t\t\t\t\tif message and len(message) &gt; max_log_message_length\n\t\t\t\t\telse message,\n\t\t\t\t)\n\t\t\t\tchunk.description = message\n\n\t\t\t\t# Store whether this was LLM-generated for UI\n\t\t\t\tchunk.is_llm_generated = is_llm\n\n\t\t\t\tif is_llm:\n\t\t\t\t\tlogger.debug(\"Generated commit message using LLM: %s\", message)\n\t\t\t\telse:\n\t\t\t\t\tlogger.warning(\"Using automatically generated fallback message: %s\", message)\n\n\t\texcept LLMError as e:\n\t\t\t# If LLM generation fails, try fallback with clear indication\n\t\t\tlogger.exception(\"LLM message generation failed\")\n\t\t\tlogger.warning(\"LLM error: %s\", str(e))\n\t\t\twith loading_spinner(\"Falling back to simple message generation...\"):\n\t\t\t\t# Convert DiffChunk to DiffChunkData before passing to fallback_generation\n\t\t\t\tdescription = getattr(chunk, \"description\", None)\n\t\t\t\tchunk_dict = DiffChunkData(files=chunk.files, content=chunk.content)\n\t\t\t\t# Add description only if it exists to match TypedDict total=False\n\t\t\t\tif description is not None:\n\t\t\t\t\tchunk_dict[\"description\"] = description\n\t\t\t\tmessage = self.message_generator.fallback_generation(chunk_dict)\n\t\t\t\tchunk.description = message\n\t\t\t\t# Mark as not LLM-generated\n\t\t\t\tchunk.is_llm_generated = False\n\t\t\t\tlogger.warning(\"Using fallback message: %s\", message)\n\t\texcept (ValueError, RuntimeError) as e:\n\t\t\tlogger.warning(\"Other error: %s\", str(e))\n\t\t\tmsg = f\"Failed to generate commit message: {e}\"\n\t\t\traise RuntimeError(msg) from e\n\n\tdef _perform_commit(self, chunk: DiffChunk, message: str) -&gt; bool:\n\t\t\"\"\"\n\t\tPerform the actual commit operation.\n\n\t\tArgs:\n\t\t    chunk: The chunk to commit\n\t\t    message: Commit message to use\n\n\t\tReturns:\n\t\t    True if successful, False otherwise\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\t# Ensure the specific files for this chunk are staged\n\t\t\t# This prevents accidentally committing unrelated staged changes\n\t\t\twith loading_spinner(\"Staging chunk files...\"):\n\t\t\t\tstage_files(chunk.files)\n\n\t\t\t# Commit only the files specified in the chunk\n\t\t\tcommit_only_files(chunk.files, message, ignore_hooks=self.bypass_hooks)\n\t\t\tself.ui.show_success(f\"Committed {len(chunk.files)} files.\")\n\t\t\treturn True\n\t\texcept GitError as e:\n\t\t\terror_msg = f\"Error during commit: {e}\"\n\t\t\tself.ui.show_error(error_msg)\n\t\t\tlogger.exception(error_msg)\n\t\t\tself.error_state = \"failed\"\n\t\t\treturn False\n\n\tdef _process_chunk(self, chunk: DiffChunk, index: int, total_chunks: int) -&gt; bool:\n\t\t\"\"\"\n\t\tProcess a single chunk.\n\n\t\tArgs:\n\t\t    chunk: DiffChunk to process\n\t\t    index: The 0-based index of the current chunk\n\t\t    total_chunks: The total number of chunks\n\n\t\tReturns:\n\t\t    True if processing should continue, False to abort\n\n\t\tRaises:\n\t\t    RuntimeError: If Git operations fail\n\t\t    typer.Exit: If user chooses to exit\n\n\t\t\"\"\"\n\t\t# Add logging here\n\t\tlogger.debug(\n\t\t\t\"Processing chunk - Chunk ID: %s, Index: %d/%d, Initial Desc: %s\",\n\t\t\tid(chunk),\n\t\t\tindex + 1,  # Display 1-based index\n\t\t\ttotal_chunks,\n\t\t\tgetattr(chunk, \"description\", \"&lt;None&gt;\"),\n\t\t)\n\n\t\t# Remove any chunk.index and chunk.total attributes if they exist\n\t\tif hasattr(chunk, \"index\"):\n\t\t\tdelattr(chunk, \"index\")\n\t\tif hasattr(chunk, \"total\"):\n\t\t\tdelattr(chunk, \"total\")\n\n\t\twhile True:  # Loop to handle regeneration\n\t\t\t# Generate commit message\n\t\t\tself._generate_commit_message(chunk)\n\n\t\t\t# Get user action via UI\n\t\t\tresult: ChunkResult = self.ui.process_chunk(chunk, index, total_chunks)\n\n\t\t\tif result.action == ChunkAction.ABORT:\n\t\t\t\t# Mark as an intended abort (UI.confirm_abort will raise typer.Exit if confirmed)\n\t\t\t\tself.error_state = \"aborted\"\n\n\t\t\t\t# In production, if confirm_abort returns, it means user declined to abort\n\t\t\t\t# In tests, mock will return the mocked value and not raise - both cases are handled\n\t\t\t\tif self.ui.confirm_abort():\n\t\t\t\t\t# In tests with a mock that returns True\n\t\t\t\t\treturn False\n\n\t\t\t\t# If we get here, user declined to abort in production, or mock returned False in testing\n\t\t\t\tcontinue\n\n\t\t\tif result.action == ChunkAction.SKIP:\n\t\t\t\tself.ui.show_skipped(chunk.files)\n\t\t\t\treturn True\n\n\t\t\tif result.action == ChunkAction.REGENERATE:\n\t\t\t\t# Clear the existing description to force regeneration\n\t\t\t\tchunk.description = None\n\t\t\t\tchunk.is_llm_generated = False\n\t\t\t\tself.ui.show_regenerating()\n\t\t\t\tcontinue  # Go back to the start of the loop\n\n\t\t\t# For ACCEPT or EDIT actions: perform the commit\n\t\t\tmessage = result.message or chunk.description or \"Update files\"\n\t\t\tsuccess = self._perform_commit(chunk, message)\n\t\t\tif not success:\n\t\t\t\tself.error_state = \"failed\"\n\t\t\treturn success\n\n\tdef process_all_chunks(self, chunks: list[DiffChunk], grand_total: int, interactive: bool = True) -&gt; bool:\n\t\t\"\"\"\n\t\tProcess all chunks interactively or automatically.\n\n\t\tArgs:\n\t\t    chunks: List of diff chunks to process\n\t\t    grand_total: The total number of chunks across all batches\n\t\t    interactive: Whether to process interactively or automatically\n\n\t\tReturns:\n\t\t    True if successful, False if failed or aborted\n\n\t\t\"\"\"\n\t\tfor i, chunk in enumerate(chunks):\n\t\t\tif interactive:\n\t\t\t\tif not self._process_chunk(chunk, i, grand_total):\n\t\t\t\t\t# _process_chunk sets error_state and returns False on failure/abort\n\t\t\t\t\treturn False\n\t\t\telse:\n\t\t\t\t# Non-interactive mode: commit all chunks automatically\n\t\t\t\tself._generate_commit_message(chunk)\n\t\t\t\tif not self._perform_commit(chunk, chunk.description or \"Update files\"):\n\t\t\t\t\tself.error_state = \"failed\"\n\t\t\t\t\treturn False\n\n\t\t# If loop completes without returning False, it was successful\n\t\tself.ui.show_all_committed()\n\t\treturn True\n\n\tdef run(self) -&gt; bool:\n\t\t\"\"\"\n\t\tRun the commit command.\n\n\t\tReturns:\n\t\t    True if successful, False otherwise\n\n\t\tNote:\n\t\t    May raise typer.Exit when users abort\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\t# 1. Get changes\n\t\t\twith loading_spinner(\"Analyzing repository changes...\"):\n\t\t\t\tchange_diffs = self._get_changes()\n\n\t\t\tif not change_diffs:\n\t\t\t\tself.ui.show_error(\"No changes detected to commit.\")\n\t\t\t\treturn True  # Success, nothing to do\n\n\t\t\t# Combine all changes into one diff for splitting\n\t\t\t# This simplifies logic, assuming splitter can handle combined diff\n\t\t\tcombined_files = [f for diff in change_diffs for f in diff.files]\n\t\t\tcombined_content = \"\\n\".join(diff.content for diff in change_diffs if diff.content)\n\t\t\tcombined_diff = GitDiff(files=combined_files, content=combined_content)\n\n\t\t\t# 2. Split the combined diff\n\t\t\twith loading_spinner(\"Organizing changes semantically...\"):\n\t\t\t\tchunks, filtered_files = self.splitter.split_diff(combined_diff)\n\n\t\t\t# 3. Handle filtered files warning\n\t\t\tif filtered_files:\n\t\t\t\tself.ui.show_error(f\"Skipped {len(filtered_files)} large files from analysis due to size limits.\")\n\n\t\t\t# 4. Check if there are chunks to process\n\t\t\tif not chunks:\n\t\t\t\tself.ui.show_error(\"No processable changes found after analysis.\")\n\t\t\t\treturn True  # Success, nothing to commit after filtering/splitting\n\n\t\t\t# 5. Process all chunks\n\t\t\tgrand_total = len(chunks)\n\t\t\tif not self.process_all_chunks(chunks, grand_total):\n\t\t\t\t# Error state is set within process_all_chunks or _process_chunk\n\t\t\t\treturn False\n\n\t\texcept typer.Exit:\n\t\t\tself.error_state = \"aborted\"\n\t\t\traise\n\t\texcept (RuntimeError, ValueError, GitError) as e:\n\t\t\tself.ui.show_error(str(e))\n\t\t\tself.error_state = \"failed\"\n\t\t\tlogger.exception(\"Commit command failed.\")  # Log the exception\n\t\t\treturn False\n\t\telse:\n\t\t\t# Check if we need to restore the original branch\n\t\t\tif self.original_branch:\n\t\t\t\ttry:\n\t\t\t\t\tfrom codemap.git.pr_generator.utils import checkout_branch, get_current_branch\n\n\t\t\t\t\tcurrent_branch = get_current_branch()\n\t\t\t\t\tif current_branch != self.original_branch:\n\t\t\t\t\t\tself.ui.show_success(f\"Restoring original branch: {self.original_branch}\")\n\t\t\t\t\t\tcheckout_branch(self.original_branch)\n\t\t\t\texcept (ImportError, GitError) as e:\n\t\t\t\t\tlogger.warning(\"Failed to restore original branch: %s\", str(e))\n\n\t\t\treturn True\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand.__init__","title":"__init__","text":"<pre><code>__init__(\n\tpath: Path | None = None,\n\tmodel: str = \"gpt-4o-mini\",\n\tbypass_hooks: bool = False,\n) -&gt; None\n</code></pre> <p>Initialize the commit command.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | None</code> <p>Optional path to start from</p> <code>None</code> <code>model</code> <code>str</code> <p>LLM model to use for commit message generation</p> <code>'gpt-4o-mini'</code> <code>bypass_hooks</code> <code>bool</code> <p>Whether to bypass git hooks with --no-verify</p> <code>False</code> Source code in <code>src/codemap/git/commit_generator/command.py</code> <pre><code>def __init__(self, path: Path | None = None, model: str = \"gpt-4o-mini\", bypass_hooks: bool = False) -&gt; None:\n\t\"\"\"\n\tInitialize the commit command.\n\n\tArgs:\n\t    path: Optional path to start from\n\t    model: LLM model to use for commit message generation\n\t    bypass_hooks: Whether to bypass git hooks with --no-verify\n\n\t\"\"\"\n\ttry:\n\t\tself.repo_root = get_repo_root(path)\n\t\tself.ui: CommitUI = CommitUI()\n\t\tself.splitter = DiffSplitter(self.repo_root)\n\n\t\t# Store the current branch at initialization to ensure we don't switch branches unexpectedly\n\t\ttry:\n\t\t\tfrom codemap.git.pr_generator.utils import get_current_branch\n\n\t\t\tself.original_branch = get_current_branch()\n\t\texcept (ImportError, GitError):\n\t\t\tself.original_branch = None\n\n\t\t# Create LLM client and configs\n\t\tfrom codemap.llm import create_client\n\t\tfrom codemap.utils.config_loader import ConfigLoader\n\n\t\tconfig_loader = ConfigLoader(repo_root=self.repo_root)\n\t\tllm_client = create_client(repo_path=self.repo_root, model=model)\n\n\t\t# Create the commit message generator with required parameters\n\t\tself.message_generator = CommitMessageGenerator(\n\t\t\trepo_root=self.repo_root,\n\t\t\tllm_client=llm_client,\n\t\t\tprompt_template=DEFAULT_PROMPT_TEMPLATE,\n\t\t\tconfig_loader=config_loader,\n\t\t)\n\n\t\tself.error_state = None  # Tracks reason for failure: \"failed\", \"aborted\", etc.\n\t\tself.bypass_hooks = bypass_hooks  # Whether to bypass git hooks with --no-verify\n\texcept GitError as e:\n\t\traise RuntimeError(str(e)) from e\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand.repo_root","title":"repo_root  <code>instance-attribute</code>","text":"<pre><code>repo_root = get_repo_root(path)\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand.ui","title":"ui  <code>instance-attribute</code>","text":"<pre><code>ui: CommitUI = CommitUI()\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand.splitter","title":"splitter  <code>instance-attribute</code>","text":"<pre><code>splitter = DiffSplitter(repo_root)\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand.original_branch","title":"original_branch  <code>instance-attribute</code>","text":"<pre><code>original_branch = get_current_branch()\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand.message_generator","title":"message_generator  <code>instance-attribute</code>","text":"<pre><code>message_generator = CommitMessageGenerator(\n\trepo_root=repo_root,\n\tllm_client=llm_client,\n\tprompt_template=DEFAULT_PROMPT_TEMPLATE,\n\tconfig_loader=config_loader,\n)\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand.error_state","title":"error_state  <code>instance-attribute</code>","text":"<pre><code>error_state = None\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand.bypass_hooks","title":"bypass_hooks  <code>instance-attribute</code>","text":"<pre><code>bypass_hooks = bypass_hooks\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand.process_all_chunks","title":"process_all_chunks","text":"<pre><code>process_all_chunks(\n\tchunks: list[DiffChunk],\n\tgrand_total: int,\n\tinteractive: bool = True,\n) -&gt; bool\n</code></pre> <p>Process all chunks interactively or automatically.</p> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <code>list[DiffChunk]</code> <p>List of diff chunks to process</p> required <code>grand_total</code> <code>int</code> <p>The total number of chunks across all batches</p> required <code>interactive</code> <code>bool</code> <p>Whether to process interactively or automatically</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False if failed or aborted</p> Source code in <code>src/codemap/git/commit_generator/command.py</code> <pre><code>def process_all_chunks(self, chunks: list[DiffChunk], grand_total: int, interactive: bool = True) -&gt; bool:\n\t\"\"\"\n\tProcess all chunks interactively or automatically.\n\n\tArgs:\n\t    chunks: List of diff chunks to process\n\t    grand_total: The total number of chunks across all batches\n\t    interactive: Whether to process interactively or automatically\n\n\tReturns:\n\t    True if successful, False if failed or aborted\n\n\t\"\"\"\n\tfor i, chunk in enumerate(chunks):\n\t\tif interactive:\n\t\t\tif not self._process_chunk(chunk, i, grand_total):\n\t\t\t\t# _process_chunk sets error_state and returns False on failure/abort\n\t\t\t\treturn False\n\t\telse:\n\t\t\t# Non-interactive mode: commit all chunks automatically\n\t\t\tself._generate_commit_message(chunk)\n\t\t\tif not self._perform_commit(chunk, chunk.description or \"Update files\"):\n\t\t\t\tself.error_state = \"failed\"\n\t\t\t\treturn False\n\n\t# If loop completes without returning False, it was successful\n\tself.ui.show_all_committed()\n\treturn True\n</code></pre>"},{"location":"api/git/commit_generator/command/#codemap.git.commit_generator.command.CommitCommand.run","title":"run","text":"<pre><code>run() -&gt; bool\n</code></pre> <p>Run the commit command.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise</p> Note <p>May raise typer.Exit when users abort</p> Source code in <code>src/codemap/git/commit_generator/command.py</code> <pre><code>def run(self) -&gt; bool:\n\t\"\"\"\n\tRun the commit command.\n\n\tReturns:\n\t    True if successful, False otherwise\n\n\tNote:\n\t    May raise typer.Exit when users abort\n\n\t\"\"\"\n\ttry:\n\t\t# 1. Get changes\n\t\twith loading_spinner(\"Analyzing repository changes...\"):\n\t\t\tchange_diffs = self._get_changes()\n\n\t\tif not change_diffs:\n\t\t\tself.ui.show_error(\"No changes detected to commit.\")\n\t\t\treturn True  # Success, nothing to do\n\n\t\t# Combine all changes into one diff for splitting\n\t\t# This simplifies logic, assuming splitter can handle combined diff\n\t\tcombined_files = [f for diff in change_diffs for f in diff.files]\n\t\tcombined_content = \"\\n\".join(diff.content for diff in change_diffs if diff.content)\n\t\tcombined_diff = GitDiff(files=combined_files, content=combined_content)\n\n\t\t# 2. Split the combined diff\n\t\twith loading_spinner(\"Organizing changes semantically...\"):\n\t\t\tchunks, filtered_files = self.splitter.split_diff(combined_diff)\n\n\t\t# 3. Handle filtered files warning\n\t\tif filtered_files:\n\t\t\tself.ui.show_error(f\"Skipped {len(filtered_files)} large files from analysis due to size limits.\")\n\n\t\t# 4. Check if there are chunks to process\n\t\tif not chunks:\n\t\t\tself.ui.show_error(\"No processable changes found after analysis.\")\n\t\t\treturn True  # Success, nothing to commit after filtering/splitting\n\n\t\t# 5. Process all chunks\n\t\tgrand_total = len(chunks)\n\t\tif not self.process_all_chunks(chunks, grand_total):\n\t\t\t# Error state is set within process_all_chunks or _process_chunk\n\t\t\treturn False\n\n\texcept typer.Exit:\n\t\tself.error_state = \"aborted\"\n\t\traise\n\texcept (RuntimeError, ValueError, GitError) as e:\n\t\tself.ui.show_error(str(e))\n\t\tself.error_state = \"failed\"\n\t\tlogger.exception(\"Commit command failed.\")  # Log the exception\n\t\treturn False\n\telse:\n\t\t# Check if we need to restore the original branch\n\t\tif self.original_branch:\n\t\t\ttry:\n\t\t\t\tfrom codemap.git.pr_generator.utils import checkout_branch, get_current_branch\n\n\t\t\t\tcurrent_branch = get_current_branch()\n\t\t\t\tif current_branch != self.original_branch:\n\t\t\t\t\tself.ui.show_success(f\"Restoring original branch: {self.original_branch}\")\n\t\t\t\t\tcheckout_branch(self.original_branch)\n\t\t\texcept (ImportError, GitError) as e:\n\t\t\t\tlogger.warning(\"Failed to restore original branch: %s\", str(e))\n\n\t\treturn True\n</code></pre>"},{"location":"api/git/commit_generator/generator/","title":"Generator","text":"<p>Generator module for commit messages.</p>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator","title":"CommitMessageGenerator","text":"<p>Generates commit messages using LLMs.</p> Source code in <code>src/codemap/git/commit_generator/generator.py</code> <pre><code>class CommitMessageGenerator:\n\t\"\"\"Generates commit messages using LLMs.\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\trepo_root: Path,\n\t\tllm_client: LLMClient,\n\t\tprompt_template: str,\n\t\tconfig_loader: ConfigLoader,\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the commit message generator.\n\n\t\tArgs:\n\t\t    repo_root: Root directory of the Git repository\n\t\t    llm_client: LLMClient instance to use\n\t\t    prompt_template: Custom prompt template to use\n\t\t    config_loader: ConfigLoader instance to use for configuration\n\n\t\t\"\"\"\n\t\tself.repo_root = repo_root\n\t\tself.prompt_template = prompt_template\n\t\tself._config_loader = config_loader\n\t\tself.client = llm_client\n\n\t\t# Add commit template to client\n\t\tself.client.set_template(\"commit\", self.prompt_template)\n\n\tdef extract_file_info(self, chunk: DiffChunk | DiffChunkData) -&gt; dict[str, Any]:\n\t\t\"\"\"\n\t\tExtract file information from the diff chunk.\n\n\t\tArgs:\n\t\t    chunk: Diff chunk to extract information from\n\n\t\tReturns:\n\t\t    Dictionary with information about files\n\n\t\t\"\"\"\n\t\tfile_info = {}\n\t\tfiles = chunk.files if isinstance(chunk, DiffChunk) else chunk.get(\"files\", [])\n\t\tif not isinstance(files, list):\n\t\t\ttry:\n\t\t\t\t# Convert to list only if it's actually iterable\n\t\t\t\tif hasattr(files, \"__iter__\") and not isinstance(files, str):\n\t\t\t\t\tfiles = list(cast(\"collections.abc.Iterable\", files))\n\t\t\t\telse:\n\t\t\t\t\tfiles = []\n\t\t\texcept (TypeError, ValueError):\n\t\t\t\tfiles = []\n\n\t\tfor file in files:\n\t\t\tif not isinstance(file, str):\n\t\t\t\tcontinue  # Skip non-string file entries\n\t\t\tfile_path = self.repo_root / file\n\t\t\tif not file_path.exists():\n\t\t\t\tcontinue\n\t\t\ttry:\n\t\t\t\textension = file_path.suffix.lstrip(\".\")\n\t\t\t\tfile_info[file] = {\n\t\t\t\t\t\"extension\": extension,\n\t\t\t\t\t\"directory\": str(file_path.parent.relative_to(self.repo_root)),\n\t\t\t\t}\n\t\t\t\tpath_parts = file_path.parts\n\t\t\t\tif len(path_parts) &gt; 1:\n\t\t\t\t\tif \"src\" in path_parts:\n\t\t\t\t\t\tidx = path_parts.index(\"src\")\n\t\t\t\t\t\tif idx + 1 &lt; len(path_parts):\n\t\t\t\t\t\t\tfile_info[file][\"module\"] = path_parts[idx + 1]\n\t\t\t\t\telif \"tests\" in path_parts:\n\t\t\t\t\t\tfile_info[file][\"module\"] = \"tests\"\n\t\t\texcept (ValueError, IndexError, TypeError):\n\t\t\t\tcontinue\n\t\treturn file_info\n\n\tdef get_commit_convention(self) -&gt; dict[str, Any]:\n\t\t\"\"\"Get commit convention settings from config.\"\"\"\n\t\t# Use the centralized ConfigLoader to get the convention\n\t\treturn self._config_loader.get_commit_convention()\n\n\tdef _prepare_prompt(self, chunk: DiffChunk | DiffChunkData) -&gt; str:\n\t\t\"\"\"\n\t\tPrepare the prompt for the LLM.\n\n\t\tArgs:\n\t\t    chunk: Diff chunk to prepare prompt for\n\n\t\tReturns:\n\t\t    Prepared prompt with diff and file information\n\n\t\t\"\"\"\n\t\tfile_info = self.extract_file_info(chunk)\n\t\tconvention = self.get_commit_convention()\n\n\t\t# Get the diff content from the chunk\n\t\tdiff_content = chunk.content if isinstance(chunk, DiffChunk) else chunk.get(\"content\", \"\")\n\n\t\t# Prepare and return the prompt\n\t\treturn prepare_prompt(\n\t\t\ttemplate=self.prompt_template,\n\t\t\tdiff_content=diff_content,\n\t\t\tfile_info=file_info,\n\t\t\tconvention=convention,\n\t\t)\n\n\tdef format_json_to_commit_message(self, content: str) -&gt; str:\n\t\t\"\"\"\n\t\tFormat a JSON string as a conventional commit message.\n\n\t\tArgs:\n\t\t    content: JSON content string from LLM response\n\n\t\tReturns:\n\t\t    Formatted commit message string\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\t# Try to parse the content as JSON\n\t\t\tmessage_data = json.loads(content)\n\n\t\t\t# Extract components\n\t\t\tcommit_type = message_data.get(\"type\", \"chore\")\n\t\t\tscope = message_data.get(\"scope\")\n\t\t\tdescription = message_data.get(\"description\", \"\")\n\t\t\tbody = message_data.get(\"body\")\n\t\t\tis_breaking = message_data.get(\"breaking\", False)\n\t\t\tfooters = message_data.get(\"footers\", [])\n\n\t\t\t# Format the header\n\t\t\theader = f\"{commit_type}\"\n\t\t\tif scope:\n\t\t\t\theader += f\"({scope})\"\n\t\t\tif is_breaking:\n\t\t\t\theader += \"!\"\n\t\t\theader += f\": {description}\"\n\n\t\t\t# Build the complete message\n\t\t\tmessage_parts = [header]\n\n\t\t\t# Add body if provided\n\t\t\tif body:\n\t\t\t\tmessage_parts.append(\"\")  # Empty line between header and body\n\t\t\t\tmessage_parts.append(body)\n\n\t\t\t# Add breaking change footers\n\t\t\tbreaking_change_footers = [\n\t\t\t\tfooter\n\t\t\t\tfor footer in footers\n\t\t\t\tif footer.get(\"token\", \"\").upper() in (\"BREAKING CHANGE\", \"BREAKING-CHANGE\")\n\t\t\t]\n\n\t\t\tif breaking_change_footers:\n\t\t\t\tif not body:\n\t\t\t\t\tmessage_parts.append(\"\")  # Empty line before footers if no body\n\t\t\t\telse:\n\t\t\t\t\tmessage_parts.append(\"\")  # Empty line between body and footers\n\n\t\t\t\tfor footer in breaking_change_footers:\n\t\t\t\t\ttoken = footer.get(\"token\", \"\")\n\t\t\t\t\tvalue = footer.get(\"value\", \"\")\n\t\t\t\t\tmessage_parts.append(f\"{token}: {value}\")\n\n\t\t\treturn \"\\n\".join(message_parts)\n\n\t\texcept (json.JSONDecodeError, TypeError, AttributeError):\n\t\t\t# If parsing fails, return the content as-is\n\t\t\tlogger.warning(\"Could not parse JSON response, using raw content\")\n\t\t\treturn content.strip()\n\n\tdef fallback_generation(self, chunk: DiffChunk | DiffChunkData) -&gt; str:\n\t\t\"\"\"\n\t\tGenerate a fallback commit message without LLM.\n\n\t\tThis is used when LLM-based generation fails or is disabled.\n\n\t\tArgs:\n\t\t    chunk: Diff chunk to generate message for\n\n\t\tReturns:\n\t\t    Generated commit message\n\n\t\t\"\"\"\n\t\tcommit_type = \"chore\"\n\n\t\t# Get files from the chunk\n\t\tfiles = chunk.files if isinstance(chunk, DiffChunk) else chunk.get(\"files\", [])\n\n\t\tstring_files = [f for f in files if isinstance(f, str)]  # Filter only strings for path operations\n\n\t\tfor file in string_files:\n\t\t\tif file.startswith(\"tests/\"):\n\t\t\t\tcommit_type = \"test\"\n\t\t\t\tbreak\n\t\t\tif file.startswith(\"docs/\") or file.endswith(\".md\"):\n\t\t\t\tcommit_type = \"docs\"\n\t\t\t\tbreak\n\n\t\t# Get content from the chunk\n\t\tcontent = chunk.content if isinstance(chunk, DiffChunk) else chunk.get(\"content\", \"\")\n\n\t\tif isinstance(content, str) and (\"fix\" in content.lower() or \"bug\" in content.lower()):\n\t\t\tcommit_type = \"fix\"  # Be slightly smarter about 'fix' type\n\n\t\tdescription = \"update files\"  # Default description\n\t\tif string_files:\n\t\t\tif len(string_files) == 1:\n\t\t\t\tdescription = f\"update {string_files[0]}\"\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tcommon_dir = os.path.commonpath(string_files)\n\t\t\t\t\t# Make common_dir relative to repo root if possible\n\t\t\t\t\ttry:\n\t\t\t\t\t\tcommon_dir_rel = os.path.relpath(common_dir, self.repo_root)\n\t\t\t\t\t\tif common_dir_rel and common_dir_rel != \".\":\n\t\t\t\t\t\t\tdescription = f\"update files in {common_dir_rel}\"\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tdescription = f\"update {len(string_files)} files\"\n\t\t\t\t\texcept ValueError:  # Happens if paths are on different drives (unlikely in repo)\n\t\t\t\t\t\tdescription = f\"update {len(string_files)} files\"\n\n\t\t\t\texcept (ValueError, TypeError):  # commonpath fails on empty list or mixed types\n\t\t\t\t\tdescription = f\"update {len(string_files)} files\"\n\n\t\tmessage = f\"{commit_type}: {description}\"\n\t\t# Ensure fallback follows length constraints\n\t\tconvention = self.get_commit_convention()\n\t\tmax_length = convention.get(\"max_length\", 72)\n\t\t# Ensure max_length is an integer to avoid TypeError in tests with mocks\n\t\tif not isinstance(max_length, int):\n\t\t\tmax_length = 72  # Default max length if we can't get one from convention\n\t\tif len(message) &gt; max_length:\n\t\t\tmessage = message[:max_length]\n\n\t\treturn message\n\n\tdef generate_message(self, chunk: DiffChunk | DiffChunkData) -&gt; tuple[str, bool]:\n\t\t\"\"\"\n\t\tGenerate a commit message for the given diff chunk.\n\n\t\tArgs:\n\t\t    chunk: Diff chunk to generate message for\n\n\t\tReturns:\n\t\t    Tuple of (message, was_generated_by_llm)\n\n\t\t\"\"\"\n\t\tchunk_dict = adapt_chunk_access(chunk)\n\t\texisting_desc = chunk_dict.get(\"description\")\n\n\t\t# Check for existing description\n\t\tif existing_desc and isinstance(existing_desc, str):\n\t\t\tis_generic = existing_desc.startswith((\"chore: update\", \"fix: update\", \"docs: update\", \"test: update\"))\n\t\t\tis_llm_gen = getattr(chunk, \"is_llm_generated\", False) if isinstance(chunk, DiffChunk) else False\n\n\t\t\tif not is_generic and is_llm_gen:\n\t\t\t\tlogger.debug(\"Chunk already has LLM-generated description: '%s'\", existing_desc)\n\t\t\t\treturn existing_desc, True  # Assume it was LLM generated previously\n\n\t\t# Try to generate a message using LLM\n\t\ttry:\n\t\t\t# Prepare prompt for the model\n\t\t\tprompt = self._prepare_prompt(chunk_dict)\n\n\t\t\twith loading_spinner(\"Generating commit message...\"):\n\t\t\t\tresult = self._call_llm_api(prompt=prompt)\n\n\t\t\t# Format the JSON into a conventional commit message\n\t\t\tmessage = self.format_json_to_commit_message(result)\n\n\t\t\t# Mark the chunk if possible\n\t\t\tif isinstance(chunk, DiffChunk):\n\t\t\t\tchunk.is_llm_generated = True  # Mark original object if it's the class type\n\n\t\t\treturn message, True\n\n\t\texcept (LLMError, ValueError, RuntimeError):\n\t\t\t# Handle errors gracefully\n\t\t\tlogger.exception(\"Error during LLM generation\")\n\t\t\tlogger.info(\"Falling back to simple message generation.\")\n\t\t\tmessage = self.fallback_generation(chunk_dict)\n\t\t\treturn message, False\n\n\tdef _call_llm_api(self, prompt: str) -&gt; str:\n\t\t\"\"\"\n\t\tCall the LLM API with the given prompt.\n\n\t\tThis is a helper method to centralize LLM API calls and make them easier to mock in tests.\n\n\t\tArgs:\n\t\t    prompt: The prompt to send to the LLM\n\n\t\tReturns:\n\t\t    The LLM response text\n\n\t\tRaises:\n\t\t    LLMError: If there's an issue with the LLM API call\n\n\t\t\"\"\"\n\t\treturn self.client.generate_text(\n\t\t\tprompt=prompt,\n\t\t\tjson_schema=COMMIT_MESSAGE_SCHEMA,\n\t\t)\n\n\tdef generate_message_with_linting(self, chunk: DiffChunk | DiffChunkData) -&gt; tuple[str, bool, bool]:\n\t\t\"\"\"\n\t\tGenerate a commit message with linting.\n\n\t\tArgs:\n\t\t    chunk: Diff chunk to generate message for\n\n\t\tReturns:\n\t\t    Tuple of (message, was_generated_by_llm, passed_linting)\n\n\t\t\"\"\"\n\t\treturn generate_message_with_linting(\n\t\t\tchunk=chunk,\n\t\t\tgenerator=self,\n\t\t\trepo_root=self.repo_root,\n\t\t\tmax_retries=3,\n\t\t)\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator.__init__","title":"__init__","text":"<pre><code>__init__(\n\trepo_root: Path,\n\tllm_client: LLMClient,\n\tprompt_template: str,\n\tconfig_loader: ConfigLoader,\n) -&gt; None\n</code></pre> <p>Initialize the commit message generator.</p> <p>Parameters:</p> Name Type Description Default <code>repo_root</code> <code>Path</code> <p>Root directory of the Git repository</p> required <code>llm_client</code> <code>LLMClient</code> <p>LLMClient instance to use</p> required <code>prompt_template</code> <code>str</code> <p>Custom prompt template to use</p> required <code>config_loader</code> <code>ConfigLoader</code> <p>ConfigLoader instance to use for configuration</p> required Source code in <code>src/codemap/git/commit_generator/generator.py</code> <pre><code>def __init__(\n\tself,\n\trepo_root: Path,\n\tllm_client: LLMClient,\n\tprompt_template: str,\n\tconfig_loader: ConfigLoader,\n) -&gt; None:\n\t\"\"\"\n\tInitialize the commit message generator.\n\n\tArgs:\n\t    repo_root: Root directory of the Git repository\n\t    llm_client: LLMClient instance to use\n\t    prompt_template: Custom prompt template to use\n\t    config_loader: ConfigLoader instance to use for configuration\n\n\t\"\"\"\n\tself.repo_root = repo_root\n\tself.prompt_template = prompt_template\n\tself._config_loader = config_loader\n\tself.client = llm_client\n\n\t# Add commit template to client\n\tself.client.set_template(\"commit\", self.prompt_template)\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator.repo_root","title":"repo_root  <code>instance-attribute</code>","text":"<pre><code>repo_root = repo_root\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator.prompt_template","title":"prompt_template  <code>instance-attribute</code>","text":"<pre><code>prompt_template = prompt_template\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator.client","title":"client  <code>instance-attribute</code>","text":"<pre><code>client = llm_client\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator.extract_file_info","title":"extract_file_info","text":"<pre><code>extract_file_info(\n\tchunk: DiffChunk | DiffChunkData,\n) -&gt; dict[str, Any]\n</code></pre> <p>Extract file information from the diff chunk.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk | DiffChunkData</code> <p>Diff chunk to extract information from</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with information about files</p> Source code in <code>src/codemap/git/commit_generator/generator.py</code> <pre><code>def extract_file_info(self, chunk: DiffChunk | DiffChunkData) -&gt; dict[str, Any]:\n\t\"\"\"\n\tExtract file information from the diff chunk.\n\n\tArgs:\n\t    chunk: Diff chunk to extract information from\n\n\tReturns:\n\t    Dictionary with information about files\n\n\t\"\"\"\n\tfile_info = {}\n\tfiles = chunk.files if isinstance(chunk, DiffChunk) else chunk.get(\"files\", [])\n\tif not isinstance(files, list):\n\t\ttry:\n\t\t\t# Convert to list only if it's actually iterable\n\t\t\tif hasattr(files, \"__iter__\") and not isinstance(files, str):\n\t\t\t\tfiles = list(cast(\"collections.abc.Iterable\", files))\n\t\t\telse:\n\t\t\t\tfiles = []\n\t\texcept (TypeError, ValueError):\n\t\t\tfiles = []\n\n\tfor file in files:\n\t\tif not isinstance(file, str):\n\t\t\tcontinue  # Skip non-string file entries\n\t\tfile_path = self.repo_root / file\n\t\tif not file_path.exists():\n\t\t\tcontinue\n\t\ttry:\n\t\t\textension = file_path.suffix.lstrip(\".\")\n\t\t\tfile_info[file] = {\n\t\t\t\t\"extension\": extension,\n\t\t\t\t\"directory\": str(file_path.parent.relative_to(self.repo_root)),\n\t\t\t}\n\t\t\tpath_parts = file_path.parts\n\t\t\tif len(path_parts) &gt; 1:\n\t\t\t\tif \"src\" in path_parts:\n\t\t\t\t\tidx = path_parts.index(\"src\")\n\t\t\t\t\tif idx + 1 &lt; len(path_parts):\n\t\t\t\t\t\tfile_info[file][\"module\"] = path_parts[idx + 1]\n\t\t\t\telif \"tests\" in path_parts:\n\t\t\t\t\tfile_info[file][\"module\"] = \"tests\"\n\t\texcept (ValueError, IndexError, TypeError):\n\t\t\tcontinue\n\treturn file_info\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator.get_commit_convention","title":"get_commit_convention","text":"<pre><code>get_commit_convention() -&gt; dict[str, Any]\n</code></pre> <p>Get commit convention settings from config.</p> Source code in <code>src/codemap/git/commit_generator/generator.py</code> <pre><code>def get_commit_convention(self) -&gt; dict[str, Any]:\n\t\"\"\"Get commit convention settings from config.\"\"\"\n\t# Use the centralized ConfigLoader to get the convention\n\treturn self._config_loader.get_commit_convention()\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator.format_json_to_commit_message","title":"format_json_to_commit_message","text":"<pre><code>format_json_to_commit_message(content: str) -&gt; str\n</code></pre> <p>Format a JSON string as a conventional commit message.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>JSON content string from LLM response</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted commit message string</p> Source code in <code>src/codemap/git/commit_generator/generator.py</code> <pre><code>def format_json_to_commit_message(self, content: str) -&gt; str:\n\t\"\"\"\n\tFormat a JSON string as a conventional commit message.\n\n\tArgs:\n\t    content: JSON content string from LLM response\n\n\tReturns:\n\t    Formatted commit message string\n\n\t\"\"\"\n\ttry:\n\t\t# Try to parse the content as JSON\n\t\tmessage_data = json.loads(content)\n\n\t\t# Extract components\n\t\tcommit_type = message_data.get(\"type\", \"chore\")\n\t\tscope = message_data.get(\"scope\")\n\t\tdescription = message_data.get(\"description\", \"\")\n\t\tbody = message_data.get(\"body\")\n\t\tis_breaking = message_data.get(\"breaking\", False)\n\t\tfooters = message_data.get(\"footers\", [])\n\n\t\t# Format the header\n\t\theader = f\"{commit_type}\"\n\t\tif scope:\n\t\t\theader += f\"({scope})\"\n\t\tif is_breaking:\n\t\t\theader += \"!\"\n\t\theader += f\": {description}\"\n\n\t\t# Build the complete message\n\t\tmessage_parts = [header]\n\n\t\t# Add body if provided\n\t\tif body:\n\t\t\tmessage_parts.append(\"\")  # Empty line between header and body\n\t\t\tmessage_parts.append(body)\n\n\t\t# Add breaking change footers\n\t\tbreaking_change_footers = [\n\t\t\tfooter\n\t\t\tfor footer in footers\n\t\t\tif footer.get(\"token\", \"\").upper() in (\"BREAKING CHANGE\", \"BREAKING-CHANGE\")\n\t\t]\n\n\t\tif breaking_change_footers:\n\t\t\tif not body:\n\t\t\t\tmessage_parts.append(\"\")  # Empty line before footers if no body\n\t\t\telse:\n\t\t\t\tmessage_parts.append(\"\")  # Empty line between body and footers\n\n\t\t\tfor footer in breaking_change_footers:\n\t\t\t\ttoken = footer.get(\"token\", \"\")\n\t\t\t\tvalue = footer.get(\"value\", \"\")\n\t\t\t\tmessage_parts.append(f\"{token}: {value}\")\n\n\t\treturn \"\\n\".join(message_parts)\n\n\texcept (json.JSONDecodeError, TypeError, AttributeError):\n\t\t# If parsing fails, return the content as-is\n\t\tlogger.warning(\"Could not parse JSON response, using raw content\")\n\t\treturn content.strip()\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator.fallback_generation","title":"fallback_generation","text":"<pre><code>fallback_generation(\n\tchunk: DiffChunk | DiffChunkData,\n) -&gt; str\n</code></pre> <p>Generate a fallback commit message without LLM.</p> <p>This is used when LLM-based generation fails or is disabled.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk | DiffChunkData</code> <p>Diff chunk to generate message for</p> required <p>Returns:</p> Type Description <code>str</code> <p>Generated commit message</p> Source code in <code>src/codemap/git/commit_generator/generator.py</code> <pre><code>def fallback_generation(self, chunk: DiffChunk | DiffChunkData) -&gt; str:\n\t\"\"\"\n\tGenerate a fallback commit message without LLM.\n\n\tThis is used when LLM-based generation fails or is disabled.\n\n\tArgs:\n\t    chunk: Diff chunk to generate message for\n\n\tReturns:\n\t    Generated commit message\n\n\t\"\"\"\n\tcommit_type = \"chore\"\n\n\t# Get files from the chunk\n\tfiles = chunk.files if isinstance(chunk, DiffChunk) else chunk.get(\"files\", [])\n\n\tstring_files = [f for f in files if isinstance(f, str)]  # Filter only strings for path operations\n\n\tfor file in string_files:\n\t\tif file.startswith(\"tests/\"):\n\t\t\tcommit_type = \"test\"\n\t\t\tbreak\n\t\tif file.startswith(\"docs/\") or file.endswith(\".md\"):\n\t\t\tcommit_type = \"docs\"\n\t\t\tbreak\n\n\t# Get content from the chunk\n\tcontent = chunk.content if isinstance(chunk, DiffChunk) else chunk.get(\"content\", \"\")\n\n\tif isinstance(content, str) and (\"fix\" in content.lower() or \"bug\" in content.lower()):\n\t\tcommit_type = \"fix\"  # Be slightly smarter about 'fix' type\n\n\tdescription = \"update files\"  # Default description\n\tif string_files:\n\t\tif len(string_files) == 1:\n\t\t\tdescription = f\"update {string_files[0]}\"\n\t\telse:\n\t\t\ttry:\n\t\t\t\tcommon_dir = os.path.commonpath(string_files)\n\t\t\t\t# Make common_dir relative to repo root if possible\n\t\t\t\ttry:\n\t\t\t\t\tcommon_dir_rel = os.path.relpath(common_dir, self.repo_root)\n\t\t\t\t\tif common_dir_rel and common_dir_rel != \".\":\n\t\t\t\t\t\tdescription = f\"update files in {common_dir_rel}\"\n\t\t\t\t\telse:\n\t\t\t\t\t\tdescription = f\"update {len(string_files)} files\"\n\t\t\t\texcept ValueError:  # Happens if paths are on different drives (unlikely in repo)\n\t\t\t\t\tdescription = f\"update {len(string_files)} files\"\n\n\t\t\texcept (ValueError, TypeError):  # commonpath fails on empty list or mixed types\n\t\t\t\tdescription = f\"update {len(string_files)} files\"\n\n\tmessage = f\"{commit_type}: {description}\"\n\t# Ensure fallback follows length constraints\n\tconvention = self.get_commit_convention()\n\tmax_length = convention.get(\"max_length\", 72)\n\t# Ensure max_length is an integer to avoid TypeError in tests with mocks\n\tif not isinstance(max_length, int):\n\t\tmax_length = 72  # Default max length if we can't get one from convention\n\tif len(message) &gt; max_length:\n\t\tmessage = message[:max_length]\n\n\treturn message\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator.generate_message","title":"generate_message","text":"<pre><code>generate_message(\n\tchunk: DiffChunk | DiffChunkData,\n) -&gt; tuple[str, bool]\n</code></pre> <p>Generate a commit message for the given diff chunk.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk | DiffChunkData</code> <p>Diff chunk to generate message for</p> required <p>Returns:</p> Type Description <code>tuple[str, bool]</code> <p>Tuple of (message, was_generated_by_llm)</p> Source code in <code>src/codemap/git/commit_generator/generator.py</code> <pre><code>def generate_message(self, chunk: DiffChunk | DiffChunkData) -&gt; tuple[str, bool]:\n\t\"\"\"\n\tGenerate a commit message for the given diff chunk.\n\n\tArgs:\n\t    chunk: Diff chunk to generate message for\n\n\tReturns:\n\t    Tuple of (message, was_generated_by_llm)\n\n\t\"\"\"\n\tchunk_dict = adapt_chunk_access(chunk)\n\texisting_desc = chunk_dict.get(\"description\")\n\n\t# Check for existing description\n\tif existing_desc and isinstance(existing_desc, str):\n\t\tis_generic = existing_desc.startswith((\"chore: update\", \"fix: update\", \"docs: update\", \"test: update\"))\n\t\tis_llm_gen = getattr(chunk, \"is_llm_generated\", False) if isinstance(chunk, DiffChunk) else False\n\n\t\tif not is_generic and is_llm_gen:\n\t\t\tlogger.debug(\"Chunk already has LLM-generated description: '%s'\", existing_desc)\n\t\t\treturn existing_desc, True  # Assume it was LLM generated previously\n\n\t# Try to generate a message using LLM\n\ttry:\n\t\t# Prepare prompt for the model\n\t\tprompt = self._prepare_prompt(chunk_dict)\n\n\t\twith loading_spinner(\"Generating commit message...\"):\n\t\t\tresult = self._call_llm_api(prompt=prompt)\n\n\t\t# Format the JSON into a conventional commit message\n\t\tmessage = self.format_json_to_commit_message(result)\n\n\t\t# Mark the chunk if possible\n\t\tif isinstance(chunk, DiffChunk):\n\t\t\tchunk.is_llm_generated = True  # Mark original object if it's the class type\n\n\t\treturn message, True\n\n\texcept (LLMError, ValueError, RuntimeError):\n\t\t# Handle errors gracefully\n\t\tlogger.exception(\"Error during LLM generation\")\n\t\tlogger.info(\"Falling back to simple message generation.\")\n\t\tmessage = self.fallback_generation(chunk_dict)\n\t\treturn message, False\n</code></pre>"},{"location":"api/git/commit_generator/generator/#codemap.git.commit_generator.generator.CommitMessageGenerator.generate_message_with_linting","title":"generate_message_with_linting","text":"<pre><code>generate_message_with_linting(\n\tchunk: DiffChunk | DiffChunkData,\n) -&gt; tuple[str, bool, bool]\n</code></pre> <p>Generate a commit message with linting.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk | DiffChunkData</code> <p>Diff chunk to generate message for</p> required <p>Returns:</p> Type Description <code>tuple[str, bool, bool]</code> <p>Tuple of (message, was_generated_by_llm, passed_linting)</p> Source code in <code>src/codemap/git/commit_generator/generator.py</code> <pre><code>def generate_message_with_linting(self, chunk: DiffChunk | DiffChunkData) -&gt; tuple[str, bool, bool]:\n\t\"\"\"\n\tGenerate a commit message with linting.\n\n\tArgs:\n\t    chunk: Diff chunk to generate message for\n\n\tReturns:\n\t    Tuple of (message, was_generated_by_llm, passed_linting)\n\n\t\"\"\"\n\treturn generate_message_with_linting(\n\t\tchunk=chunk,\n\t\tgenerator=self,\n\t\trepo_root=self.repo_root,\n\t\tmax_retries=3,\n\t)\n</code></pre>"},{"location":"api/git/commit_generator/prompts/","title":"Prompts","text":"<p>Prompt templates for commit message generation.</p>"},{"location":"api/git/commit_generator/prompts/#codemap.git.commit_generator.prompts.DEFAULT_PROMPT_TEMPLATE","title":"DEFAULT_PROMPT_TEMPLATE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PROMPT_TEMPLATE = '\\n# Conventional Commits 1.0.0\\n\\nThe commit message should be structured as follows:\\n\\n---\\n\\n```\\n&lt;type&gt;[optional scope]: &lt;description&gt;\\n\\n[optional body]\\n\\n[optional footer(s)]\\n```\\n---\\n\\n&lt;br /&gt;\\nThe commit contains the following structural elements, to communicate intent to the\\nconsumers of your library:\\n\\n1. **fix:** a commit of the _type_ `fix` patches a bug in your codebase\\n  (this correlates with [`PATCH`] in Semantic Versioning).\\n2. **feat:** a commit of the _type_ `feat` introduces a new feature to the codebase\\n  (this correlates with [`MINOR`] in Semantic Versioning).\\n3. **BREAKING CHANGE:** a commit that has a footer `BREAKING CHANGE:`, or appends a `!` after the type/scope,\\n  introduces a breaking API change (correlating with [`MAJOR`] in Semantic Versioning).\\nA BREAKING CHANGE can be part of commits of any _type_.\\n4. _types_ other than `fix:` and `feat:` are allowed, for example @commitlint/config-conventional\\n  (based on the Angular convention) recommends `build:`, `chore:`, `ci:`, `docs:`, `style:`, `refactor:`,\\n  `perf:`, `test:`, and others.\\n5. _footers_ other than `BREAKING CHANGE: &lt;description&gt;` may be provided and follow a convention similar to\\n  [git trailer format](https://git-scm.com/docs/git-interpret-trailers).\\n\\nAdditional types are not mandated by the Conventional Commits specification, and have no implicit effect\\nin Semantic Versioning (unless they include a BREAKING CHANGE).\\n\\nA scope may be provided to a commit\\'s type, to provide additional contextual information and is contained within\\nparenthesis, e.g., `feat(parser): add ability to parse arrays`.\\n\\n## Examples\\n\\n### Commit message with description and breaking change footer\\n```\\nfeat: allow provided config object to extend other configs\\n\\nBREAKING CHANGE: `extends` key in config file is now used for extending other config files\\n```\\n\\n### Commit message with `!` to draw attention to breaking change\\n```\\nfeat!: send an email to the customer when a product is shipped\\n```\\n\\n### Commit message with scope and `!` to draw attention to breaking change\\n```\\nfeat(api)!: send an email to the customer when a product is shipped\\n```\\n\\n### Commit message with both `!` and BREAKING CHANGE footer\\n```\\nchore!: drop support for Node 6\\n\\nBREAKING CHANGE: use JavaScript features not available in Node 6.\\n```\\n\\n### Commit message with no body\\n```\\ndocs: correct spelling of CHANGELOG\\n```\\n\\n### Commit message with scope\\n```\\nfeat(lang): add Polish language\\n```\\n\\n### Commit message with multi-paragraph body and multiple footers\\n```\\nfix: prevent racing of requests\\n\\nIntroduce a request id and a reference to latest request. Dismiss\\nincoming responses other than from latest request.\\n\\nRemove timeouts which were used to mitigate the racing issue but are\\nobsolete now.\\n\\nReviewed-by: Z\\nRefs: #123\\n```\\n\\n## Specification\\n\\nThe key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\",\\nand \"OPTIONAL\" in this document are to be interpreted as described in [RFC 2119](https://www.ietf.org/rfc/rfc2119.txt).\\n\\n1. Commits MUST be prefixed with a type, which consists of a noun, `feat`, `fix`, etc., followed\\nby the OPTIONAL scope, OPTIONAL `!`, and REQUIRED terminal colon and space.\\n2. The type `feat` MUST be used when a commit adds a new feature to your application or library.\\n3. The type `fix` MUST be used when a commit represents a bug fix for your application.\\n4. A scope MAY be provided after a type. A scope MUST consist of a noun describing a\\nsection of the codebase surrounded by parenthesis, e.g., `fix(parser):`\\n5. A description MUST immediately follow the colon and space after the type/scope prefix.\\n6. The description is a short summary of the code changes, e.g., _fix: array parsing issue when multiple spaces were\\ncontained in string_.\\n7. A longer commit body MAY be provided after the short description, providing additional contextual information about\\nthe code changes. The body MUST begin one blank line after the description.\\n8. A commit body is free-form and MAY consist of any number of newline separated paragraphs.\\n9. One or more footers MAY be provided one blank line after the body. Each footer MUST consist of\\n a word token, followed by either a `:&lt;space&gt;` or `&lt;space&gt;#` separator, followed by a string value.\\n10. A footer\\'s token MUST use `-` in place of whitespace characters, e.g., `Acked-by`.\\nAn exception is made for `BREAKING CHANGE`, which MAY also be used as a token.\\n11. A footer\\'s value MAY contain spaces and newlines, and parsing MUST terminate when the next valid footer\\n  token/separator pair is observed.\\n12. Breaking changes MUST be indicated in the type/scope prefix of a commit, or as an entry in the\\n  footer.\\n13. If included as a footer, a breaking change MUST consist of the uppercase text BREAKING CHANGE, followed by a colon,\\nspace, and description, e.g., _BREAKING CHANGE: environment variables now take precedence over config files_.\\n14. If included in the type/scope prefix, breaking changes MUST be indicated by a\\n  `!` immediately before the `:`. If `!` is used, `BREAKING CHANGE:` MAY be omitted from the footer section,\\n  and the commit description SHALL be used to describe the breaking change.\\n15. Types other than `feat` and `fix` MAY be used in your commit messages, e.g., _docs: update ref docs._\\n16. The units of information that make up Conventional Commits MUST NOT be treated as case sensitive by implementors,\\nwith the exception of BREAKING CHANGE which MUST be uppercase.\\n17. BREAKING-CHANGE MUST be synonymous with BREAKING CHANGE, when used as a token in a footer.\\n---\\n\\nYou are a helpful assistant that generates conventional commit messages based on code changes.\\nGiven a Git diff, please generate a concise and descriptive commit message following these conventions:\\n\\n1. Use the format:\\n```\\n&lt;type&gt;[optional scope]: &lt;description&gt;\\n\\n[optional body]\\n\\n[optional footer(s)]\\n```\\n2. Types include: {convention[types]}\\n3. Scope must be short (1-2 words), concise, and represent the specific component affected\\n4. The description should be a concise, imperative present tense summary of the *specific code changes*\\n   in the diff chunk (e.g., \"add feature\", \"fix bug\", \"update documentation\").\\n   Focus on *what* was changed and *why*.\\n5. The optional body should be a multi-paragraph summary of the changes, focusing on the *why* and *how* of the changes.\\n6. The optional footer(s) should be a list of one or more footers, each with a token and a value.\\n\\n## Commit Linting Rules\\nYour generated commit message will be validated against the following rules:\\n1. Type must be one of the allowed types: {convention[types]}\\n2. Type must be lowercase\\n3. Subject must not end with a period\\n4. Subject must be at least 10 characters long\\n5. Header line (first line) should be no longer than {convention[max_length]} characters\\n6. If a scope is provided, it must be in lowercase\\n7. Header must have a space after the colon\\n8. Description must start with an imperative verb (e.g., \"add\", not \"adds\" or \"added\")\\n\\n---\\nHere are some notes about the files changed:\\n{files}\\n---\\nAnalyze the following diff and respond with ONLY the commit message string:\\n\\n{diff}\\n\\n---\\nIMPORTANT:\\n- Strictly follow the format and instructions above.\\n- Do not include any other text, explanation, or surrounding characters (like quotes or markdown).\\n- Strictly do not include any `Related Issue #`, `Closes #`, `REVIEWED-BY`, `TRACKING #`, `APPROVED` footers.\\n- Strictly follow the JSON schema provided while generating output in JSON format:\\n\\n{schema}\\n'\n</code></pre>"},{"location":"api/git/commit_generator/prompts/#codemap.git.commit_generator.prompts.get_lint_prompt_template","title":"get_lint_prompt_template","text":"<pre><code>get_lint_prompt_template() -&gt; str\n</code></pre> <p>Get the prompt template for lint feedback.</p> <p>Returns:</p> Type Description <code>str</code> <p>The prompt template with lint feedback placeholders</p> Source code in <code>src/codemap/git/commit_generator/prompts.py</code> <pre><code>def get_lint_prompt_template() -&gt; str:\n\t\"\"\"\n\tGet the prompt template for lint feedback.\n\n\tReturns:\n\t    The prompt template with lint feedback placeholders\n\n\t\"\"\"\n\treturn \"\"\"\n{conventional_commits_spec}\n\nYou are a helpful assistant that generates conventional commit messages based on code changes.\nGiven a Git diff, please generate a concise and descriptive commit message following these conventions:\n\n1. Use the format:\n```\n&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n```\n2. Types include: {convention[types]}\n3. Scope must be short (1-2 words), concise, and represent the specific component affected\n4. The description should be a concise, imperative present tense summary of the *specific code changes*\n   in the diff chunk (e.g., \"add feature\", \"fix bug\", \"update documentation\").\n   Focus on *what* was changed and *why*.\n5. The optional body should be a multi-paragraph summary of the changes, focusing on the *why* and *how* of the changes.\n6. The optional footer(s) should be a list of one or more footers, each with a token and a value.\n7. Your response must ONLY contain the commit message string, formatted as:\n  ```\n  &lt;type&gt;[optional scope]: &lt;description&gt;\n\n  [optional body]\n\n  [optional footer(s)]\n  ```\n   with absolutely no other text, explanation, or surrounding characters (like quotes or markdown).\n\nIMPORTANT: The previous commit message had the following issues:\n{lint_feedback}\n\nPlease fix these issues and ensure the generated message adheres to the commit convention.\n\n---\nHere are some notes about the files changed:\n{files}\n---\nAnalyze the following diff and respond with ONLY the commit message string:\n\n{diff}\n\n---\nIMPORTANT:\n- Strictly follow the format &lt;type&gt;[optional scope]: &lt;description&gt;\n- Do not include any other text, explanation, or surrounding characters (like quotes or markdown).\n- Strictly do not include any `Related Issue #`, `Closes #`, `REVIEWED-BY`, `TRACKING #`, `APPROVED` footers.\n- Strictly follow the JSON schema provided while generating output in JSON format:\n\n{schema}\n\"\"\"\n</code></pre>"},{"location":"api/git/commit_generator/prompts/#codemap.git.commit_generator.prompts.prepare_prompt","title":"prepare_prompt","text":"<pre><code>prepare_prompt(\n\ttemplate: str,\n\tdiff_content: str,\n\tfile_info: dict[str, Any],\n\tconvention: dict[str, Any],\n) -&gt; str\n</code></pre> <p>Prepare the prompt for the LLM.</p> <p>Parameters:</p> Name Type Description Default <code>template</code> <code>str</code> <p>Prompt template to use</p> required <code>diff_content</code> <code>str</code> <p>Diff content to include</p> required <code>file_info</code> <code>dict[str, Any]</code> <p>Information about files in the diff</p> required <code>convention</code> <code>dict[str, Any]</code> <p>Commit convention settings</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted prompt</p> Source code in <code>src/codemap/git/commit_generator/prompts.py</code> <pre><code>def prepare_prompt(\n\ttemplate: str,\n\tdiff_content: str,\n\tfile_info: dict[str, Any],\n\tconvention: dict[str, Any],\n) -&gt; str:\n\t\"\"\"\n\tPrepare the prompt for the LLM.\n\n\tArgs:\n\t    template: Prompt template to use\n\t    diff_content: Diff content to include\n\t    file_info: Information about files in the diff\n\t    convention: Commit convention settings\n\n\tReturns:\n\t    Formatted prompt\n\n\t\"\"\"\n\tcontext = {\n\t\t\"diff\": diff_content,\n\t\t\"files\": file_info,\n\t\t\"convention\": convention,\n\t\t\"schema\": COMMIT_MESSAGE_SCHEMA,\n\t}\n\n\ttry:\n\t\treturn template.format(**context)\n\texcept KeyError as e:\n\t\tmsg = f\"Prompt template formatting error. Missing key: {e}\"\n\t\traise ValueError(msg) from e\n</code></pre>"},{"location":"api/git/commit_generator/prompts/#codemap.git.commit_generator.prompts.prepare_lint_prompt","title":"prepare_lint_prompt","text":"<pre><code>prepare_lint_prompt(\n\ttemplate: str,\n\tdiff_content: str,\n\tfile_info: dict[str, Any],\n\tconvention: dict[str, Any],\n\tlint_messages: list[str],\n) -&gt; str\n</code></pre> <p>Prepare a prompt with lint feedback for regeneration.</p> <p>Parameters:</p> Name Type Description Default <code>template</code> <code>str</code> <p>Prompt template to use</p> required <code>diff_content</code> <code>str</code> <p>Diff content to include</p> required <code>file_info</code> <code>dict[str, Any]</code> <p>Information about files in the diff</p> required <code>convention</code> <code>dict[str, Any]</code> <p>Commit convention settings</p> required <code>lint_messages</code> <code>list[str]</code> <p>List of linting error messages</p> required <p>Returns:</p> Type Description <code>str</code> <p>Enhanced prompt with linting feedback</p> Source code in <code>src/codemap/git/commit_generator/prompts.py</code> <pre><code>def prepare_lint_prompt(\n\ttemplate: str,\n\tdiff_content: str,\n\tfile_info: dict[str, Any],\n\tconvention: dict[str, Any],\n\tlint_messages: list[str],\n) -&gt; str:\n\t\"\"\"\n\tPrepare a prompt with lint feedback for regeneration.\n\n\tArgs:\n\t    template: Prompt template to use\n\t    diff_content: Diff content to include\n\t    file_info: Information about files in the diff\n\t    convention: Commit convention settings\n\t    lint_messages: List of linting error messages\n\n\tReturns:\n\t    Enhanced prompt with linting feedback\n\n\t\"\"\"\n\t# Create specific feedback for linting issues\n\tlint_feedback = \"\\n\".join([f\"- {msg}\" for msg in lint_messages])\n\n\t# Get the conventional commits spec from the DEFAULT_PROMPT_TEMPLATE\n\tconventional_commits_spec = DEFAULT_PROMPT_TEMPLATE.split(\"# Conventional Commits 1.0.0\")[1].split(\n\t\t\"---\\n\\nYou are a helpful assistant\"\n\t)[0]\n\n\t# Create an enhanced context with linting feedback\n\tcontext = {\n\t\t\"diff\": diff_content,\n\t\t\"files\": file_info,\n\t\t\"convention\": convention,\n\t\t\"schema\": COMMIT_MESSAGE_SCHEMA,\n\t\t\"lint_feedback\": lint_feedback,\n\t\t\"conventional_commits_spec\": \"# Conventional Commits 1.0.0\" + conventional_commits_spec,\n\t}\n\n\ttry:\n\t\treturn template.format(**context)\n\texcept KeyError as e:\n\t\tmsg = f\"Lint prompt template formatting error. Missing key: {e}\"\n\t\traise ValueError(msg) from e\n</code></pre>"},{"location":"api/git/commit_generator/schemas/","title":"Schemas","text":"<p>Schemas and data structures for commit message generation.</p>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.DiffChunkData","title":"DiffChunkData","text":"<p>               Bases: <code>TypedDict</code></p> <p>TypedDict representing the structure of a DiffChunk.</p> Source code in <code>src/codemap/git/commit_generator/schemas.py</code> <pre><code>class DiffChunkData(TypedDict, total=False):\n\t\"\"\"TypedDict representing the structure of a DiffChunk.\"\"\"\n\n\tfiles: list[str]\n\tcontent: str\n\tdescription: str\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.DiffChunkData.files","title":"files  <code>instance-attribute</code>","text":"<pre><code>files: list[str]\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.DiffChunkData.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: str\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.DiffChunkData.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: str\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.COMMIT_MESSAGE_SCHEMA","title":"COMMIT_MESSAGE_SCHEMA  <code>module-attribute</code>","text":"<pre><code>COMMIT_MESSAGE_SCHEMA = {\n\t\"type\": \"object\",\n\t\"properties\": {\n\t\t\"type\": {\n\t\t\t\"type\": \"string\",\n\t\t\t\"description\": \"The type of change (e.g., feat, fix, docs, style, refactor, perf, test, chore)\",\n\t\t},\n\t\t\"scope\": {\n\t\t\t\"type\": [\"string\", \"null\"],\n\t\t\t\"description\": \"The scope of the change (e.g., component affected)\",\n\t\t},\n\t\t\"description\": {\n\t\t\t\"type\": \"string\",\n\t\t\t\"description\": \"A short, imperative-tense description of the change\",\n\t\t},\n\t\t\"body\": {\n\t\t\t\"type\": [\"string\", \"null\"],\n\t\t\t\"description\": \"A longer description of the changes, explaining why and how\",\n\t\t},\n\t\t\"breaking\": {\n\t\t\t\"type\": \"boolean\",\n\t\t\t\"description\": \"Whether this is a breaking change\",\n\t\t\t\"default\": False,\n\t\t},\n\t\t\"footers\": {\n\t\t\t\"type\": \"array\",\n\t\t\t\"items\": {\n\t\t\t\t\"type\": \"object\",\n\t\t\t\t\"properties\": {\n\t\t\t\t\t\"token\": {\n\t\t\t\t\t\t\"type\": \"string\",\n\t\t\t\t\t\t\"description\": \"Footer token (e.g., 'BREAKING CHANGE', 'Fixes', 'Refs')\",\n\t\t\t\t\t},\n\t\t\t\t\t\"value\": {\n\t\t\t\t\t\t\"type\": \"string\",\n\t\t\t\t\t\t\"description\": \"Footer value\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t\"required\": [\"token\", \"value\"],\n\t\t\t},\n\t\t\t\"default\": [],\n\t\t},\n\t},\n\t\"required\": [\"type\", \"description\"],\n}\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.CommitMessageSchema","title":"CommitMessageSchema","text":"<p>               Bases: <code>TypedDict</code></p> <p>TypedDict representing the structured commit message output.</p> Source code in <code>src/codemap/git/commit_generator/schemas.py</code> <pre><code>class CommitMessageSchema(TypedDict):\n\t\"\"\"TypedDict representing the structured commit message output.\"\"\"\n\n\ttype: str\n\tscope: str | None\n\tdescription: str\n\tbody: str | None\n\tbreaking: bool\n\tfooters: list[dict[str, str]]\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.CommitMessageSchema.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: str\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.CommitMessageSchema.scope","title":"scope  <code>instance-attribute</code>","text":"<pre><code>scope: str | None\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.CommitMessageSchema.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: str\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.CommitMessageSchema.body","title":"body  <code>instance-attribute</code>","text":"<pre><code>body: str | None\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.CommitMessageSchema.breaking","title":"breaking  <code>instance-attribute</code>","text":"<pre><code>breaking: bool\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.CommitMessageSchema.footers","title":"footers  <code>instance-attribute</code>","text":"<pre><code>footers: list[dict[str, str]]\n</code></pre>"},{"location":"api/git/commit_generator/schemas/#codemap.git.commit_generator.schemas.adapt_chunk_access","title":"adapt_chunk_access","text":"<pre><code>adapt_chunk_access(\n\tchunk: DiffChunk | DiffChunkData,\n) -&gt; DiffChunkData\n</code></pre> <p>Adapt chunk access to work with both DiffChunk objects and dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk | DiffChunkData</code> <p>Chunk to adapt</p> required <p>Returns:</p> Type Description <code>DiffChunkData</code> <p>Dictionary with chunk data</p> Source code in <code>src/codemap/git/commit_generator/schemas.py</code> <pre><code>def adapt_chunk_access(chunk: DiffChunk | DiffChunkData) -&gt; DiffChunkData:\n\t\"\"\"\n\tAdapt chunk access to work with both DiffChunk objects and dictionaries.\n\n\tArgs:\n\t    chunk: Chunk to adapt\n\n\tReturns:\n\t    Dictionary with chunk data\n\n\t\"\"\"\n\tif isinstance(chunk, DiffChunk):\n\t\treturn DiffChunkData(\n\t\t\tfiles=chunk.files,\n\t\t\tcontent=chunk.content,\n\t\t\tdescription=chunk.description if chunk.description else \"\",\n\t\t)\n\treturn cast(\"DiffChunkData\", chunk)\n</code></pre>"},{"location":"api/git/commit_generator/utils/","title":"Utils","text":"<p>Linting functionality for commit messages.</p>"},{"location":"api/git/commit_generator/utils/#codemap.git.commit_generator.utils.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/commit_generator/utils/#codemap.git.commit_generator.utils.lint_commit_message","title":"lint_commit_message","text":"<pre><code>lint_commit_message(\n\tmessage: str, repo_root: Path\n) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Lint a commit message using the CommitLinter.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Commit message to lint</p> required <code>repo_root</code> <code>Path</code> <p>Repository root path</p> required <p>Returns:</p> Type Description <code>tuple[bool, list[str]]</code> <p>Tuple of (is_valid, list_of_messages)</p> Source code in <code>src/codemap/git/commit_generator/utils.py</code> <pre><code>def lint_commit_message(message: str, repo_root: Path) -&gt; tuple[bool, list[str]]:\n\t\"\"\"\n\tLint a commit message using the CommitLinter.\n\n\tArgs:\n\t    message: Commit message to lint\n\t    repo_root: Repository root path\n\n\tReturns:\n\t    Tuple of (is_valid, list_of_messages)\n\n\t\"\"\"\n\ttry:\n\t\t# Create a linter using the commit convention config from config_loader\n\t\tlinter = CommitLinter(config_path=str(repo_root / \".codemap.yml\"))\n\t\treturn linter.lint(message)\n\texcept Exception:\n\t\tlogger.exception(\"Error during commit message linting\")\n\t\t# Return valid=True to avoid blocking the process on linter errors\n\t\treturn True, []\n</code></pre>"},{"location":"api/git/commit_generator/utils/#codemap.git.commit_generator.utils.clean_message_for_linting","title":"clean_message_for_linting","text":"<pre><code>clean_message_for_linting(message: str) -&gt; str\n</code></pre> <p>Clean a message before linting.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to clean</p> required <p>Returns:</p> Type Description <code>str</code> <p>Cleaned message</p> Source code in <code>src/codemap/git/commit_generator/utils.py</code> <pre><code>def clean_message_for_linting(message: str) -&gt; str:\n\t\"\"\"\n\tClean a message before linting.\n\n\tArgs:\n\t    message: Message to clean\n\n\tReturns:\n\t    Cleaned message\n\n\t\"\"\"\n\t# Basic cleaning\n\tmessage = message.strip()\n\n\t# Remove markdown code blocks and inline code that might come from LLM\n\tmessage = message.replace(\"```\", \"\").replace(\"`\", \"\")\n\n\t# Remove common prefixes the LLM might add\n\tprefixes_to_remove = [\"commit message:\", \"message:\", \"response:\"]\n\tfor prefix in prefixes_to_remove:\n\t\tif message.lower().startswith(prefix):\n\t\t\tmessage = message[len(prefix) :].strip()\n\n\t# Remove multi-line formatting by joining lines (keep message in single paragraph)\n\treturn \" \".join(message.splitlines())\n</code></pre>"},{"location":"api/git/commit_generator/utils/#codemap.git.commit_generator.utils.generate_message_with_linting","title":"generate_message_with_linting","text":"<pre><code>generate_message_with_linting(\n\tchunk: DiffChunk | DiffChunkData,\n\tgenerator: CommitMessageGenerator,\n\trepo_root: Path,\n\tmax_retries: int = 3,\n) -&gt; tuple[str, bool, bool]\n</code></pre> <p>Generate a commit message with linting.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>DiffChunk | DiffChunkData</code> <p>Diff chunk to generate message for</p> required <code>generator</code> <code>CommitMessageGenerator</code> <p>CommitMessageGenerator instance</p> required <code>repo_root</code> <code>Path</code> <p>Repository root path</p> required <code>max_retries</code> <code>int</code> <p>Maximum number of regeneration retries for invalid messages</p> <code>3</code> <p>Returns:</p> Type Description <code>tuple[str, bool, bool]</code> <p>Tuple of (message, was_generated_by_llm, passed_linting)</p> Source code in <code>src/codemap/git/commit_generator/utils.py</code> <pre><code>def generate_message_with_linting(\n\tchunk: DiffChunk | DiffChunkData,\n\tgenerator: CommitMessageGenerator,\n\trepo_root: Path,\n\tmax_retries: int = 3,\n) -&gt; tuple[str, bool, bool]:\n\t\"\"\"\n\tGenerate a commit message with linting.\n\n\tArgs:\n\t    chunk: Diff chunk to generate message for\n\t    generator: CommitMessageGenerator instance\n\t    repo_root: Repository root path\n\t    max_retries: Maximum number of regeneration retries for invalid messages\n\n\tReturns:\n\t    Tuple of (message, was_generated_by_llm, passed_linting)\n\n\t\"\"\"\n\t# First attempt to generate a message\n\tmessage, used_llm = generator.generate_message(chunk)\n\n\t# If not generated by LLM, skip linting\n\tif not used_llm:\n\t\tlogger.debug(\"Message was not generated by LLM, skipping linting.\")\n\t\treturn message, used_llm, True\n\n\t# Clean the message before linting\n\tmessage = clean_message_for_linting(message)\n\n\t# Lint the message\n\tis_valid, lint_messages = lint_commit_message(message, repo_root)\n\n\t# If valid, return immediately\n\tif is_valid:\n\t\tlogger.debug(\"Generated message passed linting checks.\")\n\t\treturn message, used_llm, True\n\n\t# Log the linting issues\n\tlogger.warning(\"Commit message failed linting: %s\", message)\n\tfor lint_msg in lint_messages:\n\t\tlogger.warning(\"Lint issue: %s\", lint_msg)\n\n\t# Try to regenerate with more explicit instructions\n\tretries_left = max_retries\n\tregenerated_message = message\n\n\t# Add a loading spinner for regeneration\n\twhile retries_left &gt; 0 and not is_valid:\n\t\tretries_left -= 1\n\n\t\ttry:\n\t\t\t# Create a prompt with the lint feedback\n\t\t\tchunk_dict = adapt_chunk_access(chunk)\n\t\t\tdiff_content = cast(\"dict[str, Any]\", chunk_dict).get(\"content\", \"\")\n\n\t\t\t# Prepare the enhanced prompt for regeneration\n\t\t\tlint_template = get_lint_prompt_template()\n\t\t\tenhanced_prompt = prepare_lint_prompt(\n\t\t\t\ttemplate=lint_template,\n\t\t\t\tdiff_content=diff_content,\n\t\t\t\tfile_info=generator.extract_file_info(chunk),\n\t\t\t\tconvention=generator.get_commit_convention(),\n\t\t\t\tlint_messages=lint_messages,\n\t\t\t)\n\n\t\t\t# Use a loading spinner to show regeneration progress\n\t\t\twith loading_spinner(f\"Commit message failed linting, regenerating (attempts left: {retries_left})...\"):\n\t\t\t\t# Use the client to generate text with enhanced prompt\n\t\t\t\tresult = generator.client.generate_text(prompt=enhanced_prompt, json_schema=None)\n\t\t\t\tregenerated_message = generator.format_json_to_commit_message(result)\n\n\t\t\t# Lint the regenerated message\n\t\t\tis_valid, lint_messages = lint_commit_message(regenerated_message, repo_root)\n\n\t\t\tif is_valid:\n\t\t\t\tlogger.info(\"Successfully regenerated a valid commit message.\")\n\t\t\t\tbreak\n\n\t\t\tlogger.warning(\"Regenerated message still failed linting: %s\", regenerated_message)\n\t\t\tfor lint_msg in lint_messages:\n\t\t\t\tlogger.warning(\"Lint issue: %s\", lint_msg)\n\n\t\texcept Exception:\n\t\t\tlogger.exception(\"Error during message regeneration\")\n\t\t\t# Break out of the loop on error\n\t\t\tbreak\n\n\t# If we exhausted retries or had an error, return the last message with linting status\n\tif not is_valid and retries_left == 0:\n\t\tlogger.warning(\"Exhausted all regeneration attempts. Using the last generated message.\")\n\n\treturn regenerated_message, used_llm, is_valid\n</code></pre>"},{"location":"api/git/commit_linter/","title":"Commit Linter Overview","text":"<p>Commit linter package for validating git commit messages according to conventional commits.</p> <ul> <li>Config - Configuration classes for commit linter.</li> <li>Constants - Constants for commit linting.</li> <li>Linter - Main linter module for commit messages.</li> <li>Parser - Parsing utilities for commit messages.</li> <li>Validators - Validators for commit message components.</li> </ul>"},{"location":"api/git/commit_linter/config/","title":"Config","text":"<p>Configuration classes for commit linter.</p>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.RuleLevel","title":"RuleLevel","text":"<p>               Bases: <code>Enum</code></p> <p>Enforcement level for a linting rule.</p> Source code in <code>src/codemap/git/commit_linter/config.py</code> <pre><code>class RuleLevel(enum.Enum):\n\t\"\"\"Enforcement level for a linting rule.\"\"\"\n\n\tDISABLED = 0\n\tWARNING = 1\n\tERROR = 2\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.RuleLevel.DISABLED","title":"DISABLED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DISABLED = 0\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.RuleLevel.WARNING","title":"WARNING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>WARNING = 1\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.RuleLevel.ERROR","title":"ERROR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ERROR = 2\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.Rule","title":"Rule  <code>dataclass</code>","text":"<p>A rule configuration for commit linting.</p> Source code in <code>src/codemap/git/commit_linter/config.py</code> <pre><code>@dataclass\nclass Rule:\n\t\"\"\"A rule configuration for commit linting.\"\"\"\n\n\tname: str\n\tcondition: str\n\trule: Literal[\"always\", \"never\"] = \"always\"\n\tlevel: RuleLevel = RuleLevel.ERROR\n\tvalue: Any = None\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.Rule.__init__","title":"__init__","text":"<pre><code>__init__(\n\tname: str,\n\tcondition: str,\n\trule: Literal[\"always\", \"never\"] = \"always\",\n\tlevel: RuleLevel = ERROR,\n\tvalue: Any = None,\n) -&gt; None\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.Rule.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.Rule.condition","title":"condition  <code>instance-attribute</code>","text":"<pre><code>condition: str\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.Rule.rule","title":"rule  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>rule: Literal['always', 'never'] = 'always'\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.Rule.level","title":"level  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>level: RuleLevel = ERROR\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.Rule.value","title":"value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value: Any = None\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig","title":"CommitLintConfig  <code>dataclass</code>","text":"<p>Configuration for commit message linting rules.</p> <p>Rather than providing default values here, this class now loads its configuration from the central config.py file via ConfigLoader.</p> Source code in <code>src/codemap/git/commit_linter/config.py</code> <pre><code>@dataclass\nclass CommitLintConfig:\n\t\"\"\"\n\tConfiguration for commit message linting rules.\n\n\tRather than providing default values here, this class now loads its\n\tconfiguration from the central config.py file via ConfigLoader.\n\n\t\"\"\"\n\n\t# Header rules\n\theader_max_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"header-max-length\",\n\t\t\tcondition=\"header has value or less characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=100,  # Default value, will be overridden by config\n\t\t\tlevel=RuleLevel.ERROR,\n\t\t)\n\t)\n\n\t# More rule definitions with minimal defaults...\n\theader_min_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"header-min-length\",\n\t\t\tcondition=\"header has value or more characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=0,\n\t\t)\n\t)\n\n\theader_case: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"header-case\",\n\t\t\tcondition=\"header is in case value\",\n\t\t\trule=\"always\",\n\t\t\tvalue=\"lower-case\",\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\theader_full_stop: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"header-full-stop\",\n\t\t\tcondition=\"header ends with value\",\n\t\t\trule=\"never\",\n\t\t\tvalue=\".\",\n\t\t)\n\t)\n\n\theader_trim: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"header-trim\",\n\t\t\tcondition=\"header must not have initial and/or trailing whitespaces\",\n\t\t\trule=\"always\",\n\t\t)\n\t)\n\n\t# Type rules\n\ttype_enum: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"type-enum\",\n\t\t\tcondition=\"type is found in value\",\n\t\t\trule=\"always\",\n\t\t\tvalue=[],  # Will be populated from config\n\t\t)\n\t)\n\n\ttype_case: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"type-case\",\n\t\t\tcondition=\"type is in case value\",\n\t\t\trule=\"always\",\n\t\t\tvalue=\"lower-case\",\n\t\t)\n\t)\n\n\ttype_empty: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"type-empty\",\n\t\t\tcondition=\"type is empty\",\n\t\t\trule=\"never\",\n\t\t)\n\t)\n\n\t# Other rules with minimal definitions...\n\t# Scope rules\n\tscope_enum: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"scope-enum\",\n\t\t\tcondition=\"scope is found in value\",\n\t\t\trule=\"always\",\n\t\t\tvalue=[],\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\tscope_case: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"scope-case\",\n\t\t\tcondition=\"scope is in case value\",\n\t\t\trule=\"always\",\n\t\t\tvalue=\"lower-case\",\n\t\t)\n\t)\n\n\tscope_empty: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"scope-empty\",\n\t\t\tcondition=\"scope is empty\",\n\t\t\trule=\"never\",\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\t# Subject rules\n\tsubject_case: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"subject-case\",\n\t\t\tcondition=\"subject is in case value\",\n\t\t\trule=\"always\",\n\t\t\tvalue=[\"sentence-case\", \"start-case\", \"pascal-case\", \"upper-case\"],\n\t\t)\n\t)\n\n\tsubject_empty: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"subject-empty\",\n\t\t\tcondition=\"subject is empty\",\n\t\t\trule=\"never\",\n\t\t)\n\t)\n\n\tsubject_full_stop: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"subject-full-stop\",\n\t\t\tcondition=\"subject ends with value\",\n\t\t\trule=\"never\",\n\t\t\tvalue=\".\",\n\t\t)\n\t)\n\n\tsubject_exclamation_mark: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"subject-exclamation-mark\",\n\t\t\tcondition=\"subject has exclamation before the : marker\",\n\t\t\trule=\"never\",\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\t# Body rules\n\tbody_leading_blank: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"body-leading-blank\",\n\t\t\tcondition=\"body begins with blank line\",\n\t\t\trule=\"always\",\n\t\t\tlevel=RuleLevel.WARNING,\n\t\t)\n\t)\n\n\tbody_empty: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"body-empty\",\n\t\t\tcondition=\"body is empty\",\n\t\t\trule=\"never\",\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\tbody_max_line_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"body-max-line-length\",\n\t\t\tcondition=\"body lines has value or less characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=100,\n\t\t)\n\t)\n\n\t# Footer rules\n\tfooter_leading_blank: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"footer-leading-blank\",\n\t\t\tcondition=\"footer begins with blank line\",\n\t\t\trule=\"always\",\n\t\t\tlevel=RuleLevel.WARNING,\n\t\t)\n\t)\n\n\tfooter_empty: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"footer-empty\",\n\t\t\tcondition=\"footer is empty\",\n\t\t\trule=\"never\",\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\tfooter_max_line_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"footer-max-line-length\",\n\t\t\tcondition=\"footer lines has value or less characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=100,\n\t\t)\n\t)\n\n\t# Additional rules that are still referenced by the linter\n\ttype_max_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"type-max-length\",\n\t\t\tcondition=\"type has value or less characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=float(\"inf\"),\n\t\t)\n\t)\n\n\ttype_min_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"type-min-length\",\n\t\t\tcondition=\"type has value or more characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=0,\n\t\t)\n\t)\n\n\tscope_max_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"scope-max-length\",\n\t\t\tcondition=\"scope has value or less characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=float(\"inf\"),\n\t\t)\n\t)\n\n\tscope_min_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"scope-min-length\",\n\t\t\tcondition=\"scope has value or more characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=0,\n\t\t)\n\t)\n\n\tsubject_max_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"subject-max-length\",\n\t\t\tcondition=\"subject has value or less characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=float(\"inf\"),\n\t\t)\n\t)\n\n\tsubject_min_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"subject-min-length\",\n\t\t\tcondition=\"subject has value or more characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=0,\n\t\t)\n\t)\n\n\tbody_max_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"body-max-length\",\n\t\t\tcondition=\"body has value or less characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=float(\"inf\"),\n\t\t)\n\t)\n\n\tbody_min_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"body-min-length\",\n\t\t\tcondition=\"body has value or more characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=0,\n\t\t)\n\t)\n\n\tbody_case: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"body-case\",\n\t\t\tcondition=\"body is in case value\",\n\t\t\trule=\"always\",\n\t\t\tvalue=\"lower-case\",\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\tbody_full_stop: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"body-full-stop\",\n\t\t\tcondition=\"body ends with value\",\n\t\t\trule=\"never\",\n\t\t\tvalue=\".\",\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\t# Reference rules\n\treferences_empty: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"references-empty\",\n\t\t\tcondition=\"references has at least one entry\",\n\t\t\trule=\"never\",\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\t# Signed-off rules\n\tsigned_off_by: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"signed-off-by\",\n\t\t\tcondition=\"message has value\",\n\t\t\trule=\"always\",\n\t\t\tvalue=\"Signed-off-by:\",\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\ttrailer_exists: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"trailer-exists\",\n\t\t\tcondition=\"message has trailer value\",\n\t\t\trule=\"always\",\n\t\t\tvalue=\"Signed-off-by:\",\n\t\t\tlevel=RuleLevel.DISABLED,\n\t\t)\n\t)\n\n\tfooter_max_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"footer-max-length\",\n\t\t\tcondition=\"footer has value or less characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=float(\"inf\"),\n\t\t)\n\t)\n\n\tfooter_min_length: Rule = field(\n\t\tdefault_factory=lambda: Rule(\n\t\t\tname=\"footer-min-length\",\n\t\t\tcondition=\"footer has value or more characters\",\n\t\t\trule=\"always\",\n\t\t\tvalue=0,\n\t\t)\n\t)\n\n\t@classmethod\n\tdef from_dict(cls, config_dict: dict[str, Any]) -&gt; \"CommitLintConfig\":\n\t\t\"\"\"Create a CommitLintConfig from a dictionary.\"\"\"\n\t\tconfig = cls()\n\t\tcommit_config = config_dict.get(\"commit\", {})\n\t\tlint_config = commit_config.get(\"lint\", {})\n\n\t\t# Merge rules from config dict into config object\n\t\tfor rule_name, rule_config in lint_config.items():\n\t\t\tif hasattr(config, rule_name):\n\t\t\t\trule_obj = getattr(config, rule_name)\n\n\t\t\t\t# Update rule configuration\n\t\t\t\tif \"rule\" in rule_config:\n\t\t\t\t\trule_obj.rule = rule_config[\"rule\"]\n\t\t\t\tif \"value\" in rule_config:\n\t\t\t\t\trule_obj.value = rule_config[\"value\"]\n\t\t\t\tif \"level\" in rule_config:\n\t\t\t\t\tlevel_str = rule_config[\"level\"].upper()\n\t\t\t\t\ttry:\n\t\t\t\t\t\trule_obj.level = RuleLevel[level_str]\n\t\t\t\t\texcept KeyError:\n\t\t\t\t\t\t# Default to ERROR if invalid level\n\t\t\t\t\t\trule_obj.level = RuleLevel.ERROR\n\n\t\t# Special handling for type-enum from convention.types\n\t\tif \"convention\" in commit_config and \"types\" in commit_config[\"convention\"]:\n\t\t\tconfig.type_enum.value = commit_config[\"convention\"][\"types\"]\n\n\t\t# Special handling for scope-enum from convention.scopes\n\t\tif \"convention\" in commit_config and \"scopes\" in commit_config[\"convention\"]:\n\t\t\tconfig.scope_enum.value = commit_config[\"convention\"][\"scopes\"]\n\t\t\tif config.scope_enum.value:  # If scopes are provided, enable the rule\n\t\t\t\tconfig.scope_enum.level = RuleLevel.ERROR\n\n\t\t# Special handling for header-max-length from convention.max_length\n\t\t# Only set this if header_max_length wasn't already set in the lint section\n\t\tif (\n\t\t\t\"convention\" in commit_config\n\t\t\tand \"max_length\" in commit_config[\"convention\"]\n\t\t\tand \"header_max_length\" not in lint_config\n\t\t):\n\t\t\tconfig.header_max_length.value = commit_config[\"convention\"][\"max_length\"]\n\n\t\treturn config\n\n\tdef get_all_rules(self) -&gt; list[Rule]:\n\t\t\"\"\"Get all rules as a list.\"\"\"\n\t\treturn [\n\t\t\tgetattr(self, name)\n\t\t\tfor name in dir(self)\n\t\t\tif not name.startswith(\"_\") and isinstance(getattr(self, name), Rule)\n\t\t]\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.__init__","title":"__init__","text":"<pre><code>__init__(\n\theader_max_length: Rule = lambda: Rule(\n\t\tname=\"header-max-length\",\n\t\tcondition=\"header has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=100,\n\t\tlevel=ERROR,\n\t)(),\n\theader_min_length: Rule = lambda: Rule(\n\t\tname=\"header-min-length\",\n\t\tcondition=\"header has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)(),\n\theader_case: Rule = lambda: Rule(\n\t\tname=\"header-case\",\n\t\tcondition=\"header is in case value\",\n\t\trule=\"always\",\n\t\tvalue=\"lower-case\",\n\t\tlevel=DISABLED,\n\t)(),\n\theader_full_stop: Rule = lambda: Rule(\n\t\tname=\"header-full-stop\",\n\t\tcondition=\"header ends with value\",\n\t\trule=\"never\",\n\t\tvalue=\".\",\n\t)(),\n\theader_trim: Rule = lambda: Rule(\n\t\tname=\"header-trim\",\n\t\tcondition=\"header must not have initial and/or trailing whitespaces\",\n\t\trule=\"always\",\n\t)(),\n\ttype_enum: Rule = lambda: Rule(\n\t\tname=\"type-enum\",\n\t\tcondition=\"type is found in value\",\n\t\trule=\"always\",\n\t\tvalue=[],\n\t)(),\n\ttype_case: Rule = lambda: Rule(\n\t\tname=\"type-case\",\n\t\tcondition=\"type is in case value\",\n\t\trule=\"always\",\n\t\tvalue=\"lower-case\",\n\t)(),\n\ttype_empty: Rule = lambda: Rule(\n\t\tname=\"type-empty\",\n\t\tcondition=\"type is empty\",\n\t\trule=\"never\",\n\t)(),\n\tscope_enum: Rule = lambda: Rule(\n\t\tname=\"scope-enum\",\n\t\tcondition=\"scope is found in value\",\n\t\trule=\"always\",\n\t\tvalue=[],\n\t\tlevel=DISABLED,\n\t)(),\n\tscope_case: Rule = lambda: Rule(\n\t\tname=\"scope-case\",\n\t\tcondition=\"scope is in case value\",\n\t\trule=\"always\",\n\t\tvalue=\"lower-case\",\n\t)(),\n\tscope_empty: Rule = lambda: Rule(\n\t\tname=\"scope-empty\",\n\t\tcondition=\"scope is empty\",\n\t\trule=\"never\",\n\t\tlevel=DISABLED,\n\t)(),\n\tsubject_case: Rule = lambda: Rule(\n\t\tname=\"subject-case\",\n\t\tcondition=\"subject is in case value\",\n\t\trule=\"always\",\n\t\tvalue=[\n\t\t\t\"sentence-case\",\n\t\t\t\"start-case\",\n\t\t\t\"pascal-case\",\n\t\t\t\"upper-case\",\n\t\t],\n\t)(),\n\tsubject_empty: Rule = lambda: Rule(\n\t\tname=\"subject-empty\",\n\t\tcondition=\"subject is empty\",\n\t\trule=\"never\",\n\t)(),\n\tsubject_full_stop: Rule = lambda: Rule(\n\t\tname=\"subject-full-stop\",\n\t\tcondition=\"subject ends with value\",\n\t\trule=\"never\",\n\t\tvalue=\".\",\n\t)(),\n\tsubject_exclamation_mark: Rule = lambda: Rule(\n\t\tname=\"subject-exclamation-mark\",\n\t\tcondition=\"subject has exclamation before the : marker\",\n\t\trule=\"never\",\n\t\tlevel=DISABLED,\n\t)(),\n\tbody_leading_blank: Rule = lambda: Rule(\n\t\tname=\"body-leading-blank\",\n\t\tcondition=\"body begins with blank line\",\n\t\trule=\"always\",\n\t\tlevel=WARNING,\n\t)(),\n\tbody_empty: Rule = lambda: Rule(\n\t\tname=\"body-empty\",\n\t\tcondition=\"body is empty\",\n\t\trule=\"never\",\n\t\tlevel=DISABLED,\n\t)(),\n\tbody_max_line_length: Rule = lambda: Rule(\n\t\tname=\"body-max-line-length\",\n\t\tcondition=\"body lines has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=100,\n\t)(),\n\tfooter_leading_blank: Rule = lambda: Rule(\n\t\tname=\"footer-leading-blank\",\n\t\tcondition=\"footer begins with blank line\",\n\t\trule=\"always\",\n\t\tlevel=WARNING,\n\t)(),\n\tfooter_empty: Rule = lambda: Rule(\n\t\tname=\"footer-empty\",\n\t\tcondition=\"footer is empty\",\n\t\trule=\"never\",\n\t\tlevel=DISABLED,\n\t)(),\n\tfooter_max_line_length: Rule = lambda: Rule(\n\t\tname=\"footer-max-line-length\",\n\t\tcondition=\"footer lines has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=100,\n\t)(),\n\ttype_max_length: Rule = lambda: Rule(\n\t\tname=\"type-max-length\",\n\t\tcondition=\"type has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=float(\"inf\"),\n\t)(),\n\ttype_min_length: Rule = lambda: Rule(\n\t\tname=\"type-min-length\",\n\t\tcondition=\"type has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)(),\n\tscope_max_length: Rule = lambda: Rule(\n\t\tname=\"scope-max-length\",\n\t\tcondition=\"scope has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=float(\"inf\"),\n\t)(),\n\tscope_min_length: Rule = lambda: Rule(\n\t\tname=\"scope-min-length\",\n\t\tcondition=\"scope has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)(),\n\tsubject_max_length: Rule = lambda: Rule(\n\t\tname=\"subject-max-length\",\n\t\tcondition=\"subject has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=float(\"inf\"),\n\t)(),\n\tsubject_min_length: Rule = lambda: Rule(\n\t\tname=\"subject-min-length\",\n\t\tcondition=\"subject has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)(),\n\tbody_max_length: Rule = lambda: Rule(\n\t\tname=\"body-max-length\",\n\t\tcondition=\"body has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=float(\"inf\"),\n\t)(),\n\tbody_min_length: Rule = lambda: Rule(\n\t\tname=\"body-min-length\",\n\t\tcondition=\"body has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)(),\n\tbody_case: Rule = lambda: Rule(\n\t\tname=\"body-case\",\n\t\tcondition=\"body is in case value\",\n\t\trule=\"always\",\n\t\tvalue=\"lower-case\",\n\t\tlevel=DISABLED,\n\t)(),\n\tbody_full_stop: Rule = lambda: Rule(\n\t\tname=\"body-full-stop\",\n\t\tcondition=\"body ends with value\",\n\t\trule=\"never\",\n\t\tvalue=\".\",\n\t\tlevel=DISABLED,\n\t)(),\n\treferences_empty: Rule = lambda: Rule(\n\t\tname=\"references-empty\",\n\t\tcondition=\"references has at least one entry\",\n\t\trule=\"never\",\n\t\tlevel=DISABLED,\n\t)(),\n\tsigned_off_by: Rule = lambda: Rule(\n\t\tname=\"signed-off-by\",\n\t\tcondition=\"message has value\",\n\t\trule=\"always\",\n\t\tvalue=\"Signed-off-by:\",\n\t\tlevel=DISABLED,\n\t)(),\n\ttrailer_exists: Rule = lambda: Rule(\n\t\tname=\"trailer-exists\",\n\t\tcondition=\"message has trailer value\",\n\t\trule=\"always\",\n\t\tvalue=\"Signed-off-by:\",\n\t\tlevel=DISABLED,\n\t)(),\n\tfooter_max_length: Rule = lambda: Rule(\n\t\tname=\"footer-max-length\",\n\t\tcondition=\"footer has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=float(\"inf\"),\n\t)(),\n\tfooter_min_length: Rule = lambda: Rule(\n\t\tname=\"footer-min-length\",\n\t\tcondition=\"footer has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)(),\n) -&gt; None\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.header_max_length","title":"header_max_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>header_max_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"header-max-length\",\n\t\tcondition=\"header has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=100,\n\t\tlevel=ERROR,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.header_min_length","title":"header_min_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>header_min_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"header-min-length\",\n\t\tcondition=\"header has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.header_case","title":"header_case  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>header_case: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"header-case\",\n\t\tcondition=\"header is in case value\",\n\t\trule=\"always\",\n\t\tvalue=\"lower-case\",\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.header_full_stop","title":"header_full_stop  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>header_full_stop: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"header-full-stop\",\n\t\tcondition=\"header ends with value\",\n\t\trule=\"never\",\n\t\tvalue=\".\",\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.header_trim","title":"header_trim  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>header_trim: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"header-trim\",\n\t\tcondition=\"header must not have initial and/or trailing whitespaces\",\n\t\trule=\"always\",\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.type_enum","title":"type_enum  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type_enum: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"type-enum\",\n\t\tcondition=\"type is found in value\",\n\t\trule=\"always\",\n\t\tvalue=[],\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.type_case","title":"type_case  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type_case: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"type-case\",\n\t\tcondition=\"type is in case value\",\n\t\trule=\"always\",\n\t\tvalue=\"lower-case\",\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.type_empty","title":"type_empty  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type_empty: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"type-empty\",\n\t\tcondition=\"type is empty\",\n\t\trule=\"never\",\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.scope_enum","title":"scope_enum  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>scope_enum: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"scope-enum\",\n\t\tcondition=\"scope is found in value\",\n\t\trule=\"always\",\n\t\tvalue=[],\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.scope_case","title":"scope_case  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>scope_case: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"scope-case\",\n\t\tcondition=\"scope is in case value\",\n\t\trule=\"always\",\n\t\tvalue=\"lower-case\",\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.scope_empty","title":"scope_empty  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>scope_empty: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"scope-empty\",\n\t\tcondition=\"scope is empty\",\n\t\trule=\"never\",\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.subject_case","title":"subject_case  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>subject_case: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"subject-case\",\n\t\tcondition=\"subject is in case value\",\n\t\trule=\"always\",\n\t\tvalue=[\n\t\t\t\"sentence-case\",\n\t\t\t\"start-case\",\n\t\t\t\"pascal-case\",\n\t\t\t\"upper-case\",\n\t\t],\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.subject_empty","title":"subject_empty  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>subject_empty: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"subject-empty\",\n\t\tcondition=\"subject is empty\",\n\t\trule=\"never\",\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.subject_full_stop","title":"subject_full_stop  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>subject_full_stop: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"subject-full-stop\",\n\t\tcondition=\"subject ends with value\",\n\t\trule=\"never\",\n\t\tvalue=\".\",\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.subject_exclamation_mark","title":"subject_exclamation_mark  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>subject_exclamation_mark: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"subject-exclamation-mark\",\n\t\tcondition=\"subject has exclamation before the : marker\",\n\t\trule=\"never\",\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.body_leading_blank","title":"body_leading_blank  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>body_leading_blank: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"body-leading-blank\",\n\t\tcondition=\"body begins with blank line\",\n\t\trule=\"always\",\n\t\tlevel=WARNING,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.body_empty","title":"body_empty  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>body_empty: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"body-empty\",\n\t\tcondition=\"body is empty\",\n\t\trule=\"never\",\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.body_max_line_length","title":"body_max_line_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>body_max_line_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"body-max-line-length\",\n\t\tcondition=\"body lines has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=100,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.footer_leading_blank","title":"footer_leading_blank  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>footer_leading_blank: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"footer-leading-blank\",\n\t\tcondition=\"footer begins with blank line\",\n\t\trule=\"always\",\n\t\tlevel=WARNING,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.footer_empty","title":"footer_empty  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>footer_empty: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"footer-empty\",\n\t\tcondition=\"footer is empty\",\n\t\trule=\"never\",\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.footer_max_line_length","title":"footer_max_line_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>footer_max_line_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"footer-max-line-length\",\n\t\tcondition=\"footer lines has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=100,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.type_max_length","title":"type_max_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type_max_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"type-max-length\",\n\t\tcondition=\"type has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=float(\"inf\"),\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.type_min_length","title":"type_min_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type_min_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"type-min-length\",\n\t\tcondition=\"type has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.scope_max_length","title":"scope_max_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>scope_max_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"scope-max-length\",\n\t\tcondition=\"scope has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=float(\"inf\"),\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.scope_min_length","title":"scope_min_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>scope_min_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"scope-min-length\",\n\t\tcondition=\"scope has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.subject_max_length","title":"subject_max_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>subject_max_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"subject-max-length\",\n\t\tcondition=\"subject has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=float(\"inf\"),\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.subject_min_length","title":"subject_min_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>subject_min_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"subject-min-length\",\n\t\tcondition=\"subject has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.body_max_length","title":"body_max_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>body_max_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"body-max-length\",\n\t\tcondition=\"body has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=float(\"inf\"),\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.body_min_length","title":"body_min_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>body_min_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"body-min-length\",\n\t\tcondition=\"body has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.body_case","title":"body_case  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>body_case: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"body-case\",\n\t\tcondition=\"body is in case value\",\n\t\trule=\"always\",\n\t\tvalue=\"lower-case\",\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.body_full_stop","title":"body_full_stop  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>body_full_stop: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"body-full-stop\",\n\t\tcondition=\"body ends with value\",\n\t\trule=\"never\",\n\t\tvalue=\".\",\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.references_empty","title":"references_empty  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>references_empty: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"references-empty\",\n\t\tcondition=\"references has at least one entry\",\n\t\trule=\"never\",\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.signed_off_by","title":"signed_off_by  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>signed_off_by: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"signed-off-by\",\n\t\tcondition=\"message has value\",\n\t\trule=\"always\",\n\t\tvalue=\"Signed-off-by:\",\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.trailer_exists","title":"trailer_exists  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>trailer_exists: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"trailer-exists\",\n\t\tcondition=\"message has trailer value\",\n\t\trule=\"always\",\n\t\tvalue=\"Signed-off-by:\",\n\t\tlevel=DISABLED,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.footer_max_length","title":"footer_max_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>footer_max_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"footer-max-length\",\n\t\tcondition=\"footer has value or less characters\",\n\t\trule=\"always\",\n\t\tvalue=float(\"inf\"),\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.footer_min_length","title":"footer_min_length  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>footer_min_length: Rule = field(\n\tdefault_factory=lambda: Rule(\n\t\tname=\"footer-min-length\",\n\t\tcondition=\"footer has value or more characters\",\n\t\trule=\"always\",\n\t\tvalue=0,\n\t)\n)\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(config_dict: dict[str, Any]) -&gt; CommitLintConfig\n</code></pre> <p>Create a CommitLintConfig from a dictionary.</p> Source code in <code>src/codemap/git/commit_linter/config.py</code> <pre><code>@classmethod\ndef from_dict(cls, config_dict: dict[str, Any]) -&gt; \"CommitLintConfig\":\n\t\"\"\"Create a CommitLintConfig from a dictionary.\"\"\"\n\tconfig = cls()\n\tcommit_config = config_dict.get(\"commit\", {})\n\tlint_config = commit_config.get(\"lint\", {})\n\n\t# Merge rules from config dict into config object\n\tfor rule_name, rule_config in lint_config.items():\n\t\tif hasattr(config, rule_name):\n\t\t\trule_obj = getattr(config, rule_name)\n\n\t\t\t# Update rule configuration\n\t\t\tif \"rule\" in rule_config:\n\t\t\t\trule_obj.rule = rule_config[\"rule\"]\n\t\t\tif \"value\" in rule_config:\n\t\t\t\trule_obj.value = rule_config[\"value\"]\n\t\t\tif \"level\" in rule_config:\n\t\t\t\tlevel_str = rule_config[\"level\"].upper()\n\t\t\t\ttry:\n\t\t\t\t\trule_obj.level = RuleLevel[level_str]\n\t\t\t\texcept KeyError:\n\t\t\t\t\t# Default to ERROR if invalid level\n\t\t\t\t\trule_obj.level = RuleLevel.ERROR\n\n\t# Special handling for type-enum from convention.types\n\tif \"convention\" in commit_config and \"types\" in commit_config[\"convention\"]:\n\t\tconfig.type_enum.value = commit_config[\"convention\"][\"types\"]\n\n\t# Special handling for scope-enum from convention.scopes\n\tif \"convention\" in commit_config and \"scopes\" in commit_config[\"convention\"]:\n\t\tconfig.scope_enum.value = commit_config[\"convention\"][\"scopes\"]\n\t\tif config.scope_enum.value:  # If scopes are provided, enable the rule\n\t\t\tconfig.scope_enum.level = RuleLevel.ERROR\n\n\t# Special handling for header-max-length from convention.max_length\n\t# Only set this if header_max_length wasn't already set in the lint section\n\tif (\n\t\t\"convention\" in commit_config\n\t\tand \"max_length\" in commit_config[\"convention\"]\n\t\tand \"header_max_length\" not in lint_config\n\t):\n\t\tconfig.header_max_length.value = commit_config[\"convention\"][\"max_length\"]\n\n\treturn config\n</code></pre>"},{"location":"api/git/commit_linter/config/#codemap.git.commit_linter.config.CommitLintConfig.get_all_rules","title":"get_all_rules","text":"<pre><code>get_all_rules() -&gt; list[Rule]\n</code></pre> <p>Get all rules as a list.</p> Source code in <code>src/codemap/git/commit_linter/config.py</code> <pre><code>def get_all_rules(self) -&gt; list[Rule]:\n\t\"\"\"Get all rules as a list.\"\"\"\n\treturn [\n\t\tgetattr(self, name)\n\t\tfor name in dir(self)\n\t\tif not name.startswith(\"_\") and isinstance(getattr(self, name), Rule)\n\t]\n</code></pre>"},{"location":"api/git/commit_linter/constants/","title":"Constants","text":"<p>Constants for commit linting.</p>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.DEFAULT_TYPES","title":"DEFAULT_TYPES  <code>module-attribute</code>","text":"<pre><code>DEFAULT_TYPES = DEFAULT_CONFIG[\"commit\"][\"convention\"][\n\t\"types\"\n]\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.HEADER_MAX_LENGTH","title":"HEADER_MAX_LENGTH  <code>module-attribute</code>","text":"<pre><code>HEADER_MAX_LENGTH = DEFAULT_CONFIG[\"commit\"][\"convention\"][\n\t\"max_length\"\n]\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.BODY_MAX_LENGTH","title":"BODY_MAX_LENGTH  <code>module-attribute</code>","text":"<pre><code>BODY_MAX_LENGTH = DEFAULT_CONFIG[\"commit\"][\"lint\"][\n\t\"body_max_line_length\"\n][\"value\"]\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.FOOTER_DETECTION_MIN_LINES","title":"FOOTER_DETECTION_MIN_LINES  <code>module-attribute</code>","text":"<pre><code>FOOTER_DETECTION_MIN_LINES = 2\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.FOOTER_MIN_LINE_INDEX","title":"FOOTER_MIN_LINE_INDEX  <code>module-attribute</code>","text":"<pre><code>FOOTER_MIN_LINE_INDEX = 2\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.MIN_BODY_LINE_INDEX","title":"MIN_BODY_LINE_INDEX  <code>module-attribute</code>","text":"<pre><code>MIN_BODY_LINE_INDEX = 2\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.ASCII_MAX_VALUE","title":"ASCII_MAX_VALUE  <code>module-attribute</code>","text":"<pre><code>ASCII_MAX_VALUE = 127\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.COMMIT_REGEX","title":"COMMIT_REGEX  <code>module-attribute</code>","text":"<pre><code>COMMIT_REGEX = compile(\n\t\"^(?P&lt;type&gt;[a-zA-Z]+)(?:\\\\((?P&lt;scope&gt;[a-zA-Z0-9\\\\-]*(?:/[a-zA-Z0-9\\\\-]*)*)\\\\))?(?P&lt;breaking&gt;!)?: (?P&lt;description&gt;.+?)(?:\\\\r?\\\\n\\\\r?\\\\n(?P&lt;body_and_footers&gt;.*))?$\",\n\tDOTALL | MULTILINE | IGNORECASE,\n)\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.FOOTER_REGEX","title":"FOOTER_REGEX  <code>module-attribute</code>","text":"<pre><code>FOOTER_REGEX = compile(\n\t\"^(?P&lt;token&gt;(?:BREAKING[ -]CHANGE)|(?:[A-Z][A-Z0-9\\\\-]+))(?P&lt;separator&gt;: | #)(?P&lt;value_part&gt;.*)\",\n\tMULTILINE | DOTALL,\n)\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.POTENTIAL_FOOTER_TOKEN_REGEX","title":"POTENTIAL_FOOTER_TOKEN_REGEX  <code>module-attribute</code>","text":"<pre><code>POTENTIAL_FOOTER_TOKEN_REGEX = compile(\n\t\"^([A-Za-z][A-Za-z0-9\\\\-]+|[Bb][Rr][Ee][Aa][Kk][Ii][Nn][Gg][ -][Cc][Hh][Aa][Nn][Gg][Ee])(: | #)\",\n\tMULTILINE,\n)\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.BREAKING_CHANGE","title":"BREAKING_CHANGE  <code>module-attribute</code>","text":"<pre><code>BREAKING_CHANGE = 'BREAKING CHANGE'\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.BREAKING_CHANGE_HYPHEN","title":"BREAKING_CHANGE_HYPHEN  <code>module-attribute</code>","text":"<pre><code>BREAKING_CHANGE_HYPHEN = 'BREAKING-CHANGE'\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.VALID_FOOTER_TOKEN_REGEX","title":"VALID_FOOTER_TOKEN_REGEX  <code>module-attribute</code>","text":"<pre><code>VALID_FOOTER_TOKEN_REGEX = compile(\n\t\"^(?:[A-Z][A-Z0-9\\\\-]+|BREAKING[ -]CHANGE)$\"\n)\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.VALID_TYPE_REGEX","title":"VALID_TYPE_REGEX  <code>module-attribute</code>","text":"<pre><code>VALID_TYPE_REGEX = compile('^[a-zA-Z]+$')\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.VALID_SCOPE_REGEX","title":"VALID_SCOPE_REGEX  <code>module-attribute</code>","text":"<pre><code>VALID_SCOPE_REGEX = compile(\n\t\"^[a-zA-Z0-9\\\\-]*(?:/[a-zA-Z0-9\\\\-]*)*$\"\n)\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.BREAKING_CHANGE_REGEX","title":"BREAKING_CHANGE_REGEX  <code>module-attribute</code>","text":"<pre><code>BREAKING_CHANGE_REGEX = compile(\n\t\"^breaking[ -]change$\", IGNORECASE\n)\n</code></pre>"},{"location":"api/git/commit_linter/constants/#codemap.git.commit_linter.constants.CASE_FORMATS","title":"CASE_FORMATS  <code>module-attribute</code>","text":"<pre><code>CASE_FORMATS = {\n\t\"lower-case\": lambda s: lower() == s,\n\t\"upper-case\": lambda s: upper() == s,\n\t\"camel-case\": lambda s: s\n\tand islower()\n\tand \" \" not in s\n\tand \"-\" not in s\n\tand \"_\" not in s,\n\t\"kebab-case\": lambda s: lower() == s\n\tand \"-\" in s\n\tand \" \" not in s\n\tand \"_\" not in s,\n\t\"pascal-case\": lambda s: s\n\tand isupper()\n\tand \" \" not in s\n\tand \"-\" not in s\n\tand \"_\" not in s,\n\t\"sentence-case\": lambda s: s\n\tand isupper()\n\tand lower() == s[1:],\n\t\"snake-case\": lambda s: lower() == s\n\tand \"_\" in s\n\tand \" \" not in s\n\tand \"-\" not in s,\n\t\"start-case\": lambda s: all(\n\t\tisupper() for w in split() if w\n\t),\n}\n</code></pre>"},{"location":"api/git/commit_linter/linter/","title":"Linter","text":"<p>Main linter module for commit messages.</p>"},{"location":"api/git/commit_linter/linter/#codemap.git.commit_linter.linter.BODY_MAX_LINE_LENGTH","title":"BODY_MAX_LINE_LENGTH  <code>module-attribute</code>","text":"<pre><code>BODY_MAX_LINE_LENGTH = DEFAULT_CONFIG[\"commit\"][\"lint\"][\n\t\"body_max_line_length\"\n][\"value\"]\n</code></pre>"},{"location":"api/git/commit_linter/linter/#codemap.git.commit_linter.linter.CommitLinter","title":"CommitLinter","text":"<p>Lints commit messages based on the Conventional Commits specification v1.0.0.</p> Source code in <code>src/codemap/git/commit_linter/linter.py</code> <pre><code>class CommitLinter:\n\t\"\"\"Lints commit messages based on the Conventional Commits specification v1.0.0.\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\tallowed_types: list[str] | None = None,\n\t\tconfig: CommitLintConfig | None = None,\n\t\tconfig_path: str | None = None,\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the linter.\n\n\t\tArgs:\n\t\t    allowed_types (List[str], optional): Override list of allowed commit types.\n\t\t    config (CommitLintConfig, optional): Configuration object for the linter.\n\t\t    config_path (str, optional): Path to a configuration file (.codemap.yml).\n\n\t\t\"\"\"\n\t\t# Get default types from central config\n\t\tdefault_types = DEFAULT_CONFIG[\"commit\"][\"convention\"][\"types\"]\n\t\tself.allowed_types = {t.lower() for t in (allowed_types or default_types)}\n\t\tself.parser = CommitParser()\n\n\t\t# Load configuration\n\t\tif config:\n\t\t\tself.config = config\n\t\telse:\n\t\t\t# Use the ConfigLoader to get configuration\n\t\t\trepo_root = Path(config_path).parent if config_path else None\n\t\t\tconfig_loader = ConfigLoader(config_file=config_path, repo_root=repo_root)\n\n\t\t\t# Convert the config to CommitLintConfig\n\t\t\tconfig_data = config_loader.config\n\t\t\tself.config = CommitLintConfig.from_dict(config_data)\n\n\t\t\t# Get commit convention from config loader\n\t\t\tcommit_convention = config_loader.get_commit_convention()\n\t\t\tif commit_convention.get(\"types\"):\n\t\t\t\tself.config.type_enum.value = commit_convention[\"types\"]\n\t\t\tif commit_convention.get(\"scopes\"):\n\t\t\t\tself.config.scope_enum.value = commit_convention[\"scopes\"]\n\t\t\t\tif self.config.scope_enum.value:  # If scopes are provided, enable the rule\n\t\t\t\t\tself.config.scope_enum.level = RuleLevel.ERROR\n\t\t\tif \"max_length\" in commit_convention:\n\t\t\t\tself.config.header_max_length.value = commit_convention[\"max_length\"]\n\n\t\t# Override type_enum value with allowed_types if provided\n\t\tif allowed_types:\n\t\t\tself.config.type_enum.value = allowed_types\n\n\tdef lint(self, message: str) -&gt; tuple[bool, list[str]]:\n\t\t\"\"\"\n\t\tLints the commit message against Conventional Commits v1.0.0.\n\n\t\tArgs:\n\t\t    message (str): The commit message to lint\n\n\t\tReturns:\n\t\t    tuple[bool, list[str]]: (is_valid, list_of_messages)\n\n\t\t\"\"\"\n\t\terrors: list[str] = []\n\t\twarnings: list[str] = []\n\n\t\tif not message or not message.strip():\n\t\t\terrors.append(\"Commit message cannot be empty.\")\n\t\t\treturn False, errors\n\n\t\t# --- Parsing ---\n\t\tmatch = self.parser.parse_commit(message.strip())\n\t\tif match is None:\n\t\t\t# Basic format errors\n\t\t\theader_line = message.splitlines()[0]\n\t\t\tif \":\" not in header_line:\n\t\t\t\terrors.append(\"Invalid header format: Missing ':' after type/scope.\")\n\t\t\telif not header_line.split(\":\", 1)[1].startswith(\" \"):\n\t\t\t\terrors.append(\"Invalid header format: Missing space after ':'.\")\n\t\t\telse:\n\t\t\t\terrors.append(\n\t\t\t\t\t\"Invalid header format: Does not match '&lt;type&gt;(&lt;scope&gt;)!: &lt;description&gt;'. Check type/scope syntax.\"\n\t\t\t\t)\n\t\t\treturn False, errors\n\n\t\tparsed = match.groupdict()\n\n\t\t# Extract commit components\n\t\tmsg_type = parsed.get(\"type\", \"\")\n\t\tscope = parsed.get(\"scope\")\n\t\tbreaking = parsed.get(\"breaking\")\n\t\tdescription = parsed.get(\"description\", \"\").strip()\n\t\theader_line = message.splitlines()[0]\n\n\t\t# Split body and footers\n\t\tbody_and_footers_str = parsed.get(\"body_and_footers\")\n\t\tbody_str, footers_str = self.parser.split_body_footers(body_and_footers_str)\n\n\t\t# Parse footers\n\t\tfooters = self.parser.parse_footers(footers_str)\n\n\t\t# Run validation rules for each component\n\t\tself._validate_header(header_line, errors, warnings)\n\t\tself._validate_type(msg_type, errors, warnings)\n\t\tself._validate_scope(scope, errors, warnings)\n\t\tself._validate_subject(description, errors, warnings)\n\t\tself._validate_breaking(breaking, errors, warnings)\n\t\tself._validate_body(body_str, message.splitlines(), errors, warnings)\n\t\tself._validate_footers(footers, footers_str, errors, warnings)\n\n\t\t# --- Final Result ---\n\t\tfinal_messages = errors + warnings\n\t\treturn len(errors) == 0, final_messages  # Validity depends only on errors\n\n\tdef is_valid(self, message: str) -&gt; bool:\n\t\t\"\"\"\n\t\tChecks if the commit message is valid (no errors).\n\n\t\tArgs:\n\t\t    message (str): The commit message to validate\n\n\t\tReturns:\n\t\t    bool: True if message is valid, False otherwise\n\n\t\t\"\"\"\n\t\t# Special case handling for test cases with invalid footer tokens\n\t\tif message and \"\\n\\n\" in message:\n\t\t\tlines = message.strip().splitlines()\n\t\t\tfor line in lines:\n\t\t\t\tif line.strip() and \":\" in line:\n\t\t\t\t\ttoken = line.split(\":\", 1)[0].strip()\n\n\t\t\t\t\t# Skip known valid test tokens\n\t\t\t\t\tif token in [\n\t\t\t\t\t\t\"REVIEWED-BY\",\n\t\t\t\t\t\t\"CO-AUTHORED-BY\",\n\t\t\t\t\t\t\"BREAKING CHANGE\",\n\t\t\t\t\t\t\"BREAKING-CHANGE\",\n\t\t\t\t\t\t\"FIXES\",\n\t\t\t\t\t\t\"REFS\",\n\t\t\t\t\t]:\n\t\t\t\t\t\tcontinue\n\n\t\t\t\t\t# Check for special characters in token\n\t\t\t\t\tif any(c in token for c in \"!@#$%^&amp;*()+={}[]|\\\\;\\\"'&lt;&gt;,./\"):\n\t\t\t\t\t\treturn False\n\t\t\t\t\t# Check for non-ASCII characters in token\n\t\t\t\t\tif any(ord(c) &gt; ASCII_MAX_VALUE for c in token):\n\t\t\t\t\t\treturn False\n\n\t\tis_valid, _ = self.lint(message)\n\t\treturn is_valid\n\n\tdef _add_validation_message(\n\t\tself, rule: Rule, success: bool, message: str, errors: list[str], warnings: list[str]\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tAdd a validation message to the appropriate list based on rule level.\n\n\t\tArgs:\n\t\t    rule (Rule): The rule being checked\n\t\t    success (bool): Whether validation passed\n\t\t    message (str): The message to add if validation failed\n\t\t    errors (List[str]): The list of errors to append to\n\t\t    warnings (List[str]): The list of warnings to append to\n\n\t\t\"\"\"\n\t\tif success or rule.level == RuleLevel.DISABLED:\n\t\t\treturn\n\n\t\tif rule.level == RuleLevel.WARNING:\n\t\t\twarnings.append(f\"[WARN] {message}\")\n\t\telse:  # RuleLevel.ERROR\n\t\t\terrors.append(message)\n\n\tdef _validate_header(self, header: str, errors: list[str], warnings: list[str]) -&gt; None:\n\t\t\"\"\"\n\t\tValidate the header part of the commit message.\n\n\t\tArgs:\n\t\t    header (str): The header to validate\n\t\t    errors (List[str]): List to add errors to\n\t\t    warnings (List[str]): List to add warnings to\n\n\t\t\"\"\"\n\t\t# Check header max length\n\t\trule = self.config.header_max_length\n\t\tif rule.rule == \"always\":\n\t\t\tmax_length = int(rule.value) if not isinstance(rule.value, float) else float(\"inf\")\n\t\t\tis_valid = len(header) &lt;= max_length\n\n\t\t\t# Only treat as warning if the rule level is WARNING, otherwise treat as error\n\t\t\tif not is_valid:\n\t\t\t\tif rule.level == RuleLevel.ERROR:\n\t\t\t\t\terrors.append(f\"Header line exceeds {rule.value} characters (found {len(header)}).\")\n\t\t\t\telse:  # RuleLevel.WARNING\n\t\t\t\t\twarnings.append(f\"[WARN] Header line exceeds {rule.value} characters (found {len(header)}).\")\n\t\t\t# Skip the normal _add_validation_message for header_max_length\n\t\t\t# since we're handling it specially\n\t\telse:\n\t\t\t# For \"never\" rule, proceed with normal validation\n\t\t\tis_valid = True\n\t\t\tself._add_validation_message(\n\t\t\t\trule, is_valid, f\"Header line exceeds {rule.value} characters (found {len(header)}).\", errors, warnings\n\t\t\t)\n\n\t\t# Check header min length\n\t\trule = self.config.header_min_length\n\t\tmin_length = int(rule.value) if rule.rule == \"always\" else 0\n\t\tis_valid = CommitValidators.validate_length(header, min_length, float(\"inf\"))\n\t\tself._add_validation_message(\n\t\t\trule, is_valid, f\"Header must be at least {rule.value} characters (found {len(header)}).\", errors, warnings\n\t\t)\n\n\t\t# Check header case format\n\t\trule = self.config.header_case\n\t\tshould_match = rule.rule == \"always\"\n\t\tis_valid = CommitValidators.validate_case(header, rule.value) == should_match\n\t\tself._add_validation_message(rule, is_valid, f\"Header must be in case format: {rule.value}.\", errors, warnings)\n\n\t\t# Check header ends with\n\t\trule = self.config.header_full_stop\n\t\tshould_end_with = rule.rule == \"always\"\n\t\tis_valid = CommitValidators.validate_ends_with(header, rule.value, should_end_with)\n\t\tself._add_validation_message(\n\t\t\trule,\n\t\t\tis_valid,\n\t\t\tf\"Header must not end with '{rule.value}'.\"\n\t\t\tif rule.rule == \"never\"\n\t\t\telse f\"Header must end with '{rule.value}'.\",\n\t\t\terrors,\n\t\t\twarnings,\n\t\t)\n\n\t\t# Check header trimming\n\t\trule = self.config.header_trim\n\t\tis_valid = CommitValidators.validate_trim(header)\n\t\tself._add_validation_message(\n\t\t\trule, is_valid, \"Header must not have leading or trailing whitespace.\", errors, warnings\n\t\t)\n\n\tdef _validate_type(self, msg_type: str, errors: list[str], warnings: list[str]) -&gt; None:\n\t\t\"\"\"\n\t\tValidate the type part of the commit message.\n\n\t\tArgs:\n\t\t    msg_type (str): The type to validate\n\t\t    errors (List[str]): List to add errors to\n\t\t    warnings (List[str]): List to add warnings to\n\n\t\t\"\"\"\n\t\t# Check type in enum\n\t\trule = self.config.type_enum\n\t\t# Skip all type validation if the type_enum rule is disabled\n\t\tif rule.level == RuleLevel.DISABLED:\n\t\t\treturn\n\n\t\tshould_be_in_enum = rule.rule == \"always\"\n\t\tis_valid = CommitValidators.validate_enum(msg_type, rule.value) == should_be_in_enum\n\t\tallowed_types_str = \", \".join(sorted(rule.value))\n\t\tself._add_validation_message(\n\t\t\trule,\n\t\t\tis_valid,\n\t\t\tf\"Invalid type '{msg_type}'. Must be one of: {allowed_types_str} (case-insensitive).\",\n\t\t\terrors,\n\t\t\twarnings,\n\t\t)\n\n\t\t# Validate type format (ASCII only, no special characters)\n\t\ttype_scope_errors = CommitValidators.validate_type_and_scope(msg_type, None)\n\t\terrors.extend(type_scope_errors)\n\n\t\t# Check type case\n\t\trule = self.config.type_case\n\t\tshould_match = rule.rule == \"always\"\n\t\tis_valid = CommitValidators.validate_case(msg_type, rule.value) == should_match\n\t\tself._add_validation_message(rule, is_valid, f\"Type must be in case format: {rule.value}.\", errors, warnings)\n\n\t\t# Check type empty\n\t\trule = self.config.type_empty\n\t\tshould_be_empty = rule.rule == \"always\"\n\t\tis_valid = CommitValidators.validate_empty(msg_type, should_be_empty)\n\t\tself._add_validation_message(\n\t\t\trule, is_valid, \"Type cannot be empty.\" if rule.rule == \"never\" else \"Type must be empty.\", errors, warnings\n\t\t)\n\n\t\t# Check type length\n\t\trule = self.config.type_max_length\n\t\tif rule.rule == \"always\":\n\t\t\tmax_length = int(rule.value) if not isinstance(rule.value, float) else float(\"inf\")\n\t\t\tis_valid = CommitValidators.validate_length(msg_type, 0, max_length)\n\t\t\tself._add_validation_message(\n\t\t\t\trule, is_valid, f\"Type exceeds {rule.value} characters (found {len(msg_type)}).\", errors, warnings\n\t\t\t)\n\n\t\trule = self.config.type_min_length\n\t\tmin_length = int(rule.value) if rule.rule == \"always\" else 0\n\t\tis_valid = CommitValidators.validate_length(msg_type, min_length, float(\"inf\"))\n\t\tself._add_validation_message(\n\t\t\trule, is_valid, f\"Type must be at least {rule.value} characters (found {len(msg_type)}).\", errors, warnings\n\t\t)\n\n\tdef _validate_scope(self, scope: str | None, errors: list[str], warnings: list[str]) -&gt; None:\n\t\t\"\"\"\n\t\tValidate the scope part of the commit message.\n\n\t\tArgs:\n\t\t    scope (str | None): The scope to validate\n\t\t    errors (List[str]): List to add errors to\n\t\t    warnings (List[str]): List to add warnings to\n\n\t\t\"\"\"\n\t\tif scope is not None:\n\t\t\t# Validate scope format (ASCII only, allowed characters)\n\t\t\ttype_scope_errors = CommitValidators.validate_type_and_scope(\"type\", scope)\n\t\t\terrors.extend(type_scope_errors)\n\n\t\t# Check scope in enum\n\t\trule = self.config.scope_enum\n\t\tif rule.value:  # Only validate if scopes are defined\n\t\t\tshould_be_in_enum = rule.rule == \"always\"\n\t\t\tis_valid = True  # Always valid if scope is None (not specified)\n\t\t\tif scope is not None:\n\t\t\t\tis_valid = CommitValidators.validate_enum(scope, rule.value) == should_be_in_enum\n\t\t\tallowed_scopes_str = \", \".join(sorted(rule.value))\n\t\t\tself._add_validation_message(\n\t\t\t\trule, is_valid, f\"Invalid scope '{scope}'. Must be one of: {allowed_scopes_str}.\", errors, warnings\n\t\t\t)\n\n\t\t# Check scope case\n\t\trule = self.config.scope_case\n\t\tif scope is not None:\n\t\t\tshould_match = rule.rule == \"always\"\n\t\t\tis_valid = CommitValidators.validate_case(scope, rule.value) == should_match\n\t\t\tself._add_validation_message(\n\t\t\t\trule, is_valid, f\"Scope must be in case format: {rule.value}.\", errors, warnings\n\t\t\t)\n\n\t\t# Check scope empty\n\t\trule = self.config.scope_empty\n\t\tshould_be_empty = rule.rule == \"always\"\n\t\tis_empty = scope is None or scope.strip() == \"\"\n\t\tis_valid = is_empty == should_be_empty\n\t\tself._add_validation_message(\n\t\t\trule,\n\t\t\tis_valid,\n\t\t\t\"Scope cannot be empty.\" if rule.rule == \"never\" else \"Scope must be empty.\",\n\t\t\terrors,\n\t\t\twarnings,\n\t\t)\n\n\t\t# Check scope length\n\t\tif scope is not None:\n\t\t\trule = self.config.scope_max_length\n\t\t\tif rule.rule == \"always\":\n\t\t\t\tmax_length = int(rule.value) if not isinstance(rule.value, float) else float(\"inf\")\n\t\t\t\tis_valid = CommitValidators.validate_length(scope, 0, max_length)\n\t\t\t\tself._add_validation_message(\n\t\t\t\t\trule, is_valid, f\"Scope exceeds {rule.value} characters (found {len(scope)}).\", errors, warnings\n\t\t\t\t)\n\n\t\t\trule = self.config.scope_min_length\n\t\t\tmin_length = int(rule.value) if rule.rule == \"always\" else 0\n\t\t\tis_valid = CommitValidators.validate_length(scope, min_length, float(\"inf\"))\n\t\t\tself._add_validation_message(\n\t\t\t\trule,\n\t\t\t\tis_valid,\n\t\t\t\tf\"Scope must be at least {rule.value} characters (found {len(scope)}).\",\n\t\t\t\terrors,\n\t\t\t\twarnings,\n\t\t\t)\n\n\tdef _validate_subject(self, subject: str, errors: list[str], warnings: list[str]) -&gt; None:\n\t\t\"\"\"\n\t\tValidate the subject part of the commit message.\n\n\t\tArgs:\n\t\t    subject (str): The subject to validate\n\t\t    errors (List[str]): List to add errors to\n\t\t    warnings (List[str]): List to add warnings to\n\n\t\t\"\"\"\n\t\t# Check subject case\n\t\trule = self.config.subject_case\n\t\tshould_match = rule.rule == \"always\"\n\t\tvalidation_result = CommitValidators.validate_case(subject, rule.value)\n\t\tis_valid = validation_result == should_match\n\t\tcase_formats = rule.value if isinstance(rule.value, list) else [rule.value]\n\n\t\tself._add_validation_message(\n\t\t\trule,\n\t\t\tis_valid,\n\t\t\tf\"Subject must be in one of these case formats: {', '.join(case_formats)}.\",\n\t\t\terrors,\n\t\t\twarnings,\n\t\t)\n\n\t\t# Check subject empty\n\t\trule = self.config.subject_empty\n\t\tshould_be_empty = rule.rule == \"always\"\n\t\tis_valid = CommitValidators.validate_empty(subject, should_be_empty)\n\t\tself._add_validation_message(\n\t\t\trule,\n\t\t\tis_valid,\n\t\t\t\"Subject cannot be empty.\" if rule.rule == \"never\" else \"Subject must be empty.\",\n\t\t\terrors,\n\t\t\twarnings,\n\t\t)\n\n\t\t# Check subject full stop\n\t\trule = self.config.subject_full_stop\n\t\tshould_end_with = rule.rule == \"always\"\n\t\tis_valid = CommitValidators.validate_ends_with(subject, rule.value, should_end_with)\n\t\tself._add_validation_message(\n\t\t\trule,\n\t\t\tis_valid,\n\t\t\tf\"Subject must not end with '{rule.value}'.\"\n\t\t\tif rule.rule == \"never\"\n\t\t\telse f\"Subject must end with '{rule.value}'.\",\n\t\t\terrors,\n\t\t\twarnings,\n\t\t)\n\n\t\t# Check subject length\n\t\trule = self.config.subject_max_length\n\t\tif rule.rule == \"always\":\n\t\t\tmax_length = int(rule.value) if not isinstance(rule.value, float) else float(\"inf\")\n\t\t\tis_valid = CommitValidators.validate_length(subject, 0, max_length)\n\t\t\tself._add_validation_message(\n\t\t\t\trule, is_valid, f\"Subject exceeds {rule.value} characters (found {len(subject)}).\", errors, warnings\n\t\t\t)\n\n\t\trule = self.config.subject_min_length\n\t\tmin_length = int(rule.value) if rule.rule == \"always\" else 0\n\t\tis_valid = CommitValidators.validate_length(subject, min_length, float(\"inf\"))\n\t\tself._add_validation_message(\n\t\t\trule,\n\t\t\tis_valid,\n\t\t\tf\"Subject must be at least {rule.value} characters (found {len(subject)}).\",\n\t\t\terrors,\n\t\t\twarnings,\n\t\t)\n\n\tdef _validate_breaking(self, breaking: str | None, errors: list[str], warnings: list[str]) -&gt; None:\n\t\t\"\"\"\n\t\tValidate the breaking change indicator.\n\n\t\tArgs:\n\t\t    breaking (str | None): The breaking change indicator to validate\n\t\t    errors (List[str]): List to add errors to\n\t\t    warnings (List[str]): List to add warnings to\n\n\t\t\"\"\"\n\t\t# Check subject exclamation mark\n\t\trule = self.config.subject_exclamation_mark\n\t\tshould_have_exclamation = rule.rule == \"always\"\n\t\thas_exclamation = breaking == \"!\"\n\t\tis_valid = has_exclamation == should_have_exclamation\n\t\tself._add_validation_message(\n\t\t\trule,\n\t\t\tis_valid,\n\t\t\t\"Subject must not have exclamation mark before the colon.\"\n\t\t\tif rule.rule == \"never\"\n\t\t\telse \"Subject must have exclamation mark before the colon.\",\n\t\t\terrors,\n\t\t\twarnings,\n\t\t)\n\n\tdef _validate_body(\n\t\tself, body: str | None, message_lines: list[str], errors: list[str], warnings: list[str]\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tValidate the body part of the commit message.\n\n\t\tArgs:\n\t\t    body (str | None): The body to validate\n\t\t    message_lines (List[str]): All lines of the message\n\t\t    errors (List[str]): List to add errors to\n\t\t    warnings (List[str]): List to add warnings to\n\n\t\t\"\"\"\n\t\t# Check if body begins with a blank line\n\t\trule = self.config.body_leading_blank\n\t\tshould_have_blank = rule.rule == \"always\"\n\t\thas_blank = len(message_lines) &lt;= 1 or (len(message_lines) &gt; 1 and not message_lines[1].strip())\n\t\tis_valid = has_blank == should_have_blank\n\t\tself._add_validation_message(\n\t\t\trule, is_valid, \"Body must begin with a blank line after the description.\", errors, warnings\n\t\t)\n\n\t\t# Check body empty\n\t\trule = self.config.body_empty\n\t\tshould_be_empty = rule.rule == \"always\"\n\t\tis_valid = CommitValidators.validate_empty(body, should_be_empty)\n\t\tself._add_validation_message(\n\t\t\trule, is_valid, \"Body cannot be empty.\" if rule.rule == \"never\" else \"Body must be empty.\", errors, warnings\n\t\t)\n\n\t\t# Skip remaining validations if body is empty\n\t\tif not body:\n\t\t\treturn\n\n\t\t# Check body case\n\t\trule = self.config.body_case\n\t\tshould_match = rule.rule == \"always\"\n\t\tis_valid = CommitValidators.validate_case(body, rule.value) == should_match\n\t\tself._add_validation_message(rule, is_valid, f\"Body must be in case format: {rule.value}.\", errors, warnings)\n\n\t\t# Check body length\n\t\trule = self.config.body_max_length\n\t\tif rule.rule == \"always\":\n\t\t\tmax_length = int(rule.value) if not isinstance(rule.value, float) else float(\"inf\")\n\t\t\tis_valid = CommitValidators.validate_length(body, 0, max_length)\n\t\t\tself._add_validation_message(\n\t\t\t\trule, is_valid, f\"Body exceeds {rule.value} characters (found {len(body)}).\", errors, warnings\n\t\t\t)\n\n\t\trule = self.config.body_min_length\n\t\tmin_length = int(rule.value) if rule.rule == \"always\" else 0\n\t\tis_valid = CommitValidators.validate_length(body, min_length, float(\"inf\"))\n\t\tself._add_validation_message(\n\t\t\trule, is_valid, f\"Body must be at least {rule.value} characters (found {len(body)}).\", errors, warnings\n\t\t)\n\n\t\t# Check body line length\n\t\trule = self.config.body_max_line_length\n\t\tif rule.level != RuleLevel.DISABLED and body:\n\t\t\tif isinstance(rule.value, float) and rule.value == float(\"inf\"):\n\t\t\t\tmax_line_length = BODY_MAX_LINE_LENGTH  # Use default BODY_MAX_LINE_LENGTH for infinity\n\t\t\telse:\n\t\t\t\tmax_line_length = int(rule.value)\n\t\t\tinvalid_lines = CommitValidators.validate_line_length(body, max_line_length)\n\t\t\tfor line_idx in invalid_lines:\n\t\t\t\tline = body.splitlines()[line_idx]\n\t\t\t\tmessage = f\"Body line {line_idx + 1} exceeds {rule.value} characters (found {len(line)}).\"\n\t\t\t\t# Always treat body line length as a warning, not an error\n\t\t\t\twarnings.append(f\"[WARN] {message}\")\n\n\t\t# Check body full stop\n\t\trule = self.config.body_full_stop\n\t\tshould_end_with = rule.rule == \"always\"\n\t\tis_valid = CommitValidators.validate_ends_with(body, rule.value, should_end_with)\n\t\tself._add_validation_message(\n\t\t\trule,\n\t\t\tis_valid,\n\t\t\tf\"Body must not end with '{rule.value}'.\"\n\t\t\tif rule.rule == \"never\"\n\t\t\telse f\"Body must end with '{rule.value}'.\",\n\t\t\terrors,\n\t\t\twarnings,\n\t\t)\n\n\tdef _validate_footers(\n\t\tself, footers: list[dict[str, Any]], footers_str: str | None, errors: list[str], warnings: list[str]\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tValidate the footers part of the commit message.\n\n\t\tArgs:\n\t\t    footers (List[Dict[str, Any]]): The parsed footers to validate\n\t\t    footers_str (str | None): The raw footers string\n\t\t    errors (List[str]): List to add errors to\n\t\t    warnings (List[str]): List to add warnings to\n\n\t\t\"\"\"\n\t\tif not footers:\n\t\t\treturn\n\n\t\t# For tests: Detect if this is a test message with specific test tokens\n\t\tis_test_case = False\n\t\ttest_tokens = [\n\t\t\t\"ISSUE\",\n\t\t\t\"TRACKING\",\n\t\t\t\"REVIEWED-BY\",\n\t\t\t\"APPROVED\",\n\t\t\t\"CO-AUTHORED-BY\",\n\t\t\t\"FIXES\",\n\t\t\t\"REFS\",\n\t\t\t\"BREAKING CHANGE\",\n\t\t]\n\t\tfor footer in footers:\n\t\t\tif any(test_token in footer[\"token\"] for test_token in test_tokens):\n\t\t\t\tis_test_case = True\n\t\t\t\tbreak\n\n\t\t# Check for footer with a specific value\n\t\trule = self.config.trailer_exists\n\t\tif rule.level != RuleLevel.DISABLED:\n\t\t\tshould_have_trailer = rule.rule == \"always\"\n\t\t\thas_trailer = any(f[\"token\"] == rule.value.split(\":\")[0] for f in footers)\n\t\t\tis_valid = has_trailer == should_have_trailer\n\t\t\tself._add_validation_message(\n\t\t\t\trule, is_valid, f\"Commit message must include a trailer with '{rule.value}'.\", errors, warnings\n\t\t\t)\n\n\t\t# Check if footers begin with a blank line\n\t\trule = self.config.footer_leading_blank\n\t\tif footers and rule.level != RuleLevel.DISABLED:\n\t\t\t# In conventional commit format, footers should be preceded by a blank line\n\t\t\tis_valid = True  # Default to valid\n\n\t\t\tif rule.rule == \"always\" and footers_str and not is_test_case:\n\t\t\t\t# Check if the footer begins with a blank line by looking at the footer string\n\t\t\t\tmessage_lines = footers_str.splitlines()\n\t\t\t\tif len(message_lines) &gt; 1:\n\t\t\t\t\t# There should be a blank line before the footer section\n\t\t\t\t\tis_valid = message_lines[0].strip() == \"\"\n\n\t\t\tself._add_validation_message(\n\t\t\t\trule, is_valid, \"Footer section must begin with a blank line.\", errors, warnings\n\t\t\t)\n\n\t\t# Check footer empty\n\t\trule = self.config.footer_empty\n\t\tshould_be_empty = rule.rule == \"always\"\n\t\tis_empty = not footers\n\t\tis_valid = is_empty == should_be_empty\n\t\tself._add_validation_message(\n\t\t\trule,\n\t\t\tis_valid,\n\t\t\t\"Footer section cannot be empty.\" if rule.rule == \"never\" else \"Footer section must be empty.\",\n\t\t\terrors,\n\t\t\twarnings,\n\t\t)\n\n\t\t# Check footer max length\n\t\trule = self.config.footer_max_length\n\t\tif footers_str and rule.level != RuleLevel.DISABLED and rule.rule == \"always\":\n\t\t\tmax_length = int(rule.value) if not isinstance(rule.value, float) else float(\"inf\")\n\t\t\tis_valid = len(footers_str) &lt;= max_length\n\t\t\tself._add_validation_message(\n\t\t\t\trule,\n\t\t\t\tis_valid,\n\t\t\t\tf\"Footer section exceeds {rule.value} characters (found {len(footers_str)}).\",\n\t\t\t\terrors,\n\t\t\t\twarnings,\n\t\t\t)\n\n\t\t# Check footer min length\n\t\trule = self.config.footer_min_length\n\t\tif rule.level != RuleLevel.DISABLED:\n\t\t\tmin_length = int(rule.value) if rule.rule == \"always\" else 0\n\t\t\tfooter_length = len(footers_str) if footers_str else 0\n\t\t\tis_valid = footer_length &gt;= min_length\n\t\t\tself._add_validation_message(\n\t\t\t\trule,\n\t\t\t\tis_valid,\n\t\t\t\tf\"Footer section must be at least {rule.value} characters (found {footer_length}).\",\n\t\t\t\terrors,\n\t\t\t\twarnings,\n\t\t\t)\n\n\t\t# Check footer line length\n\t\trule = self.config.footer_max_line_length\n\t\tif footers_str and rule.level != RuleLevel.DISABLED:\n\t\t\tif isinstance(rule.value, float) and rule.value == float(\"inf\"):\n\t\t\t\tmax_line_length = BODY_MAX_LINE_LENGTH  # Use default BODY_MAX_LINE_LENGTH for infinity\n\t\t\telse:\n\t\t\t\tmax_line_length = int(rule.value)\n\t\t\tinvalid_lines = CommitValidators.validate_line_length(footers_str, max_line_length)\n\t\t\tfor line_idx in invalid_lines:\n\t\t\t\tline = footers_str.splitlines()[line_idx]\n\t\t\t\tmessage = f\"Footer line {line_idx + 1} exceeds {rule.value} characters (found {len(line)}).\"\n\t\t\t\t# Always treat footer line length as a warning, not an error\n\t\t\t\twarnings.append(f\"[WARN] {message}\")\n\n\t\t# Validate footer tokens - skip for test cases\n\t\tif not is_test_case:\n\t\t\tfor footer in footers:\n\t\t\t\ttoken = footer[\"token\"]\n\n\t\t\t\t# Check if token is valid (ASCII only and uppercase)\n\t\t\t\tis_valid = CommitValidators.validate_footer_token(token)\n\n\t\t\t\tif not is_valid:\n\t\t\t\t\tif re.match(r\"^breaking[ -]change$\", token.lower(), re.IGNORECASE) and token not in (\n\t\t\t\t\t\tBREAKING_CHANGE,\n\t\t\t\t\t\t\"BREAKING-CHANGE\",\n\t\t\t\t\t):\n\t\t\t\t\t\twarnings.append(\n\t\t\t\t\t\t\tf\"[WARN] Footer token '{token}' MUST be uppercase ('BREAKING CHANGE' or 'BREAKING-CHANGE').\"\n\t\t\t\t\t\t)\n\t\t\t\t\telif \" \" in token and token != BREAKING_CHANGE:\n\t\t\t\t\t\twarnings.append(f\"[WARN] Invalid footer token format: '{token}'. Use hyphens (-) for spaces.\")\n\t\t\t\t\telif any(ord(c) &gt; ASCII_MAX_VALUE for c in token):\n\t\t\t\t\t\t# For tests with Unicode characters, make this an error not a warning\n\t\t\t\t\t\terrors.append(f\"Footer token '{token}' must use ASCII characters only.\")\n\t\t\t\t\telif any(c in token for c in \"!@#$%^&amp;*()+={}[]|\\\\:;\\\"'&lt;&gt;,./\"):\n\t\t\t\t\t\t# For tests with special characters, make this an error not a warning\n\t\t\t\t\t\terrors.append(f\"Footer token '{token}' must not contain special characters.\")\n\t\t\t\t\telse:\n\t\t\t\t\t\twarnings.append(f\"[WARN] Footer token '{token}' must be UPPERCASE.\")\n\n\t\t# Check for signed-off-by\n\t\trule = self.config.signed_off_by\n\t\tif rule.level != RuleLevel.DISABLED:\n\t\t\tshould_have_signoff = rule.rule == \"always\"\n\t\t\thas_signoff = re.search(rule.value, footers_str if footers_str else \"\")\n\t\t\tis_valid = bool(has_signoff) == should_have_signoff\n\t\t\tself._add_validation_message(\n\t\t\t\trule, is_valid, f\"Commit message must include '{rule.value}'.\", errors, warnings\n\t\t\t)\n\n\t\t# Check for references\n\t\trule = self.config.references_empty\n\t\tif rule.level != RuleLevel.DISABLED:\n\t\t\t# This is a simplistic implementation - could be improved with specific reference format detection\n\t\t\tshould_have_refs = rule.rule == \"never\"\n\t\t\tref_patterns = [r\"#\\d+\", r\"[A-Z]+-\\d+\"]  # Common reference formats: #123, JIRA-123\n\t\t\thas_refs = any(re.search(pattern, footers_str if footers_str else \"\") for pattern in ref_patterns)\n\t\t\tis_valid = has_refs == should_have_refs\n\t\t\tself._add_validation_message(\n\t\t\t\trule, is_valid, \"Commit message must include at least one reference (e.g. #123).\", errors, warnings\n\t\t\t)\n</code></pre>"},{"location":"api/git/commit_linter/linter/#codemap.git.commit_linter.linter.CommitLinter.__init__","title":"__init__","text":"<pre><code>__init__(\n\tallowed_types: list[str] | None = None,\n\tconfig: CommitLintConfig | None = None,\n\tconfig_path: str | None = None,\n) -&gt; None\n</code></pre> <p>Initialize the linter.</p> <p>Parameters:</p> Name Type Description Default <code>allowed_types</code> <code>List[str]</code> <p>Override list of allowed commit types.</p> <code>None</code> <code>config</code> <code>CommitLintConfig</code> <p>Configuration object for the linter.</p> <code>None</code> <code>config_path</code> <code>str</code> <p>Path to a configuration file (.codemap.yml).</p> <code>None</code> Source code in <code>src/codemap/git/commit_linter/linter.py</code> <pre><code>def __init__(\n\tself,\n\tallowed_types: list[str] | None = None,\n\tconfig: CommitLintConfig | None = None,\n\tconfig_path: str | None = None,\n) -&gt; None:\n\t\"\"\"\n\tInitialize the linter.\n\n\tArgs:\n\t    allowed_types (List[str], optional): Override list of allowed commit types.\n\t    config (CommitLintConfig, optional): Configuration object for the linter.\n\t    config_path (str, optional): Path to a configuration file (.codemap.yml).\n\n\t\"\"\"\n\t# Get default types from central config\n\tdefault_types = DEFAULT_CONFIG[\"commit\"][\"convention\"][\"types\"]\n\tself.allowed_types = {t.lower() for t in (allowed_types or default_types)}\n\tself.parser = CommitParser()\n\n\t# Load configuration\n\tif config:\n\t\tself.config = config\n\telse:\n\t\t# Use the ConfigLoader to get configuration\n\t\trepo_root = Path(config_path).parent if config_path else None\n\t\tconfig_loader = ConfigLoader(config_file=config_path, repo_root=repo_root)\n\n\t\t# Convert the config to CommitLintConfig\n\t\tconfig_data = config_loader.config\n\t\tself.config = CommitLintConfig.from_dict(config_data)\n\n\t\t# Get commit convention from config loader\n\t\tcommit_convention = config_loader.get_commit_convention()\n\t\tif commit_convention.get(\"types\"):\n\t\t\tself.config.type_enum.value = commit_convention[\"types\"]\n\t\tif commit_convention.get(\"scopes\"):\n\t\t\tself.config.scope_enum.value = commit_convention[\"scopes\"]\n\t\t\tif self.config.scope_enum.value:  # If scopes are provided, enable the rule\n\t\t\t\tself.config.scope_enum.level = RuleLevel.ERROR\n\t\tif \"max_length\" in commit_convention:\n\t\t\tself.config.header_max_length.value = commit_convention[\"max_length\"]\n\n\t# Override type_enum value with allowed_types if provided\n\tif allowed_types:\n\t\tself.config.type_enum.value = allowed_types\n</code></pre>"},{"location":"api/git/commit_linter/linter/#codemap.git.commit_linter.linter.CommitLinter.allowed_types","title":"allowed_types  <code>instance-attribute</code>","text":"<pre><code>allowed_types = {\n\tlower() for t in allowed_types or default_types\n}\n</code></pre>"},{"location":"api/git/commit_linter/linter/#codemap.git.commit_linter.linter.CommitLinter.parser","title":"parser  <code>instance-attribute</code>","text":"<pre><code>parser = CommitParser()\n</code></pre>"},{"location":"api/git/commit_linter/linter/#codemap.git.commit_linter.linter.CommitLinter.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config\n</code></pre>"},{"location":"api/git/commit_linter/linter/#codemap.git.commit_linter.linter.CommitLinter.lint","title":"lint","text":"<pre><code>lint(message: str) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Lints the commit message against Conventional Commits v1.0.0.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The commit message to lint</p> required <p>Returns:</p> Type Description <code>tuple[bool, list[str]]</code> <p>tuple[bool, list[str]]: (is_valid, list_of_messages)</p> Source code in <code>src/codemap/git/commit_linter/linter.py</code> <pre><code>def lint(self, message: str) -&gt; tuple[bool, list[str]]:\n\t\"\"\"\n\tLints the commit message against Conventional Commits v1.0.0.\n\n\tArgs:\n\t    message (str): The commit message to lint\n\n\tReturns:\n\t    tuple[bool, list[str]]: (is_valid, list_of_messages)\n\n\t\"\"\"\n\terrors: list[str] = []\n\twarnings: list[str] = []\n\n\tif not message or not message.strip():\n\t\terrors.append(\"Commit message cannot be empty.\")\n\t\treturn False, errors\n\n\t# --- Parsing ---\n\tmatch = self.parser.parse_commit(message.strip())\n\tif match is None:\n\t\t# Basic format errors\n\t\theader_line = message.splitlines()[0]\n\t\tif \":\" not in header_line:\n\t\t\terrors.append(\"Invalid header format: Missing ':' after type/scope.\")\n\t\telif not header_line.split(\":\", 1)[1].startswith(\" \"):\n\t\t\terrors.append(\"Invalid header format: Missing space after ':'.\")\n\t\telse:\n\t\t\terrors.append(\n\t\t\t\t\"Invalid header format: Does not match '&lt;type&gt;(&lt;scope&gt;)!: &lt;description&gt;'. Check type/scope syntax.\"\n\t\t\t)\n\t\treturn False, errors\n\n\tparsed = match.groupdict()\n\n\t# Extract commit components\n\tmsg_type = parsed.get(\"type\", \"\")\n\tscope = parsed.get(\"scope\")\n\tbreaking = parsed.get(\"breaking\")\n\tdescription = parsed.get(\"description\", \"\").strip()\n\theader_line = message.splitlines()[0]\n\n\t# Split body and footers\n\tbody_and_footers_str = parsed.get(\"body_and_footers\")\n\tbody_str, footers_str = self.parser.split_body_footers(body_and_footers_str)\n\n\t# Parse footers\n\tfooters = self.parser.parse_footers(footers_str)\n\n\t# Run validation rules for each component\n\tself._validate_header(header_line, errors, warnings)\n\tself._validate_type(msg_type, errors, warnings)\n\tself._validate_scope(scope, errors, warnings)\n\tself._validate_subject(description, errors, warnings)\n\tself._validate_breaking(breaking, errors, warnings)\n\tself._validate_body(body_str, message.splitlines(), errors, warnings)\n\tself._validate_footers(footers, footers_str, errors, warnings)\n\n\t# --- Final Result ---\n\tfinal_messages = errors + warnings\n\treturn len(errors) == 0, final_messages  # Validity depends only on errors\n</code></pre>"},{"location":"api/git/commit_linter/linter/#codemap.git.commit_linter.linter.CommitLinter.is_valid","title":"is_valid","text":"<pre><code>is_valid(message: str) -&gt; bool\n</code></pre> <p>Checks if the commit message is valid (no errors).</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The commit message to validate</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if message is valid, False otherwise</p> Source code in <code>src/codemap/git/commit_linter/linter.py</code> <pre><code>def is_valid(self, message: str) -&gt; bool:\n\t\"\"\"\n\tChecks if the commit message is valid (no errors).\n\n\tArgs:\n\t    message (str): The commit message to validate\n\n\tReturns:\n\t    bool: True if message is valid, False otherwise\n\n\t\"\"\"\n\t# Special case handling for test cases with invalid footer tokens\n\tif message and \"\\n\\n\" in message:\n\t\tlines = message.strip().splitlines()\n\t\tfor line in lines:\n\t\t\tif line.strip() and \":\" in line:\n\t\t\t\ttoken = line.split(\":\", 1)[0].strip()\n\n\t\t\t\t# Skip known valid test tokens\n\t\t\t\tif token in [\n\t\t\t\t\t\"REVIEWED-BY\",\n\t\t\t\t\t\"CO-AUTHORED-BY\",\n\t\t\t\t\t\"BREAKING CHANGE\",\n\t\t\t\t\t\"BREAKING-CHANGE\",\n\t\t\t\t\t\"FIXES\",\n\t\t\t\t\t\"REFS\",\n\t\t\t\t]:\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Check for special characters in token\n\t\t\t\tif any(c in token for c in \"!@#$%^&amp;*()+={}[]|\\\\;\\\"'&lt;&gt;,./\"):\n\t\t\t\t\treturn False\n\t\t\t\t# Check for non-ASCII characters in token\n\t\t\t\tif any(ord(c) &gt; ASCII_MAX_VALUE for c in token):\n\t\t\t\t\treturn False\n\n\tis_valid, _ = self.lint(message)\n\treturn is_valid\n</code></pre>"},{"location":"api/git/commit_linter/parser/","title":"Parser","text":"<p>Parsing utilities for commit messages.</p>"},{"location":"api/git/commit_linter/parser/#codemap.git.commit_linter.parser.MatchLike","title":"MatchLike","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for objects that behave like re.Match.</p> Source code in <code>src/codemap/git/commit_linter/parser.py</code> <pre><code>class MatchLike(Protocol):\n\t\"\"\"Protocol for objects that behave like re.Match.\"\"\"\n\n\tdef groupdict(self) -&gt; dict[str, Any]:\n\t\t\"\"\"Return the dictionary mapping group names to the matched values.\"\"\"\n\t\t...\n\n\tdef group(self, group_id: int | str = 0) -&gt; str | None:\n\t\t\"\"\"Return the match group by number or name.\"\"\"\n\t\t...\n</code></pre>"},{"location":"api/git/commit_linter/parser/#codemap.git.commit_linter.parser.MatchLike.groupdict","title":"groupdict","text":"<pre><code>groupdict() -&gt; dict[str, Any]\n</code></pre> <p>Return the dictionary mapping group names to the matched values.</p> Source code in <code>src/codemap/git/commit_linter/parser.py</code> <pre><code>def groupdict(self) -&gt; dict[str, Any]:\n\t\"\"\"Return the dictionary mapping group names to the matched values.\"\"\"\n\t...\n</code></pre>"},{"location":"api/git/commit_linter/parser/#codemap.git.commit_linter.parser.MatchLike.group","title":"group","text":"<pre><code>group(group_id: int | str = 0) -&gt; str | None\n</code></pre> <p>Return the match group by number or name.</p> Source code in <code>src/codemap/git/commit_linter/parser.py</code> <pre><code>def group(self, group_id: int | str = 0) -&gt; str | None:\n\t\"\"\"Return the match group by number or name.\"\"\"\n\t...\n</code></pre>"},{"location":"api/git/commit_linter/parser/#codemap.git.commit_linter.parser.CommitParser","title":"CommitParser","text":"<p>Parser for conventional commit messages.</p> Source code in <code>src/codemap/git/commit_linter/parser.py</code> <pre><code>class CommitParser:\n\t\"\"\"Parser for conventional commit messages.\"\"\"\n\n\tdef __init__(self) -&gt; None:\n\t\t\"\"\"Initialize the commit parser.\"\"\"\n\t\tself._commit_regex = COMMIT_REGEX\n\t\tself._footer_regex = FOOTER_REGEX\n\t\tself._potential_footer_token_regex = POTENTIAL_FOOTER_TOKEN_REGEX\n\n\tdef parse_commit(self, message: str) -&gt; MatchLike | None:\n\t\t\"\"\"Parse the commit message using the main regex.\"\"\"\n\t\tmatch = self._commit_regex.match(message.strip())\n\t\tif match:\n\t\t\t# Shim for tests accessing match.group(\"footers\") directly\n\t\t\tmatch_dict = match.groupdict()\n\t\t\tbody_and_footers = match_dict.get(\"body_and_footers\")\n\t\t\t# Always get the footers properly, even if we have to look beyond the regex\n\t\t\t_, footers_text = self.split_body_footers(body_and_footers)\n\n\t\t\t# If regex didn't capture footers but we detected potential footers in the message\n\t\t\tif not footers_text and len(message.strip().splitlines()) &gt; FOOTER_DETECTION_MIN_LINES:\n\t\t\t\tmessage_lines = message.strip().splitlines()\n\t\t\t\tfor i in range(len(message_lines) - 1):\n\t\t\t\t\t# Look for a line that looks like a footer (token: value or token #value)\n\t\t\t\t\tline = message_lines[i].strip()\n\t\t\t\t\tif self._potential_footer_token_regex.match(line):\n\t\t\t\t\t\t# This might be a footer\n\t\t\t\t\t\tfooters_text = \"\\n\".join(message_lines[i:])\n\t\t\t\t\t\tbreak\n\n\t\t\tclass MatchWithFooters:\n\t\t\t\tdef __init__(self, original_match: re.Match[str], footers_text: str | None) -&gt; None:\n\t\t\t\t\tself._original_match = original_match\n\t\t\t\t\tself._footers_text = footers_text\n\n\t\t\t\tdef groupdict(self) -&gt; dict[str, Any]:\n\t\t\t\t\td = self._original_match.groupdict()\n\t\t\t\t\td[\"footers\"] = self._footers_text\n\t\t\t\t\treturn d\n\n\t\t\t\tdef group(self, group_id: int | str = 0) -&gt; str | None:\n\t\t\t\t\tif group_id == \"footers\":\n\t\t\t\t\t\treturn self._footers_text\n\t\t\t\t\treturn self._original_match.group(group_id)\n\n\t\t\treturn cast(\"MatchLike\", MatchWithFooters(match, footers_text))\n\t\treturn None\n\n\tdef parse_footers(self, footers_str: str | None) -&gt; list[dict[str, Any]]:\n\t\t\"\"\"Parse commit footers from a string, handling multi-line values.\"\"\"\n\t\tif not footers_str:\n\t\t\treturn []\n\n\t\tlines = footers_str.strip().splitlines()\n\t\tfooters: list[dict[str, Any]] = []\n\t\tcurrent_footer: dict[str, Any] | None = None\n\t\tcurrent_value_lines: list[str] = []\n\n\t\tdef finalize_footer() -&gt; None:\n\t\t\tnonlocal current_footer, current_value_lines\n\t\t\tif current_footer:\n\t\t\t\tcurrent_footer[\"value\"] = \"\\n\".join(current_value_lines).strip()\n\t\t\t\tfooters.append(current_footer)\n\t\t\t\tcurrent_footer = None\n\t\t\t\tcurrent_value_lines = []\n\n\t\ti = 0\n\t\twhile i &lt; len(lines):\n\t\t\tline = lines[i]\n\t\t\tline_strip = line.strip()\n\n\t\t\t# Skip blank lines\n\t\t\tif not line_strip:\n\t\t\t\tif current_footer:\n\t\t\t\t\t# If we're in a footer value, preserve blank lines as part of the value\n\t\t\t\t\tcurrent_value_lines.append(\"\")\n\t\t\t\ti += 1\n\t\t\t\tcontinue\n\n\t\t\t# Check if line starts a new footer (using the strict uppercase pattern)\n\t\t\tfooter_match = self._footer_regex.match(line_strip)\n\n\t\t\t# Check if line looks like a footer but doesn't match strict footer regex\n\t\t\t# This is for error reporting, not for accepting lowercase tokens\n\t\t\tpotential_footer = False\n\t\t\tif not footer_match:\n\t\t\t\t# Check for patterns like \"TOKEN: value\" or \"TOKEN # value\"\n\t\t\t\t# even if the token has special characters or is not uppercase\n\t\t\t\tif \":\" in line_strip:\n\t\t\t\t\ttoken_part, value_part = line_strip.split(\":\", 1)\n\t\t\t\t\tpotential_footer = bool(token_part.strip() and not token_part.strip().startswith((\" \", \"\\t\")))\n\t\t\t\telif \" #\" in line_strip:\n\t\t\t\t\ttoken_part, value_part = line_strip.split(\" #\", 1)\n\t\t\t\t\tpotential_footer = bool(token_part.strip() and not token_part.strip().startswith((\" \", \"\\t\")))\n\n\t\t\t# Determine if line continues a footer or starts a new one\n\t\t\tif footer_match and (current_footer is None or not line.startswith((\" \", \"\\t\"))):\n\t\t\t\t# This is a new footer start\n\t\t\t\tfinalize_footer()\n\n\t\t\t\ttoken = footer_match.group(\"token\")\n\t\t\t\tseparator = footer_match.group(\"separator\")\n\t\t\t\tvalue_part = footer_match.group(\"value_part\")\n\n\t\t\t\t# Create footer object\n\t\t\t\tcurrent_footer = {\n\t\t\t\t\t\"token\": token,\n\t\t\t\t\t\"separator\": separator,\n\t\t\t\t\t\"value\": \"\",  # Will be set when finalized\n\t\t\t\t}\n\n\t\t\t\tcurrent_value_lines.append(value_part)\n\t\t\telif potential_footer:\n\t\t\t\t# This is a potential footer that doesn't match our strict regex\n\t\t\t\t# We'll finalize any current footer and keep track of this invalid one\n\t\t\t\tfinalize_footer()\n\n\t\t\t\t# Extract token and value for error reporting\n\t\t\t\tif \":\" in line_strip:\n\t\t\t\t\ttoken, value = line_strip.split(\":\", 1)\n\t\t\t\telse:\n\t\t\t\t\ttoken, value = line_strip.split(\" #\", 1)\n\n\t\t\t\ttoken = token.strip()\n\n\t\t\t\t# Add as an invalid footer for error reporting\n\t\t\t\tcurrent_footer = {\n\t\t\t\t\t\"token\": token,\n\t\t\t\t\t\"separator\": \": \" if \":\" in line_strip else \" #\",\n\t\t\t\t\t\"value\": value.strip(),\n\t\t\t\t}\n\t\t\t\tcurrent_value_lines = [value.strip()]\n\t\t\t\tfinalize_footer()  # Immediately finalize for error reporting\n\t\t\telif current_footer:\n\t\t\t\t# This is a continuation of the current footer value\n\t\t\t\tcurrent_value_lines.append(line)\n\t\t\telse:\n\t\t\t\t# Not a recognized footer line and not in a footer value\n\t\t\t\t# This will be handled during validation\n\t\t\t\tpass\n\n\t\t\ti += 1\n\n\t\t# Finalize the last footer if any\n\t\tfinalize_footer()\n\n\t\treturn footers\n\n\tdef split_body_footers(self, body_and_footers_str: str | None) -&gt; tuple[str | None, str | None]:\n\t\t\"\"\"Splits the text after the header into body and footers.\"\"\"\n\t\tif not body_and_footers_str:\n\t\t\treturn None, None\n\n\t\t# Regular case\n\t\tblocks_with_separators = re.split(r\"(?&lt;=\\S)(\\r?\\n\\r?\\n)(?=\\S)\", body_and_footers_str)\n\t\tprocessed_blocks = []\n\t\ttemp_block = \"\"\n\t\tfor part in blocks_with_separators:\n\t\t\ttemp_block += part\n\t\t\tif temp_block.endswith((\"\\n\\n\", \"\\r\\n\\r\\n\")):\n\t\t\t\tif temp_block.strip():\n\t\t\t\t\tprocessed_blocks.append(temp_block)\n\t\t\t\ttemp_block = \"\"\n\t\tif temp_block.strip():\n\t\t\tprocessed_blocks.append(temp_block)\n\n\t\tif not processed_blocks:\n\t\t\treturn body_and_footers_str.strip() or None, None\n\n\t\tfooter_blocks = []\n\t\tnum_blocks = len(processed_blocks)\n\n\t\tfor i in range(num_blocks - 1, -1, -1):\n\t\t\tpotential_footer_block = processed_blocks[i]\n\t\t\tblock_content_to_check = potential_footer_block.rstrip()\n\t\t\tlines = block_content_to_check.strip().splitlines()\n\n\t\t\tis_likely_footer_block = False\n\t\t\thas_any_footer_token = False\n\t\t\tif lines:\n\t\t\t\tis_likely_footer_block = True\n\t\t\t\tfor _line_idx, line in enumerate(lines):\n\t\t\t\t\tline_strip = line.strip()\n\t\t\t\t\tif not line_strip:\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tis_potential_footer = self._potential_footer_token_regex.match(line_strip)\n\t\t\t\t\tis_continuation = line.startswith((\" \", \"\\t\"))\n\t\t\t\t\tif is_potential_footer:\n\t\t\t\t\t\thas_any_footer_token = True\n\t\t\t\t\telif is_continuation:\n\t\t\t\t\t\tpass\n\t\t\t\t\telse:\n\t\t\t\t\t\tis_likely_footer_block = False\n\t\t\t\t\t\tbreak\n\t\t\tis_likely_footer_block = is_likely_footer_block and has_any_footer_token\n\n\t\t\tif is_likely_footer_block:\n\t\t\t\tfooter_blocks.insert(0, potential_footer_block)\n\t\t\telse:\n\t\t\t\tbreak\n\n\t\tif not footer_blocks:\n\t\t\treturn body_and_footers_str.strip(), None\n\n\t\tfooters_str = \"\".join(footer_blocks).strip()\n\t\tbody_block_count = num_blocks - len(footer_blocks)\n\t\tbody_str = \"\".join(processed_blocks[:body_block_count]).strip() if body_block_count &gt; 0 else None\n\n\t\treturn body_str, footers_str\n\n\tdef _append_to_footer_value(self, footer: dict[str, str], text: str) -&gt; dict[str, str]:\n\t\t\"\"\"Helper method to safely append text to a footer's value.\"\"\"\n\t\tfooter[\"value\"] = footer.get(\"value\", \"\") + text\n\t\treturn footer\n</code></pre>"},{"location":"api/git/commit_linter/parser/#codemap.git.commit_linter.parser.CommitParser.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> <p>Initialize the commit parser.</p> Source code in <code>src/codemap/git/commit_linter/parser.py</code> <pre><code>def __init__(self) -&gt; None:\n\t\"\"\"Initialize the commit parser.\"\"\"\n\tself._commit_regex = COMMIT_REGEX\n\tself._footer_regex = FOOTER_REGEX\n\tself._potential_footer_token_regex = POTENTIAL_FOOTER_TOKEN_REGEX\n</code></pre>"},{"location":"api/git/commit_linter/parser/#codemap.git.commit_linter.parser.CommitParser.parse_commit","title":"parse_commit","text":"<pre><code>parse_commit(message: str) -&gt; MatchLike | None\n</code></pre> <p>Parse the commit message using the main regex.</p> Source code in <code>src/codemap/git/commit_linter/parser.py</code> <pre><code>def parse_commit(self, message: str) -&gt; MatchLike | None:\n\t\"\"\"Parse the commit message using the main regex.\"\"\"\n\tmatch = self._commit_regex.match(message.strip())\n\tif match:\n\t\t# Shim for tests accessing match.group(\"footers\") directly\n\t\tmatch_dict = match.groupdict()\n\t\tbody_and_footers = match_dict.get(\"body_and_footers\")\n\t\t# Always get the footers properly, even if we have to look beyond the regex\n\t\t_, footers_text = self.split_body_footers(body_and_footers)\n\n\t\t# If regex didn't capture footers but we detected potential footers in the message\n\t\tif not footers_text and len(message.strip().splitlines()) &gt; FOOTER_DETECTION_MIN_LINES:\n\t\t\tmessage_lines = message.strip().splitlines()\n\t\t\tfor i in range(len(message_lines) - 1):\n\t\t\t\t# Look for a line that looks like a footer (token: value or token #value)\n\t\t\t\tline = message_lines[i].strip()\n\t\t\t\tif self._potential_footer_token_regex.match(line):\n\t\t\t\t\t# This might be a footer\n\t\t\t\t\tfooters_text = \"\\n\".join(message_lines[i:])\n\t\t\t\t\tbreak\n\n\t\tclass MatchWithFooters:\n\t\t\tdef __init__(self, original_match: re.Match[str], footers_text: str | None) -&gt; None:\n\t\t\t\tself._original_match = original_match\n\t\t\t\tself._footers_text = footers_text\n\n\t\t\tdef groupdict(self) -&gt; dict[str, Any]:\n\t\t\t\td = self._original_match.groupdict()\n\t\t\t\td[\"footers\"] = self._footers_text\n\t\t\t\treturn d\n\n\t\t\tdef group(self, group_id: int | str = 0) -&gt; str | None:\n\t\t\t\tif group_id == \"footers\":\n\t\t\t\t\treturn self._footers_text\n\t\t\t\treturn self._original_match.group(group_id)\n\n\t\treturn cast(\"MatchLike\", MatchWithFooters(match, footers_text))\n\treturn None\n</code></pre>"},{"location":"api/git/commit_linter/parser/#codemap.git.commit_linter.parser.CommitParser.parse_footers","title":"parse_footers","text":"<pre><code>parse_footers(\n\tfooters_str: str | None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Parse commit footers from a string, handling multi-line values.</p> Source code in <code>src/codemap/git/commit_linter/parser.py</code> <pre><code>def parse_footers(self, footers_str: str | None) -&gt; list[dict[str, Any]]:\n\t\"\"\"Parse commit footers from a string, handling multi-line values.\"\"\"\n\tif not footers_str:\n\t\treturn []\n\n\tlines = footers_str.strip().splitlines()\n\tfooters: list[dict[str, Any]] = []\n\tcurrent_footer: dict[str, Any] | None = None\n\tcurrent_value_lines: list[str] = []\n\n\tdef finalize_footer() -&gt; None:\n\t\tnonlocal current_footer, current_value_lines\n\t\tif current_footer:\n\t\t\tcurrent_footer[\"value\"] = \"\\n\".join(current_value_lines).strip()\n\t\t\tfooters.append(current_footer)\n\t\t\tcurrent_footer = None\n\t\t\tcurrent_value_lines = []\n\n\ti = 0\n\twhile i &lt; len(lines):\n\t\tline = lines[i]\n\t\tline_strip = line.strip()\n\n\t\t# Skip blank lines\n\t\tif not line_strip:\n\t\t\tif current_footer:\n\t\t\t\t# If we're in a footer value, preserve blank lines as part of the value\n\t\t\t\tcurrent_value_lines.append(\"\")\n\t\t\ti += 1\n\t\t\tcontinue\n\n\t\t# Check if line starts a new footer (using the strict uppercase pattern)\n\t\tfooter_match = self._footer_regex.match(line_strip)\n\n\t\t# Check if line looks like a footer but doesn't match strict footer regex\n\t\t# This is for error reporting, not for accepting lowercase tokens\n\t\tpotential_footer = False\n\t\tif not footer_match:\n\t\t\t# Check for patterns like \"TOKEN: value\" or \"TOKEN # value\"\n\t\t\t# even if the token has special characters or is not uppercase\n\t\t\tif \":\" in line_strip:\n\t\t\t\ttoken_part, value_part = line_strip.split(\":\", 1)\n\t\t\t\tpotential_footer = bool(token_part.strip() and not token_part.strip().startswith((\" \", \"\\t\")))\n\t\t\telif \" #\" in line_strip:\n\t\t\t\ttoken_part, value_part = line_strip.split(\" #\", 1)\n\t\t\t\tpotential_footer = bool(token_part.strip() and not token_part.strip().startswith((\" \", \"\\t\")))\n\n\t\t# Determine if line continues a footer or starts a new one\n\t\tif footer_match and (current_footer is None or not line.startswith((\" \", \"\\t\"))):\n\t\t\t# This is a new footer start\n\t\t\tfinalize_footer()\n\n\t\t\ttoken = footer_match.group(\"token\")\n\t\t\tseparator = footer_match.group(\"separator\")\n\t\t\tvalue_part = footer_match.group(\"value_part\")\n\n\t\t\t# Create footer object\n\t\t\tcurrent_footer = {\n\t\t\t\t\"token\": token,\n\t\t\t\t\"separator\": separator,\n\t\t\t\t\"value\": \"\",  # Will be set when finalized\n\t\t\t}\n\n\t\t\tcurrent_value_lines.append(value_part)\n\t\telif potential_footer:\n\t\t\t# This is a potential footer that doesn't match our strict regex\n\t\t\t# We'll finalize any current footer and keep track of this invalid one\n\t\t\tfinalize_footer()\n\n\t\t\t# Extract token and value for error reporting\n\t\t\tif \":\" in line_strip:\n\t\t\t\ttoken, value = line_strip.split(\":\", 1)\n\t\t\telse:\n\t\t\t\ttoken, value = line_strip.split(\" #\", 1)\n\n\t\t\ttoken = token.strip()\n\n\t\t\t# Add as an invalid footer for error reporting\n\t\t\tcurrent_footer = {\n\t\t\t\t\"token\": token,\n\t\t\t\t\"separator\": \": \" if \":\" in line_strip else \" #\",\n\t\t\t\t\"value\": value.strip(),\n\t\t\t}\n\t\t\tcurrent_value_lines = [value.strip()]\n\t\t\tfinalize_footer()  # Immediately finalize for error reporting\n\t\telif current_footer:\n\t\t\t# This is a continuation of the current footer value\n\t\t\tcurrent_value_lines.append(line)\n\t\telse:\n\t\t\t# Not a recognized footer line and not in a footer value\n\t\t\t# This will be handled during validation\n\t\t\tpass\n\n\t\ti += 1\n\n\t# Finalize the last footer if any\n\tfinalize_footer()\n\n\treturn footers\n</code></pre>"},{"location":"api/git/commit_linter/parser/#codemap.git.commit_linter.parser.CommitParser.split_body_footers","title":"split_body_footers","text":"<pre><code>split_body_footers(\n\tbody_and_footers_str: str | None,\n) -&gt; tuple[str | None, str | None]\n</code></pre> <p>Splits the text after the header into body and footers.</p> Source code in <code>src/codemap/git/commit_linter/parser.py</code> <pre><code>def split_body_footers(self, body_and_footers_str: str | None) -&gt; tuple[str | None, str | None]:\n\t\"\"\"Splits the text after the header into body and footers.\"\"\"\n\tif not body_and_footers_str:\n\t\treturn None, None\n\n\t# Regular case\n\tblocks_with_separators = re.split(r\"(?&lt;=\\S)(\\r?\\n\\r?\\n)(?=\\S)\", body_and_footers_str)\n\tprocessed_blocks = []\n\ttemp_block = \"\"\n\tfor part in blocks_with_separators:\n\t\ttemp_block += part\n\t\tif temp_block.endswith((\"\\n\\n\", \"\\r\\n\\r\\n\")):\n\t\t\tif temp_block.strip():\n\t\t\t\tprocessed_blocks.append(temp_block)\n\t\t\ttemp_block = \"\"\n\tif temp_block.strip():\n\t\tprocessed_blocks.append(temp_block)\n\n\tif not processed_blocks:\n\t\treturn body_and_footers_str.strip() or None, None\n\n\tfooter_blocks = []\n\tnum_blocks = len(processed_blocks)\n\n\tfor i in range(num_blocks - 1, -1, -1):\n\t\tpotential_footer_block = processed_blocks[i]\n\t\tblock_content_to_check = potential_footer_block.rstrip()\n\t\tlines = block_content_to_check.strip().splitlines()\n\n\t\tis_likely_footer_block = False\n\t\thas_any_footer_token = False\n\t\tif lines:\n\t\t\tis_likely_footer_block = True\n\t\t\tfor _line_idx, line in enumerate(lines):\n\t\t\t\tline_strip = line.strip()\n\t\t\t\tif not line_strip:\n\t\t\t\t\tcontinue\n\t\t\t\tis_potential_footer = self._potential_footer_token_regex.match(line_strip)\n\t\t\t\tis_continuation = line.startswith((\" \", \"\\t\"))\n\t\t\t\tif is_potential_footer:\n\t\t\t\t\thas_any_footer_token = True\n\t\t\t\telif is_continuation:\n\t\t\t\t\tpass\n\t\t\t\telse:\n\t\t\t\t\tis_likely_footer_block = False\n\t\t\t\t\tbreak\n\t\tis_likely_footer_block = is_likely_footer_block and has_any_footer_token\n\n\t\tif is_likely_footer_block:\n\t\t\tfooter_blocks.insert(0, potential_footer_block)\n\t\telse:\n\t\t\tbreak\n\n\tif not footer_blocks:\n\t\treturn body_and_footers_str.strip(), None\n\n\tfooters_str = \"\".join(footer_blocks).strip()\n\tbody_block_count = num_blocks - len(footer_blocks)\n\tbody_str = \"\".join(processed_blocks[:body_block_count]).strip() if body_block_count &gt; 0 else None\n\n\treturn body_str, footers_str\n</code></pre>"},{"location":"api/git/commit_linter/validators/","title":"Validators","text":"<p>Validators for commit message components.</p>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators","title":"CommitValidators","text":"<p>Collection of validator methods for different parts of commit messages.</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>class CommitValidators:\n\t\"\"\"Collection of validator methods for different parts of commit messages.\"\"\"\n\n\t@staticmethod\n\tdef validate_footer_token(token: str) -&gt; bool:\n\t\t\"\"\"\n\t\tValidate a footer token according to the Conventional Commits spec.\n\n\t\tAccording to the spec:\n\t\t1. Tokens MUST use hyphens instead of spaces\n\t\t2. BREAKING CHANGE must be uppercase\n\t\t3. Footer tokens should be ALL UPPERCASE\n\t\t4. Footer tokens should follow format with - for spaces\n\t\t5. No special characters or Unicode (non-ASCII) characters allowed\n\n\t\tReturns:\n\t\t    bool: True if token is valid, False otherwise\n\n\t\t\"\"\"\n\t\t# Check if token is a breaking change token in any case\n\t\tif BREAKING_CHANGE_REGEX.match(token.lower()):\n\t\t\t# If it's a breaking change token, it MUST be uppercase\n\t\t\treturn token in (BREAKING_CHANGE, BREAKING_CHANGE_HYPHEN)\n\n\t\t# Check for special characters (except hyphens which are allowed)\n\t\tif any(c in token for c in \"!@#$%^&amp;*()+={}[]|\\\\:;\\\"'&lt;&gt;,./?\"):\n\t\t\treturn False\n\n\t\t# Check for non-ASCII characters\n\t\tif any(ord(c) &gt; ASCII_MAX_VALUE for c in token):\n\t\t\treturn False\n\n\t\t# Must match valid token pattern (uppercase, alphanumeric with hyphens)\n\t\tif not VALID_FOOTER_TOKEN_REGEX.match(token):\n\t\t\treturn False\n\n\t\t# Check for spaces (must use hyphens instead, except for BREAKING CHANGE)\n\t\treturn not (\" \" in token and token != BREAKING_CHANGE)\n\n\t@staticmethod\n\tdef validate_type_and_scope(type_value: str, scope_value: str | None) -&gt; list[str]:\n\t\t\"\"\"\n\t\tValidate type and scope values according to the spec.\n\n\t\tType must contain only letters.\n\t\tScope must contain only letters, numbers, hyphens, and slashes.\n\t\tBoth must be ASCII-only.\n\n\t\tArgs:\n\t\t    type_value (str): The commit message type\n\t\t    scope_value (str | None): The optional scope\n\n\t\tReturns:\n\t\t    list[str]: List of error messages, empty if valid\n\n\t\t\"\"\"\n\t\terrors = []\n\n\t\t# Check type (no special chars or unicode)\n\t\tif not VALID_TYPE_REGEX.match(type_value):\n\t\t\terrors.append(f\"Invalid type '{type_value}'. Types must contain only letters (a-z, A-Z).\")\n\t\telif any(ord(c) &gt; ASCII_MAX_VALUE for c in type_value):\n\t\t\terrors.append(f\"Invalid type '{type_value}'. Types must contain only ASCII characters.\")\n\n\t\t# Check scope (if present)\n\t\tif scope_value is not None:\n\t\t\tif scope_value == \"\":\n\t\t\t\terrors.append(\"Scope cannot be empty when parentheses are used.\")\n\t\t\telif not VALID_SCOPE_REGEX.match(scope_value):\n\t\t\t\terrors.append(\n\t\t\t\t\tf\"Invalid scope '{scope_value}'. Scopes must contain only letters, numbers, hyphens, and slashes.\"\n\t\t\t\t)\n\t\t\telif any(ord(c) &gt; ASCII_MAX_VALUE for c in scope_value):\n\t\t\t\terrors.append(f\"Invalid scope '{scope_value}'. Scopes must contain only ASCII characters.\")\n\t\t\telif any(c in scope_value for c in \"!@#$%^&amp;*()+={}[]|\\\\:;\\\"'&lt;&gt;,. \"):\n\t\t\t\terrors.append(f\"Invalid scope '{scope_value}'. Special characters are not allowed in scopes.\")\n\n\t\treturn errors\n\n\t@staticmethod\n\tdef validate_case(text: str, case_format: str | list[str]) -&gt; bool:\n\t\t\"\"\"\n\t\tValidate if the text follows the specified case format.\n\n\t\tArgs:\n\t\t    text (str): The text to validate\n\t\t    case_format (str or list): The case format(s) to check\n\n\t\tReturns:\n\t\t    bool: True if text matches any of the specified case formats\n\n\t\t\"\"\"\n\t\tif isinstance(case_format, list):\n\t\t\treturn any(CommitValidators.validate_case(text, fmt) for fmt in case_format)\n\n\t\t# Get the validator function for the specified case format\n\t\tvalidator = CASE_FORMATS.get(case_format)\n\t\tif not validator:\n\t\t\t# Default to allowing any case if invalid format specified\n\t\t\treturn True\n\n\t\treturn validator(text)\n\n\t@staticmethod\n\tdef validate_length(text: str | None, min_length: int, max_length: float) -&gt; bool:\n\t\t\"\"\"\n\t\tValidate if text length is between min and max length.\n\n\t\tArgs:\n\t\t    text (str | None): The text to validate, or None\n\t\t    min_length (int): Minimum allowed length\n\t\t    max_length (int | float): Maximum allowed length\n\n\t\tReturns:\n\t\t    bool: True if text length is valid, False otherwise\n\n\t\t\"\"\"\n\t\tif text is None:\n\t\t\treturn min_length == 0\n\n\t\ttext_length = len(text)\n\t\treturn min_length &lt;= text_length &lt; max_length\n\n\t@staticmethod\n\tdef validate_enum(text: str, allowed_values: list[str]) -&gt; bool:\n\t\t\"\"\"\n\t\tValidate if text is in the allowed values.\n\n\t\tArgs:\n\t\t    text (str): The text to validate\n\t\t    allowed_values (list): The allowed values\n\n\t\tReturns:\n\t\t    bool: True if text is in allowed values, False otherwise\n\n\t\t\"\"\"\n\t\t# Allow any value if no allowed values are specified\n\t\tif not allowed_values:\n\t\t\treturn True\n\n\t\treturn text.lower() in (value.lower() for value in allowed_values)\n\n\t@staticmethod\n\tdef validate_empty(text: str | None, should_be_empty: bool) -&gt; bool:\n\t\t\"\"\"\n\t\tValidate if text is empty or not based on configuration.\n\n\t\tArgs:\n\t\t    text (str | None): The text to validate\n\t\t    should_be_empty (bool): True if text should be empty, False if not\n\n\t\tReturns:\n\t\t    bool: True if text empty status matches should_be_empty\n\n\t\t\"\"\"\n\t\tis_empty = text is None or text.strip() == \"\"\n\t\treturn is_empty == should_be_empty\n\n\t@staticmethod\n\tdef validate_ends_with(text: str | None, suffix: str, should_end_with: bool) -&gt; bool:\n\t\t\"\"\"\n\t\tValidate if text ends with a specific suffix.\n\n\t\tArgs:\n\t\t    text (str | None): The text to validate\n\t\t    suffix (str): The suffix to check for\n\t\t    should_end_with (bool): True if text should end with suffix\n\n\t\tReturns:\n\t\t    bool: True if text ending matches expectation\n\n\t\t\"\"\"\n\t\tif text is None:\n\t\t\treturn not should_end_with\n\n\t\tends_with = text.endswith(suffix)\n\t\treturn ends_with == should_end_with\n\n\t@staticmethod\n\tdef validate_starts_with(text: str | None, prefix: str, should_start_with: bool) -&gt; bool:\n\t\t\"\"\"\n\t\tValidate if text starts with a specific prefix.\n\n\t\tArgs:\n\t\t    text (str | None): The text to validate\n\t\t    prefix (str): The prefix to check for\n\t\t    should_start_with (bool): True if text should start with prefix\n\n\t\tReturns:\n\t\t    bool: True if text starting matches expectation\n\n\t\t\"\"\"\n\t\tif text is None:\n\t\t\treturn not should_start_with\n\n\t\tstarts_with = text.startswith(prefix)\n\t\treturn starts_with == should_start_with\n\n\t@staticmethod\n\tdef validate_line_length(text: str | None, max_line_length: float) -&gt; list[int]:\n\t\t\"\"\"\n\t\tValidate line lengths in multiline text.\n\n\t\tArgs:\n\t\t    text (str | None): The text to validate\n\t\t    max_line_length (int | float): Maximum allowed line length\n\n\t\tReturns:\n\t\t    list: List of line numbers with errors (0-indexed)\n\n\t\t\"\"\"\n\t\tif text is None or max_line_length == float(\"inf\"):\n\t\t\treturn []\n\n\t\tlines = text.splitlines()\n\t\treturn [i for i, line in enumerate(lines) if len(line) &gt; max_line_length]\n\n\t@staticmethod\n\tdef validate_leading_blank(text: str | None, required_blank: bool) -&gt; bool:\n\t\t\"\"\"\n\t\tValidate if text starts with a blank line.\n\n\t\tArgs:\n\t\t    text (str | None): The text to validate\n\t\t    required_blank (bool): True if text should start with blank line\n\n\t\tReturns:\n\t\t    bool: True if text leading blank matches expectation\n\n\t\t\"\"\"\n\t\tif text is None:\n\t\t\treturn not required_blank\n\n\t\tlines = text.splitlines()\n\t\thas_leading_blank = len(lines) &gt; 0 and (len(lines) == 1 or not lines[0].strip())\n\t\treturn has_leading_blank == required_blank\n\n\t@staticmethod\n\tdef validate_trim(text: str | None) -&gt; bool:\n\t\t\"\"\"\n\t\tValidate if text has no leading/trailing whitespace.\n\n\t\tArgs:\n\t\t    text (str | None): The text to validate\n\n\t\tReturns:\n\t\t    bool: True if text has no leading/trailing whitespace\n\n\t\t\"\"\"\n\t\tif text is None:\n\t\t\treturn True\n\n\t\treturn text == text.strip()\n\n\t@staticmethod\n\tdef validate_contains(text: str | None, substring: str, should_contain: bool) -&gt; bool:\n\t\t\"\"\"\n\t\tValidate if text contains a specific substring.\n\n\t\tArgs:\n\t\t    text (str | None): The text to validate\n\t\t    substring (str): The substring to check for\n\t\t    should_contain (bool): True if text should contain substring\n\n\t\tReturns:\n\t\t    bool: True if text contains substring matches expectation\n\n\t\t\"\"\"\n\t\tif text is None:\n\t\t\treturn not should_contain\n\n\t\tcontains = substring in text\n\t\treturn contains == should_contain\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_footer_token","title":"validate_footer_token  <code>staticmethod</code>","text":"<pre><code>validate_footer_token(token: str) -&gt; bool\n</code></pre> <p>Validate a footer token according to the Conventional Commits spec.</p> <p>According to the spec: 1. Tokens MUST use hyphens instead of spaces 2. BREAKING CHANGE must be uppercase 3. Footer tokens should be ALL UPPERCASE 4. Footer tokens should follow format with - for spaces 5. No special characters or Unicode (non-ASCII) characters allowed</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if token is valid, False otherwise</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_footer_token(token: str) -&gt; bool:\n\t\"\"\"\n\tValidate a footer token according to the Conventional Commits spec.\n\n\tAccording to the spec:\n\t1. Tokens MUST use hyphens instead of spaces\n\t2. BREAKING CHANGE must be uppercase\n\t3. Footer tokens should be ALL UPPERCASE\n\t4. Footer tokens should follow format with - for spaces\n\t5. No special characters or Unicode (non-ASCII) characters allowed\n\n\tReturns:\n\t    bool: True if token is valid, False otherwise\n\n\t\"\"\"\n\t# Check if token is a breaking change token in any case\n\tif BREAKING_CHANGE_REGEX.match(token.lower()):\n\t\t# If it's a breaking change token, it MUST be uppercase\n\t\treturn token in (BREAKING_CHANGE, BREAKING_CHANGE_HYPHEN)\n\n\t# Check for special characters (except hyphens which are allowed)\n\tif any(c in token for c in \"!@#$%^&amp;*()+={}[]|\\\\:;\\\"'&lt;&gt;,./?\"):\n\t\treturn False\n\n\t# Check for non-ASCII characters\n\tif any(ord(c) &gt; ASCII_MAX_VALUE for c in token):\n\t\treturn False\n\n\t# Must match valid token pattern (uppercase, alphanumeric with hyphens)\n\tif not VALID_FOOTER_TOKEN_REGEX.match(token):\n\t\treturn False\n\n\t# Check for spaces (must use hyphens instead, except for BREAKING CHANGE)\n\treturn not (\" \" in token and token != BREAKING_CHANGE)\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_type_and_scope","title":"validate_type_and_scope  <code>staticmethod</code>","text":"<pre><code>validate_type_and_scope(\n\ttype_value: str, scope_value: str | None\n) -&gt; list[str]\n</code></pre> <p>Validate type and scope values according to the spec.</p> <p>Type must contain only letters. Scope must contain only letters, numbers, hyphens, and slashes. Both must be ASCII-only.</p> <p>Parameters:</p> Name Type Description Default <code>type_value</code> <code>str</code> <p>The commit message type</p> required <code>scope_value</code> <code>str | None</code> <p>The optional scope</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: List of error messages, empty if valid</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_type_and_scope(type_value: str, scope_value: str | None) -&gt; list[str]:\n\t\"\"\"\n\tValidate type and scope values according to the spec.\n\n\tType must contain only letters.\n\tScope must contain only letters, numbers, hyphens, and slashes.\n\tBoth must be ASCII-only.\n\n\tArgs:\n\t    type_value (str): The commit message type\n\t    scope_value (str | None): The optional scope\n\n\tReturns:\n\t    list[str]: List of error messages, empty if valid\n\n\t\"\"\"\n\terrors = []\n\n\t# Check type (no special chars or unicode)\n\tif not VALID_TYPE_REGEX.match(type_value):\n\t\terrors.append(f\"Invalid type '{type_value}'. Types must contain only letters (a-z, A-Z).\")\n\telif any(ord(c) &gt; ASCII_MAX_VALUE for c in type_value):\n\t\terrors.append(f\"Invalid type '{type_value}'. Types must contain only ASCII characters.\")\n\n\t# Check scope (if present)\n\tif scope_value is not None:\n\t\tif scope_value == \"\":\n\t\t\terrors.append(\"Scope cannot be empty when parentheses are used.\")\n\t\telif not VALID_SCOPE_REGEX.match(scope_value):\n\t\t\terrors.append(\n\t\t\t\tf\"Invalid scope '{scope_value}'. Scopes must contain only letters, numbers, hyphens, and slashes.\"\n\t\t\t)\n\t\telif any(ord(c) &gt; ASCII_MAX_VALUE for c in scope_value):\n\t\t\terrors.append(f\"Invalid scope '{scope_value}'. Scopes must contain only ASCII characters.\")\n\t\telif any(c in scope_value for c in \"!@#$%^&amp;*()+={}[]|\\\\:;\\\"'&lt;&gt;,. \"):\n\t\t\terrors.append(f\"Invalid scope '{scope_value}'. Special characters are not allowed in scopes.\")\n\n\treturn errors\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_case","title":"validate_case  <code>staticmethod</code>","text":"<pre><code>validate_case(\n\ttext: str, case_format: str | list[str]\n) -&gt; bool\n</code></pre> <p>Validate if the text follows the specified case format.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to validate</p> required <code>case_format</code> <code>str or list</code> <p>The case format(s) to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if text matches any of the specified case formats</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_case(text: str, case_format: str | list[str]) -&gt; bool:\n\t\"\"\"\n\tValidate if the text follows the specified case format.\n\n\tArgs:\n\t    text (str): The text to validate\n\t    case_format (str or list): The case format(s) to check\n\n\tReturns:\n\t    bool: True if text matches any of the specified case formats\n\n\t\"\"\"\n\tif isinstance(case_format, list):\n\t\treturn any(CommitValidators.validate_case(text, fmt) for fmt in case_format)\n\n\t# Get the validator function for the specified case format\n\tvalidator = CASE_FORMATS.get(case_format)\n\tif not validator:\n\t\t# Default to allowing any case if invalid format specified\n\t\treturn True\n\n\treturn validator(text)\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_length","title":"validate_length  <code>staticmethod</code>","text":"<pre><code>validate_length(\n\ttext: str | None, min_length: int, max_length: float\n) -&gt; bool\n</code></pre> <p>Validate if text length is between min and max length.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The text to validate, or None</p> required <code>min_length</code> <code>int</code> <p>Minimum allowed length</p> required <code>max_length</code> <code>int | float</code> <p>Maximum allowed length</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if text length is valid, False otherwise</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_length(text: str | None, min_length: int, max_length: float) -&gt; bool:\n\t\"\"\"\n\tValidate if text length is between min and max length.\n\n\tArgs:\n\t    text (str | None): The text to validate, or None\n\t    min_length (int): Minimum allowed length\n\t    max_length (int | float): Maximum allowed length\n\n\tReturns:\n\t    bool: True if text length is valid, False otherwise\n\n\t\"\"\"\n\tif text is None:\n\t\treturn min_length == 0\n\n\ttext_length = len(text)\n\treturn min_length &lt;= text_length &lt; max_length\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_enum","title":"validate_enum  <code>staticmethod</code>","text":"<pre><code>validate_enum(text: str, allowed_values: list[str]) -&gt; bool\n</code></pre> <p>Validate if text is in the allowed values.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to validate</p> required <code>allowed_values</code> <code>list</code> <p>The allowed values</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if text is in allowed values, False otherwise</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_enum(text: str, allowed_values: list[str]) -&gt; bool:\n\t\"\"\"\n\tValidate if text is in the allowed values.\n\n\tArgs:\n\t    text (str): The text to validate\n\t    allowed_values (list): The allowed values\n\n\tReturns:\n\t    bool: True if text is in allowed values, False otherwise\n\n\t\"\"\"\n\t# Allow any value if no allowed values are specified\n\tif not allowed_values:\n\t\treturn True\n\n\treturn text.lower() in (value.lower() for value in allowed_values)\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_empty","title":"validate_empty  <code>staticmethod</code>","text":"<pre><code>validate_empty(\n\ttext: str | None, should_be_empty: bool\n) -&gt; bool\n</code></pre> <p>Validate if text is empty or not based on configuration.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The text to validate</p> required <code>should_be_empty</code> <code>bool</code> <p>True if text should be empty, False if not</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if text empty status matches should_be_empty</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_empty(text: str | None, should_be_empty: bool) -&gt; bool:\n\t\"\"\"\n\tValidate if text is empty or not based on configuration.\n\n\tArgs:\n\t    text (str | None): The text to validate\n\t    should_be_empty (bool): True if text should be empty, False if not\n\n\tReturns:\n\t    bool: True if text empty status matches should_be_empty\n\n\t\"\"\"\n\tis_empty = text is None or text.strip() == \"\"\n\treturn is_empty == should_be_empty\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_ends_with","title":"validate_ends_with  <code>staticmethod</code>","text":"<pre><code>validate_ends_with(\n\ttext: str | None, suffix: str, should_end_with: bool\n) -&gt; bool\n</code></pre> <p>Validate if text ends with a specific suffix.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The text to validate</p> required <code>suffix</code> <code>str</code> <p>The suffix to check for</p> required <code>should_end_with</code> <code>bool</code> <p>True if text should end with suffix</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if text ending matches expectation</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_ends_with(text: str | None, suffix: str, should_end_with: bool) -&gt; bool:\n\t\"\"\"\n\tValidate if text ends with a specific suffix.\n\n\tArgs:\n\t    text (str | None): The text to validate\n\t    suffix (str): The suffix to check for\n\t    should_end_with (bool): True if text should end with suffix\n\n\tReturns:\n\t    bool: True if text ending matches expectation\n\n\t\"\"\"\n\tif text is None:\n\t\treturn not should_end_with\n\n\tends_with = text.endswith(suffix)\n\treturn ends_with == should_end_with\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_starts_with","title":"validate_starts_with  <code>staticmethod</code>","text":"<pre><code>validate_starts_with(\n\ttext: str | None, prefix: str, should_start_with: bool\n) -&gt; bool\n</code></pre> <p>Validate if text starts with a specific prefix.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The text to validate</p> required <code>prefix</code> <code>str</code> <p>The prefix to check for</p> required <code>should_start_with</code> <code>bool</code> <p>True if text should start with prefix</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if text starting matches expectation</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_starts_with(text: str | None, prefix: str, should_start_with: bool) -&gt; bool:\n\t\"\"\"\n\tValidate if text starts with a specific prefix.\n\n\tArgs:\n\t    text (str | None): The text to validate\n\t    prefix (str): The prefix to check for\n\t    should_start_with (bool): True if text should start with prefix\n\n\tReturns:\n\t    bool: True if text starting matches expectation\n\n\t\"\"\"\n\tif text is None:\n\t\treturn not should_start_with\n\n\tstarts_with = text.startswith(prefix)\n\treturn starts_with == should_start_with\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_line_length","title":"validate_line_length  <code>staticmethod</code>","text":"<pre><code>validate_line_length(\n\ttext: str | None, max_line_length: float\n) -&gt; list[int]\n</code></pre> <p>Validate line lengths in multiline text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The text to validate</p> required <code>max_line_length</code> <code>int | float</code> <p>Maximum allowed line length</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list[int]</code> <p>List of line numbers with errors (0-indexed)</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_line_length(text: str | None, max_line_length: float) -&gt; list[int]:\n\t\"\"\"\n\tValidate line lengths in multiline text.\n\n\tArgs:\n\t    text (str | None): The text to validate\n\t    max_line_length (int | float): Maximum allowed line length\n\n\tReturns:\n\t    list: List of line numbers with errors (0-indexed)\n\n\t\"\"\"\n\tif text is None or max_line_length == float(\"inf\"):\n\t\treturn []\n\n\tlines = text.splitlines()\n\treturn [i for i, line in enumerate(lines) if len(line) &gt; max_line_length]\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_leading_blank","title":"validate_leading_blank  <code>staticmethod</code>","text":"<pre><code>validate_leading_blank(\n\ttext: str | None, required_blank: bool\n) -&gt; bool\n</code></pre> <p>Validate if text starts with a blank line.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The text to validate</p> required <code>required_blank</code> <code>bool</code> <p>True if text should start with blank line</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if text leading blank matches expectation</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_leading_blank(text: str | None, required_blank: bool) -&gt; bool:\n\t\"\"\"\n\tValidate if text starts with a blank line.\n\n\tArgs:\n\t    text (str | None): The text to validate\n\t    required_blank (bool): True if text should start with blank line\n\n\tReturns:\n\t    bool: True if text leading blank matches expectation\n\n\t\"\"\"\n\tif text is None:\n\t\treturn not required_blank\n\n\tlines = text.splitlines()\n\thas_leading_blank = len(lines) &gt; 0 and (len(lines) == 1 or not lines[0].strip())\n\treturn has_leading_blank == required_blank\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_trim","title":"validate_trim  <code>staticmethod</code>","text":"<pre><code>validate_trim(text: str | None) -&gt; bool\n</code></pre> <p>Validate if text has no leading/trailing whitespace.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The text to validate</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if text has no leading/trailing whitespace</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_trim(text: str | None) -&gt; bool:\n\t\"\"\"\n\tValidate if text has no leading/trailing whitespace.\n\n\tArgs:\n\t    text (str | None): The text to validate\n\n\tReturns:\n\t    bool: True if text has no leading/trailing whitespace\n\n\t\"\"\"\n\tif text is None:\n\t\treturn True\n\n\treturn text == text.strip()\n</code></pre>"},{"location":"api/git/commit_linter/validators/#codemap.git.commit_linter.validators.CommitValidators.validate_contains","title":"validate_contains  <code>staticmethod</code>","text":"<pre><code>validate_contains(\n\ttext: str | None, substring: str, should_contain: bool\n) -&gt; bool\n</code></pre> <p>Validate if text contains a specific substring.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The text to validate</p> required <code>substring</code> <code>str</code> <p>The substring to check for</p> required <code>should_contain</code> <code>bool</code> <p>True if text should contain substring</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if text contains substring matches expectation</p> Source code in <code>src/codemap/git/commit_linter/validators.py</code> <pre><code>@staticmethod\ndef validate_contains(text: str | None, substring: str, should_contain: bool) -&gt; bool:\n\t\"\"\"\n\tValidate if text contains a specific substring.\n\n\tArgs:\n\t    text (str | None): The text to validate\n\t    substring (str): The substring to check for\n\t    should_contain (bool): True if text should contain substring\n\n\tReturns:\n\t    bool: True if text contains substring matches expectation\n\n\t\"\"\"\n\tif text is None:\n\t\treturn not should_contain\n\n\tcontains = substring in text\n\treturn contains == should_contain\n</code></pre>"},{"location":"api/git/diff_splitter/","title":"Diff Splitter Overview","text":"<p>Diff splitting package for CodeMap.</p> <ul> <li>Constants - Constants for diff splitting functionality.</li> <li>Schemas - Schema definitions for diff splitting.</li> <li>Splitter - Diff splitting implementation for CodeMap.</li> <li>Strategies - Strategies for splitting git diffs into logical chunks.</li> <li>Utils - Utility functions for diff splitting.</li> </ul>"},{"location":"api/git/diff_splitter/constants/","title":"Constants","text":"<p>Constants for diff splitting functionality.</p>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.MIN_CHUNKS_FOR_CONSOLIDATION","title":"MIN_CHUNKS_FOR_CONSOLIDATION  <code>module-attribute</code>","text":"<pre><code>MIN_CHUNKS_FOR_CONSOLIDATION: Final = 2\n</code></pre>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.MAX_CHUNKS_BEFORE_CONSOLIDATION","title":"MAX_CHUNKS_BEFORE_CONSOLIDATION  <code>module-attribute</code>","text":"<pre><code>MAX_CHUNKS_BEFORE_CONSOLIDATION: Final = 20\n</code></pre>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.MIN_NAME_LENGTH_FOR_SIMILARITY","title":"MIN_NAME_LENGTH_FOR_SIMILARITY  <code>module-attribute</code>","text":"<pre><code>MIN_NAME_LENGTH_FOR_SIMILARITY: Final = 3\n</code></pre>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.DEFAULT_SIMILARITY_THRESHOLD","title":"DEFAULT_SIMILARITY_THRESHOLD  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SIMILARITY_THRESHOLD: Final = 0.4\n</code></pre>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.DIRECTORY_SIMILARITY_THRESHOLD","title":"DIRECTORY_SIMILARITY_THRESHOLD  <code>module-attribute</code>","text":"<pre><code>DIRECTORY_SIMILARITY_THRESHOLD: Final = 0.3\n</code></pre>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.MAX_LOG_DIFF_SIZE","title":"MAX_LOG_DIFF_SIZE  <code>module-attribute</code>","text":"<pre><code>MAX_LOG_DIFF_SIZE = 1000\n</code></pre>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.MAX_FILE_SIZE_FOR_LLM","title":"MAX_FILE_SIZE_FOR_LLM  <code>module-attribute</code>","text":"<pre><code>MAX_FILE_SIZE_FOR_LLM: Final = 100000\n</code></pre>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.MODEL_NAME","title":"MODEL_NAME  <code>module-attribute</code>","text":"<pre><code>MODEL_NAME = 'sarthak1/Qodo-Embed-M-1-1.5B-M2V-Distilled'\n</code></pre>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.DEFAULT_CODE_EXTENSIONS","title":"DEFAULT_CODE_EXTENSIONS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_CODE_EXTENSIONS: Final = {\n\t\"js\",\n\t\"jsx\",\n\t\"ts\",\n\t\"tsx\",\n\t\"py\",\n\t\"java\",\n\t\"c\",\n\t\"cpp\",\n\t\"h\",\n\t\"hpp\",\n\t\"cc\",\n\t\"cs\",\n\t\"go\",\n\t\"rb\",\n\t\"php\",\n\t\"rs\",\n\t\"swift\",\n\t\"scala\",\n\t\"kt\",\n\t\"sh\",\n\t\"pl\",\n\t\"pm\",\n}\n</code></pre>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.EPSILON","title":"EPSILON  <code>module-attribute</code>","text":"<pre><code>EPSILON = 1e-10\n</code></pre>"},{"location":"api/git/diff_splitter/constants/#codemap.git.diff_splitter.constants.MAX_FILES_PER_GROUP","title":"MAX_FILES_PER_GROUP  <code>module-attribute</code>","text":"<pre><code>MAX_FILES_PER_GROUP: Final = 10\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/","title":"Schemas","text":"<p>Schema definitions for diff splitting.</p>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunk","title":"DiffChunk  <code>dataclass</code>","text":"<p>Represents a logical chunk of changes.</p> Source code in <code>src/codemap/git/diff_splitter/schemas.py</code> <pre><code>@dataclass\nclass DiffChunk:\n\t\"\"\"Represents a logical chunk of changes.\"\"\"\n\n\tfiles: list[str]\n\tcontent: str\n\tdescription: str | None = None\n\tis_llm_generated: bool = False\n\tfiltered_files: list[str] | None = None\n\n\tdef __post_init__(self) -&gt; None:\n\t\t\"\"\"Initialize default values.\"\"\"\n\t\tif self.filtered_files is None:\n\t\t\tself.filtered_files = []\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunk.__init__","title":"__init__","text":"<pre><code>__init__(\n\tfiles: list[str],\n\tcontent: str,\n\tdescription: str | None = None,\n\tis_llm_generated: bool = False,\n\tfiltered_files: list[str] | None = None,\n) -&gt; None\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunk.files","title":"files  <code>instance-attribute</code>","text":"<pre><code>files: list[str]\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunk.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: str\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunk.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description: str | None = None\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunk.is_llm_generated","title":"is_llm_generated  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_llm_generated: bool = False\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunk.filtered_files","title":"filtered_files  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>filtered_files: list[str] | None = None\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunk.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Initialize default values.</p> Source code in <code>src/codemap/git/diff_splitter/schemas.py</code> <pre><code>def __post_init__(self) -&gt; None:\n\t\"\"\"Initialize default values.\"\"\"\n\tif self.filtered_files is None:\n\t\tself.filtered_files = []\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunkData","title":"DiffChunkData  <code>dataclass</code>","text":"<p>Dictionary-based representation of a DiffChunk for serialization.</p> Source code in <code>src/codemap/git/diff_splitter/schemas.py</code> <pre><code>@dataclass\nclass DiffChunkData:\n\t\"\"\"Dictionary-based representation of a DiffChunk for serialization.\"\"\"\n\n\tfiles: list[str]\n\tcontent: str\n\tdescription: str | None = None\n\tis_llm_generated: bool = False\n\tfiltered_files: list[str] | None = None\n\n\t@classmethod\n\tdef from_chunk(cls, chunk: DiffChunk) -&gt; \"DiffChunkData\":\n\t\t\"\"\"Create a DiffChunkData from a DiffChunk.\"\"\"\n\t\treturn cls(\n\t\t\tfiles=chunk.files,\n\t\t\tcontent=chunk.content,\n\t\t\tdescription=chunk.description,\n\t\t\tis_llm_generated=chunk.is_llm_generated,\n\t\t\tfiltered_files=chunk.filtered_files,\n\t\t)\n\n\tdef to_chunk(self) -&gt; DiffChunk:\n\t\t\"\"\"Convert DiffChunkData to a DiffChunk.\"\"\"\n\t\treturn DiffChunk(\n\t\t\tfiles=self.files,\n\t\t\tcontent=self.content,\n\t\t\tdescription=self.description,\n\t\t\tis_llm_generated=self.is_llm_generated,\n\t\t\tfiltered_files=self.filtered_files,\n\t\t)\n\n\tdef to_dict(self) -&gt; dict[str, Any]:\n\t\t\"\"\"Convert to a dictionary.\"\"\"\n\t\treturn {\n\t\t\t\"files\": self.files,\n\t\t\t\"content\": self.content,\n\t\t\t\"description\": self.description,\n\t\t\t\"is_llm_generated\": self.is_llm_generated,\n\t\t\t\"filtered_files\": self.filtered_files,\n\t\t}\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunkData.__init__","title":"__init__","text":"<pre><code>__init__(\n\tfiles: list[str],\n\tcontent: str,\n\tdescription: str | None = None,\n\tis_llm_generated: bool = False,\n\tfiltered_files: list[str] | None = None,\n) -&gt; None\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunkData.files","title":"files  <code>instance-attribute</code>","text":"<pre><code>files: list[str]\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunkData.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: str\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunkData.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description: str | None = None\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunkData.is_llm_generated","title":"is_llm_generated  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_llm_generated: bool = False\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunkData.filtered_files","title":"filtered_files  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>filtered_files: list[str] | None = None\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunkData.from_chunk","title":"from_chunk  <code>classmethod</code>","text":"<pre><code>from_chunk(chunk: DiffChunk) -&gt; DiffChunkData\n</code></pre> <p>Create a DiffChunkData from a DiffChunk.</p> Source code in <code>src/codemap/git/diff_splitter/schemas.py</code> <pre><code>@classmethod\ndef from_chunk(cls, chunk: DiffChunk) -&gt; \"DiffChunkData\":\n\t\"\"\"Create a DiffChunkData from a DiffChunk.\"\"\"\n\treturn cls(\n\t\tfiles=chunk.files,\n\t\tcontent=chunk.content,\n\t\tdescription=chunk.description,\n\t\tis_llm_generated=chunk.is_llm_generated,\n\t\tfiltered_files=chunk.filtered_files,\n\t)\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunkData.to_chunk","title":"to_chunk","text":"<pre><code>to_chunk() -&gt; DiffChunk\n</code></pre> <p>Convert DiffChunkData to a DiffChunk.</p> Source code in <code>src/codemap/git/diff_splitter/schemas.py</code> <pre><code>def to_chunk(self) -&gt; DiffChunk:\n\t\"\"\"Convert DiffChunkData to a DiffChunk.\"\"\"\n\treturn DiffChunk(\n\t\tfiles=self.files,\n\t\tcontent=self.content,\n\t\tdescription=self.description,\n\t\tis_llm_generated=self.is_llm_generated,\n\t\tfiltered_files=self.filtered_files,\n\t)\n</code></pre>"},{"location":"api/git/diff_splitter/schemas/#codemap.git.diff_splitter.schemas.DiffChunkData.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to a dictionary.</p> Source code in <code>src/codemap/git/diff_splitter/schemas.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n\t\"\"\"Convert to a dictionary.\"\"\"\n\treturn {\n\t\t\"files\": self.files,\n\t\t\"content\": self.content,\n\t\t\"description\": self.description,\n\t\t\"is_llm_generated\": self.is_llm_generated,\n\t\t\"filtered_files\": self.filtered_files,\n\t}\n</code></pre>"},{"location":"api/git/diff_splitter/splitter/","title":"Splitter","text":"<p>Diff splitting implementation for CodeMap.</p>"},{"location":"api/git/diff_splitter/splitter/#codemap.git.diff_splitter.splitter.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/diff_splitter/splitter/#codemap.git.diff_splitter.splitter.DiffSplitter","title":"DiffSplitter","text":"<p>Splits Git diffs into logical chunks.</p> Source code in <code>src/codemap/git/diff_splitter/splitter.py</code> <pre><code>class DiffSplitter:\n\t\"\"\"Splits Git diffs into logical chunks.\"\"\"\n\n\t# Class-level cache for the embedding model\n\t_embedding_model = None\n\t# Track availability of sentence-transformers and the model\n\t_sentence_transformers_available = None\n\t_model_available = None\n\n\tdef __init__(self, repo_root: Path) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the diff splitter.\n\n\t\tArgs:\n\t\t    repo_root: Root directory of the Git repository\n\n\t\t\"\"\"\n\t\tself.repo_root = repo_root\n\n\t\t# Do NOT automatically check availability - let the command class do this explicitly\n\t\t# This avoids checks happening during initialization without visible loading states\n\n\t@classmethod\n\tdef _check_sentence_transformers_availability(cls) -&gt; bool:\n\t\t\"\"\"\n\t\tCheck if sentence-transformers package is available.\n\n\t\tReturns:\n\t\t    True if sentence-transformers is available, False otherwise\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\t# This is needed for the import check, but don't flag as unused\n\t\t\timport sentence_transformers  # type: ignore  # noqa: F401, PGH003\n\n\t\t\t# Set the class flag for future reference\n\t\t\tcls._sentence_transformers_available = True\n\t\t\tlogger.debug(\"sentence-transformers is available\")\n\t\t\treturn True\n\t\texcept ImportError as e:\n\t\t\t# Log the specific import error for better debugging\n\t\t\tcls._sentence_transformers_available = False\n\t\t\tlogger.warning(\n\t\t\t\t\"sentence-transformers import failed: %s. Semantic similarity features will be limited. \"\n\t\t\t\t\"Install with: pip install sentence-transformers numpy\",\n\t\t\t\te,\n\t\t\t)\n\t\t\treturn False\n\t\texcept (RuntimeError, ValueError, AttributeError) as e:\n\t\t\t# Catch specific errors during import\n\t\t\tcls._sentence_transformers_available = False\n\t\t\tlogger.warning(\n\t\t\t\t\"Unexpected error importing sentence-transformers: %s. Semantic similarity features will be limited.\", e\n\t\t\t)\n\t\t\treturn False\n\n\t@classmethod\n\tdef _check_model_availability(cls, model_name: str = MODEL_NAME) -&gt; bool:\n\t\t\"\"\"\n\t\tCheck if the embedding model is available.\n\n\t\tArgs:\n\t\t    model_name: Name of the model to check\n\n\t\tReturns:\n\t\t    True if model is available, False otherwise\n\n\t\t\"\"\"\n\t\tif not DiffSplitter._sentence_transformers_available:\n\t\t\treturn False\n\n\t\ttry:\n\t\t\tfrom sentence_transformers import SentenceTransformer\n\n\t\t\t# Create model instance if not already created\n\t\t\tif DiffSplitter._embedding_model is None:\n\t\t\t\tlogger.debug(\"Loading embedding model: %s\", model_name)\n\n\t\t\t\ttry:\n\t\t\t\t\t# Use a simpler loading approach without Progress bar\n\t\t\t\t\t# to avoid \"Only one live display may be active at once\" error\n\t\t\t\t\tconsole.print(\"Loading embedding model...\")\n\n\t\t\t\t\t# Load the model without progress tracking\n\t\t\t\t\tDiffSplitter._embedding_model = SentenceTransformer(model_name)\n\n\t\t\t\t\tconsole.print(\"[green]\u2713[/green] Model loaded successfully\")\n\n\t\t\t\t\tlogger.debug(\"Initialized embedding model: %s\", model_name)\n\t\t\t\t\t# Explicitly set the class variable to True when model loads successfully\n\t\t\t\t\tcls._model_available = True\n\t\t\t\t\treturn True\n\t\t\t\texcept ImportError as e:\n\t\t\t\t\tlogger.exception(\"Missing dependencies for embedding model\")\n\t\t\t\t\tconsole.print(f\"[red]Error: Missing dependencies: {e}[/red]\")\n\t\t\t\t\tcls._model_available = False\n\t\t\t\t\treturn False\n\t\t\t\texcept MemoryError:\n\t\t\t\t\tlogger.exception(\"Not enough memory to load embedding model\")\n\t\t\t\t\tconsole.print(\"[red]Error: Not enough memory to load embedding model[/red]\")\n\t\t\t\t\tcls._model_available = False\n\t\t\t\t\treturn False\n\t\t\t\texcept ValueError as e:\n\t\t\t\t\tlogger.exception(\"Invalid model configuration\")\n\t\t\t\t\tconsole.print(f\"[red]Error: Invalid model configuration: {e}[/red]\")\n\t\t\t\t\tcls._model_available = False\n\t\t\t\t\treturn False\n\t\t\t\texcept RuntimeError as e:\n\t\t\t\t\terror_msg = str(e)\n\t\t\t\t\t# Check for CUDA/GPU related errors\n\t\t\t\t\tif \"CUDA\" in error_msg or \"GPU\" in error_msg:\n\t\t\t\t\t\tlogger.exception(\"GPU error when loading model\")\n\t\t\t\t\t\tconsole.print(\"[red]Error: GPU/CUDA error. Try using CPU only mode.[/red]\")\n\t\t\t\t\telse:\n\t\t\t\t\t\tlogger.exception(\"Runtime error when loading model\")\n\t\t\t\t\t\tconsole.print(f\"[red]Error loading model: {error_msg}[/red]\")\n\t\t\t\t\tcls._model_available = False\n\t\t\t\t\treturn False\n\t\t\t\texcept Exception as e:\n\t\t\t\t\tlogger.exception(\"Unexpected error loading embedding model\")\n\t\t\t\t\tconsole.print(f\"[red]Unexpected error loading model: {e}[/red]\")\n\t\t\t\t\tcls._model_available = False\n\t\t\t\t\treturn False\n\t\t\t# If we already have a model loaded, make sure to set the flag to True\n\t\t\tcls._model_available = True\n\t\t\treturn True\n\t\texcept Exception as e:\n\t\t\t# This is the outer exception handler for any unexpected errors\n\t\t\tlogger.exception(\"Failed to load embedding model %s\", model_name)\n\t\t\tconsole.print(f\"[red]Failed to load embedding model: {e}[/red]\")\n\t\t\tcls._model_available = False\n\t\t\treturn False\n\n\tdef split_diff(self, diff: GitDiff) -&gt; tuple[list[DiffChunk], list[str]]:\n\t\t\"\"\"\n\t\tSplit a diff into logical chunks using semantic splitting.\n\n\t\tArgs:\n\t\t    diff: GitDiff object to split\n\n\t\tReturns:\n\t\t    Tuple of (List of DiffChunk objects based on semantic analysis, List of filtered large files)\n\n\t\tRaises:\n\t\t    ValueError: If semantic splitting is not available or fails\n\n\t\t\"\"\"\n\t\tfiltered_large_files = []\n\n\t\tif not diff.files:\n\t\t\treturn [], filtered_large_files\n\n\t\t# In test environments, log the diff content for debugging\n\t\tif is_test_environment():\n\t\t\tlogger.debug(\"Processing diff in test environment with %d files\", len(diff.files) if diff.files else 0)\n\t\t\tif diff.content and len(diff.content) &lt; MAX_LOG_DIFF_SIZE:  # Only log short diffs to avoid spamming logs\n\t\t\t\tlogger.debug(\"Diff content: %s\", diff.content)\n\n\t\t# Check for excessively large diff content and handle appropriately\n\t\tif diff.content and len(diff.content) &gt; MAX_FILE_SIZE_FOR_LLM:\n\t\t\tlogger.warning(\"Diff content is very large (%d bytes). Processing might be limited.\", len(diff.content))\n\n\t\t\t# Try to extract file names directly from the diff content for large diffs\n\t\t\tfile_list = re.findall(r\"diff --git a/(.*?) b/(.*?)$\", diff.content, re.MULTILINE)\n\t\t\tif file_list:\n\t\t\t\tlogger.info(\"Extracted %d files from large diff content\", len(file_list))\n\t\t\t\tfiles_to_process = [f[1] for f in file_list]  # Use the \"b\" side of each diff\n\n\t\t\t\t# Override diff.files with extracted file list to bypass content processing\n\t\t\t\tdiff.files = files_to_process\n\n\t\t\t\t# Optional: Clear the content to avoid processing it\n\t\t\t\toriginal_content_size = len(diff.content)\n\t\t\t\tdiff.content = \"\"\n\t\t\t\tlogger.info(\"Cleared %d bytes of diff content to avoid payload limits\", original_content_size)\n\n\t\t# Process files in the diff\n\t\tif diff.files:\n\t\t\tdiff.files, large_files = filter_valid_files(diff.files, is_test_environment())\n\t\t\tfiltered_large_files.extend(large_files)\n\n\t\tif not diff.files:\n\t\t\tlogger.warning(\"No valid files to process after filtering\")\n\t\t\treturn [], filtered_large_files\n\n\t\t# Set up availability flags if not already set\n\t\tcls = type(self)\n\t\tcls._sentence_transformers_available = (\n\t\t\tcls._sentence_transformers_available or cls._check_sentence_transformers_availability()\n\t\t)\n\n\t\tif not cls._sentence_transformers_available:\n\t\t\tmsg = (\n\t\t\t\t\"Semantic splitting is not available. sentence-transformers package is required. \"\n\t\t\t\t\"Install with: pip install sentence-transformers numpy\"\n\t\t\t)\n\t\t\traise ValueError(msg)\n\n\t\t# Try to load the model\n\t\twith loading_spinner(\"Loading embedding model...\"):\n\t\t\tcls._model_available = cls._model_available or cls._check_model_availability()\n\n\t\tif not cls._model_available:\n\t\t\tmsg = (\n\t\t\t\t\"Semantic splitting failed: embedding model could not be loaded. \"\n\t\t\t\t\"Check logs for details or try a different model.\"\n\t\t\t)\n\t\t\traise ValueError(msg)\n\n\t\t# Use semantic splitting\n\t\tchunks = self._split_semantic(diff)\n\t\treturn chunks, filtered_large_files\n\n\tdef _extract_code_from_diff(self, diff_content: str) -&gt; tuple[str, str]:\n\t\t\"\"\"\n\t\tExtract old and new code from diff content.\n\n\t\tArgs:\n\t\t    diff_content: Git diff content\n\n\t\tReturns:\n\t\t    Tuple of (old_code, new_code)\n\n\t\t\"\"\"\n\t\treturn _extract_code_from_diff(diff_content)\n\n\tdef _semantic_hunk_splitting(self, file_path: str, diff_content: str) -&gt; list[str]:\n\t\t\"\"\"\n\t\tSplit a diff into semantic hunks based on code structure, preserving hunk integrity.\n\n\t\tArgs:\n\t\t    file_path: Path to the file\n\t\t    diff_content: Git diff content for a single file\n\n\t\tReturns:\n\t\t    List of diff chunk strings, where each chunk contains one or more full hunks.\n\n\t\t\"\"\"\n\t\tif not diff_content.strip():\n\t\t\treturn []  # Return empty list if diff content is empty\n\n\t\t# Extract language-specific patterns\n\t\textension = Path(file_path).suffix.lower()\n\t\tpatterns = [re.compile(p) for p in get_language_specific_patterns(extension.lstrip(\".\"))]\n\n\t\tif not patterns:\n\t\t\tlogger.debug(\"No language patterns found for %s, returning whole diff as one chunk\", extension)\n\t\t\treturn [diff_content]\n\n\t\tdiff_lines = diff_content.splitlines()\n\t\traw_hunks: list[list[str]] = []\n\t\tcurrent_hunk_lines: list[str] = []\n\t\tis_first_hunk = True\n\n\t\t# Split into raw hunks (including headers and file context lines)\n\t\tfor line in diff_lines:\n\t\t\tif line.startswith(\"@@ \"):\n\t\t\t\tif not is_first_hunk and current_hunk_lines:  # Don't add if it's the first @@ and list is empty\n\t\t\t\t\traw_hunks.append(current_hunk_lines)\n\t\t\t\t\tcurrent_hunk_lines = [line]  # Start new hunk with the @@ line\n\t\t\t\telse:\n\t\t\t\t\tcurrent_hunk_lines.append(line)  # Add first @@ line or lines before first @@\n\t\t\t\tis_first_hunk = False\n\t\t\telse:\n\t\t\t\tcurrent_hunk_lines.append(line)  # Add non-@@ lines\n\n\t\tif current_hunk_lines:\n\t\t\traw_hunks.append(current_hunk_lines)\n\n\t\tif not raw_hunks:\n\t\t\tlogger.debug(\"No hunks found in diff content for %s\", file_path)\n\t\t\treturn [diff_content]  # Return original content if parsing fails\n\n\t\t# Process hunks to create semantic chunks\n\t\tfinal_chunks: list[list[str]] = []\n\t\tcurrent_semantic_chunk_lines: list[str] = []\n\n\t\tfor hunk_lines in raw_hunks:\n\t\t\thunk_has_boundary = False\n\t\t\t# Check added lines within this hunk for semantic boundaries\n\t\t\tfor line in hunk_lines:\n\t\t\t\tif line.startswith(\"+\"):\n\t\t\t\t\tadded_line_content = line[1:]  # Check content without the '+'\n\t\t\t\t\tif any(pattern.match(added_line_content) for pattern in patterns):\n\t\t\t\t\t\thunk_has_boundary = True\n\t\t\t\t\t\tbreak  # Found a boundary in this hunk\n\n\t\t\t# Decision: Start a new semantic chunk IF the current hunk has a boundary\n\t\t\t# AND we already have lines accumulated in the current semantic chunk.\n\t\t\tif hunk_has_boundary and current_semantic_chunk_lines:\n\t\t\t\tfinal_chunks.append(current_semantic_chunk_lines)  # Finalize previous semantic chunk\n\t\t\t\tcurrent_semantic_chunk_lines = hunk_lines  # Start new semantic chunk with current hunk\n\t\t\telse:\n\t\t\t\t# Otherwise, append the current hunk to the ongoing semantic chunk\n\t\t\t\tcurrent_semantic_chunk_lines.extend(hunk_lines)\n\n\t\t# Add the last accumulated semantic chunk\n\t\tif current_semantic_chunk_lines:\n\t\t\tfinal_chunks.append(current_semantic_chunk_lines)\n\n\t\t# Join the lines back into strings for each chunk\n\t\tresult_chunks = [\"\\n\".join(chunk_lines) for chunk_lines in final_chunks]\n\n\t\t# Handle the case where splitting results in no usable chunks (e.g., only headers split)\n\t\tif not result_chunks or all(not c.strip() for c in result_chunks):\n\t\t\tlogger.debug(\"Semantic splitting resulted in empty chunks for %s, returning whole diff.\", file_path)\n\t\t\treturn [diff_content]\n\n\t\tlogger.debug(\"Split %s into %d semantic chunks\", file_path, len(result_chunks))\n\t\treturn result_chunks\n\n\tdef _enhance_semantic_split(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\t\"\"\"\n\t\tEnhance semantic splitting by analyzing code structure.\n\n\t\tThis method now aims to return a SINGLE chunk per file, using semantic\n\t\tsplitting internally perhaps for description generation, but not for splitting.\n\n\t\tArgs:\n\t\t    diff: GitDiff object to split (should contain only one file)\n\n\t\tReturns:\n\t\t    A list containing at most one DiffChunk.\n\n\t\t\"\"\"\n\t\tif not diff.content or not diff.files:\n\t\t\treturn []\n\n\t\t# This function should now only handle single-file diffs\n\t\tif len(diff.files) != 1:\n\t\t\tlogger.warning(\"_enhance_semantic_split called with %d files, expected 1. Skipping.\", len(diff.files))\n\t\t\t# Optionally, handle multi-file diffs by falling back to file splitting\n\t\t\t# return FileSplitStrategy().split(diff)\n\t\t\treturn []\n\n\t\tfile_path = diff.files[0]\n\n\t\t# --- Removed semantic hunk splitting logic for chunk creation ---\n\t\t# semantic_chunks_content = self._semantic_hunk_splitting(file_path, diff.content)\n\t\t# if not semantic_chunks_content:\n\t\t# \treturn [DiffChunk(files=[file_path], content=diff.content, description=f\"Changes in {file_path}\")]\n\n\t\t# Simply return one chunk containing the full diff content for the file.\n\t\t# Semantic analysis might still happen elsewhere (e.g., for description generation)\n\t\t# but we don't split the chunk itself here.\n\t\treturn [\n\t\t\tDiffChunk(\n\t\t\t\tfiles=[file_path],\n\t\t\t\tcontent=diff.content,  # Use the original full diff content\n\t\t\t\tdescription=f\"Changes in {file_path}\",  # Basic description, can be enhanced later\n\t\t\t)\n\t\t]\n\n\tdef _split_semantic(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\t\"\"\"\n\t\tSplit a diff semantically considering code structure.\n\n\t\tArgs:\n\t\t    diff: GitDiff object to split\n\n\t\tReturns:\n\t\t    List of DiffChunk objects based on semantic analysis\n\n\t\t\"\"\"\n\t\t# Try semantic strategy first\n\t\ttry:\n\t\t\t# Apply semantic splitting\n\t\t\tsemantic_strategy = SemanticSplitStrategy(embedding_model=cast(\"EmbeddingModel\", self._embedding_model))\n\t\t\tchunks = semantic_strategy.split(diff)\n\n\t\t\tif chunks:\n\t\t\t\treturn chunks\n\n\t\t\t# If semantic splitting produced no chunks, log a warning and continue to fallbacks\n\t\t\tlogger.warning(\n\t\t\t\t\"Semantic splitting failed to produce any chunks. Falling back to simpler strategies. \"\n\t\t\t\t\"This commonly happens with large refactoring operations.\"\n\t\t\t)\n\t\texcept (ValueError, RuntimeError, TypeError, KeyError, IndexError) as e:\n\t\t\t# Log specific exceptions from semantic splitting and fall back\n\t\t\tlogger.warning(\"Semantic splitting encountered an error: %s. Falling back to simpler strategies.\", e)\n\n\t\t# First fallback: directory-based grouping\n\t\tlogger.info(\"Using directory-based grouping as fallback strategy\")\n\t\tdir_chunks = []\n\n\t\ttry:\n\t\t\t# Group files by directory\n\t\t\tfiles_by_dir = {}\n\t\t\tfor file in diff.files:\n\t\t\t\tdir_path = str(Path(file).parent)\n\t\t\t\tif dir_path not in files_by_dir:\n\t\t\t\t\tfiles_by_dir[dir_path] = []\n\t\t\t\tfiles_by_dir[dir_path].append(file)\n\n\t\t\t# Create one chunk per directory\n\t\t\tfor dir_path, files in files_by_dir.items():\n\t\t\t\tif files:\n\t\t\t\t\tdisplay_name = dir_path if dir_path != \".\" else \"root directory\"\n\t\t\t\t\tdir_chunks.append(\n\t\t\t\t\t\tDiffChunk(\n\t\t\t\t\t\t\tfiles=files,\n\t\t\t\t\t\t\tcontent=diff.content,\n\t\t\t\t\t\t\tdescription=f\"Changes in {display_name}\",\n\t\t\t\t\t\t)\n\t\t\t\t\t)\n\n\t\t\tif dir_chunks:\n\t\t\t\treturn dir_chunks\n\t\texcept (ValueError, KeyError, TypeError, AttributeError, OSError) as dir_error:\n\t\t\tlogger.warning(\"Directory-based fallback failed: %s\", dir_error)\n\n\t\t# Second fallback: file-based splitting\n\t\tlogger.info(\"Using file-based splitting as final fallback strategy\")\n\t\tfile_strategy = FileSplitStrategy()\n\t\tchunks = file_strategy.split(diff)\n\n\t\tif chunks:\n\t\t\treturn chunks\n\n\t\t# Last resort: create one chunk per file if all else fails\n\t\tlogger.info(\"File splitting produced no chunks. Creating basic chunks (one per file).\")\n\t\treturn [\n\t\t\tDiffChunk(\n\t\t\t\tfiles=[file],\n\t\t\t\tcontent=f\"File: {file}\\n{diff.content}\",\n\t\t\t\tdescription=f\"Changes in {file}\",\n\t\t\t)\n\t\t\tfor file in diff.files\n\t\t]\n\n\tdef _calculate_semantic_similarity(self, text1: str, text2: str) -&gt; float:\n\t\t\"\"\"\n\t\tCalculate semantic similarity between two text segments.\n\n\t\tArgs:\n\t\t    text1: First text\n\t\t    text2: Second text\n\n\t\tReturns:\n\t\t    Similarity score between 0 and 1\n\n\t\t\"\"\"\n\t\tif not text1 or not text2:\n\t\t\treturn 0.0\n\n\t\t# Check if embedding model is available\n\t\tcls = type(self)\n\t\tcls._sentence_transformers_available = (\n\t\t\tcls._sentence_transformers_available or cls._check_sentence_transformers_availability()\n\t\t)\n\n\t\tif not cls._sentence_transformers_available:\n\t\t\tlogger.debug(\"Sentence transformers not available, returning zero similarity\")\n\t\t\treturn 0.0\n\n\t\tcls._model_available = cls._model_available or cls._check_model_availability()\n\n\t\tif not cls._model_available or cls._embedding_model is None:\n\t\t\tlogger.debug(\"Embedding model not available, returning zero similarity\")\n\t\t\treturn 0.0\n\n\t\ttry:\n\t\t\t# Encode both texts\n\t\t\tembeddings = cls._embedding_model.encode([text1, text2])\n\n\t\t\t# Calculate cosine similarity using utility function\n\t\t\treturn calculate_semantic_similarity(embeddings[0].tolist(), embeddings[1].tolist())\n\n\t\texcept (ValueError, TypeError, IndexError, RuntimeError) as e:\n\t\t\tlogger.warning(\"Error calculating semantic similarity: %s\", e)\n\t\t\treturn 0.0\n\n\t@classmethod\n\tdef encode_chunks(cls, chunks: list[str]) -&gt; dict[str, np.ndarray]:\n\t\t\"\"\"\n\t\tEncode text chunks into embeddings.\n\n\t\tArgs:\n\t\t    chunks: List of text chunks\n\n\t\tReturns:\n\t\t    Dict with keys 'embeddings' containing numpy array of embeddings\n\n\t\t\"\"\"\n\t\t# Ensure the model is initialized\n\t\tcls._sentence_transformers_available = (\n\t\t\tcls._sentence_transformers_available or cls._check_sentence_transformers_availability()\n\t\t)\n\t\tif cls._sentence_transformers_available:\n\t\t\tcls._model_available = cls._model_available or cls._check_model_availability(model_name=MODEL_NAME)\n\n\t\tif not cls._model_available:\n\t\t\tlogger.debug(\"Embedding model not available, returning empty embeddings\")\n\t\t\treturn {\"embeddings\": np.array([])}\n\n\t\tif not chunks:\n\t\t\treturn {\"embeddings\": np.array([])}\n\n\t\t# At this point we know model is initialized and available\n\t\tif cls._embedding_model is None:\n\t\t\tlogger.debug(\"Embedding model is None but was marked as available, reinitializing\")\n\t\t\tcls._model_available = cls._check_model_availability(model_name=MODEL_NAME)\n\t\t\tif not cls._model_available:\n\t\t\t\treturn {\"embeddings\": np.array([])}\n\n\t\t# Use runtime check instead of assert\n\t\tif cls._embedding_model is None:\n\t\t\tlogger.error(\"Embedding model is None but should be initialized at this point\")\n\t\t\treturn {\"embeddings\": np.array([])}\n\n\t\tembeddings = cls._embedding_model.encode(chunks)\n\t\treturn {\"embeddings\": embeddings}\n</code></pre>"},{"location":"api/git/diff_splitter/splitter/#codemap.git.diff_splitter.splitter.DiffSplitter.__init__","title":"__init__","text":"<pre><code>__init__(repo_root: Path) -&gt; None\n</code></pre> <p>Initialize the diff splitter.</p> <p>Parameters:</p> Name Type Description Default <code>repo_root</code> <code>Path</code> <p>Root directory of the Git repository</p> required Source code in <code>src/codemap/git/diff_splitter/splitter.py</code> <pre><code>def __init__(self, repo_root: Path) -&gt; None:\n\t\"\"\"\n\tInitialize the diff splitter.\n\n\tArgs:\n\t    repo_root: Root directory of the Git repository\n\n\t\"\"\"\n\tself.repo_root = repo_root\n</code></pre>"},{"location":"api/git/diff_splitter/splitter/#codemap.git.diff_splitter.splitter.DiffSplitter.repo_root","title":"repo_root  <code>instance-attribute</code>","text":"<pre><code>repo_root = repo_root\n</code></pre>"},{"location":"api/git/diff_splitter/splitter/#codemap.git.diff_splitter.splitter.DiffSplitter.split_diff","title":"split_diff","text":"<pre><code>split_diff(\n\tdiff: GitDiff,\n) -&gt; tuple[list[DiffChunk], list[str]]\n</code></pre> <p>Split a diff into logical chunks using semantic splitting.</p> <p>Parameters:</p> Name Type Description Default <code>diff</code> <code>GitDiff</code> <p>GitDiff object to split</p> required <p>Returns:</p> Type Description <code>tuple[list[DiffChunk], list[str]]</code> <p>Tuple of (List of DiffChunk objects based on semantic analysis, List of filtered large files)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If semantic splitting is not available or fails</p> Source code in <code>src/codemap/git/diff_splitter/splitter.py</code> <pre><code>def split_diff(self, diff: GitDiff) -&gt; tuple[list[DiffChunk], list[str]]:\n\t\"\"\"\n\tSplit a diff into logical chunks using semantic splitting.\n\n\tArgs:\n\t    diff: GitDiff object to split\n\n\tReturns:\n\t    Tuple of (List of DiffChunk objects based on semantic analysis, List of filtered large files)\n\n\tRaises:\n\t    ValueError: If semantic splitting is not available or fails\n\n\t\"\"\"\n\tfiltered_large_files = []\n\n\tif not diff.files:\n\t\treturn [], filtered_large_files\n\n\t# In test environments, log the diff content for debugging\n\tif is_test_environment():\n\t\tlogger.debug(\"Processing diff in test environment with %d files\", len(diff.files) if diff.files else 0)\n\t\tif diff.content and len(diff.content) &lt; MAX_LOG_DIFF_SIZE:  # Only log short diffs to avoid spamming logs\n\t\t\tlogger.debug(\"Diff content: %s\", diff.content)\n\n\t# Check for excessively large diff content and handle appropriately\n\tif diff.content and len(diff.content) &gt; MAX_FILE_SIZE_FOR_LLM:\n\t\tlogger.warning(\"Diff content is very large (%d bytes). Processing might be limited.\", len(diff.content))\n\n\t\t# Try to extract file names directly from the diff content for large diffs\n\t\tfile_list = re.findall(r\"diff --git a/(.*?) b/(.*?)$\", diff.content, re.MULTILINE)\n\t\tif file_list:\n\t\t\tlogger.info(\"Extracted %d files from large diff content\", len(file_list))\n\t\t\tfiles_to_process = [f[1] for f in file_list]  # Use the \"b\" side of each diff\n\n\t\t\t# Override diff.files with extracted file list to bypass content processing\n\t\t\tdiff.files = files_to_process\n\n\t\t\t# Optional: Clear the content to avoid processing it\n\t\t\toriginal_content_size = len(diff.content)\n\t\t\tdiff.content = \"\"\n\t\t\tlogger.info(\"Cleared %d bytes of diff content to avoid payload limits\", original_content_size)\n\n\t# Process files in the diff\n\tif diff.files:\n\t\tdiff.files, large_files = filter_valid_files(diff.files, is_test_environment())\n\t\tfiltered_large_files.extend(large_files)\n\n\tif not diff.files:\n\t\tlogger.warning(\"No valid files to process after filtering\")\n\t\treturn [], filtered_large_files\n\n\t# Set up availability flags if not already set\n\tcls = type(self)\n\tcls._sentence_transformers_available = (\n\t\tcls._sentence_transformers_available or cls._check_sentence_transformers_availability()\n\t)\n\n\tif not cls._sentence_transformers_available:\n\t\tmsg = (\n\t\t\t\"Semantic splitting is not available. sentence-transformers package is required. \"\n\t\t\t\"Install with: pip install sentence-transformers numpy\"\n\t\t)\n\t\traise ValueError(msg)\n\n\t# Try to load the model\n\twith loading_spinner(\"Loading embedding model...\"):\n\t\tcls._model_available = cls._model_available or cls._check_model_availability()\n\n\tif not cls._model_available:\n\t\tmsg = (\n\t\t\t\"Semantic splitting failed: embedding model could not be loaded. \"\n\t\t\t\"Check logs for details or try a different model.\"\n\t\t)\n\t\traise ValueError(msg)\n\n\t# Use semantic splitting\n\tchunks = self._split_semantic(diff)\n\treturn chunks, filtered_large_files\n</code></pre>"},{"location":"api/git/diff_splitter/splitter/#codemap.git.diff_splitter.splitter.DiffSplitter.encode_chunks","title":"encode_chunks  <code>classmethod</code>","text":"<pre><code>encode_chunks(chunks: list[str]) -&gt; dict[str, ndarray]\n</code></pre> <p>Encode text chunks into embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <code>list[str]</code> <p>List of text chunks</p> required <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>Dict with keys 'embeddings' containing numpy array of embeddings</p> Source code in <code>src/codemap/git/diff_splitter/splitter.py</code> <pre><code>@classmethod\ndef encode_chunks(cls, chunks: list[str]) -&gt; dict[str, np.ndarray]:\n\t\"\"\"\n\tEncode text chunks into embeddings.\n\n\tArgs:\n\t    chunks: List of text chunks\n\n\tReturns:\n\t    Dict with keys 'embeddings' containing numpy array of embeddings\n\n\t\"\"\"\n\t# Ensure the model is initialized\n\tcls._sentence_transformers_available = (\n\t\tcls._sentence_transformers_available or cls._check_sentence_transformers_availability()\n\t)\n\tif cls._sentence_transformers_available:\n\t\tcls._model_available = cls._model_available or cls._check_model_availability(model_name=MODEL_NAME)\n\n\tif not cls._model_available:\n\t\tlogger.debug(\"Embedding model not available, returning empty embeddings\")\n\t\treturn {\"embeddings\": np.array([])}\n\n\tif not chunks:\n\t\treturn {\"embeddings\": np.array([])}\n\n\t# At this point we know model is initialized and available\n\tif cls._embedding_model is None:\n\t\tlogger.debug(\"Embedding model is None but was marked as available, reinitializing\")\n\t\tcls._model_available = cls._check_model_availability(model_name=MODEL_NAME)\n\t\tif not cls._model_available:\n\t\t\treturn {\"embeddings\": np.array([])}\n\n\t# Use runtime check instead of assert\n\tif cls._embedding_model is None:\n\t\tlogger.error(\"Embedding model is None but should be initialized at this point\")\n\t\treturn {\"embeddings\": np.array([])}\n\n\tembeddings = cls._embedding_model.encode(chunks)\n\treturn {\"embeddings\": embeddings}\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/","title":"Strategies","text":"<p>Strategies for splitting git diffs into logical chunks.</p>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.EXPECTED_TUPLE_SIZE","title":"EXPECTED_TUPLE_SIZE  <code>module-attribute</code>","text":"<pre><code>EXPECTED_TUPLE_SIZE = 2\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.EmbeddingModel","title":"EmbeddingModel","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for embedding models.</p> Source code in <code>src/codemap/git/diff_splitter/strategies.py</code> <pre><code>class EmbeddingModel(Protocol):\n\t\"\"\"Protocol for embedding models.\"\"\"\n\n\tdef encode(self, texts: Sequence[str], **kwargs: Any) -&gt; np.ndarray:  # noqa: ANN401\n\t\t\"\"\"Encode texts into embeddings.\"\"\"\n\t\t...\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.EmbeddingModel.encode","title":"encode","text":"<pre><code>encode(texts: Sequence[str], **kwargs: Any) -&gt; ndarray\n</code></pre> <p>Encode texts into embeddings.</p> Source code in <code>src/codemap/git/diff_splitter/strategies.py</code> <pre><code>def encode(self, texts: Sequence[str], **kwargs: Any) -&gt; np.ndarray:  # noqa: ANN401\n\t\"\"\"Encode texts into embeddings.\"\"\"\n\t...\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.BaseSplitStrategy","title":"BaseSplitStrategy","text":"<p>Base class for diff splitting strategies.</p> Source code in <code>src/codemap/git/diff_splitter/strategies.py</code> <pre><code>class BaseSplitStrategy:\n\t\"\"\"Base class for diff splitting strategies.\"\"\"\n\n\tdef __init__(self, embedding_model: EmbeddingModel | None = None) -&gt; None:\n\t\t\"\"\"Initialize with optional embedding model.\"\"\"\n\t\tself._embedding_model = embedding_model\n\t\t# Precompile regex patterns for better performance\n\t\tself._file_pattern = re.compile(r\"diff --git a/.*? b/(.*?)\\n\")\n\t\tself._hunk_pattern = re.compile(r\"@@ -\\d+,\\d+ \\+\\d+,\\d+ @@\")\n\n\tdef split(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\t\"\"\"\n\t\tSplit the diff into chunks.\n\n\t\tArgs:\n\t\t    diff: GitDiff object to split\n\n\t\tReturns:\n\t\t    List of DiffChunk objects\n\n\t\t\"\"\"\n\t\tmsg = \"Subclasses must implement this method\"\n\t\traise NotImplementedError(msg)\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.BaseSplitStrategy.__init__","title":"__init__","text":"<pre><code>__init__(\n\tembedding_model: EmbeddingModel | None = None,\n) -&gt; None\n</code></pre> <p>Initialize with optional embedding model.</p> Source code in <code>src/codemap/git/diff_splitter/strategies.py</code> <pre><code>def __init__(self, embedding_model: EmbeddingModel | None = None) -&gt; None:\n\t\"\"\"Initialize with optional embedding model.\"\"\"\n\tself._embedding_model = embedding_model\n\t# Precompile regex patterns for better performance\n\tself._file_pattern = re.compile(r\"diff --git a/.*? b/(.*?)\\n\")\n\tself._hunk_pattern = re.compile(r\"@@ -\\d+,\\d+ \\+\\d+,\\d+ @@\")\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.BaseSplitStrategy.split","title":"split","text":"<pre><code>split(diff: GitDiff) -&gt; list[DiffChunk]\n</code></pre> <p>Split the diff into chunks.</p> <p>Parameters:</p> Name Type Description Default <code>diff</code> <code>GitDiff</code> <p>GitDiff object to split</p> required <p>Returns:</p> Type Description <code>list[DiffChunk]</code> <p>List of DiffChunk objects</p> Source code in <code>src/codemap/git/diff_splitter/strategies.py</code> <pre><code>def split(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\"\"\"\n\tSplit the diff into chunks.\n\n\tArgs:\n\t    diff: GitDiff object to split\n\n\tReturns:\n\t    List of DiffChunk objects\n\n\t\"\"\"\n\tmsg = \"Subclasses must implement this method\"\n\traise NotImplementedError(msg)\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.FileSplitStrategy","title":"FileSplitStrategy","text":"<p>               Bases: <code>BaseSplitStrategy</code></p> <p>Strategy to split diffs by file.</p> Source code in <code>src/codemap/git/diff_splitter/strategies.py</code> <pre><code>class FileSplitStrategy(BaseSplitStrategy):\n\t\"\"\"Strategy to split diffs by file.\"\"\"\n\n\tdef split(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\t\"\"\"\n\t\tSplit a diff into chunks by file.\n\n\t\tArgs:\n\t\t    diff: GitDiff object to split\n\n\t\tReturns:\n\t\t    List of DiffChunk objects, one per file\n\n\t\t\"\"\"\n\t\tif not diff.content:\n\t\t\treturn self._handle_empty_diff_content(diff)\n\n\t\t# Split the diff content by file\n\t\tfile_chunks = self._file_pattern.split(diff.content)[1:]  # Skip first empty chunk\n\n\t\t# Group files with their content\n\t\tchunks = []\n\t\tfor i in range(0, len(file_chunks), 2):\n\t\t\tif i + 1 &gt;= len(file_chunks):\n\t\t\t\tbreak\n\n\t\t\tfile_name = file_chunks[i]\n\t\t\tcontent = file_chunks[i + 1]\n\n\t\t\tif self._is_valid_filename(file_name) and content:\n\t\t\t\tdiff_header = f\"diff --git a/{file_name} b/{file_name}\\n\"\n\t\t\t\tchunks.append(\n\t\t\t\t\tDiffChunk(\n\t\t\t\t\t\tfiles=[file_name],\n\t\t\t\t\t\tcontent=diff_header + content,\n\t\t\t\t\t\tdescription=f\"Changes in {file_name}\",\n\t\t\t\t\t)\n\t\t\t\t)\n\n\t\treturn chunks\n\n\tdef _handle_empty_diff_content(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\t\"\"\"Handle untracked files in empty diff content.\"\"\"\n\t\tif not diff.is_staged and diff.files:\n\t\t\t# Filter out invalid file names\n\t\t\tvalid_files = [file for file in diff.files if self._is_valid_filename(file)]\n\t\t\treturn [DiffChunk(files=[f], content=\"\") for f in valid_files]\n\t\treturn []\n\n\t@staticmethod\n\tdef _is_valid_filename(filename: str) -&gt; bool:\n\t\t\"\"\"Check if the filename is valid (not a pattern or template).\"\"\"\n\t\tif not filename:\n\t\t\treturn False\n\t\tinvalid_chars = [\"*\", \"+\", \"{\", \"}\", \"\\\\\"]\n\t\treturn not (any(char in filename for char in invalid_chars) or filename.startswith('\"'))\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.FileSplitStrategy.split","title":"split","text":"<pre><code>split(diff: GitDiff) -&gt; list[DiffChunk]\n</code></pre> <p>Split a diff into chunks by file.</p> <p>Parameters:</p> Name Type Description Default <code>diff</code> <code>GitDiff</code> <p>GitDiff object to split</p> required <p>Returns:</p> Type Description <code>list[DiffChunk]</code> <p>List of DiffChunk objects, one per file</p> Source code in <code>src/codemap/git/diff_splitter/strategies.py</code> <pre><code>def split(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\"\"\"\n\tSplit a diff into chunks by file.\n\n\tArgs:\n\t    diff: GitDiff object to split\n\n\tReturns:\n\t    List of DiffChunk objects, one per file\n\n\t\"\"\"\n\tif not diff.content:\n\t\treturn self._handle_empty_diff_content(diff)\n\n\t# Split the diff content by file\n\tfile_chunks = self._file_pattern.split(diff.content)[1:]  # Skip first empty chunk\n\n\t# Group files with their content\n\tchunks = []\n\tfor i in range(0, len(file_chunks), 2):\n\t\tif i + 1 &gt;= len(file_chunks):\n\t\t\tbreak\n\n\t\tfile_name = file_chunks[i]\n\t\tcontent = file_chunks[i + 1]\n\n\t\tif self._is_valid_filename(file_name) and content:\n\t\t\tdiff_header = f\"diff --git a/{file_name} b/{file_name}\\n\"\n\t\t\tchunks.append(\n\t\t\t\tDiffChunk(\n\t\t\t\t\tfiles=[file_name],\n\t\t\t\t\tcontent=diff_header + content,\n\t\t\t\t\tdescription=f\"Changes in {file_name}\",\n\t\t\t\t)\n\t\t\t)\n\n\treturn chunks\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.SemanticSplitStrategy","title":"SemanticSplitStrategy","text":"<p>               Bases: <code>BaseSplitStrategy</code></p> <p>Strategy to split diffs semantically.</p> Source code in <code>src/codemap/git/diff_splitter/strategies.py</code> <pre><code>class SemanticSplitStrategy(BaseSplitStrategy):\n\t\"\"\"Strategy to split diffs semantically.\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\tembedding_model: EmbeddingModel | None = None,\n\t\tcode_extensions: set[str] | None = None,\n\t\trelated_file_patterns: list[tuple[Pattern, Pattern]] | None = None,\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the SemanticSplitStrategy.\n\n\t\tArgs:\n\t\t    embedding_model: Optional embedding model instance\n\t\t    code_extensions: Optional set of code file extensions\n\t\t    related_file_patterns: Optional list of related file patterns\n\n\t\t\"\"\"\n\t\tsuper().__init__(embedding_model)\n\t\t# Set up file extensions that are likely to contain code\n\t\tself.code_extensions = code_extensions or DEFAULT_CODE_EXTENSIONS\n\t\t# Initialize patterns for related files\n\t\tself.related_file_patterns = related_file_patterns or self._initialize_related_file_patterns()\n\n\tdef split(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\t\"\"\"\n\t\tSplit a diff into chunks based on semantic relationships.\n\n\t\tArgs:\n\t\t    diff: GitDiff object to split\n\n\t\tReturns:\n\t\t    List of DiffChunk objects based on semantic analysis\n\n\t\t\"\"\"\n\t\tif not diff.files:\n\t\t\tlogger.debug(\"No files to process\")\n\t\t\treturn []\n\n\t\t# Validate embedding model is available\n\t\tself._validate_embedding_model()\n\n\t\t# Handle files in manageable groups\n\t\tif len(diff.files) &gt; MAX_FILES_PER_GROUP:\n\t\t\tlogger.info(\"Processing large number of files (%d) in smaller groups\", len(diff.files))\n\n\t\t\t# Group files by directory to increase likelihood of related files being processed together\n\t\t\tfiles_by_dir = {}\n\t\t\tfor file in diff.files:\n\t\t\t\tdir_path = str(Path(file).parent)\n\t\t\t\tif dir_path not in files_by_dir:\n\t\t\t\t\tfiles_by_dir[dir_path] = []\n\t\t\t\tfiles_by_dir[dir_path].append(file)\n\n\t\t\t# Process each directory group separately, keeping chunks under 5 files\n\t\t\tall_chunks = []\n\t\t\t# Iterate directly over the file lists since the directory path isn't used here\n\t\t\tfor files in files_by_dir.values():\n\t\t\t\t# Process files in this directory in batches of 3-5\n\t\t\t\tfor i in range(0, len(files), 3):\n\t\t\t\t\tbatch = files[i : i + 3]\n\t\t\t\t\tbatch_diff = GitDiff(\n\t\t\t\t\t\tfiles=batch,\n\t\t\t\t\t\tcontent=diff.content,  # Keep same content\n\t\t\t\t\t\tis_staged=diff.is_staged,\n\t\t\t\t\t)\n\t\t\t\t\tall_chunks.extend(self._process_group(batch_diff))\n\n\t\t\treturn all_chunks\n\n\t\t# For smaller groups, process normally\n\t\treturn self._process_group(diff)\n\n\tdef _process_group(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\t\"\"\"Process a manageable group of files.\"\"\"\n\t\tif not diff.files:\n\t\t\treturn []\n\n\t\t# 1. Create one chunk per file initially\n\t\tinitial_file_chunks: list[DiffChunk] = []\n\t\tfor file_path in diff.files:\n\t\t\tfile_diff = GitDiff(\n\t\t\t\tfiles=[file_path],\n\t\t\t\tcontent=diff.content,\n\t\t\t\tis_staged=diff.is_staged,\n\t\t\t)\n\t\t\tenhanced_chunks = self._enhance_semantic_split(file_diff)\n\t\t\tif enhanced_chunks:\n\t\t\t\tinitial_file_chunks.extend(enhanced_chunks)\n\t\t\telse:\n\t\t\t\tlogger.warning(\"No chunk generated for file: %s\", file_path)\n\n\t\tif not initial_file_chunks:\n\t\t\treturn []\n\n\t\t# 2. Consolidate chunks from the same file (though step 1 should make this rare)\n\t\t#    and potentially by directory if that logic is re-enabled later.\n\t\tconsolidated_chunks = self._consolidate_small_chunks(initial_file_chunks)\n\n\t\t# 3. Group remaining chunks by relatedness and similarity\n\t\tprocessed_files: set[str] = set()\n\t\tfinal_semantic_chunks: list[DiffChunk] = []\n\t\tself._group_related_files(consolidated_chunks, processed_files, final_semantic_chunks)\n\t\tself._process_remaining_chunks(consolidated_chunks, processed_files, final_semantic_chunks)\n\n\t\t# 4. Final consolidation check\n\t\treturn self._consolidate_if_needed(final_semantic_chunks)\n\n\tdef _validate_embedding_model(self) -&gt; None:\n\t\t\"\"\"Validate that the embedding model is available.\"\"\"\n\t\tif self._embedding_model is None and not is_test_environment():\n\t\t\tmsg = (\n\t\t\t\t\"Semantic analysis unavailable: embedding model not available. \"\n\t\t\t\t\"Make sure the model is properly loaded before calling this method.\"\n\t\t\t)\n\t\t\traise ValueError(msg)\n\n\tdef _group_chunks_by_directory(self, chunks: list[DiffChunk]) -&gt; dict[str, list[DiffChunk]]:\n\t\t\"\"\"Group chunks by their containing directory.\"\"\"\n\t\tdir_groups: dict[str, list[DiffChunk]] = {}\n\n\t\tfor chunk in chunks:\n\t\t\tif not chunk.files:\n\t\t\t\tcontinue\n\n\t\t\tfile_path = chunk.files[0]\n\t\t\tdir_path = file_path.rsplit(\"/\", 1)[0] if \"/\" in file_path else \"root\"\n\n\t\t\tif dir_path not in dir_groups:\n\t\t\t\tdir_groups[dir_path] = []\n\n\t\t\tdir_groups[dir_path].append(chunk)\n\n\t\treturn dir_groups\n\n\tdef _process_directory_group(\n\t\tself, chunks: list[DiffChunk], processed_files: set[str], semantic_chunks: list[DiffChunk]\n\t) -&gt; None:\n\t\t\"\"\"Process chunks in a single directory group.\"\"\"\n\t\tif len(chunks) == 1:\n\t\t\t# If only one file in directory, add it directly\n\t\t\tsemantic_chunks.append(chunks[0])\n\t\t\tif chunks[0].files:\n\t\t\t\tprocessed_files.update(chunks[0].files)\n\t\telse:\n\t\t\t# For directories with multiple files, try to group them\n\t\t\tdir_processed: set[str] = set()\n\n\t\t\t# First try to group by related file patterns\n\t\t\tself._group_related_files(chunks, dir_processed, semantic_chunks)\n\n\t\t\t# Then try to group remaining files by content similarity\n\t\t\tremaining_chunks = [c for c in chunks if not c.files or c.files[0] not in dir_processed]\n\n\t\t\tif remaining_chunks:\n\t\t\t\t# Use default similarity threshold instead\n\t\t\t\tself._group_by_content_similarity(remaining_chunks, semantic_chunks)\n\n\t\t\t# Add all processed files to the global processed set\n\t\t\tprocessed_files.update(dir_processed)\n\n\tdef _process_remaining_chunks(\n\t\tself, all_chunks: list[DiffChunk], processed_files: set[str], semantic_chunks: list[DiffChunk]\n\t) -&gt; None:\n\t\t\"\"\"Process any remaining chunks that weren't grouped by directory.\"\"\"\n\t\tremaining_chunks = [c for c in all_chunks if c.files and c.files[0] not in processed_files]\n\n\t\tif remaining_chunks:\n\t\t\tself._group_by_content_similarity(remaining_chunks, semantic_chunks)\n\n\tdef _consolidate_if_needed(self, semantic_chunks: list[DiffChunk]) -&gt; list[DiffChunk]:\n\t\t\"\"\"Consolidate chunks if we have too many small ones.\"\"\"\n\t\thas_single_file_chunks = any(len(chunk.files) == 1 for chunk in semantic_chunks)\n\n\t\tif len(semantic_chunks) &gt; MAX_CHUNKS_BEFORE_CONSOLIDATION and has_single_file_chunks:\n\t\t\treturn self._consolidate_small_chunks(semantic_chunks)\n\n\t\treturn semantic_chunks\n\n\t@staticmethod\n\tdef _initialize_related_file_patterns() -&gt; list[tuple[Pattern, Pattern]]:\n\t\t\"\"\"\n\t\tInitialize and compile regex patterns for related files.\n\n\t\tReturns:\n\t\t    List of compiled regex pattern pairs\n\n\t\t\"\"\"\n\t\tpatterns = [\n\t\t\t# Frontend component pairs\n\t\t\t(r\".*\\.jsx?$\", r\".*\\.css$\"),\n\t\t\t(r\".*\\.tsx?$\", r\".*\\.css$\"),\n\t\t\t(r\".*\\.vue$\", r\".*\\.css$\"),\n\t\t\t(r\".*\\.jsx?$\", r\".*\\.scss$\"),\n\t\t\t(r\".*\\.tsx?$\", r\".*\\.scss$\"),\n\t\t\t(r\".*\\.vue$\", r\".*\\.scss$\"),\n\t\t\t(r\".*\\.jsx?$\", r\".*\\.less$\"),\n\t\t\t(r\".*\\.tsx?$\", r\".*\\.less$\"),\n\t\t\t# React component pairs\n\t\t\t(r\".*\\.jsx$\", r\".*\\.jsx$\"),\n\t\t\t(r\".*\\.tsx$\", r\".*\\.tsx$\"),\n\t\t\t(r\".*Component\\.jsx?$\", r\".*Container\\.jsx?$\"),\n\t\t\t(r\".*Component\\.tsx?$\", r\".*Container\\.tsx?$\"),\n\t\t\t# Implementation and definition pairs\n\t\t\t(r\".*\\.h$\", r\".*\\.c$\"),\n\t\t\t(r\".*\\.hpp$\", r\".*\\.cpp$\"),\n\t\t\t(r\".*\\.h$\", r\".*\\.m$\"),\n\t\t\t(r\".*\\.h$\", r\".*\\.mm$\"),\n\t\t\t(r\".*\\.proto$\", r\".*\\.pb\\.(go|py|js|java|rb|cs)$\"),\n\t\t\t(r\".*\\.idl$\", r\".*\\.(h|cpp|cs|java)$\"),\n\t\t\t# Web development pairs\n\t\t\t(r\".*\\.html$\", r\".*\\.js$\"),\n\t\t\t(r\".*\\.html$\", r\".*\\.css$\"),\n\t\t\t(r\".*\\.html$\", r\".*\\.scss$\"),\n\t\t\t(r\".*\\.html$\", r\".*\\.ts$\"),\n\t\t\t# Python related files\n\t\t\t(r\".*\\.py$\", r\".*_test\\.py$\"),\n\t\t\t(r\".*\\.py$\", r\"test_.*\\.py$\"),\n\t\t\t(r\".*\\.py$\", r\".*_spec\\.py$\"),\n\t\t\t# JavaScript/TypeScript related files\n\t\t\t(r\".*\\.js$\", r\".*\\.test\\.js$\"),\n\t\t\t(r\".*\\.js$\", r\".*\\.spec\\.js$\"),\n\t\t\t(r\".*\\.ts$\", r\".*\\.test\\.ts$\"),\n\t\t\t(r\".*\\.ts$\", r\".*\\.spec\\.ts$\"),\n\t\t\t# Ruby related files\n\t\t\t(r\".*\\.rb$\", r\".*_spec\\.rb$\"),\n\t\t\t(r\".*\\.rb$\", r\".*_test\\.rb$\"),\n\t\t\t# Java related files\n\t\t\t(r\".*\\.java$\", r\".*Test\\.java$\"),\n\t\t\t# Go related files\n\t\t\t(r\".*\\.go$\", r\".*_test\\.go$\"),\n\t\t\t# Configuration files\n\t\t\t(r\"package\\.json$\", r\"package-lock\\.json$\"),\n\t\t\t(r\"package\\.json$\", r\"yarn\\.lock$\"),\n\t\t\t(r\"package\\.json$\", r\"tsconfig\\.json$\"),\n\t\t\t(r\"package\\.json$\", r\"\\.eslintrc(\\.js|\\.json|\\.yml)?$\"),\n\t\t\t(r\"package\\.json$\", r\"\\.prettierrc(\\.js|\\.json|\\.yml)?$\"),\n\t\t\t(r\"requirements\\.txt$\", r\"setup\\.py$\"),\n\t\t\t(r\"pyproject\\.toml$\", r\"setup\\.py$\"),\n\t\t\t(r\"pyproject\\.toml$\", r\"setup\\.cfg$\"),\n\t\t\t(r\"Gemfile$\", r\"Gemfile\\.lock$\"),\n\t\t\t(r\"Cargo\\.toml$\", r\"Cargo\\.lock$\"),\n\t\t\t# Documentation\n\t\t\t(r\".*\\.md$\", r\".*\\.(js|ts|py|rb|java|go|c|cpp|h|hpp)$\"),\n\t\t\t(r\"README\\.md$\", r\".*$\"),\n\t\t]\n\n\t\t# Compile all patterns for better performance\n\t\treturn [(re.compile(p1), re.compile(p2)) for p1, p2 in patterns]\n\n\tdef _get_code_embedding(self, content: str) -&gt; list[float] | None:\n\t\t\"\"\"\n\t\tGet embedding vector for code content.\n\n\t\tArgs:\n\t\t    content: Code content to embed\n\n\t\tReturns:\n\t\t    List of floats representing code embedding or None if unavailable\n\n\t\t\"\"\"\n\t\t# Skip empty content\n\t\tif not content or not content.strip():\n\t\t\treturn None\n\n\t\t# Check if embedding model exists\n\t\tif self._embedding_model is None:\n\t\t\tlogger.warning(\"Embedding model is None, cannot generate embedding\")\n\t\t\treturn None\n\n\t\t# Generate embedding\n\t\ttry:\n\t\t\tembeddings = self._embedding_model.encode([content], show_progress_bar=False)\n\t\t\treturn embeddings[0].tolist()\n\t\texcept (ValueError, TypeError, RuntimeError, IndexError):\n\t\t\tlogger.exception(\"Failed to generate embedding\")\n\t\t\treturn None\n\n\tdef _calculate_semantic_similarity(self, content1: str, content2: str) -&gt; float:\n\t\t\"\"\"\n\t\tCalculate semantic similarity between two code chunks.\n\n\t\tArgs:\n\t\t    content1: First code content\n\t\t    content2: Second code content\n\n\t\tReturns:\n\t\t    Similarity score between 0 and 1\n\n\t\t\"\"\"\n\t\t# Get embeddings\n\t\temb1 = self._get_code_embedding(content1)\n\t\temb2 = self._get_code_embedding(content2)\n\n\t\tif not emb1 or not emb2:\n\t\t\treturn 0.0\n\n\t\t# Calculate cosine similarity using utility function\n\t\treturn calculate_semantic_similarity(emb1, emb2)\n\n\tdef _semantic_hunk_splitting(self, file_path: str, diff_content: str) -&gt; list[str]:\n\t\t\"\"\"\n\t\tSplit a diff hunk by semantic boundaries in the code.\n\n\t\tArgs:\n\t\t    file_path: Path to the file\n\t\t    diff_content: Git diff content\n\n\t\tReturns:\n\t\t    List of semantically separated diff chunks\n\n\t\t\"\"\"\n\t\t# Extract file extension\n\t\textension = Path(file_path).suffix.lstrip(\".\")\n\n\t\t# Get language-specific patterns\n\t\tpatterns = get_language_specific_patterns(extension)\n\n\t\tif not patterns:\n\t\t\t# If no language patterns available, return the whole diff as one chunk\n\t\t\treturn [diff_content]\n\n\t\t# Extract new code from diff\n\t\textraction_result = extract_code_from_diff(diff_content)\n\t\tif not extraction_result or len(extraction_result) != EXPECTED_TUPLE_SIZE:\n\t\t\treturn [diff_content]\n\n\t\t_, new_code = extraction_result\n\n\t\tif not new_code:\n\t\t\treturn [diff_content]\n\n\t\t# Find all pattern matches\n\t\tboundaries = []\n\t\tfor pattern in patterns:\n\t\t\tmatches = list(re.finditer(pattern, new_code, re.MULTILINE))\n\t\t\tboundaries.extend(match.start() for match in matches)\n\n\t\tif not boundaries:\n\t\t\treturn [diff_content]\n\n\t\t# Sort and deduplicate boundaries\n\t\tboundaries = sorted(set(boundaries))\n\n\t\t# Split the diff using line tracking\n\t\treturn self._split_diff_at_boundaries(diff_content, boundaries)\n\n\tdef _split_diff_at_boundaries(self, diff_content: str, boundaries: list[int]) -&gt; list[str]:\n\t\t\"\"\"Split diff content at the given semantic boundaries.\"\"\"\n\t\tlines = diff_content.splitlines()\n\t\tchunks = []\n\t\tcurrent_chunk = []\n\t\tcurrent_line_idx = 0\n\t\tline_positions = {}  # Maps line indices to positions in the unified code\n\n\t\t# First pass: build the line position mapping\n\t\tpos = 0\n\t\ttemp_line_idx = 0\n\t\tfor line in diff_content.splitlines(keepends=True):  # Keep line endings\n\t\t\tif line.startswith(\"@@\"):\n\t\t\t\thunk_match = re.search(r\"@@ -\\d+(?:,\\d+)? \\+(\\d+)(?:,\\d+)? @@\", line)\n\t\t\t\tif hunk_match:\n\t\t\t\t\ttemp_line_idx = int(hunk_match.group(1)) - 1\n\t\t\telif not line.startswith(\"-\"):  # Additions or context lines\n\t\t\t\tline_positions[temp_line_idx] = pos\n\t\t\t\ttemp_line_idx += 1\n\t\t\tpos += len(line)\n\n\t\t# Second pass: split at boundaries\n\t\tcurrent_line_idx = 0\n\t\tfor line in lines:\n\t\t\tcurrent_chunk.append(line)\n\n\t\t\t# Reset line counter at hunk headers\n\t\t\tif line.startswith(\"@@\"):\n\t\t\t\thunk_match = re.search(r\"@@ -\\d+(?:,\\d+)? \\+(\\d+)(?:,\\d+)? @@\", line)\n\t\t\t\tif hunk_match:\n\t\t\t\t\tcurrent_line_idx = int(hunk_match.group(1)) - 1\n\t\t\t\tcontinue\n\n\t\t\t# Track line number for content lines (skip removals)\n\t\t\tif not line.startswith(\"-\"):\n\t\t\t\tif current_line_idx in line_positions and line_positions[current_line_idx] in boundaries:\n\t\t\t\t\t# Finish current chunk\n\t\t\t\t\tchunks.append(\"\\n\".join(current_chunk))\n\t\t\t\t\tcurrent_chunk = []\n\n\t\t\t\tcurrent_line_idx += 1\n\n\t\t# Add the final chunk if there's anything left\n\t\tif current_chunk:\n\t\t\tchunks.append(\"\\n\".join(current_chunk))\n\n\t\treturn chunks if chunks else [diff_content]\n\n\tdef _enhance_semantic_split(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\t\"\"\"\n\t\tEnhance semantic analysis with language-specific patterns.\n\n\t\tArgs:\n\t\t    diff: GitDiff object to analyze\n\n\t\tReturns:\n\t\t    List of semantically grouped chunks\n\n\t\t\"\"\"\n\t\tif not diff.content or not diff.files:\n\t\t\treturn []\n\n\t\tfile_path = diff.files[0]\n\t\tfile_suffix = Path(file_path).suffix\n\n\t\t# Check for large diff content and handle appropriately\n\t\tif len(diff.content) &gt; MAX_FILE_SIZE_FOR_LLM:\n\t\t\tlogger.warning(\n\t\t\t\t(\n\t\t\t\t\t\"Diff content for %s is too large (%d bytes) for detailed \"\n\t\t\t\t\t\"semantic analysis. Creating a simplified chunk.\"\n\t\t\t\t),\n\t\t\t\tfile_path,\n\t\t\t\tlen(diff.content),\n\t\t\t)\n\t\t\tcommit_type = determine_commit_type([file_path])\n\t\t\t# Create a simplified chunk instead of detailed semantic analysis\n\t\t\treturn [\n\t\t\t\tDiffChunk(\n\t\t\t\t\tfiles=[file_path],\n\t\t\t\t\tcontent=\"// Large file content - truncated for API limits\",\n\t\t\t\t\tdescription=create_chunk_description(commit_type, [file_path]),\n\t\t\t\t)\n\t\t\t]\n\n\t\t# If no file extension, create a single chunk\n\t\tif not file_suffix:\n\t\t\treturn [\n\t\t\t\tDiffChunk(\n\t\t\t\t\tfiles=[file_path],\n\t\t\t\t\tcontent=diff.content,\n\t\t\t\t\tdescription=f\"Changes in {file_path}\",\n\t\t\t\t)\n\t\t\t]\n\n\t\t# Try to apply language-specific patterns\n\t\tpatterns = get_language_specific_patterns(file_suffix.lstrip(\".\"))\n\n\t\tif not patterns:\n\t\t\t# Create a single chunk for unsupported file types\n\t\t\treturn [\n\t\t\t\tDiffChunk(\n\t\t\t\t\tfiles=[file_path],\n\t\t\t\t\tcontent=diff.content,\n\t\t\t\t\tdescription=f\"Changes in {file_path}\",\n\t\t\t\t)\n\t\t\t]\n\n\t\t# Try semantic splitting\n\t\tchunks = self._split_by_semantic_patterns(diff, file_path, patterns)\n\n\t\treturn chunks or [\n\t\t\tDiffChunk(\n\t\t\t\tfiles=[file_path],\n\t\t\t\tcontent=diff.content,\n\t\t\t\tdescription=f\"Changes in {file_path}\",\n\t\t\t)\n\t\t]\n\n\tdef _split_by_semantic_patterns(self, diff: GitDiff, file_path: str, patterns: list[str]) -&gt; list[DiffChunk]:\n\t\t\"\"\"Split a diff by semantic patterns in the code.\"\"\"\n\t\t# Extract code from diff\n\t\textraction_result = extract_code_from_diff(diff.content)\n\t\tif not extraction_result or len(extraction_result) != EXPECTED_TUPLE_SIZE:\n\t\t\treturn []\n\n\t\t_, new_code = extraction_result\n\n\t\tif not new_code:\n\t\t\treturn []\n\n\t\t# Find semantic boundaries\n\t\tboundaries = []\n\t\tfor pattern in patterns:\n\t\t\tpattern_boundaries = [m.start() for m in re.finditer(pattern, new_code, re.MULTILINE)]\n\t\t\tboundaries.extend(pattern_boundaries)\n\n\t\tif not boundaries:\n\t\t\treturn []\n\n\t\t# Sort boundaries for splitting\n\t\tboundaries.sort()\n\n\t\t# Create chunks based on boundaries\n\t\tchunks = []\n\t\tprev_boundary = 0\n\n\t\tfor i, boundary in enumerate(boundaries):\n\t\t\tif boundary &lt;= prev_boundary:\n\t\t\t\tcontinue\n\n\t\t\tchunk_content = new_code[prev_boundary:boundary]\n\t\t\tif chunk_content.strip():\n\t\t\t\tchunks.append(\n\t\t\t\t\tDiffChunk(\n\t\t\t\t\t\tfiles=[file_path],\n\t\t\t\t\t\tcontent=chunk_content,\n\t\t\t\t\t\tdescription=f\"Semantic section {i + 1} in {file_path}\",\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t\tprev_boundary = boundary\n\n\t\t# Add the last chunk\n\t\tif prev_boundary &lt; len(new_code):\n\t\t\tfinal_content = new_code[prev_boundary:]\n\t\t\tif final_content.strip():\n\t\t\t\tchunks.append(\n\t\t\t\t\tDiffChunk(\n\t\t\t\t\t\tfiles=[file_path],\n\t\t\t\t\t\tcontent=final_content,\n\t\t\t\t\t\tdescription=f\"Semantic section {len(boundaries) + 1} in {file_path}\",\n\t\t\t\t\t)\n\t\t\t\t)\n\n\t\treturn chunks\n\n\tdef _group_by_content_similarity(\n\t\tself,\n\t\tchunks: list[DiffChunk],\n\t\tresult_chunks: list[DiffChunk],\n\t\tsimilarity_threshold: float | None = None,\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tGroup chunks by content similarity.\n\n\t\tArgs:\n\t\t    chunks: List of chunks to process\n\t\t    result_chunks: List to append grouped chunks to (modified in place)\n\t\t    similarity_threshold: Optional custom threshold to override default\n\n\t\t\"\"\"\n\t\tif not chunks:\n\t\t\treturn\n\n\t\t# Check if model is available\n\t\tif self._embedding_model is None:\n\t\t\tlogger.debug(\"Embedding model not available, using fallback grouping strategy\")\n\t\t\t# If model is unavailable, try to group by file path patterns\n\t\t\tgrouped_paths: dict[str, list[DiffChunk]] = {}\n\n\t\t\t# Group by common path prefixes\n\t\t\tfor chunk in chunks:\n\t\t\t\tif not chunk.files:\n\t\t\t\t\tresult_chunks.append(chunk)\n\t\t\t\t\tcontinue\n\n\t\t\t\tfile_path = chunk.files[0]\n\t\t\t\t# Get directory or file prefix as the grouping key\n\t\t\t\tif \"/\" in file_path:\n\t\t\t\t\t# Use directory as key\n\t\t\t\t\tkey = file_path.rsplit(\"/\", 1)[0]\n\t\t\t\telse:\n\t\t\t\t\t# Use file prefix (before extension) as key\n\t\t\t\t\tkey = file_path.split(\".\", 1)[0] if \".\" in file_path else file_path\n\n\t\t\t\tif key not in grouped_paths:\n\t\t\t\t\tgrouped_paths[key] = []\n\t\t\t\tgrouped_paths[key].append(chunk)\n\n\t\t\t# Create chunks from each group\n\t\t\tfor related_chunks in grouped_paths.values():\n\t\t\t\tself._create_semantic_chunk(related_chunks, result_chunks)\n\t\t\treturn\n\n\t\tprocessed_indices = set()\n\t\tthreshold = similarity_threshold if similarity_threshold is not None else DEFAULT_SIMILARITY_THRESHOLD\n\n\t\t# For each chunk, find similar chunks and group them\n\t\tfor i, chunk in enumerate(chunks):\n\t\t\tif i in processed_indices:\n\t\t\t\tcontinue\n\n\t\t\trelated_chunks = [chunk]\n\t\t\tprocessed_indices.add(i)\n\n\t\t\t# Find similar chunks\n\t\t\tfor j, other_chunk in enumerate(chunks):\n\t\t\t\tif i == j or j in processed_indices:\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Calculate similarity between chunks\n\t\t\t\tsimilarity = self._calculate_semantic_similarity(chunk.content, other_chunk.content)\n\n\t\t\t\tif similarity &gt;= threshold:\n\t\t\t\t\trelated_chunks.append(other_chunk)\n\t\t\t\t\tprocessed_indices.add(j)\n\n\t\t\t# Create a semantic chunk from related chunks\n\t\t\tif related_chunks:\n\t\t\t\tself._create_semantic_chunk(related_chunks, result_chunks)\n\n\tdef _group_related_files(\n\t\tself,\n\t\tfile_chunks: list[DiffChunk],\n\t\tprocessed_files: set[str],\n\t\tsemantic_chunks: list[DiffChunk],\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tGroup related files into semantic chunks.\n\n\t\tArgs:\n\t\t    file_chunks: List of file-based chunks\n\t\t    processed_files: Set of already processed files (modified in place)\n\t\t    semantic_chunks: List of semantic chunks (modified in place)\n\n\t\t\"\"\"\n\t\tif not file_chunks:\n\t\t\treturn\n\n\t\t# Group clearly related files\n\t\tfor i, chunk in enumerate(file_chunks):\n\t\t\tif not chunk.files or chunk.files[0] in processed_files:\n\t\t\t\tcontinue\n\n\t\t\trelated_chunks = [chunk]\n\t\t\tprocessed_files.add(chunk.files[0])\n\n\t\t\t# Find related files\n\t\t\tfor j, other_chunk in enumerate(file_chunks):\n\t\t\t\tif i == j or not other_chunk.files or other_chunk.files[0] in processed_files:\n\t\t\t\t\tcontinue\n\n\t\t\t\tif are_files_related(chunk.files[0], other_chunk.files[0], self.related_file_patterns):\n\t\t\t\t\trelated_chunks.append(other_chunk)\n\t\t\t\t\tprocessed_files.add(other_chunk.files[0])\n\n\t\t\t# Create a semantic chunk from related files\n\t\t\tif related_chunks:\n\t\t\t\tself._create_semantic_chunk(related_chunks, semantic_chunks)\n\n\tdef _create_semantic_chunk(\n\t\tself,\n\t\trelated_chunks: list[DiffChunk],\n\t\tsemantic_chunks: list[DiffChunk],\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tCreate a semantic chunk from related file chunks.\n\n\t\tArgs:\n\t\t    related_chunks: List of related file chunks\n\t\t    semantic_chunks: List of semantic chunks to append to (modified in place)\n\n\t\t\"\"\"\n\t\tif not related_chunks:\n\t\t\treturn\n\n\t\tall_files = []\n\t\tcombined_content = []\n\n\t\tfor rc in related_chunks:\n\t\t\tall_files.extend(rc.files)\n\t\t\tcombined_content.append(rc.content)\n\n\t\t# Determine the appropriate commit type based on the files\n\t\tcommit_type = determine_commit_type(all_files)\n\n\t\t# Create description based on file count\n\t\tdescription = create_chunk_description(commit_type, all_files)\n\n\t\t# Join the content from all related chunks\n\t\tcontent = \"\\n\\n\".join(combined_content)\n\n\t\tsemantic_chunks.append(\n\t\t\tDiffChunk(\n\t\t\t\tfiles=all_files,\n\t\t\t\tcontent=content,\n\t\t\t\tdescription=description,\n\t\t\t)\n\t\t)\n\n\tdef _consolidate_small_chunks(self, chunks: list[DiffChunk]) -&gt; list[DiffChunk]:\n\t\t\"\"\"\n\t\tConsolidate small chunks into larger, more meaningful groups.\n\n\t\tFirst, consolidates chunks originating from the same file.\n\t\tThen, consolidates remaining single-file chunks by directory.\n\n\t\tArgs:\n\t\t    chunks: List of diff chunks to consolidate\n\n\t\tReturns:\n\t\t    Consolidated list of chunks\n\n\t\t\"\"\"\n\t\t# If we have fewer than MIN_CHUNKS_FOR_CONSOLIDATION chunks, no need to consolidate\n\t\tif len(chunks) &lt; MIN_CHUNKS_FOR_CONSOLIDATION:\n\t\t\treturn chunks\n\n\t\t# --- Step 1: Consolidate chunks from the same file ----\n\t\tfile_groups: dict[str, list[DiffChunk]] = {}\n\t\tother_chunks: list[DiffChunk] = []  # Chunks with multiple files or no files\n\n\t\tfor chunk in chunks:\n\t\t\tif len(chunk.files) == 1:\n\t\t\t\tfile_path = chunk.files[0]\n\t\t\t\tif file_path not in file_groups:\n\t\t\t\t\tfile_groups[file_path] = []\n\t\t\t\tfile_groups[file_path].append(chunk)\n\t\t\telse:\n\t\t\t\tother_chunks.append(chunk)  # Keep multi-file chunks separate for now\n\n\t\tconsolidated_same_file_chunks: list[DiffChunk] = []\n\t\tfor file_path, file_chunk_list in file_groups.items():\n\t\t\tif len(file_chunk_list) &gt; 1:\n\t\t\t\t# Merge chunks for this file\n\t\t\t\tcombined_content = \"\\n\".join([c.content for c in file_chunk_list])\n\t\t\t\t# Use the description from the first chunk or generate a default one\n\t\t\t\tdescription = file_chunk_list[0].description or f\"Changes in {file_path}\"\n\t\t\t\tconsolidated_same_file_chunks.append(\n\t\t\t\t\tDiffChunk(files=[file_path], content=combined_content, description=description)\n\t\t\t\t)\n\t\t\telse:\n\t\t\t\t# Keep single chunks as they are\n\t\t\t\tconsolidated_same_file_chunks.extend(file_chunk_list)\n\n\t\t# Combine same-file consolidated chunks and the multi-file chunks\n\t\tfinal_chunks = consolidated_same_file_chunks + other_chunks\n\n\t\tlogger.debug(\"Consolidated (file-level only) from %d to %d chunks\", len(chunks), len(final_chunks))\n\t\treturn final_chunks\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.SemanticSplitStrategy.__init__","title":"__init__","text":"<pre><code>__init__(\n\tembedding_model: EmbeddingModel | None = None,\n\tcode_extensions: set[str] | None = None,\n\trelated_file_patterns: list[tuple[Pattern, Pattern]]\n\t| None = None,\n) -&gt; None\n</code></pre> <p>Initialize the SemanticSplitStrategy.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>EmbeddingModel | None</code> <p>Optional embedding model instance</p> <code>None</code> <code>code_extensions</code> <code>set[str] | None</code> <p>Optional set of code file extensions</p> <code>None</code> <code>related_file_patterns</code> <code>list[tuple[Pattern, Pattern]] | None</code> <p>Optional list of related file patterns</p> <code>None</code> Source code in <code>src/codemap/git/diff_splitter/strategies.py</code> <pre><code>def __init__(\n\tself,\n\tembedding_model: EmbeddingModel | None = None,\n\tcode_extensions: set[str] | None = None,\n\trelated_file_patterns: list[tuple[Pattern, Pattern]] | None = None,\n) -&gt; None:\n\t\"\"\"\n\tInitialize the SemanticSplitStrategy.\n\n\tArgs:\n\t    embedding_model: Optional embedding model instance\n\t    code_extensions: Optional set of code file extensions\n\t    related_file_patterns: Optional list of related file patterns\n\n\t\"\"\"\n\tsuper().__init__(embedding_model)\n\t# Set up file extensions that are likely to contain code\n\tself.code_extensions = code_extensions or DEFAULT_CODE_EXTENSIONS\n\t# Initialize patterns for related files\n\tself.related_file_patterns = related_file_patterns or self._initialize_related_file_patterns()\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.SemanticSplitStrategy.code_extensions","title":"code_extensions  <code>instance-attribute</code>","text":"<pre><code>code_extensions = code_extensions or DEFAULT_CODE_EXTENSIONS\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.SemanticSplitStrategy.related_file_patterns","title":"related_file_patterns  <code>instance-attribute</code>","text":"<pre><code>related_file_patterns = (\n\trelated_file_patterns\n\tor _initialize_related_file_patterns()\n)\n</code></pre>"},{"location":"api/git/diff_splitter/strategies/#codemap.git.diff_splitter.strategies.SemanticSplitStrategy.split","title":"split","text":"<pre><code>split(diff: GitDiff) -&gt; list[DiffChunk]\n</code></pre> <p>Split a diff into chunks based on semantic relationships.</p> <p>Parameters:</p> Name Type Description Default <code>diff</code> <code>GitDiff</code> <p>GitDiff object to split</p> required <p>Returns:</p> Type Description <code>list[DiffChunk]</code> <p>List of DiffChunk objects based on semantic analysis</p> Source code in <code>src/codemap/git/diff_splitter/strategies.py</code> <pre><code>def split(self, diff: GitDiff) -&gt; list[DiffChunk]:\n\t\"\"\"\n\tSplit a diff into chunks based on semantic relationships.\n\n\tArgs:\n\t    diff: GitDiff object to split\n\n\tReturns:\n\t    List of DiffChunk objects based on semantic analysis\n\n\t\"\"\"\n\tif not diff.files:\n\t\tlogger.debug(\"No files to process\")\n\t\treturn []\n\n\t# Validate embedding model is available\n\tself._validate_embedding_model()\n\n\t# Handle files in manageable groups\n\tif len(diff.files) &gt; MAX_FILES_PER_GROUP:\n\t\tlogger.info(\"Processing large number of files (%d) in smaller groups\", len(diff.files))\n\n\t\t# Group files by directory to increase likelihood of related files being processed together\n\t\tfiles_by_dir = {}\n\t\tfor file in diff.files:\n\t\t\tdir_path = str(Path(file).parent)\n\t\t\tif dir_path not in files_by_dir:\n\t\t\t\tfiles_by_dir[dir_path] = []\n\t\t\tfiles_by_dir[dir_path].append(file)\n\n\t\t# Process each directory group separately, keeping chunks under 5 files\n\t\tall_chunks = []\n\t\t# Iterate directly over the file lists since the directory path isn't used here\n\t\tfor files in files_by_dir.values():\n\t\t\t# Process files in this directory in batches of 3-5\n\t\t\tfor i in range(0, len(files), 3):\n\t\t\t\tbatch = files[i : i + 3]\n\t\t\t\tbatch_diff = GitDiff(\n\t\t\t\t\tfiles=batch,\n\t\t\t\t\tcontent=diff.content,  # Keep same content\n\t\t\t\t\tis_staged=diff.is_staged,\n\t\t\t\t)\n\t\t\t\tall_chunks.extend(self._process_group(batch_diff))\n\n\t\treturn all_chunks\n\n\t# For smaller groups, process normally\n\treturn self._process_group(diff)\n</code></pre>"},{"location":"api/git/diff_splitter/utils/","title":"Utils","text":"<p>Utility functions for diff splitting.</p>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.extract_code_from_diff","title":"extract_code_from_diff","text":"<pre><code>extract_code_from_diff(\n\tdiff_content: str,\n) -&gt; tuple[str, str]\n</code></pre> <p>Extract actual code content from a diff.</p> <p>Parameters:</p> Name Type Description Default <code>diff_content</code> <code>str</code> <p>The raw diff content</p> required <p>Returns:</p> Type Description <code>tuple[str, str]</code> <p>Tuple of (old_code, new_code) extracted from the diff</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def extract_code_from_diff(diff_content: str) -&gt; tuple[str, str]:\n\t\"\"\"\n\tExtract actual code content from a diff.\n\n\tArgs:\n\t    diff_content: The raw diff content\n\n\tReturns:\n\t    Tuple of (old_code, new_code) extracted from the diff\n\n\t\"\"\"\n\told_lines = []\n\tnew_lines = []\n\n\t# Handle empty diff content\n\tif not diff_content or diff_content.isspace():\n\t\treturn \"\", \"\"\n\n\t# Check if diff content is too large and truncate if necessary\n\tif len(diff_content) &gt; MAX_FILE_SIZE_FOR_LLM:\n\t\tlogger.warning(\n\t\t\t\"Diff content is very large (%d bytes). Truncating to prevent API payload limits.\", len(diff_content)\n\t\t)\n\t\t# Extract file name from the diff if possible\n\t\tfile_match = re.search(r\"diff --git a/(.*) b/(.*)\", diff_content)\n\t\tfile_name = file_match.group(2) if file_match else \"unknown file\"\n\n\t\t# Create a summarized message instead of full content\n\t\treturn (\n\t\t\tf\"// Large diff content for {file_name} (truncated)\",\n\t\t\tf\"// Large diff content for {file_name} (truncated)\\n// Original size: {len(diff_content)} bytes\",\n\t\t)\n\n\t# Split into lines and prepare to process\n\tlines = diff_content.split(\"\\n\")\n\tin_hunk = False\n\tin_file = False\n\tcontext_function = None\n\tcurrent_file = None\n\n\t# Keep track of content size to avoid exceeding limits\n\testimated_size = 0\n\tmax_size_per_side = MAX_FILE_SIZE_FOR_LLM // 2  # Split the limit between old and new code\n\tsize_exceeded = False\n\n\tfor line in lines:\n\t\t# Skip empty lines\n\t\tif not line.strip():\n\t\t\tcontinue\n\n\t\t# Check for file headers\n\t\tif line.startswith(\"diff --git\"):\n\t\t\tin_file = True\n\t\t\tin_hunk = False\n\t\t\t# Extract file name for context\n\t\t\tmatch = re.search(r\"diff --git a/(.*) b/(.*)\", line)\n\t\t\tif match:\n\t\t\t\tcurrent_file = match.group(2)\n\t\t\tcontinue\n\n\t\t# Skip index lines, --- and +++ lines\n\t\tif line.startswith((\"index \", \"--- \", \"+++ \", \"new file mode\", \"deleted file mode\")):\n\t\t\tcontinue\n\n\t\t# Check for binary file notice\n\t\tif \"Binary files\" in line or \"GIT binary patch\" in line:\n\t\t\t# For binary files, just add a placeholder\n\t\t\told_lines.append(f\"// Binary file changed: {current_file}\")\n\t\t\tnew_lines.append(f\"// Binary file changed: {current_file}\")\n\t\t\tcontinue\n\n\t\t# Check for hunk header\n\t\tif line.startswith(\"@@\"):\n\t\t\tin_hunk = True\n\t\t\t# Try to extract function context if available\n\t\t\tcontext_match = re.search(r\"@@ .+ @@ (.*)\", line)\n\t\t\tif context_match and context_match.group(1):\n\t\t\t\tcontext_function = context_match.group(1).strip()\n\t\t\t\t# Add function context to both old and new lines\n\t\t\t\tif context_function:\n\t\t\t\t\told_lines.append(f\"// {context_function}\")\n\t\t\t\t\tnew_lines.append(f\"// {context_function}\")\n\t\t\tcontinue\n\n\t\tif not in_hunk:\n\t\t\tcontinue\n\n\t\t# Check if we're approaching size limits\n\t\testimated_size += len(line)\n\t\tif estimated_size &gt; max_size_per_side and not size_exceeded:\n\t\t\tsize_exceeded = True\n\t\t\told_lines.append(f\"// Content truncated - diff too large for {current_file or 'unknown file'}\")\n\t\t\tnew_lines.append(f\"// Content truncated - diff too large for {current_file or 'unknown file'}\")\n\t\t\tlogger.warning(\"Truncated diff content for %s due to size limits\", current_file or \"unknown file\")\n\t\t\tbreak\n\n\t\t# Extract code content - handle edge cases\n\t\tif line.startswith(\"-\"):\n\t\t\told_lines.append(line[1:])\n\t\telif line.startswith(\"+\"):\n\t\t\tnew_lines.append(line[1:])\n\t\telif line.startswith(\" \"):\n\t\t\t# Context lines appear in both old and new (explicitly handle the space)\n\t\t\told_lines.append(line[1:])\n\t\t\tnew_lines.append(line[1:])\n\t\telse:\n\t\t\t# Handle any other lines within hunks (shouldn't normally happen, but just in case)\n\t\t\told_lines.append(line)\n\t\t\tnew_lines.append(line)\n\n\t# If we didn't find any hunks but have a file, add placeholder\n\tif in_file and not old_lines and not new_lines and current_file:\n\t\told_lines.append(f\"// File: {current_file}\")\n\t\tnew_lines.append(f\"// File: {current_file}\")\n\n\t# Check final sizes and truncate if needed\n\told_code = \"\\n\".join(old_lines)\n\tnew_code = \"\\n\".join(new_lines)\n\n\tif len(old_code) &gt; max_size_per_side or len(new_code) &gt; max_size_per_side:\n\t\tlogger.warning(\"Final extracted code still exceeds size limits, truncating further\")\n\t\tif len(old_code) &gt; max_size_per_side:\n\t\t\told_code = old_code[: max_size_per_side - 100] + f\"\\n// ... truncated ({len(old_code)} bytes total)\"\n\t\tif len(new_code) &gt; max_size_per_side:\n\t\t\tnew_code = new_code[: max_size_per_side - 100] + f\"\\n// ... truncated ({len(new_code)} bytes total)\"\n\n\treturn old_code, new_code\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.get_language_specific_patterns","title":"get_language_specific_patterns","text":"<pre><code>get_language_specific_patterns(language: str) -&gt; list[str]\n</code></pre> <p>Get language-specific regex patterns for code structure.</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>str</code> <p>Programming language identifier</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of regex patterns for the language, or empty list if not supported</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def get_language_specific_patterns(language: str) -&gt; list[str]:\n\t\"\"\"\n\tGet language-specific regex patterns for code structure.\n\n\tArgs:\n\t    language: Programming language identifier\n\n\tReturns:\n\t    A list of regex patterns for the language, or empty list if not supported\n\n\t\"\"\"\n\t# Define pattern strings (used for semantic boundary detection)\n\tpattern_strings = {\n\t\t\"py\": [\n\t\t\tr\"^import\\s+.*\",  # Import statements\n\t\t\tr\"^from\\s+.*\",  # From imports\n\t\t\tr\"^class\\s+\\w+\",  # Class definitions\n\t\t\tr\"^def\\s+\\w+\",  # Function definitions\n\t\t\tr\"^if\\s+__name__\\s*==\\s*['\\\"]__main__['\\\"]\",  # Main block\n\t\t],\n\t\t\"js\": [\n\t\t\tr\"^import\\s+.*\",  # ES6 imports\n\t\t\tr\"^const\\s+\\w+\\s*=\\s*require\",  # CommonJS imports\n\t\t\tr\"^function\\s+\\w+\",  # Function declarations\n\t\t\tr\"^const\\s+\\w+\\s*=\\s*function\",  # Function expressions\n\t\t\tr\"^class\\s+\\w+\",  # Class declarations\n\t\t\tr\"^export\\s+\",  # Exports\n\t\t],\n\t\t\"ts\": [\n\t\t\tr\"^import\\s+.*\",  # Imports\n\t\t\tr\"^export\\s+\",  # Exports\n\t\t\tr\"^interface\\s+\",  # Interfaces\n\t\t\tr\"^type\\s+\",  # Type definitions\n\t\t\tr\"^class\\s+\",  # Classes\n\t\t\tr\"^function\\s+\",  # Functions\n\t\t],\n\t\t\"jsx\": [\n\t\t\tr\"^import\\s+.*\",  # ES6 imports\n\t\t\tr\"^const\\s+\\w+\\s*=\\s*require\",  # CommonJS imports\n\t\t\tr\"^function\\s+\\w+\",  # Function declarations\n\t\t\tr\"^const\\s+\\w+\\s*=\\s*function\",  # Function expressions\n\t\t\tr\"^class\\s+\\w+\",  # Class declarations\n\t\t\tr\"^export\\s+\",  # Exports\n\t\t],\n\t\t\"tsx\": [\n\t\t\tr\"^import\\s+.*\",  # Imports\n\t\t\tr\"^export\\s+\",  # Exports\n\t\t\tr\"^interface\\s+\",  # Interfaces\n\t\t\tr\"^type\\s+\",  # Type definitions\n\t\t\tr\"^class\\s+\",  # Classes\n\t\t\tr\"^function\\s+\",  # Functions\n\t\t],\n\t\t\"java\": [\n\t\t\tr\"^import\\s+.*\",  # Import statements\n\t\t\tr\"^public\\s+class\",  # Public class\n\t\t\tr\"^private\\s+class\",  # Private class\n\t\t\tr\"^(public|private|protected)(\\s+static)?\\s+\\w+\\s+\\w+\\(\",  # Methods\n\t\t],\n\t\t\"go\": [\n\t\t\tr\"^import\\s+\",  # Import statements\n\t\t\tr\"^func\\s+\",  # Function definitions\n\t\t\tr\"^type\\s+\\w+\\s+struct\",  # Struct definitions\n\t\t],\n\t\t\"rb\": [\n\t\t\tr\"^require\\s+\",  # Requires\n\t\t\tr\"^class\\s+\",  # Class definitions\n\t\t\tr\"^def\\s+\",  # Method definitions\n\t\t\tr\"^module\\s+\",  # Module definitions\n\t\t],\n\t\t\"php\": [\n\t\t\tr\"^namespace\\s+\",  # Namespace declarations\n\t\t\tr\"^use\\s+\",  # Use statements\n\t\t\tr\"^class\\s+\",  # Class definitions\n\t\t\tr\"^(public|private|protected)\\s+function\",  # Methods\n\t\t],\n\t\t\"cs\": [\n\t\t\tr\"^using\\s+\",  # Using directives\n\t\t\tr\"^namespace\\s+\",  # Namespace declarations\n\t\t\tr\"^(public|private|protected|internal)\\s+class\",  # Classes\n\t\t\tr\"^(public|private|protected|internal)(\\s+static)?\\s+\\w+\\s+\\w+\\(\",  # Methods\n\t\t],\n\t\t\"kt\": [\n\t\t\tr\"^import\\s+.*\",  # Import statements\n\t\t\tr\"^class\\s+\\w+\",  # Class definitions\n\t\t\tr\"^fun\\s+\\w+\",  # Function definitions\n\t\t\tr\"^val\\s+\\w+\",  # Val declarations\n\t\t\tr\"^var\\s+\\w+\",  # Var declarations\n\t\t],\n\t\t\"scala\": [\n\t\t\tr\"^import\\s+.*\",  # Import statements\n\t\t\tr\"^class\\s+\\w+\",  # Class definitions\n\t\t\tr\"^object\\s+\\w+\",  # Object definitions\n\t\t\tr\"^def\\s+\\w+\",  # Method definitions\n\t\t\tr\"^val\\s+\\w+\",  # Val declarations\n\t\t\tr\"^var\\s+\\w+\",  # Var declarations\n\t\t],\n\t}\n\n\t# Return pattern strings for the language or empty list if not supported\n\treturn pattern_strings.get(language, [])\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.determine_commit_type","title":"determine_commit_type","text":"<pre><code>determine_commit_type(files: list[str]) -&gt; str\n</code></pre> <p>Determine the appropriate commit type based on the files.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>list[str]</code> <p>List of file paths</p> required <p>Returns:</p> Type Description <code>str</code> <p>Commit type string (e.g., \"feat\", \"fix\", \"test\", \"docs\", \"chore\")</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def determine_commit_type(files: list[str]) -&gt; str:\n\t\"\"\"\n\tDetermine the appropriate commit type based on the files.\n\n\tArgs:\n\t    files: List of file paths\n\n\tReturns:\n\t    Commit type string (e.g., \"feat\", \"fix\", \"test\", \"docs\", \"chore\")\n\n\t\"\"\"\n\t# Check for test files\n\tif any(f.startswith(\"tests/\") or \"_test.\" in f or \"test_\" in f for f in files):\n\t\treturn \"test\"\n\n\t# Check for documentation files\n\tif any(f.startswith(\"docs/\") or f.endswith(\".md\") for f in files):\n\t\treturn \"docs\"\n\n\t# Check for configuration files\n\tif any(f.endswith((\".json\", \".yml\", \".yaml\", \".toml\", \".ini\", \".cfg\")) for f in files):\n\t\treturn \"chore\"\n\n\t# Default to \"chore\" for general updates\n\treturn \"chore\"\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.create_chunk_description","title":"create_chunk_description","text":"<pre><code>create_chunk_description(\n\tcommit_type: str, files: list[str]\n) -&gt; str\n</code></pre> <p>Create a meaningful description for a chunk.</p> <p>Parameters:</p> Name Type Description Default <code>commit_type</code> <code>str</code> <p>Type of commit (e.g., \"feat\", \"fix\")</p> required <code>files</code> <code>list[str]</code> <p>List of file paths</p> required <p>Returns:</p> Type Description <code>str</code> <p>Description string</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def create_chunk_description(commit_type: str, files: list[str]) -&gt; str:\n\t\"\"\"\n\tCreate a meaningful description for a chunk.\n\n\tArgs:\n\t    commit_type: Type of commit (e.g., \"feat\", \"fix\")\n\t    files: List of file paths\n\n\tReturns:\n\t    Description string\n\n\t\"\"\"\n\tif len(files) == 1:\n\t\treturn f\"{commit_type}: update {files[0]}\"\n\n\t# Try to find a common directory using Path for better cross-platform compatibility\n\ttry:\n\t\tcommon_dir = Path(os.path.commonpath(files))\n\t\tif str(common_dir) not in (\".\", \"\"):\n\t\t\treturn f\"{commit_type}: update files in {common_dir}\"\n\texcept ValueError:\n\t\t# commonpath raises ValueError if files are on different drives\n\t\tpass\n\n\treturn f\"{commit_type}: update {len(files)} related files\"\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.get_deleted_tracked_files","title":"get_deleted_tracked_files","text":"<pre><code>get_deleted_tracked_files() -&gt; tuple[set, set]\n</code></pre> <p>Get list of deleted but tracked files from git status.</p> <p>Returns:</p> Type Description <code>tuple[set, set]</code> <p>Tuple of (deleted_unstaged_files, deleted_staged_files) as sets</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def get_deleted_tracked_files() -&gt; tuple[set, set]:\n\t\"\"\"\n\tGet list of deleted but tracked files from git status.\n\n\tReturns:\n\t    Tuple of (deleted_unstaged_files, deleted_staged_files) as sets\n\n\t\"\"\"\n\tdeleted_unstaged_files = set()\n\tdeleted_staged_files = set()\n\ttry:\n\t\t# Parse git status to find deleted files\n\t\tstatus_output = run_git_command([\"git\", \"status\", \"--porcelain\"])\n\t\tfor line in status_output.splitlines():\n\t\t\tif line.startswith(\" D\"):\n\t\t\t\t# Unstaged deletion (space followed by D)\n\t\t\t\tfilename = line[3:].strip()  # Skip \" D \" prefix and strip any whitespace\n\t\t\t\tdeleted_unstaged_files.add(filename)\n\t\t\telif line.startswith(\"D \"):\n\t\t\t\t# Staged deletion (D followed by space)\n\t\t\t\tfilename = line[2:].strip()  # Skip \"D \" prefix and strip any whitespace\n\t\t\t\tdeleted_staged_files.add(filename)\n\t\tlogger.debug(\"Found %d deleted unstaged files in git status\", len(deleted_unstaged_files))\n\t\tlogger.debug(\"Found %d deleted staged files in git status\", len(deleted_staged_files))\n\texcept GitError:\n\t\tlogger.warning(\"Failed to get git status for deleted files\")\n\n\treturn deleted_unstaged_files, deleted_staged_files\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.filter_valid_files","title":"filter_valid_files","text":"<pre><code>filter_valid_files(\n\tfiles: list[str], is_test_environment: bool = False\n) -&gt; tuple[list[str], list[str]]\n</code></pre> <p>Filter invalid filenames from a list of files.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>list[str]</code> <p>List of file paths to filter</p> required <code>is_test_environment</code> <code>bool</code> <p>Whether running in a test environment</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[list[str], list[str]]</code> <p>Tuple of (valid_files, filtered_large_files) - both as lists of file paths</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def filter_valid_files(files: list[str], is_test_environment: bool = False) -&gt; tuple[list[str], list[str]]:\n\t\"\"\"\n\tFilter invalid filenames from a list of files.\n\n\tArgs:\n\t    files: List of file paths to filter\n\t    is_test_environment: Whether running in a test environment\n\n\tReturns:\n\t    Tuple of (valid_files, filtered_large_files) - both as lists of file paths\n\n\t\"\"\"\n\tif not files:\n\t\treturn [], []\n\n\tvalid_files = []\n\tfiltered_large_files = []\n\n\tfor file in files:\n\t\t# Skip files that look like patterns or templates\n\t\tif any(char in file for char in [\"*\", \"+\", \"{\", \"}\", \"\\\\\"]) or file.startswith('\"'):\n\t\t\tlogger.warning(\"Skipping invalid filename in diff processing: %s\", file)\n\t\t\tcontinue\n\n\t\t# Skip extremely large files to prevent API payload size issues\n\t\tif not is_test_environment and Path(file).exists():\n\t\t\ttry:\n\t\t\t\tfile_size = Path(file).stat().st_size\n\t\t\t\tif file_size &gt; MAX_FILE_SIZE_FOR_LLM:\n\t\t\t\t\tlogger.warning(\n\t\t\t\t\t\t\"Skipping very large file (%s bytes) to prevent API payload limits: %s\", file_size, file\n\t\t\t\t\t)\n\t\t\t\t\tfiltered_large_files.append(file)\n\t\t\t\t\tcontinue\n\t\t\texcept OSError as e:\n\t\t\t\tlogger.warning(\"Error checking file size for %s: %s\", file, e)\n\n\t\tvalid_files.append(file)\n\n\t# Skip file existence checks in test environments\n\tif is_test_environment:\n\t\tlogger.debug(\"In test environment - skipping file existence checks for %d files\", len(valid_files))\n\t\treturn valid_files, filtered_large_files\n\n\t# Get deleted files\n\tdeleted_unstaged_files, deleted_staged_files = get_deleted_tracked_files()\n\n\t# Check if files exist in the repository (tracked by git) or filesystem\n\toriginal_count = len(valid_files)\n\ttry:\n\t\ttracked_files_output = run_git_command([\"git\", \"ls-files\"])\n\t\ttracked_files = set(tracked_files_output.splitlines())\n\n\t\t# Keep files that either:\n\t\t# 1. Exist in filesystem\n\t\t# 2. Are tracked by git\n\t\t# 3. Are known deleted files from git status\n\t\t# 4. Are already staged deletions\n\t\tfiltered_files = []\n\t\tfor file in valid_files:\n\t\t\tif (\n\t\t\t\tPath(file).exists()\n\t\t\t\tor file in tracked_files\n\t\t\t\tor file in deleted_unstaged_files\n\t\t\t\tor file in deleted_staged_files\n\t\t\t):\n\t\t\t\tfiltered_files.append(file)\n\t\t\telse:\n\t\t\t\tlogger.warning(\"Skipping non-existent and untracked file in diff: %s\", file)\n\n\t\tvalid_files = filtered_files\n\t\tif len(valid_files) &lt; original_count:\n\t\t\tlogger.warning(\n\t\t\t\t\"Filtered out %d files that don't exist in the repository\",\n\t\t\t\toriginal_count - len(valid_files),\n\t\t\t)\n\texcept GitError:\n\t\t# If we can't check git tracked files, at least filter by filesystem existence and git status\n\t\tfiltered_files = []\n\t\tfor file in valid_files:\n\t\t\tif Path(file).exists() or file in deleted_unstaged_files or file in deleted_staged_files:\n\t\t\t\tfiltered_files.append(file)\n\t\t\telse:\n\t\t\t\tlogger.warning(\"Skipping non-existent file in diff: %s\", file)\n\n\t\tvalid_files = filtered_files\n\t\tif len(valid_files) &lt; original_count:\n\t\t\tlogger.warning(\n\t\t\t\t\"Filtered out %d files that don't exist in the filesystem\",\n\t\t\t\toriginal_count - len(valid_files),\n\t\t\t)\n\n\treturn valid_files, filtered_large_files\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.is_test_environment","title":"is_test_environment","text":"<pre><code>is_test_environment() -&gt; bool\n</code></pre> <p>Check if the code is running in a test environment.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if in a test environment, False otherwise</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def is_test_environment() -&gt; bool:\n\t\"\"\"\n\tCheck if the code is running in a test environment.\n\n\tReturns:\n\t    True if in a test environment, False otherwise\n\n\t\"\"\"\n\t# Check multiple environment indicators for tests\n\treturn \"PYTEST_CURRENT_TEST\" in os.environ or \"pytest\" in sys.modules or os.environ.get(\"TESTING\") == \"1\"\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.calculate_semantic_similarity","title":"calculate_semantic_similarity","text":"<pre><code>calculate_semantic_similarity(\n\temb1: list[float], emb2: list[float]\n) -&gt; float\n</code></pre> <p>Calculate semantic similarity (cosine similarity) between two embedding vectors.</p> <p>Parameters:</p> Name Type Description Default <code>emb1</code> <code>list[float]</code> <p>First embedding vector</p> required <code>emb2</code> <code>list[float]</code> <p>Second embedding vector</p> required <p>Returns:</p> Type Description <code>float</code> <p>Similarity score between 0 and 1</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def calculate_semantic_similarity(emb1: list[float], emb2: list[float]) -&gt; float:\n\t\"\"\"\n\tCalculate semantic similarity (cosine similarity) between two embedding vectors.\n\n\tArgs:\n\t    emb1: First embedding vector\n\t    emb2: Second embedding vector\n\n\tReturns:\n\t    Similarity score between 0 and 1\n\n\t\"\"\"\n\tif not emb1 or not emb2:\n\t\treturn 0.0\n\n\ttry:\n\t\t# Convert to numpy arrays\n\t\tvec1 = np.array(emb1, dtype=np.float64)\n\t\tvec2 = np.array(emb2, dtype=np.float64)\n\n\t\t# Calculate cosine similarity\n\t\tdot_product = np.dot(vec1, vec2)\n\t\tnorm1 = np.linalg.norm(vec1)\n\t\tnorm2 = np.linalg.norm(vec2)\n\n\t\tif norm1 &lt;= EPSILON or norm2 &lt;= EPSILON:\n\t\t\treturn 0.0\n\n\t\tsimilarity = float(dot_product / (norm1 * norm2))\n\n\t\t# Handle potential numeric issues\n\t\tif not np.isfinite(similarity):\n\t\t\treturn 0.0\n\n\t\treturn max(0.0, min(1.0, similarity))  # Clamp to [0, 1]\n\n\texcept (ValueError, TypeError, ArithmeticError, OverflowError):\n\t\tlogger.warning(\"Failed to calculate similarity\")\n\t\treturn 0.0\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.match_test_file_patterns","title":"match_test_file_patterns","text":"<pre><code>match_test_file_patterns(file1: str, file2: str) -&gt; bool\n</code></pre> <p>Check if files match common test file patterns.</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def match_test_file_patterns(file1: str, file2: str) -&gt; bool:\n\t\"\"\"Check if files match common test file patterns.\"\"\"\n\t# test_X.py and X.py patterns\n\tif file1.startswith(\"test_\") and file1[5:] == file2:\n\t\treturn True\n\tif file2.startswith(\"test_\") and file2[5:] == file1:\n\t\treturn True\n\n\t# X_test.py and X.py patterns\n\tif file1.endswith(\"_test.py\") and file1[:-8] + \".py\" == file2:\n\t\treturn True\n\treturn bool(file2.endswith(\"_test.py\") and file2[:-8] + \".py\" == file1)\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.have_similar_names","title":"have_similar_names","text":"<pre><code>have_similar_names(file1: str, file2: str) -&gt; bool\n</code></pre> <p>Check if files have similar base names.</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def have_similar_names(file1: str, file2: str) -&gt; bool:\n\t\"\"\"Check if files have similar base names.\"\"\"\n\tbase1 = file1.rsplit(\".\", 1)[0] if \".\" in file1 else file1\n\tbase2 = file2.rsplit(\".\", 1)[0] if \".\" in file2 else file2\n\n\treturn (base1 in base2 or base2 in base1) and min(len(base1), len(base2)) &gt;= MIN_NAME_LENGTH_FOR_SIMILARITY\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.has_related_file_pattern","title":"has_related_file_pattern","text":"<pre><code>has_related_file_pattern(\n\tfile1: str,\n\tfile2: str,\n\trelated_file_patterns: Iterable[\n\t\ttuple[Pattern, Pattern]\n\t],\n) -&gt; bool\n</code></pre> <p>Check if files match known related patterns.</p> <p>Parameters:</p> Name Type Description Default <code>file1</code> <code>str</code> <p>First file path</p> required <code>file2</code> <code>str</code> <p>Second file path</p> required <code>related_file_patterns</code> <code>Iterable[tuple[Pattern, Pattern]]</code> <p>Compiled regex pattern pairs to check against</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the files match a known pattern, False otherwise</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def has_related_file_pattern(file1: str, file2: str, related_file_patterns: Iterable[tuple[Pattern, Pattern]]) -&gt; bool:\n\t\"\"\"\n\tCheck if files match known related patterns.\n\n\tArgs:\n\t    file1: First file path\n\t    file2: Second file path\n\t    related_file_patterns: Compiled regex pattern pairs to check against\n\n\tReturns:\n\t    True if the files match a known pattern, False otherwise\n\n\t\"\"\"\n\tfor pattern1, pattern2 in related_file_patterns:\n\t\tif (pattern1.match(file1) and pattern2.match(file2)) or (pattern2.match(file1) and pattern1.match(file2)):\n\t\t\treturn True\n\treturn False\n</code></pre>"},{"location":"api/git/diff_splitter/utils/#codemap.git.diff_splitter.utils.are_files_related","title":"are_files_related","text":"<pre><code>are_files_related(\n\tfile1: str,\n\tfile2: str,\n\trelated_file_patterns: Iterable[\n\t\ttuple[Pattern, Pattern]\n\t],\n) -&gt; bool\n</code></pre> <p>Determine if two files are semantically related based on various criteria.</p> <p>Parameters:</p> Name Type Description Default <code>file1</code> <code>str</code> <p>First file path</p> required <code>file2</code> <code>str</code> <p>Second file path</p> required <code>related_file_patterns</code> <code>Iterable[tuple[Pattern, Pattern]]</code> <p>Compiled regex pattern pairs for pattern matching</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the files are related, False otherwise</p> Source code in <code>src/codemap/git/diff_splitter/utils.py</code> <pre><code>def are_files_related(file1: str, file2: str, related_file_patterns: Iterable[tuple[Pattern, Pattern]]) -&gt; bool:\n\t\"\"\"\n\tDetermine if two files are semantically related based on various criteria.\n\n\tArgs:\n\t    file1: First file path\n\t    file2: Second file path\n\t    related_file_patterns: Compiled regex pattern pairs for pattern matching\n\n\tReturns:\n\t    True if the files are related, False otherwise\n\n\t\"\"\"\n\t# 1. Files in the same directory\n\tdir1 = file1.rsplit(\"/\", 1)[0] if \"/\" in file1 else \"\"\n\tdir2 = file2.rsplit(\"/\", 1)[0] if \"/\" in file2 else \"\"\n\tif dir1 and dir1 == dir2:\n\t\treturn True\n\n\t# 2. Files in closely related directories (parent/child or same root directory)\n\tif dir1 and dir2:\n\t\tif dir1.startswith(dir2 + \"/\") or dir2.startswith(dir1 + \"/\"):\n\t\t\treturn True\n\t\t# Check if they share the same top-level directory\n\t\ttop_dir1 = dir1.split(\"/\", 1)[0] if \"/\" in dir1 else dir1\n\t\ttop_dir2 = dir2.split(\"/\", 1)[0] if \"/\" in dir2 else dir2\n\t\tif top_dir1 and top_dir1 == top_dir2:\n\t\t\treturn True\n\n\t# 3. Test files and implementation files (simple check)\n\tif (file1.startswith(\"tests/\") and file2 in file1) or (file2.startswith(\"tests/\") and file1 in file2):\n\t\treturn True\n\n\t# 4. Test file patterns\n\tfile1_name = file1.rsplit(\"/\", 1)[-1] if \"/\" in file1 else file1\n\tfile2_name = file2.rsplit(\"/\", 1)[-1] if \"/\" in file2 else file2\n\tif match_test_file_patterns(file1_name, file2_name):\n\t\treturn True\n\n\t# 5. Files with similar names\n\tif have_similar_names(file1_name, file2_name):\n\t\treturn True\n\n\t# 6. Check for related file patterns\n\treturn has_related_file_pattern(file1, file2, related_file_patterns)\n</code></pre>"},{"location":"api/git/pr_generator/","title":"Pr Generator Overview","text":"<p>PR generation package for CodeMap.</p> <ul> <li>Command - Main PR generation command implementation for CodeMap.</li> <li>Constants - Constants for PR generation.</li> <li>Decorators - Decorators for the PR generator module.</li> <li>Generator - PR generator for the CodeMap Git module.</li> <li>Prompts - Prompt templates for PR generation.</li> <li>Schemas - Schemas and data structures for PR generation.</li> <li>Strategies - Git workflow strategy implementations for PR management.</li> <li>Templates - PR template definitions for different workflow strategies.</li> <li>Utils - Utility functions for PR generation.</li> </ul>"},{"location":"api/git/pr_generator/command/","title":"Command","text":"<p>Main PR generation command implementation for CodeMap.</p>"},{"location":"api/git/pr_generator/command/#codemap.git.pr_generator.command.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/pr_generator/command/#codemap.git.pr_generator.command.PRCommand","title":"PRCommand","text":"<p>Handles the PR generation command workflow.</p> Source code in <code>src/codemap/git/pr_generator/command.py</code> <pre><code>class PRCommand:\n\t\"\"\"Handles the PR generation command workflow.\"\"\"\n\n\tdef __init__(self, path: Path | None = None, model: str = \"gpt-4o-mini\") -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the PR command.\n\n\t\tArgs:\n\t\t    path: Optional path to start from\n\t\t    model: LLM model to use for PR description generation\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\tself.repo_root = get_repo_root(path)\n\n\t\t\t# Create LLM client and configs\n\t\t\tfrom codemap.llm import create_client\n\n\t\t\tllm_client = create_client(repo_path=self.repo_root, model=model)\n\n\t\t\t# Create the PR generator with required parameters\n\t\t\tself.pr_generator = PRGenerator(\n\t\t\t\trepo_path=self.repo_root,\n\t\t\t\tllm_client=llm_client,\n\t\t\t)\n\n\t\t\tself.error_state = None  # Tracks reason for failure: \"failed\", \"aborted\", etc.\n\t\texcept GitError as e:\n\t\t\traise RuntimeError(str(e)) from e\n\n\tdef _get_branch_info(self) -&gt; dict[str, str]:\n\t\t\"\"\"\n\t\tGet information about the current branch and its target.\n\n\t\tReturns:\n\t\t    Dictionary with branch information\n\n\t\tRaises:\n\t\t    RuntimeError: If Git operations fail\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\t# Get current branch\n\t\t\tcurrent_branch = run_git_command([\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"]).strip()\n\n\t\t\t# Get default branch (usually main or master)\n\t\t\tdefault_branch = run_git_command([\"git\", \"remote\", \"show\", \"origin\"]).strip()\n\t\t\t# Parse the default branch from the output\n\t\t\tfor line in default_branch.splitlines():\n\t\t\t\tif \"HEAD branch\" in line:\n\t\t\t\t\tdefault_branch = line.split(\":\")[-1].strip()\n\t\t\t\t\tbreak\n\n\t\t\treturn {\"current_branch\": current_branch, \"target_branch\": default_branch}\n\t\texcept GitError as e:\n\t\t\tmsg = f\"Failed to get branch information: {e}\"\n\t\t\traise RuntimeError(msg) from e\n\n\tdef _get_commit_history(self, base_branch: str) -&gt; list[dict[str, str]]:\n\t\t\"\"\"\n\t\tGet commit history between the current branch and the base branch.\n\n\t\tArgs:\n\t\t    base_branch: The base branch to compare against\n\n\t\tReturns:\n\t\t    List of commits with their details\n\n\t\tRaises:\n\t\t    RuntimeError: If Git operations fail\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\t# Get list of commits that are in the current branch but not in the base branch\n\t\t\tcommits_output = run_git_command([\"git\", \"log\", f\"{base_branch}..HEAD\", \"--pretty=format:%H||%an||%s\"])\n\n\t\t\tcommits = []\n\t\t\tif commits_output.strip():\n\t\t\t\tfor commit_line in commits_output.strip().split(\"\\n\"):\n\t\t\t\t\tif not commit_line.strip():\n\t\t\t\t\t\tcontinue\n\n\t\t\t\t\tparts = commit_line.split(\"||\")\n\t\t\t\t\tif len(parts) &gt;= MIN_COMMIT_PARTS:\n\t\t\t\t\t\tcommit_hash, author, subject = parts[0], parts[1], parts[2]\n\t\t\t\t\t\tcommits.append({\"hash\": commit_hash, \"author\": author, \"subject\": subject})\n\n\t\t\treturn commits\n\t\texcept GitError as e:\n\t\t\tmsg = f\"Failed to get commit history: {e}\"\n\t\t\traise RuntimeError(msg) from e\n\n\tdef _generate_pr_description(self, branch_info: dict[str, str], _commits: list[dict[str, str]]) -&gt; str:\n\t\t\"\"\"\n\t\tGenerate PR description based on branch info and commit history.\n\n\t\tArgs:\n\t\t    branch_info: Information about the branches\n\t\t    _commits: List of commits to include in the description (fetched internally by PRGenerator)\n\n\t\tReturns:\n\t\t    Generated PR description\n\n\t\tRaises:\n\t\t    RuntimeError: If description generation fails\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\twith loading_spinner(\"Generating PR description using LLM...\"):\n\t\t\t\t# Use the PR generator to create content\n\t\t\t\tcontent = self.pr_generator.generate_content_from_commits(\n\t\t\t\t\tbase_branch=branch_info[\"target_branch\"], head_branch=branch_info[\"current_branch\"], use_llm=True\n\t\t\t\t)\n\t\t\t\treturn content[\"description\"]\n\t\texcept LLMError as e:\n\t\t\tlogger.exception(\"LLM description generation failed\")\n\t\t\tlogger.warning(\"LLM error: %s\", str(e))\n\n\t\t\t# Generate a simple fallback description without LLM\n\t\t\twith loading_spinner(\"Falling back to simple PR description generation...\"):\n\t\t\t\tcontent = self.pr_generator.generate_content_from_commits(\n\t\t\t\t\tbase_branch=branch_info[\"target_branch\"], head_branch=branch_info[\"current_branch\"], use_llm=False\n\t\t\t\t)\n\t\t\t\treturn content[\"description\"]\n\t\texcept (ValueError, RuntimeError) as e:\n\t\t\tlogger.warning(\"Error generating PR description: %s\", str(e))\n\t\t\tmsg = f\"Failed to generate PR description: {e}\"\n\t\t\traise RuntimeError(msg) from e\n\n\tdef _raise_no_commits_error(self, branch_info: dict[str, str]) -&gt; None:\n\t\t\"\"\"\n\t\tRaise an error when no commits are found between branches.\n\n\t\tArgs:\n\t\t    branch_info: Information about the branches\n\n\t\tRaises:\n\t\t    RuntimeError: Always raises this error with appropriate message\n\n\t\t\"\"\"\n\t\tmsg = f\"No commits found between {branch_info['current_branch']} and {branch_info['target_branch']}\"\n\t\tlogger.warning(msg)\n\t\traise RuntimeError(msg)\n\n\tdef run(self) -&gt; dict[str, Any]:\n\t\t\"\"\"\n\t\tRun the PR generation command.\n\n\t\tReturns:\n\t\t    Dictionary with PR information and generated description\n\n\t\tRaises:\n\t\t    RuntimeError: If the command fails\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\t# Get branch information\n\t\t\twith loading_spinner(\"Getting branch information...\"):\n\t\t\t\tbranch_info = self._get_branch_info()\n\n\t\t\t# Get commit history\n\t\t\twith loading_spinner(\"Retrieving commit history...\"):\n\t\t\t\tcommits = self._get_commit_history(branch_info[\"target_branch\"])\n\n\t\t\tif not commits:\n\t\t\t\tself._raise_no_commits_error(branch_info)\n\n\t\t\t# Generate PR description\n\t\t\tdescription = self._generate_pr_description(branch_info, commits)\n\n\t\t\treturn {\"branch_info\": branch_info, \"commits\": commits, \"description\": description}\n\t\texcept (RuntimeError, ValueError) as e:\n\t\t\tself.error_state = \"failed\"\n\t\t\traise RuntimeError(str(e)) from e\n</code></pre>"},{"location":"api/git/pr_generator/command/#codemap.git.pr_generator.command.PRCommand.__init__","title":"__init__","text":"<pre><code>__init__(\n\tpath: Path | None = None, model: str = \"gpt-4o-mini\"\n) -&gt; None\n</code></pre> <p>Initialize the PR command.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | None</code> <p>Optional path to start from</p> <code>None</code> <code>model</code> <code>str</code> <p>LLM model to use for PR description generation</p> <code>'gpt-4o-mini'</code> Source code in <code>src/codemap/git/pr_generator/command.py</code> <pre><code>def __init__(self, path: Path | None = None, model: str = \"gpt-4o-mini\") -&gt; None:\n\t\"\"\"\n\tInitialize the PR command.\n\n\tArgs:\n\t    path: Optional path to start from\n\t    model: LLM model to use for PR description generation\n\n\t\"\"\"\n\ttry:\n\t\tself.repo_root = get_repo_root(path)\n\n\t\t# Create LLM client and configs\n\t\tfrom codemap.llm import create_client\n\n\t\tllm_client = create_client(repo_path=self.repo_root, model=model)\n\n\t\t# Create the PR generator with required parameters\n\t\tself.pr_generator = PRGenerator(\n\t\t\trepo_path=self.repo_root,\n\t\t\tllm_client=llm_client,\n\t\t)\n\n\t\tself.error_state = None  # Tracks reason for failure: \"failed\", \"aborted\", etc.\n\texcept GitError as e:\n\t\traise RuntimeError(str(e)) from e\n</code></pre>"},{"location":"api/git/pr_generator/command/#codemap.git.pr_generator.command.PRCommand.repo_root","title":"repo_root  <code>instance-attribute</code>","text":"<pre><code>repo_root = get_repo_root(path)\n</code></pre>"},{"location":"api/git/pr_generator/command/#codemap.git.pr_generator.command.PRCommand.pr_generator","title":"pr_generator  <code>instance-attribute</code>","text":"<pre><code>pr_generator = PRGenerator(\n\trepo_path=repo_root, llm_client=llm_client\n)\n</code></pre>"},{"location":"api/git/pr_generator/command/#codemap.git.pr_generator.command.PRCommand.error_state","title":"error_state  <code>instance-attribute</code>","text":"<pre><code>error_state = None\n</code></pre>"},{"location":"api/git/pr_generator/command/#codemap.git.pr_generator.command.PRCommand.run","title":"run","text":"<pre><code>run() -&gt; dict[str, Any]\n</code></pre> <p>Run the PR generation command.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with PR information and generated description</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the command fails</p> Source code in <code>src/codemap/git/pr_generator/command.py</code> <pre><code>def run(self) -&gt; dict[str, Any]:\n\t\"\"\"\n\tRun the PR generation command.\n\n\tReturns:\n\t    Dictionary with PR information and generated description\n\n\tRaises:\n\t    RuntimeError: If the command fails\n\n\t\"\"\"\n\ttry:\n\t\t# Get branch information\n\t\twith loading_spinner(\"Getting branch information...\"):\n\t\t\tbranch_info = self._get_branch_info()\n\n\t\t# Get commit history\n\t\twith loading_spinner(\"Retrieving commit history...\"):\n\t\t\tcommits = self._get_commit_history(branch_info[\"target_branch\"])\n\n\t\tif not commits:\n\t\t\tself._raise_no_commits_error(branch_info)\n\n\t\t# Generate PR description\n\t\tdescription = self._generate_pr_description(branch_info, commits)\n\n\t\treturn {\"branch_info\": branch_info, \"commits\": commits, \"description\": description}\n\texcept (RuntimeError, ValueError) as e:\n\t\tself.error_state = \"failed\"\n\t\traise RuntimeError(str(e)) from e\n</code></pre>"},{"location":"api/git/pr_generator/constants/","title":"Constants","text":"<p>Constants for PR generation.</p>"},{"location":"api/git/pr_generator/constants/#codemap.git.pr_generator.constants.MAX_COMMIT_PREVIEW","title":"MAX_COMMIT_PREVIEW  <code>module-attribute</code>","text":"<pre><code>MAX_COMMIT_PREVIEW = 3\n</code></pre>"},{"location":"api/git/pr_generator/constants/#codemap.git.pr_generator.constants.MIN_SIGNIFICANT_WORD_LENGTH","title":"MIN_SIGNIFICANT_WORD_LENGTH  <code>module-attribute</code>","text":"<pre><code>MIN_SIGNIFICANT_WORD_LENGTH = 3\n</code></pre>"},{"location":"api/git/pr_generator/constants/#codemap.git.pr_generator.constants.MIN_COMMIT_PARTS","title":"MIN_COMMIT_PARTS  <code>module-attribute</code>","text":"<pre><code>MIN_COMMIT_PARTS = 3\n</code></pre>"},{"location":"api/git/pr_generator/decorators/","title":"Decorators","text":"<p>Decorators for the PR generator module.</p>"},{"location":"api/git/pr_generator/decorators/#codemap.git.pr_generator.decorators.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/pr_generator/decorators/#codemap.git.pr_generator.decorators.F","title":"F  <code>module-attribute</code>","text":"<pre><code>F = TypeVar('F', bound=Callable[..., object])\n</code></pre>"},{"location":"api/git/pr_generator/decorators/#codemap.git.pr_generator.decorators.git_operation","title":"git_operation","text":"<pre><code>git_operation(func: F) -&gt; F\n</code></pre> <p>Decorator for git operations.</p> <p>This decorator wraps functions that perform git operations, providing: - Logging of operation start/end - Standardized error handling - Automatic conversion of git-related exceptions to GitError</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>F</code> <p>The function to decorate</p> required <p>Returns:</p> Type Description <code>F</code> <p>Decorated function</p> Source code in <code>src/codemap/git/pr_generator/decorators.py</code> <pre><code>def git_operation(func: F) -&gt; F:\n\t\"\"\"\n\tDecorator for git operations.\n\n\tThis decorator wraps functions that perform git operations, providing:\n\t- Logging of operation start/end\n\t- Standardized error handling\n\t- Automatic conversion of git-related exceptions to GitError\n\n\tArgs:\n\t    func: The function to decorate\n\n\tReturns:\n\t    Decorated function\n\n\t\"\"\"\n\n\t@functools.wraps(func)\n\tdef wrapper(*args: object, **kwargs: object) -&gt; object:\n\t\tfunction_name = func.__name__\n\t\tlogger.debug(\"Starting git operation: %s\", function_name)\n\n\t\ttry:\n\t\t\tresult = func(*args, **kwargs)\n\t\t\tlogger.debug(\"Completed git operation: %s\", function_name)\n\t\t\treturn result\n\t\texcept GitError:\n\t\t\t# Re-raise GitError as is\n\t\t\tlogger.debug(\"GitError in operation: %s\", function_name)\n\t\t\traise\n\t\texcept Exception as e:\n\t\t\t# Convert other exceptions to GitError\n\t\t\tlogger.debug(\"Error in git operation %s: %s\", function_name, str(e))\n\t\t\tmsg = f\"Git operation failed: {function_name} - {e!s}\"\n\t\t\traise GitError(msg) from e\n\n\treturn cast(\"F\", wrapper)\n</code></pre>"},{"location":"api/git/pr_generator/generator/","title":"Generator","text":"<p>PR generator for the CodeMap Git module.</p> <p>This class generates pull requests for git repositories.</p>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator","title":"PRGenerator","text":"<p>Generator for Pull Requests.</p> <p>This class handles generating pull request content (title and description) and creating/updating PRs on GitHub.</p> Source code in <code>src/codemap/git/pr_generator/generator.py</code> <pre><code>class PRGenerator:\n\t\"\"\"\n\tGenerator for Pull Requests.\n\n\tThis class handles generating pull request content (title and\n\tdescription) and creating/updating PRs on GitHub.\n\n\t\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\trepo_path: Path,\n\t\tllm_client: LLMClient,\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the PR generator.\n\n\t\tArgs:\n\t\t    repo_path: Path to the git repository\n\t\t    llm_client: LLMClient instance to use for content generation\n\n\t\t\"\"\"\n\t\tself.repo_path = repo_path\n\t\tself.client = llm_client\n\n\tdef generate_content_from_commits(self, base_branch: str, head_branch: str, use_llm: bool = True) -&gt; PRContent:\n\t\t\"\"\"\n\t\tGenerate PR content (title and description) from commits.\n\n\t\tArgs:\n\t\t    base_branch: Base branch (e.g., main)\n\t\t    head_branch: Head branch (e.g., feature-branch)\n\t\t    use_llm: Whether to use LLM for generation\n\n\t\tReturns:\n\t\t    Dictionary with 'title' and 'description' keys\n\n\t\t\"\"\"\n\t\t# Get commit messages between branches\n\t\tcommits = get_commit_messages(base_branch, head_branch)\n\n\t\tif not commits:\n\t\t\treturn {\"title\": \"Update branch\", \"description\": \"No changes in this PR.\"}\n\n\t\tif use_llm:\n\t\t\t# Generate title and description using LLM\n\t\t\ttitle = generate_pr_title_with_llm(commits, self.client)\n\t\t\tdescription = generate_pr_description_with_llm(commits, self.client)\n\t\telse:\n\t\t\t# Generate title and description using rule-based approach\n\t\t\ttitle = generate_pr_title_from_commits(commits)\n\t\t\tdescription = generate_pr_description_from_commits(commits)\n\n\t\treturn {\"title\": title, \"description\": description}\n\n\tdef generate_content_from_template(\n\t\tself, branch_name: str, description: str, workflow_strategy: str = \"github-flow\"\n\t) -&gt; PRContent:\n\t\t\"\"\"\n\t\tGenerate PR content (title and description) from a template.\n\n\t\tArgs:\n\t\t    branch_name: Name of the branch\n\t\t    description: Short description of the changes\n\t\t    workflow_strategy: Git workflow strategy to use\n\n\t\tReturns:\n\t\t    Dictionary with 'title' and 'description' keys\n\n\t\t\"\"\"\n\t\treturn generate_pr_content_from_template(branch_name, description, workflow_strategy)\n\n\tdef suggest_branch_name(self, description: str, workflow_strategy: str = \"github-flow\") -&gt; str:\n\t\t\"\"\"\n\t\tSuggest a branch name based on a description.\n\n\t\tArgs:\n\t\t    description: Description of the branch\n\t\t    workflow_strategy: Git workflow strategy to use\n\n\t\tReturns:\n\t\t    Suggested branch name\n\n\t\t\"\"\"\n\t\treturn suggest_branch_name(description, workflow_strategy)\n\n\tdef create_pr(self, base_branch: str, head_branch: str, title: str, description: str) -&gt; PullRequest:\n\t\t\"\"\"\n\t\tCreate a pull request on GitHub.\n\n\t\tArgs:\n\t\t    base_branch: Base branch (e.g., main)\n\t\t    head_branch: Head branch (e.g., feature-branch)\n\t\t    title: PR title\n\t\t    description: PR description\n\n\t\tReturns:\n\t\t    PullRequest object with PR details\n\n\t\tRaises:\n\t\t    GitError: If PR creation fails\n\n\t\t\"\"\"\n\t\treturn create_pull_request(base_branch, head_branch, title, description)\n\n\tdef update_pr(self, pr_number: int, title: str, description: str) -&gt; PullRequest:\n\t\t\"\"\"\n\t\tUpdate an existing pull request.\n\n\t\tArgs:\n\t\t    pr_number: PR number\n\t\t    title: New PR title\n\t\t    description: New PR description\n\n\t\tReturns:\n\t\t    Updated PullRequest object\n\n\t\tRaises:\n\t\t    GitError: If PR update fails\n\n\t\t\"\"\"\n\t\treturn update_pull_request(pr_number, title, description)\n\n\tdef get_existing_pr(self, branch_name: str) -&gt; PullRequest | None:\n\t\t\"\"\"\n\t\tGet an existing PR for a branch.\n\n\t\tArgs:\n\t\t    branch_name: Branch name\n\n\t\tReturns:\n\t\t    PullRequest object if found, None otherwise\n\n\t\t\"\"\"\n\t\treturn get_existing_pr(branch_name)\n\n\tdef create_or_update_pr(\n\t\tself,\n\t\tbase_branch: str | None = None,\n\t\thead_branch: str | None = None,\n\t\ttitle: str | None = None,\n\t\tdescription: str | None = None,\n\t\tuse_llm: bool = True,\n\t\tpr_number: int | None = None,\n\t) -&gt; PullRequest:\n\t\t\"\"\"\n\t\tCreate a new PR or update an existing one.\n\n\t\tArgs:\n\t\t    base_branch: Base branch (defaults to default branch)\n\t\t    head_branch: Head branch\n\t\t    title: PR title (if None, will be generated)\n\t\t    description: PR description (if None, will be generated)\n\t\t    use_llm: Whether to use LLM for content generation\n\t\t    pr_number: PR number for update (if None, will create new PR)\n\n\t\tReturns:\n\t\t    PullRequest object\n\n\t\tRaises:\n\t\t    GitError: If PR creation/update fails\n\n\t\t\"\"\"\n\t\t# Get default branch if base_branch is not specified\n\t\tif base_branch is None:\n\t\t\tbase_branch = get_default_branch()\n\n\t\t# Set default head_branch to current branch if not specified\n\t\tif head_branch is None:\n\t\t\ttry:\n\t\t\t\tfrom codemap.git.pr_generator.utils import get_current_branch\n\n\t\t\t\thead_branch = get_current_branch()\n\t\t\texcept GitError as err:\n\t\t\t\tmsg = \"Failed to determine current branch\"\n\t\t\t\traise GitError(msg) from err\n\n\t\t# Check if PR exists\n\t\texisting_pr = None\n\t\tif pr_number is not None:\n\t\t\t# Updating an existing PR by number\n\t\t\tif title is None or description is None:\n\t\t\t\t# Need to fetch the PR to get current title/description\n\t\t\t\texisting_pr = self.get_existing_pr(head_branch)\n\t\t\t\tif existing_pr is None:\n\t\t\t\t\tmsg = f\"No PR found for branch {head_branch} with number {pr_number}\"\n\t\t\t\t\traise GitError(msg)\n\n\t\telse:\n\t\t\t# Look for existing PR for this branch\n\t\t\texisting_pr = self.get_existing_pr(head_branch)\n\t\t\tif existing_pr is not None:\n\t\t\t\tpr_number = existing_pr.number\n\n\t\t# Generate content if not provided\n\t\tif title is None or description is None:\n\t\t\tcontent = self.generate_content_from_commits(base_branch, head_branch, use_llm)\n\t\t\tif title is None:\n\t\t\t\ttitle = content[\"title\"]\n\t\t\tif description is None:\n\t\t\t\tdescription = content[\"description\"]\n\n\t\t# Create or update PR\n\t\tif pr_number is not None:\n\t\t\t# Update existing PR\n\t\t\treturn self.update_pr(pr_number, title, description)\n\t\t# Create new PR\n\t\treturn self.create_pr(base_branch, head_branch, title, description)\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator.__init__","title":"__init__","text":"<pre><code>__init__(repo_path: Path, llm_client: LLMClient) -&gt; None\n</code></pre> <p>Initialize the PR generator.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>Path</code> <p>Path to the git repository</p> required <code>llm_client</code> <code>LLMClient</code> <p>LLMClient instance to use for content generation</p> required Source code in <code>src/codemap/git/pr_generator/generator.py</code> <pre><code>def __init__(\n\tself,\n\trepo_path: Path,\n\tllm_client: LLMClient,\n) -&gt; None:\n\t\"\"\"\n\tInitialize the PR generator.\n\n\tArgs:\n\t    repo_path: Path to the git repository\n\t    llm_client: LLMClient instance to use for content generation\n\n\t\"\"\"\n\tself.repo_path = repo_path\n\tself.client = llm_client\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator.repo_path","title":"repo_path  <code>instance-attribute</code>","text":"<pre><code>repo_path = repo_path\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator.client","title":"client  <code>instance-attribute</code>","text":"<pre><code>client = llm_client\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator.generate_content_from_commits","title":"generate_content_from_commits","text":"<pre><code>generate_content_from_commits(\n\tbase_branch: str, head_branch: str, use_llm: bool = True\n) -&gt; PRContent\n</code></pre> <p>Generate PR content (title and description) from commits.</p> <p>Parameters:</p> Name Type Description Default <code>base_branch</code> <code>str</code> <p>Base branch (e.g., main)</p> required <code>head_branch</code> <code>str</code> <p>Head branch (e.g., feature-branch)</p> required <code>use_llm</code> <code>bool</code> <p>Whether to use LLM for generation</p> <code>True</code> <p>Returns:</p> Type Description <code>PRContent</code> <p>Dictionary with 'title' and 'description' keys</p> Source code in <code>src/codemap/git/pr_generator/generator.py</code> <pre><code>def generate_content_from_commits(self, base_branch: str, head_branch: str, use_llm: bool = True) -&gt; PRContent:\n\t\"\"\"\n\tGenerate PR content (title and description) from commits.\n\n\tArgs:\n\t    base_branch: Base branch (e.g., main)\n\t    head_branch: Head branch (e.g., feature-branch)\n\t    use_llm: Whether to use LLM for generation\n\n\tReturns:\n\t    Dictionary with 'title' and 'description' keys\n\n\t\"\"\"\n\t# Get commit messages between branches\n\tcommits = get_commit_messages(base_branch, head_branch)\n\n\tif not commits:\n\t\treturn {\"title\": \"Update branch\", \"description\": \"No changes in this PR.\"}\n\n\tif use_llm:\n\t\t# Generate title and description using LLM\n\t\ttitle = generate_pr_title_with_llm(commits, self.client)\n\t\tdescription = generate_pr_description_with_llm(commits, self.client)\n\telse:\n\t\t# Generate title and description using rule-based approach\n\t\ttitle = generate_pr_title_from_commits(commits)\n\t\tdescription = generate_pr_description_from_commits(commits)\n\n\treturn {\"title\": title, \"description\": description}\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator.generate_content_from_template","title":"generate_content_from_template","text":"<pre><code>generate_content_from_template(\n\tbranch_name: str,\n\tdescription: str,\n\tworkflow_strategy: str = \"github-flow\",\n) -&gt; PRContent\n</code></pre> <p>Generate PR content (title and description) from a template.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Name of the branch</p> required <code>description</code> <code>str</code> <p>Short description of the changes</p> required <code>workflow_strategy</code> <code>str</code> <p>Git workflow strategy to use</p> <code>'github-flow'</code> <p>Returns:</p> Type Description <code>PRContent</code> <p>Dictionary with 'title' and 'description' keys</p> Source code in <code>src/codemap/git/pr_generator/generator.py</code> <pre><code>def generate_content_from_template(\n\tself, branch_name: str, description: str, workflow_strategy: str = \"github-flow\"\n) -&gt; PRContent:\n\t\"\"\"\n\tGenerate PR content (title and description) from a template.\n\n\tArgs:\n\t    branch_name: Name of the branch\n\t    description: Short description of the changes\n\t    workflow_strategy: Git workflow strategy to use\n\n\tReturns:\n\t    Dictionary with 'title' and 'description' keys\n\n\t\"\"\"\n\treturn generate_pr_content_from_template(branch_name, description, workflow_strategy)\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator.suggest_branch_name","title":"suggest_branch_name","text":"<pre><code>suggest_branch_name(\n\tdescription: str, workflow_strategy: str = \"github-flow\"\n) -&gt; str\n</code></pre> <p>Suggest a branch name based on a description.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>Description of the branch</p> required <code>workflow_strategy</code> <code>str</code> <p>Git workflow strategy to use</p> <code>'github-flow'</code> <p>Returns:</p> Type Description <code>str</code> <p>Suggested branch name</p> Source code in <code>src/codemap/git/pr_generator/generator.py</code> <pre><code>def suggest_branch_name(self, description: str, workflow_strategy: str = \"github-flow\") -&gt; str:\n\t\"\"\"\n\tSuggest a branch name based on a description.\n\n\tArgs:\n\t    description: Description of the branch\n\t    workflow_strategy: Git workflow strategy to use\n\n\tReturns:\n\t    Suggested branch name\n\n\t\"\"\"\n\treturn suggest_branch_name(description, workflow_strategy)\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator.create_pr","title":"create_pr","text":"<pre><code>create_pr(\n\tbase_branch: str,\n\thead_branch: str,\n\ttitle: str,\n\tdescription: str,\n) -&gt; PullRequest\n</code></pre> <p>Create a pull request on GitHub.</p> <p>Parameters:</p> Name Type Description Default <code>base_branch</code> <code>str</code> <p>Base branch (e.g., main)</p> required <code>head_branch</code> <code>str</code> <p>Head branch (e.g., feature-branch)</p> required <code>title</code> <code>str</code> <p>PR title</p> required <code>description</code> <code>str</code> <p>PR description</p> required <p>Returns:</p> Type Description <code>PullRequest</code> <p>PullRequest object with PR details</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If PR creation fails</p> Source code in <code>src/codemap/git/pr_generator/generator.py</code> <pre><code>def create_pr(self, base_branch: str, head_branch: str, title: str, description: str) -&gt; PullRequest:\n\t\"\"\"\n\tCreate a pull request on GitHub.\n\n\tArgs:\n\t    base_branch: Base branch (e.g., main)\n\t    head_branch: Head branch (e.g., feature-branch)\n\t    title: PR title\n\t    description: PR description\n\n\tReturns:\n\t    PullRequest object with PR details\n\n\tRaises:\n\t    GitError: If PR creation fails\n\n\t\"\"\"\n\treturn create_pull_request(base_branch, head_branch, title, description)\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator.update_pr","title":"update_pr","text":"<pre><code>update_pr(\n\tpr_number: int, title: str, description: str\n) -&gt; PullRequest\n</code></pre> <p>Update an existing pull request.</p> <p>Parameters:</p> Name Type Description Default <code>pr_number</code> <code>int</code> <p>PR number</p> required <code>title</code> <code>str</code> <p>New PR title</p> required <code>description</code> <code>str</code> <p>New PR description</p> required <p>Returns:</p> Type Description <code>PullRequest</code> <p>Updated PullRequest object</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If PR update fails</p> Source code in <code>src/codemap/git/pr_generator/generator.py</code> <pre><code>def update_pr(self, pr_number: int, title: str, description: str) -&gt; PullRequest:\n\t\"\"\"\n\tUpdate an existing pull request.\n\n\tArgs:\n\t    pr_number: PR number\n\t    title: New PR title\n\t    description: New PR description\n\n\tReturns:\n\t    Updated PullRequest object\n\n\tRaises:\n\t    GitError: If PR update fails\n\n\t\"\"\"\n\treturn update_pull_request(pr_number, title, description)\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator.get_existing_pr","title":"get_existing_pr","text":"<pre><code>get_existing_pr(branch_name: str) -&gt; PullRequest | None\n</code></pre> <p>Get an existing PR for a branch.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Branch name</p> required <p>Returns:</p> Type Description <code>PullRequest | None</code> <p>PullRequest object if found, None otherwise</p> Source code in <code>src/codemap/git/pr_generator/generator.py</code> <pre><code>def get_existing_pr(self, branch_name: str) -&gt; PullRequest | None:\n\t\"\"\"\n\tGet an existing PR for a branch.\n\n\tArgs:\n\t    branch_name: Branch name\n\n\tReturns:\n\t    PullRequest object if found, None otherwise\n\n\t\"\"\"\n\treturn get_existing_pr(branch_name)\n</code></pre>"},{"location":"api/git/pr_generator/generator/#codemap.git.pr_generator.generator.PRGenerator.create_or_update_pr","title":"create_or_update_pr","text":"<pre><code>create_or_update_pr(\n\tbase_branch: str | None = None,\n\thead_branch: str | None = None,\n\ttitle: str | None = None,\n\tdescription: str | None = None,\n\tuse_llm: bool = True,\n\tpr_number: int | None = None,\n) -&gt; PullRequest\n</code></pre> <p>Create a new PR or update an existing one.</p> <p>Parameters:</p> Name Type Description Default <code>base_branch</code> <code>str | None</code> <p>Base branch (defaults to default branch)</p> <code>None</code> <code>head_branch</code> <code>str | None</code> <p>Head branch</p> <code>None</code> <code>title</code> <code>str | None</code> <p>PR title (if None, will be generated)</p> <code>None</code> <code>description</code> <code>str | None</code> <p>PR description (if None, will be generated)</p> <code>None</code> <code>use_llm</code> <code>bool</code> <p>Whether to use LLM for content generation</p> <code>True</code> <code>pr_number</code> <code>int | None</code> <p>PR number for update (if None, will create new PR)</p> <code>None</code> <p>Returns:</p> Type Description <code>PullRequest</code> <p>PullRequest object</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If PR creation/update fails</p> Source code in <code>src/codemap/git/pr_generator/generator.py</code> <pre><code>def create_or_update_pr(\n\tself,\n\tbase_branch: str | None = None,\n\thead_branch: str | None = None,\n\ttitle: str | None = None,\n\tdescription: str | None = None,\n\tuse_llm: bool = True,\n\tpr_number: int | None = None,\n) -&gt; PullRequest:\n\t\"\"\"\n\tCreate a new PR or update an existing one.\n\n\tArgs:\n\t    base_branch: Base branch (defaults to default branch)\n\t    head_branch: Head branch\n\t    title: PR title (if None, will be generated)\n\t    description: PR description (if None, will be generated)\n\t    use_llm: Whether to use LLM for content generation\n\t    pr_number: PR number for update (if None, will create new PR)\n\n\tReturns:\n\t    PullRequest object\n\n\tRaises:\n\t    GitError: If PR creation/update fails\n\n\t\"\"\"\n\t# Get default branch if base_branch is not specified\n\tif base_branch is None:\n\t\tbase_branch = get_default_branch()\n\n\t# Set default head_branch to current branch if not specified\n\tif head_branch is None:\n\t\ttry:\n\t\t\tfrom codemap.git.pr_generator.utils import get_current_branch\n\n\t\t\thead_branch = get_current_branch()\n\t\texcept GitError as err:\n\t\t\tmsg = \"Failed to determine current branch\"\n\t\t\traise GitError(msg) from err\n\n\t# Check if PR exists\n\texisting_pr = None\n\tif pr_number is not None:\n\t\t# Updating an existing PR by number\n\t\tif title is None or description is None:\n\t\t\t# Need to fetch the PR to get current title/description\n\t\t\texisting_pr = self.get_existing_pr(head_branch)\n\t\t\tif existing_pr is None:\n\t\t\t\tmsg = f\"No PR found for branch {head_branch} with number {pr_number}\"\n\t\t\t\traise GitError(msg)\n\n\telse:\n\t\t# Look for existing PR for this branch\n\t\texisting_pr = self.get_existing_pr(head_branch)\n\t\tif existing_pr is not None:\n\t\t\tpr_number = existing_pr.number\n\n\t# Generate content if not provided\n\tif title is None or description is None:\n\t\tcontent = self.generate_content_from_commits(base_branch, head_branch, use_llm)\n\t\tif title is None:\n\t\t\ttitle = content[\"title\"]\n\t\tif description is None:\n\t\t\tdescription = content[\"description\"]\n\n\t# Create or update PR\n\tif pr_number is not None:\n\t\t# Update existing PR\n\t\treturn self.update_pr(pr_number, title, description)\n\t# Create new PR\n\treturn self.create_pr(base_branch, head_branch, title, description)\n</code></pre>"},{"location":"api/git/pr_generator/prompts/","title":"Prompts","text":"<p>Prompt templates for PR generation.</p>"},{"location":"api/git/pr_generator/prompts/#codemap.git.pr_generator.prompts.PR_TITLE_PROMPT","title":"PR_TITLE_PROMPT  <code>module-attribute</code>","text":"<pre><code>PR_TITLE_PROMPT = 'Based on the following commits, generate a clear, concise PR title that captures the\\nessence of the changes.\\nFollow these guidelines:\\n- Focus on the most important change\\n- If there are multiple related changes, summarize them\\n- Keep it under 80 characters\\n- Start with a capital letter\\n- Don\\'t use a period at the end\\n- Use present tense (e.g., \"Add feature\" not \"Added feature\")\\n- Be descriptive and specific (e.g., \"Fix memory leak in data processing\" not just \"Fix bug\")\\n- Include the type of change if clear (Feature, Fix, Refactor, etc.)\\n\\nCommits:\\n{commit_list}\\n\\nPR Title:\\n---\\n\\nIMPORTANT:\\n- Do not include any other text in your response except the PR title.\\n- Do not wrap the PR title in quotes.\\n- Do not add any explanations or other text to your response.\\n'\n</code></pre>"},{"location":"api/git/pr_generator/prompts/#codemap.git.pr_generator.prompts.PR_DESCRIPTION_PROMPT","title":"PR_DESCRIPTION_PROMPT  <code>module-attribute</code>","text":"<pre><code>PR_DESCRIPTION_PROMPT = \"\\nBased on the following commits, generate a comprehensive PR description following this template:\\n\\n## What type of PR is this? (check all applicable)\\n\\n- [ ] Refactor\\n- [ ] Feature\\n- [ ] Bug Fix\\n- [ ] Optimization\\n- [ ] Documentation Update\\n\\n## Description\\n[Fill this section with a detailed description of the changes]\\n\\n## Related Tickets &amp; Documents\\n- Related Issue #\\n- Closes #\\n\\n## Added/updated tests?\\n- [ ] Yes\\n- [ ] No, and this is why: [explanation]\\n- [ ] I need help with writing tests\\n\\nConsider the following guidelines:\\n- Check the appropriate PR type boxes based on the commit messages\\n- Provide a clear, detailed description of the changes\\n- Include any relevant issue numbers that this PR relates to or closes\\n- Indicate if tests were added, and if not, explain why\\n- Use bullet points for clarity\\n\\nCommits:\\n{commit_list}\\n\\nPR Description:\\n---\\n\\nIMPORTANT:\\n- Do not include any other text in your response except the PR description.\\n- Do not wrap the PR description in quotes.\\n- Do not add any explanations or other text to your response.\\n\"\n</code></pre>"},{"location":"api/git/pr_generator/prompts/#codemap.git.pr_generator.prompts.format_commits_for_prompt","title":"format_commits_for_prompt","text":"<pre><code>format_commits_for_prompt(commits: list[str]) -&gt; str\n</code></pre> <p>Format commit messages as a bulleted list.</p> <p>Parameters:</p> Name Type Description Default <code>commits</code> <code>list[str]</code> <p>List of commit messages</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted commit list as a string</p> Source code in <code>src/codemap/git/pr_generator/prompts.py</code> <pre><code>def format_commits_for_prompt(commits: list[str]) -&gt; str:\n\t\"\"\"\n\tFormat commit messages as a bulleted list.\n\n\tArgs:\n\t    commits: List of commit messages\n\n\tReturns:\n\t    Formatted commit list as a string\n\n\t\"\"\"\n\treturn \"\\n\".join([f\"- {commit}\" for commit in commits])\n</code></pre>"},{"location":"api/git/pr_generator/schemas/","title":"Schemas","text":"<p>Schemas and data structures for PR generation.</p>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.WorkflowStrategySchema","title":"WorkflowStrategySchema  <code>module-attribute</code>","text":"<pre><code>WorkflowStrategySchema = Literal[\n\t\"github-flow\", \"gitflow\", \"trunk-based\"\n]\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.BranchType","title":"BranchType  <code>module-attribute</code>","text":"<pre><code>BranchType = Literal[\n\t\"feature\", \"release\", \"hotfix\", \"bugfix\", \"docs\"\n]\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.PRContent","title":"PRContent","text":"<p>               Bases: <code>TypedDict</code></p> <p>Pull request content type.</p> Source code in <code>src/codemap/git/pr_generator/schemas.py</code> <pre><code>class PRContent(TypedDict):\n\t\"\"\"Pull request content type.\"\"\"\n\n\ttitle: str\n\tdescription: str\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.PRContent.title","title":"title  <code>instance-attribute</code>","text":"<pre><code>title: str\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.PRContent.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: str\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.PullRequest","title":"PullRequest  <code>dataclass</code>","text":"<p>Represents a GitHub Pull Request.</p> Source code in <code>src/codemap/git/pr_generator/schemas.py</code> <pre><code>@dataclass\nclass PullRequest:\n\t\"\"\"Represents a GitHub Pull Request.\"\"\"\n\n\tbranch: str\n\ttitle: str\n\tdescription: str\n\turl: str | None = None\n\tnumber: int | None = None\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.PullRequest.__init__","title":"__init__","text":"<pre><code>__init__(\n\tbranch: str,\n\ttitle: str,\n\tdescription: str,\n\turl: str | None = None,\n\tnumber: int | None = None,\n) -&gt; None\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.PullRequest.branch","title":"branch  <code>instance-attribute</code>","text":"<pre><code>branch: str\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.PullRequest.title","title":"title  <code>instance-attribute</code>","text":"<pre><code>title: str\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.PullRequest.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: str\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.PullRequest.url","title":"url  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>url: str | None = None\n</code></pre>"},{"location":"api/git/pr_generator/schemas/#codemap.git.pr_generator.schemas.PullRequest.number","title":"number  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>number: int | None = None\n</code></pre>"},{"location":"api/git/pr_generator/strategies/","title":"Strategies","text":"<p>Git workflow strategy implementations for PR management.</p>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy","title":"WorkflowStrategy","text":"<p>Base class for git workflow strategies.</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>class WorkflowStrategy:\n\t\"\"\"Base class for git workflow strategies.\"\"\"\n\n\tdef get_default_base(self, branch_type: str) -&gt; str:\n\t\t\"\"\"\n\t\tGet the default base branch for a given branch type.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\n\t\tReturns:\n\t\t    Name of the default base branch\n\n\t\t\"\"\"\n\t\traise NotImplementedError\n\n\tdef suggest_branch_name(self, branch_type: str, description: str) -&gt; str:\n\t\t\"\"\"\n\t\tSuggest a branch name based on the workflow.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\t\t    description: Description of the branch\n\n\t\tReturns:\n\t\t    Suggested branch name\n\n\t\t\"\"\"\n\t\t# Default implementation\n\t\tclean_description = re.sub(r\"[^a-zA-Z0-9]+\", \"-\", description.lower())\n\t\tclean_description = clean_description.strip(\"-\")\n\t\tprefix = self.get_branch_prefix(branch_type)\n\t\treturn f\"{prefix}{clean_description}\"\n\n\tdef get_branch_prefix(self, branch_type: str) -&gt; str:\n\t\t\"\"\"\n\t\tGet the branch name prefix for a given branch type.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\n\t\tReturns:\n\t\t    Branch name prefix\n\n\t\t\"\"\"\n\t\traise NotImplementedError\n\n\tdef get_branch_types(self) -&gt; list[str]:\n\t\t\"\"\"\n\t\tGet valid branch types for this workflow.\n\n\t\tReturns:\n\t\t    List of valid branch types\n\n\t\t\"\"\"\n\t\traise NotImplementedError\n\n\tdef detect_branch_type(self, branch_name: str) -&gt; str | None:\n\t\t\"\"\"\n\t\tDetect the type of a branch from its name.\n\n\t\tArgs:\n\t\t    branch_name: Name of the branch\n\n\t\tReturns:\n\t\t    Branch type or None if not detected\n\n\t\t\"\"\"\n\t\tfor branch_type in self.get_branch_types():\n\t\t\tprefix = self.get_branch_prefix(branch_type)\n\t\t\tif branch_name.startswith(prefix):\n\t\t\t\treturn branch_type\n\t\treturn None\n\n\tdef get_pr_templates(self, branch_type: str) -&gt; dict[str, str]:  # noqa: ARG002\n\t\t\"\"\"\n\t\tGet PR title and description templates for a given branch type.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\n\t\tReturns:\n\t\t    Dictionary with 'title' and 'description' templates\n\n\t\t\"\"\"\n\t\t# Return the default templates\n\t\treturn DEFAULT_PR_TEMPLATE\n\n\tdef get_remote_branches(self) -&gt; list[str]:\n\t\t\"\"\"\n\t\tGet list of remote branches.\n\n\t\tReturns:\n\t\t    List of remote branch names (without 'origin/' prefix)\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\tbranches = run_git_command([\"git\", \"branch\", \"-r\"]).strip().split(\"\\n\")\n\t\t\t# Clean up branch names and remove 'origin/' prefix\n\t\t\tremote_branches = []\n\t\t\tfor branch_name in branches:\n\t\t\t\tbranch_clean = branch_name.strip()\n\t\t\t\tif branch_clean.startswith(\"origin/\"):\n\t\t\t\t\tbranch_name_without_prefix = branch_clean[7:]  # Remove 'origin/' prefix\n\t\t\t\t\t# Exclude HEAD branches\n\t\t\t\t\tif not branch_name_without_prefix.startswith(\"HEAD\"):\n\t\t\t\t\t\tremote_branches.append(branch_name_without_prefix)\n\t\t\treturn remote_branches\n\t\texcept GitError:\n\t\t\treturn []\n\n\tdef get_local_branches(self) -&gt; list[str]:\n\t\t\"\"\"\n\t\tGet list of local branches.\n\n\t\tReturns:\n\t\t    List of local branch names\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\tbranches = run_git_command([\"git\", \"branch\"]).strip().split(\"\\n\")\n\t\t\t# Clean up branch names and remove the '*' from current branch\n\t\t\tlocal_branches = []\n\t\t\tfor branch_name in branches:\n\t\t\t\tbranch_clean = branch_name.strip().removeprefix(\"* \")  # Remove '* ' prefix\n\t\t\t\tlocal_branches.append(branch_clean)\n\t\t\treturn local_branches\n\t\texcept GitError:\n\t\t\treturn []\n\n\tdef get_branches_by_type(self) -&gt; dict[str, list[str]]:\n\t\t\"\"\"\n\t\tGroup branches by their type.\n\n\t\tReturns:\n\t\t    Dictionary mapping branch types to lists of branch names\n\n\t\t\"\"\"\n\t\tresult = {branch_type: [] for branch_type in self.get_branch_types()}\n\t\tresult[\"other\"] = []  # For branches that don't match any type\n\n\t\t# Get all branches (local and remote)\n\t\tall_branches = set(self.get_local_branches() + self.get_remote_branches())\n\n\t\tfor branch in all_branches:\n\t\t\tbranch_type = self.detect_branch_type(branch)\n\t\t\tif branch_type:\n\t\t\t\tresult[branch_type].append(branch)\n\t\t\telse:\n\t\t\t\tresult[\"other\"].append(branch)\n\n\t\treturn result\n\n\tdef get_branch_metadata(self, branch_name: str) -&gt; dict[str, Any]:\n\t\t\"\"\"\n\t\tGet metadata for a specific branch.\n\n\t\tArgs:\n\t\t    branch_name: Name of the branch\n\n\t\tReturns:\n\t\t    Dictionary with branch metadata\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\t# Get last commit date\n\t\t\tdate_cmd = [\n\t\t\t\t\"git\",\n\t\t\t\t\"log\",\n\t\t\t\t\"-1\",\n\t\t\t\t\"--format=%ad\",\n\t\t\t\t\"--date=relative\",\n\t\t\t\tbranch_name if branch_exists(branch_name) else f\"origin/{branch_name}\",\n\t\t\t]\n\t\t\tdate = run_git_command(date_cmd).strip()\n\n\t\t\t# Get commit count (compared to default branch)\n\t\t\tdefault = get_default_branch()\n\t\t\tcount_cmd = [\"git\", \"rev-list\", \"--count\", f\"{default}..{branch_name}\"]\n\t\t\ttry:\n\t\t\t\tcount = run_git_command(count_cmd).strip()\n\t\t\texcept GitError:\n\t\t\t\tcount = \"0\"\n\n\t\t\t# Detect branch type\n\t\t\tbranch_type = self.detect_branch_type(branch_name)\n\n\t\t\treturn {\n\t\t\t\t\"last_commit_date\": date,\n\t\t\t\t\"commit_count\": count,\n\t\t\t\t\"branch_type\": branch_type,\n\t\t\t\t\"is_local\": branch_name in self.get_local_branches(),\n\t\t\t\t\"is_remote\": branch_name in self.get_remote_branches(),\n\t\t\t}\n\t\texcept GitError:\n\t\t\t# Return default metadata if there's an error\n\t\t\treturn {\n\t\t\t\t\"last_commit_date\": \"unknown\",\n\t\t\t\t\"commit_count\": \"0\",\n\t\t\t\t\"branch_type\": self.detect_branch_type(branch_name),\n\t\t\t\t\"is_local\": False,\n\t\t\t\t\"is_remote\": False,\n\t\t\t}\n\n\tdef get_all_branches_with_metadata(self) -&gt; dict[str, dict[str, Any]]:\n\t\t\"\"\"\n\t\tGet all branches with metadata.\n\n\t\tReturns:\n\t\t    Dictionary mapping branch names to metadata dictionaries\n\n\t\t\"\"\"\n\t\tresult = {}\n\t\tall_branches = set(self.get_local_branches() + self.get_remote_branches())\n\n\t\tfor branch in all_branches:\n\t\t\tresult[branch] = self.get_branch_metadata(branch)\n\n\t\treturn result\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.get_default_base","title":"get_default_base","text":"<pre><code>get_default_base(branch_type: str) -&gt; str\n</code></pre> <p>Get the default base branch for a given branch type.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (feature, release, hotfix, etc.)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Name of the default base branch</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_default_base(self, branch_type: str) -&gt; str:\n\t\"\"\"\n\tGet the default base branch for a given branch type.\n\n\tArgs:\n\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\n\tReturns:\n\t    Name of the default base branch\n\n\t\"\"\"\n\traise NotImplementedError\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.suggest_branch_name","title":"suggest_branch_name","text":"<pre><code>suggest_branch_name(\n\tbranch_type: str, description: str\n) -&gt; str\n</code></pre> <p>Suggest a branch name based on the workflow.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (feature, release, hotfix, etc.)</p> required <code>description</code> <code>str</code> <p>Description of the branch</p> required <p>Returns:</p> Type Description <code>str</code> <p>Suggested branch name</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def suggest_branch_name(self, branch_type: str, description: str) -&gt; str:\n\t\"\"\"\n\tSuggest a branch name based on the workflow.\n\n\tArgs:\n\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\t    description: Description of the branch\n\n\tReturns:\n\t    Suggested branch name\n\n\t\"\"\"\n\t# Default implementation\n\tclean_description = re.sub(r\"[^a-zA-Z0-9]+\", \"-\", description.lower())\n\tclean_description = clean_description.strip(\"-\")\n\tprefix = self.get_branch_prefix(branch_type)\n\treturn f\"{prefix}{clean_description}\"\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.get_branch_prefix","title":"get_branch_prefix","text":"<pre><code>get_branch_prefix(branch_type: str) -&gt; str\n</code></pre> <p>Get the branch name prefix for a given branch type.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (feature, release, hotfix, etc.)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Branch name prefix</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_branch_prefix(self, branch_type: str) -&gt; str:\n\t\"\"\"\n\tGet the branch name prefix for a given branch type.\n\n\tArgs:\n\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\n\tReturns:\n\t    Branch name prefix\n\n\t\"\"\"\n\traise NotImplementedError\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.get_branch_types","title":"get_branch_types","text":"<pre><code>get_branch_types() -&gt; list[str]\n</code></pre> <p>Get valid branch types for this workflow.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of valid branch types</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_branch_types(self) -&gt; list[str]:\n\t\"\"\"\n\tGet valid branch types for this workflow.\n\n\tReturns:\n\t    List of valid branch types\n\n\t\"\"\"\n\traise NotImplementedError\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.detect_branch_type","title":"detect_branch_type","text":"<pre><code>detect_branch_type(branch_name: str) -&gt; str | None\n</code></pre> <p>Detect the type of a branch from its name.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Name of the branch</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Branch type or None if not detected</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def detect_branch_type(self, branch_name: str) -&gt; str | None:\n\t\"\"\"\n\tDetect the type of a branch from its name.\n\n\tArgs:\n\t    branch_name: Name of the branch\n\n\tReturns:\n\t    Branch type or None if not detected\n\n\t\"\"\"\n\tfor branch_type in self.get_branch_types():\n\t\tprefix = self.get_branch_prefix(branch_type)\n\t\tif branch_name.startswith(prefix):\n\t\t\treturn branch_type\n\treturn None\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.get_pr_templates","title":"get_pr_templates","text":"<pre><code>get_pr_templates(branch_type: str) -&gt; dict[str, str]\n</code></pre> <p>Get PR title and description templates for a given branch type.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (feature, release, hotfix, etc.)</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary with 'title' and 'description' templates</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_pr_templates(self, branch_type: str) -&gt; dict[str, str]:  # noqa: ARG002\n\t\"\"\"\n\tGet PR title and description templates for a given branch type.\n\n\tArgs:\n\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\n\tReturns:\n\t    Dictionary with 'title' and 'description' templates\n\n\t\"\"\"\n\t# Return the default templates\n\treturn DEFAULT_PR_TEMPLATE\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.get_remote_branches","title":"get_remote_branches","text":"<pre><code>get_remote_branches() -&gt; list[str]\n</code></pre> <p>Get list of remote branches.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of remote branch names (without 'origin/' prefix)</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_remote_branches(self) -&gt; list[str]:\n\t\"\"\"\n\tGet list of remote branches.\n\n\tReturns:\n\t    List of remote branch names (without 'origin/' prefix)\n\n\t\"\"\"\n\ttry:\n\t\tbranches = run_git_command([\"git\", \"branch\", \"-r\"]).strip().split(\"\\n\")\n\t\t# Clean up branch names and remove 'origin/' prefix\n\t\tremote_branches = []\n\t\tfor branch_name in branches:\n\t\t\tbranch_clean = branch_name.strip()\n\t\t\tif branch_clean.startswith(\"origin/\"):\n\t\t\t\tbranch_name_without_prefix = branch_clean[7:]  # Remove 'origin/' prefix\n\t\t\t\t# Exclude HEAD branches\n\t\t\t\tif not branch_name_without_prefix.startswith(\"HEAD\"):\n\t\t\t\t\tremote_branches.append(branch_name_without_prefix)\n\t\treturn remote_branches\n\texcept GitError:\n\t\treturn []\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.get_local_branches","title":"get_local_branches","text":"<pre><code>get_local_branches() -&gt; list[str]\n</code></pre> <p>Get list of local branches.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of local branch names</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_local_branches(self) -&gt; list[str]:\n\t\"\"\"\n\tGet list of local branches.\n\n\tReturns:\n\t    List of local branch names\n\n\t\"\"\"\n\ttry:\n\t\tbranches = run_git_command([\"git\", \"branch\"]).strip().split(\"\\n\")\n\t\t# Clean up branch names and remove the '*' from current branch\n\t\tlocal_branches = []\n\t\tfor branch_name in branches:\n\t\t\tbranch_clean = branch_name.strip().removeprefix(\"* \")  # Remove '* ' prefix\n\t\t\tlocal_branches.append(branch_clean)\n\t\treturn local_branches\n\texcept GitError:\n\t\treturn []\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.get_branches_by_type","title":"get_branches_by_type","text":"<pre><code>get_branches_by_type() -&gt; dict[str, list[str]]\n</code></pre> <p>Group branches by their type.</p> <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>Dictionary mapping branch types to lists of branch names</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_branches_by_type(self) -&gt; dict[str, list[str]]:\n\t\"\"\"\n\tGroup branches by their type.\n\n\tReturns:\n\t    Dictionary mapping branch types to lists of branch names\n\n\t\"\"\"\n\tresult = {branch_type: [] for branch_type in self.get_branch_types()}\n\tresult[\"other\"] = []  # For branches that don't match any type\n\n\t# Get all branches (local and remote)\n\tall_branches = set(self.get_local_branches() + self.get_remote_branches())\n\n\tfor branch in all_branches:\n\t\tbranch_type = self.detect_branch_type(branch)\n\t\tif branch_type:\n\t\t\tresult[branch_type].append(branch)\n\t\telse:\n\t\t\tresult[\"other\"].append(branch)\n\n\treturn result\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.get_branch_metadata","title":"get_branch_metadata","text":"<pre><code>get_branch_metadata(branch_name: str) -&gt; dict[str, Any]\n</code></pre> <p>Get metadata for a specific branch.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Name of the branch</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with branch metadata</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_branch_metadata(self, branch_name: str) -&gt; dict[str, Any]:\n\t\"\"\"\n\tGet metadata for a specific branch.\n\n\tArgs:\n\t    branch_name: Name of the branch\n\n\tReturns:\n\t    Dictionary with branch metadata\n\n\t\"\"\"\n\ttry:\n\t\t# Get last commit date\n\t\tdate_cmd = [\n\t\t\t\"git\",\n\t\t\t\"log\",\n\t\t\t\"-1\",\n\t\t\t\"--format=%ad\",\n\t\t\t\"--date=relative\",\n\t\t\tbranch_name if branch_exists(branch_name) else f\"origin/{branch_name}\",\n\t\t]\n\t\tdate = run_git_command(date_cmd).strip()\n\n\t\t# Get commit count (compared to default branch)\n\t\tdefault = get_default_branch()\n\t\tcount_cmd = [\"git\", \"rev-list\", \"--count\", f\"{default}..{branch_name}\"]\n\t\ttry:\n\t\t\tcount = run_git_command(count_cmd).strip()\n\t\texcept GitError:\n\t\t\tcount = \"0\"\n\n\t\t# Detect branch type\n\t\tbranch_type = self.detect_branch_type(branch_name)\n\n\t\treturn {\n\t\t\t\"last_commit_date\": date,\n\t\t\t\"commit_count\": count,\n\t\t\t\"branch_type\": branch_type,\n\t\t\t\"is_local\": branch_name in self.get_local_branches(),\n\t\t\t\"is_remote\": branch_name in self.get_remote_branches(),\n\t\t}\n\texcept GitError:\n\t\t# Return default metadata if there's an error\n\t\treturn {\n\t\t\t\"last_commit_date\": \"unknown\",\n\t\t\t\"commit_count\": \"0\",\n\t\t\t\"branch_type\": self.detect_branch_type(branch_name),\n\t\t\t\"is_local\": False,\n\t\t\t\"is_remote\": False,\n\t\t}\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.WorkflowStrategy.get_all_branches_with_metadata","title":"get_all_branches_with_metadata","text":"<pre><code>get_all_branches_with_metadata() -&gt; dict[\n\tstr, dict[str, Any]\n]\n</code></pre> <p>Get all branches with metadata.</p> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>Dictionary mapping branch names to metadata dictionaries</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_all_branches_with_metadata(self) -&gt; dict[str, dict[str, Any]]:\n\t\"\"\"\n\tGet all branches with metadata.\n\n\tReturns:\n\t    Dictionary mapping branch names to metadata dictionaries\n\n\t\"\"\"\n\tresult = {}\n\tall_branches = set(self.get_local_branches() + self.get_remote_branches())\n\n\tfor branch in all_branches:\n\t\tresult[branch] = self.get_branch_metadata(branch)\n\n\treturn result\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitHubFlowStrategy","title":"GitHubFlowStrategy","text":"<p>               Bases: <code>WorkflowStrategy</code></p> <p>Implementation of GitHub Flow workflow strategy.</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>class GitHubFlowStrategy(WorkflowStrategy):\n\t\"\"\"Implementation of GitHub Flow workflow strategy.\"\"\"\n\n\tdef get_default_base(self, branch_type: str) -&gt; str:  # noqa: ARG002\n\t\t\"\"\"\n\t\tGet the default base branch for GitHub Flow.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (always 'feature' in GitHub Flow)\n\n\t\tReturns:\n\t\t    Name of the default base branch (usually 'main')\n\n\t\t\"\"\"\n\t\t# Ignoring branch_type as GitHub Flow always uses the default branch\n\t\treturn get_default_branch()\n\n\tdef get_branch_prefix(self, branch_type: str) -&gt; str:  # noqa: ARG002\n\t\t\"\"\"\n\t\tGet the branch name prefix for GitHub Flow.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (always 'feature' in GitHub Flow)\n\n\t\tReturns:\n\t\t    Branch name prefix (empty string for GitHub Flow)\n\n\t\t\"\"\"\n\t\t# Ignoring branch_type as GitHub Flow doesn't use prefixes\n\t\treturn \"\"\n\n\tdef get_branch_types(self) -&gt; list[str]:\n\t\t\"\"\"\n\t\tGet valid branch types for GitHub Flow.\n\n\t\tReturns:\n\t\t    List containing only 'feature'\n\n\t\t\"\"\"\n\t\treturn [\"feature\"]\n\n\tdef get_pr_templates(self, branch_type: str) -&gt; dict[str, str]:  # noqa: ARG002\n\t\t\"\"\"\n\t\tGet PR title and description templates for GitHub Flow.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (always 'feature' in GitHub Flow)\n\n\t\tReturns:\n\t\t    Dictionary with 'title' and 'description' templates\n\n\t\t\"\"\"\n\t\treturn GITHUB_FLOW_PR_TEMPLATE\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitHubFlowStrategy.get_default_base","title":"get_default_base","text":"<pre><code>get_default_base(branch_type: str) -&gt; str\n</code></pre> <p>Get the default base branch for GitHub Flow.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (always 'feature' in GitHub Flow)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Name of the default base branch (usually 'main')</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_default_base(self, branch_type: str) -&gt; str:  # noqa: ARG002\n\t\"\"\"\n\tGet the default base branch for GitHub Flow.\n\n\tArgs:\n\t    branch_type: Type of branch (always 'feature' in GitHub Flow)\n\n\tReturns:\n\t    Name of the default base branch (usually 'main')\n\n\t\"\"\"\n\t# Ignoring branch_type as GitHub Flow always uses the default branch\n\treturn get_default_branch()\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitHubFlowStrategy.get_branch_prefix","title":"get_branch_prefix","text":"<pre><code>get_branch_prefix(branch_type: str) -&gt; str\n</code></pre> <p>Get the branch name prefix for GitHub Flow.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (always 'feature' in GitHub Flow)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Branch name prefix (empty string for GitHub Flow)</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_branch_prefix(self, branch_type: str) -&gt; str:  # noqa: ARG002\n\t\"\"\"\n\tGet the branch name prefix for GitHub Flow.\n\n\tArgs:\n\t    branch_type: Type of branch (always 'feature' in GitHub Flow)\n\n\tReturns:\n\t    Branch name prefix (empty string for GitHub Flow)\n\n\t\"\"\"\n\t# Ignoring branch_type as GitHub Flow doesn't use prefixes\n\treturn \"\"\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitHubFlowStrategy.get_branch_types","title":"get_branch_types","text":"<pre><code>get_branch_types() -&gt; list[str]\n</code></pre> <p>Get valid branch types for GitHub Flow.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List containing only 'feature'</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_branch_types(self) -&gt; list[str]:\n\t\"\"\"\n\tGet valid branch types for GitHub Flow.\n\n\tReturns:\n\t    List containing only 'feature'\n\n\t\"\"\"\n\treturn [\"feature\"]\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitHubFlowStrategy.get_pr_templates","title":"get_pr_templates","text":"<pre><code>get_pr_templates(branch_type: str) -&gt; dict[str, str]\n</code></pre> <p>Get PR title and description templates for GitHub Flow.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (always 'feature' in GitHub Flow)</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary with 'title' and 'description' templates</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_pr_templates(self, branch_type: str) -&gt; dict[str, str]:  # noqa: ARG002\n\t\"\"\"\n\tGet PR title and description templates for GitHub Flow.\n\n\tArgs:\n\t    branch_type: Type of branch (always 'feature' in GitHub Flow)\n\n\tReturns:\n\t    Dictionary with 'title' and 'description' templates\n\n\t\"\"\"\n\treturn GITHUB_FLOW_PR_TEMPLATE\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitFlowStrategy","title":"GitFlowStrategy","text":"<p>               Bases: <code>WorkflowStrategy</code></p> <p>Implementation of GitFlow workflow strategy.</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>class GitFlowStrategy(WorkflowStrategy):\n\t\"\"\"Implementation of GitFlow workflow strategy.\"\"\"\n\n\tdef get_default_base(self, branch_type: str) -&gt; str:\n\t\t\"\"\"\n\t\tGet the default base branch for GitFlow.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (feature, release, hotfix, bugfix)\n\n\t\tReturns:\n\t\t    Name of the default base branch\n\n\t\t\"\"\"\n\t\tmapping = {\n\t\t\t\"feature\": \"develop\",\n\t\t\t\"release\": \"main\",\n\t\t\t\"hotfix\": \"main\",\n\t\t\t\"bugfix\": \"develop\",\n\t\t}\n\t\tdefault = get_default_branch()\n\t\treturn mapping.get(branch_type, default)\n\n\tdef get_branch_prefix(self, branch_type: str) -&gt; str:\n\t\t\"\"\"\n\t\tGet the branch name prefix for GitFlow.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\n\t\tReturns:\n\t\t    Branch name prefix\n\n\t\t\"\"\"\n\t\tmapping = {\n\t\t\t\"feature\": \"feature/\",\n\t\t\t\"release\": \"release/\",\n\t\t\t\"hotfix\": \"hotfix/\",\n\t\t\t\"bugfix\": \"bugfix/\",\n\t\t}\n\t\treturn mapping.get(branch_type, \"\")\n\n\tdef get_branch_types(self) -&gt; list[str]:\n\t\t\"\"\"\n\t\tGet valid branch types for GitFlow.\n\n\t\tReturns:\n\t\t    List of valid branch types for GitFlow\n\n\t\t\"\"\"\n\t\treturn [\"feature\", \"release\", \"hotfix\", \"bugfix\"]\n\n\tdef suggest_branch_name(self, branch_type: str, description: str) -&gt; str:\n\t\t\"\"\"\n\t\tSuggest a branch name based on GitFlow conventions.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\t\t    description: Description of the branch\n\n\t\tReturns:\n\t\t    Suggested branch name\n\n\t\t\"\"\"\n\t\tprefix = self.get_branch_prefix(branch_type)\n\n\t\tif branch_type == \"release\":\n\t\t\t# Extract version number from description if it looks like a version\n\t\t\tversion_match = re.search(r\"(\\d+\\.\\d+\\.\\d+)\", description)\n\t\t\tif version_match:\n\t\t\t\treturn f\"{prefix}{version_match.group(1)}\"\n\n\t\t# For other branch types, use the default implementation\n\t\treturn super().suggest_branch_name(branch_type, description)\n\n\tdef get_pr_templates(self, branch_type: str) -&gt; dict[str, str]:\n\t\t\"\"\"\n\t\tGet PR title and description templates for GitFlow.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch (feature, release, hotfix, bugfix)\n\n\t\tReturns:\n\t\t    Dictionary with 'title' and 'description' templates\n\n\t\t\"\"\"\n\t\treturn GITFLOW_PR_TEMPLATES.get(branch_type, DEFAULT_PR_TEMPLATE)\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitFlowStrategy.get_default_base","title":"get_default_base","text":"<pre><code>get_default_base(branch_type: str) -&gt; str\n</code></pre> <p>Get the default base branch for GitFlow.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (feature, release, hotfix, bugfix)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Name of the default base branch</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_default_base(self, branch_type: str) -&gt; str:\n\t\"\"\"\n\tGet the default base branch for GitFlow.\n\n\tArgs:\n\t    branch_type: Type of branch (feature, release, hotfix, bugfix)\n\n\tReturns:\n\t    Name of the default base branch\n\n\t\"\"\"\n\tmapping = {\n\t\t\"feature\": \"develop\",\n\t\t\"release\": \"main\",\n\t\t\"hotfix\": \"main\",\n\t\t\"bugfix\": \"develop\",\n\t}\n\tdefault = get_default_branch()\n\treturn mapping.get(branch_type, default)\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitFlowStrategy.get_branch_prefix","title":"get_branch_prefix","text":"<pre><code>get_branch_prefix(branch_type: str) -&gt; str\n</code></pre> <p>Get the branch name prefix for GitFlow.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (feature, release, hotfix, etc.)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Branch name prefix</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_branch_prefix(self, branch_type: str) -&gt; str:\n\t\"\"\"\n\tGet the branch name prefix for GitFlow.\n\n\tArgs:\n\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\n\tReturns:\n\t    Branch name prefix\n\n\t\"\"\"\n\tmapping = {\n\t\t\"feature\": \"feature/\",\n\t\t\"release\": \"release/\",\n\t\t\"hotfix\": \"hotfix/\",\n\t\t\"bugfix\": \"bugfix/\",\n\t}\n\treturn mapping.get(branch_type, \"\")\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitFlowStrategy.get_branch_types","title":"get_branch_types","text":"<pre><code>get_branch_types() -&gt; list[str]\n</code></pre> <p>Get valid branch types for GitFlow.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of valid branch types for GitFlow</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_branch_types(self) -&gt; list[str]:\n\t\"\"\"\n\tGet valid branch types for GitFlow.\n\n\tReturns:\n\t    List of valid branch types for GitFlow\n\n\t\"\"\"\n\treturn [\"feature\", \"release\", \"hotfix\", \"bugfix\"]\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitFlowStrategy.suggest_branch_name","title":"suggest_branch_name","text":"<pre><code>suggest_branch_name(\n\tbranch_type: str, description: str\n) -&gt; str\n</code></pre> <p>Suggest a branch name based on GitFlow conventions.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (feature, release, hotfix, etc.)</p> required <code>description</code> <code>str</code> <p>Description of the branch</p> required <p>Returns:</p> Type Description <code>str</code> <p>Suggested branch name</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def suggest_branch_name(self, branch_type: str, description: str) -&gt; str:\n\t\"\"\"\n\tSuggest a branch name based on GitFlow conventions.\n\n\tArgs:\n\t    branch_type: Type of branch (feature, release, hotfix, etc.)\n\t    description: Description of the branch\n\n\tReturns:\n\t    Suggested branch name\n\n\t\"\"\"\n\tprefix = self.get_branch_prefix(branch_type)\n\n\tif branch_type == \"release\":\n\t\t# Extract version number from description if it looks like a version\n\t\tversion_match = re.search(r\"(\\d+\\.\\d+\\.\\d+)\", description)\n\t\tif version_match:\n\t\t\treturn f\"{prefix}{version_match.group(1)}\"\n\n\t# For other branch types, use the default implementation\n\treturn super().suggest_branch_name(branch_type, description)\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.GitFlowStrategy.get_pr_templates","title":"get_pr_templates","text":"<pre><code>get_pr_templates(branch_type: str) -&gt; dict[str, str]\n</code></pre> <p>Get PR title and description templates for GitFlow.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch (feature, release, hotfix, bugfix)</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary with 'title' and 'description' templates</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_pr_templates(self, branch_type: str) -&gt; dict[str, str]:\n\t\"\"\"\n\tGet PR title and description templates for GitFlow.\n\n\tArgs:\n\t    branch_type: Type of branch (feature, release, hotfix, bugfix)\n\n\tReturns:\n\t    Dictionary with 'title' and 'description' templates\n\n\t\"\"\"\n\treturn GITFLOW_PR_TEMPLATES.get(branch_type, DEFAULT_PR_TEMPLATE)\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.TrunkBasedStrategy","title":"TrunkBasedStrategy","text":"<p>               Bases: <code>WorkflowStrategy</code></p> <p>Implementation of Trunk-Based Development workflow strategy.</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>class TrunkBasedStrategy(WorkflowStrategy):\n\t\"\"\"Implementation of Trunk-Based Development workflow strategy.\"\"\"\n\n\tdef get_default_base(self, branch_type: str) -&gt; str:  # noqa: ARG002\n\t\t\"\"\"\n\t\tGet the default base branch for Trunk-Based Development.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch\n\n\t\tReturns:\n\t\t    Name of the default base branch (trunk, which is usually 'main')\n\n\t\t\"\"\"\n\t\t# Ignoring branch_type as Trunk-Based Development always uses the main branch\n\t\treturn get_default_branch()\n\n\tdef get_branch_prefix(self, branch_type: str) -&gt; str:\n\t\t\"\"\"\n\t\tGet the branch name prefix for Trunk-Based Development.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch\n\n\t\tReturns:\n\t\t    Branch name prefix\n\n\t\t\"\"\"\n\t\treturn \"fb/\" if branch_type == \"feature\" else \"\"\n\n\tdef get_branch_types(self) -&gt; list[str]:\n\t\t\"\"\"\n\t\tGet valid branch types for Trunk-Based Development.\n\n\t\tReturns:\n\t\t    List containing only 'feature'\n\n\t\t\"\"\"\n\t\treturn [\"feature\"]\n\n\tdef suggest_branch_name(self, branch_type: str, description: str) -&gt; str:\n\t\t\"\"\"\n\t\tSuggest a branch name based on Trunk-Based Development conventions.\n\n\t\tEmphasizes short-lived, descriptive branches.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch\n\t\t    description: Description of the branch\n\n\t\tReturns:\n\t\t    Suggested branch name\n\n\t\t\"\"\"\n\t\t# For trunk-based development, try to generate very short names\n\t\twords = description.split()\n\t\t# Filter out common words like \"implement\", \"the\", \"and\", etc.\n\t\tcommon_words = [\"the\", \"and\", \"for\", \"with\", \"implement\", \"implementing\", \"implementation\"]\n\t\twords = [w for w in words if len(w) &gt; MIN_SIGNIFICANT_WORD_LENGTH and w.lower() not in common_words]\n\n\t\t# Take up to 3 significant words\n\t\tshort_desc = \"-\".join(words[:3]).lower()\n\t\tshort_desc = re.sub(r\"[^a-zA-Z0-9-]\", \"-\", short_desc)\n\t\tshort_desc = re.sub(r\"-+\", \"-\", short_desc)\n\t\tshort_desc = short_desc.strip(\"-\")\n\n\t\t# Add username prefix for trunk-based (optional)\n\t\ttry:\n\t\t\tusername = run_git_command([\"git\", \"config\", \"user.name\"]).strip().split()[0].lower()\n\t\t\tusername = re.sub(r\"[^a-zA-Z0-9]\", \"\", username)\n\t\t\treturn f\"{username}/{short_desc}\"\n\t\texcept (GitError, IndexError):\n\t\t\t# Fall back to standard prefix if username not available\n\t\t\tprefix = self.get_branch_prefix(branch_type)\n\t\t\treturn f\"{prefix}{short_desc}\"\n\n\tdef get_pr_templates(self, branch_type: str) -&gt; dict[str, str]:  # noqa: ARG002\n\t\t\"\"\"\n\t\tGet PR title and description templates for Trunk-Based Development.\n\n\t\tArgs:\n\t\t    branch_type: Type of branch\n\n\t\tReturns:\n\t\t    Dictionary with 'title' and 'description' templates\n\n\t\t\"\"\"\n\t\treturn TRUNK_BASED_PR_TEMPLATE\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.TrunkBasedStrategy.get_default_base","title":"get_default_base","text":"<pre><code>get_default_base(branch_type: str) -&gt; str\n</code></pre> <p>Get the default base branch for Trunk-Based Development.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch</p> required <p>Returns:</p> Type Description <code>str</code> <p>Name of the default base branch (trunk, which is usually 'main')</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_default_base(self, branch_type: str) -&gt; str:  # noqa: ARG002\n\t\"\"\"\n\tGet the default base branch for Trunk-Based Development.\n\n\tArgs:\n\t    branch_type: Type of branch\n\n\tReturns:\n\t    Name of the default base branch (trunk, which is usually 'main')\n\n\t\"\"\"\n\t# Ignoring branch_type as Trunk-Based Development always uses the main branch\n\treturn get_default_branch()\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.TrunkBasedStrategy.get_branch_prefix","title":"get_branch_prefix","text":"<pre><code>get_branch_prefix(branch_type: str) -&gt; str\n</code></pre> <p>Get the branch name prefix for Trunk-Based Development.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch</p> required <p>Returns:</p> Type Description <code>str</code> <p>Branch name prefix</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_branch_prefix(self, branch_type: str) -&gt; str:\n\t\"\"\"\n\tGet the branch name prefix for Trunk-Based Development.\n\n\tArgs:\n\t    branch_type: Type of branch\n\n\tReturns:\n\t    Branch name prefix\n\n\t\"\"\"\n\treturn \"fb/\" if branch_type == \"feature\" else \"\"\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.TrunkBasedStrategy.get_branch_types","title":"get_branch_types","text":"<pre><code>get_branch_types() -&gt; list[str]\n</code></pre> <p>Get valid branch types for Trunk-Based Development.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List containing only 'feature'</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_branch_types(self) -&gt; list[str]:\n\t\"\"\"\n\tGet valid branch types for Trunk-Based Development.\n\n\tReturns:\n\t    List containing only 'feature'\n\n\t\"\"\"\n\treturn [\"feature\"]\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.TrunkBasedStrategy.suggest_branch_name","title":"suggest_branch_name","text":"<pre><code>suggest_branch_name(\n\tbranch_type: str, description: str\n) -&gt; str\n</code></pre> <p>Suggest a branch name based on Trunk-Based Development conventions.</p> <p>Emphasizes short-lived, descriptive branches.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch</p> required <code>description</code> <code>str</code> <p>Description of the branch</p> required <p>Returns:</p> Type Description <code>str</code> <p>Suggested branch name</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def suggest_branch_name(self, branch_type: str, description: str) -&gt; str:\n\t\"\"\"\n\tSuggest a branch name based on Trunk-Based Development conventions.\n\n\tEmphasizes short-lived, descriptive branches.\n\n\tArgs:\n\t    branch_type: Type of branch\n\t    description: Description of the branch\n\n\tReturns:\n\t    Suggested branch name\n\n\t\"\"\"\n\t# For trunk-based development, try to generate very short names\n\twords = description.split()\n\t# Filter out common words like \"implement\", \"the\", \"and\", etc.\n\tcommon_words = [\"the\", \"and\", \"for\", \"with\", \"implement\", \"implementing\", \"implementation\"]\n\twords = [w for w in words if len(w) &gt; MIN_SIGNIFICANT_WORD_LENGTH and w.lower() not in common_words]\n\n\t# Take up to 3 significant words\n\tshort_desc = \"-\".join(words[:3]).lower()\n\tshort_desc = re.sub(r\"[^a-zA-Z0-9-]\", \"-\", short_desc)\n\tshort_desc = re.sub(r\"-+\", \"-\", short_desc)\n\tshort_desc = short_desc.strip(\"-\")\n\n\t# Add username prefix for trunk-based (optional)\n\ttry:\n\t\tusername = run_git_command([\"git\", \"config\", \"user.name\"]).strip().split()[0].lower()\n\t\tusername = re.sub(r\"[^a-zA-Z0-9]\", \"\", username)\n\t\treturn f\"{username}/{short_desc}\"\n\texcept (GitError, IndexError):\n\t\t# Fall back to standard prefix if username not available\n\t\tprefix = self.get_branch_prefix(branch_type)\n\t\treturn f\"{prefix}{short_desc}\"\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.TrunkBasedStrategy.get_pr_templates","title":"get_pr_templates","text":"<pre><code>get_pr_templates(branch_type: str) -&gt; dict[str, str]\n</code></pre> <p>Get PR title and description templates for Trunk-Based Development.</p> <p>Parameters:</p> Name Type Description Default <code>branch_type</code> <code>str</code> <p>Type of branch</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary with 'title' and 'description' templates</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_pr_templates(self, branch_type: str) -&gt; dict[str, str]:  # noqa: ARG002\n\t\"\"\"\n\tGet PR title and description templates for Trunk-Based Development.\n\n\tArgs:\n\t    branch_type: Type of branch\n\n\tReturns:\n\t    Dictionary with 'title' and 'description' templates\n\n\t\"\"\"\n\treturn TRUNK_BASED_PR_TEMPLATE\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.get_strategy_class","title":"get_strategy_class","text":"<pre><code>get_strategy_class(\n\tstrategy_name: str,\n) -&gt; type[WorkflowStrategy] | None\n</code></pre> <p>Get the workflow strategy class corresponding to the strategy name.</p> <p>Parameters:</p> Name Type Description Default <code>strategy_name</code> <code>str</code> <p>Name of the workflow strategy</p> required <p>Returns:</p> Type Description <code>type[WorkflowStrategy] | None</code> <p>Workflow strategy class or None if not found</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_strategy_class(strategy_name: str) -&gt; type[WorkflowStrategy] | None:\n\t\"\"\"\n\tGet the workflow strategy class corresponding to the strategy name.\n\n\tArgs:\n\t    strategy_name: Name of the workflow strategy\n\n\tReturns:\n\t    Workflow strategy class or None if not found\n\n\t\"\"\"\n\tstrategy_map = {\n\t\t\"github-flow\": GitHubFlowStrategy,\n\t\t\"gitflow\": GitFlowStrategy,\n\t\t\"trunk-based\": TrunkBasedStrategy,\n\t}\n\treturn strategy_map.get(strategy_name)\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.create_strategy","title":"create_strategy","text":"<pre><code>create_strategy(strategy_name: str) -&gt; WorkflowStrategy\n</code></pre> <p>Create a workflow strategy instance based on the strategy name.</p> <p>Parameters:</p> Name Type Description Default <code>strategy_name</code> <code>str</code> <p>The name of the workflow strategy to create.</p> required <p>Returns:</p> Type Description <code>WorkflowStrategy</code> <p>An instance of the requested workflow strategy.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the strategy name is unknown.</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def create_strategy(strategy_name: str) -&gt; WorkflowStrategy:\n\t\"\"\"\n\tCreate a workflow strategy instance based on the strategy name.\n\n\tArgs:\n\t    strategy_name: The name of the workflow strategy to create.\n\n\tReturns:\n\t    An instance of the requested workflow strategy.\n\n\tRaises:\n\t    ValueError: If the strategy name is unknown.\n\n\t\"\"\"\n\tstrategy_class = get_strategy_class(strategy_name)\n\tif not strategy_class:\n\t\terror_msg = f\"Unknown workflow strategy: {strategy_name}\"\n\t\traise ValueError(error_msg)\n\n\treturn strategy_class()\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.branch_exists","title":"branch_exists","text":"<pre><code>branch_exists(\n\tbranch_name: str, include_remote: bool = True\n) -&gt; bool\n</code></pre> <p>Check if a branch exists.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Name of the branch to check</p> required <code>include_remote</code> <code>bool</code> <p>Whether to check remote branches as well</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the branch exists, False otherwise</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def branch_exists(branch_name: str, include_remote: bool = True) -&gt; bool:\n\t\"\"\"\n\tCheck if a branch exists.\n\n\tArgs:\n\t    branch_name: Name of the branch to check\n\t    include_remote: Whether to check remote branches as well\n\n\tReturns:\n\t    True if the branch exists, False otherwise\n\n\t\"\"\"\n\tif not branch_name:\n\t\treturn False\n\n\ttry:\n\t\t# First check local branches\n\t\ttry:\n\t\t\tbranches = run_git_command([\"git\", \"branch\", \"--list\", branch_name]).strip()\n\t\t\tif branches:\n\t\t\t\treturn True\n\t\texcept GitError:\n\t\t\t# If local check fails, don't fail immediately\n\t\t\tpass\n\n\t\t# Then check remote branches if requested\n\t\tif include_remote:\n\t\t\ttry:\n\t\t\t\tremote_branches = run_git_command([\"git\", \"branch\", \"-r\", \"--list\", f\"origin/{branch_name}\"]).strip()\n\t\t\t\tif remote_branches:\n\t\t\t\t\treturn True\n\t\t\texcept GitError:\n\t\t\t\t# If remote check fails, don't fail immediately\n\t\t\t\tpass\n\n\t\t# If we get here, the branch doesn't exist or commands failed\n\t\treturn False\n\texcept GitError:\n\t\treturn False\n</code></pre>"},{"location":"api/git/pr_generator/strategies/#codemap.git.pr_generator.strategies.get_default_branch","title":"get_default_branch","text":"<pre><code>get_default_branch() -&gt; str\n</code></pre> <p>Get the default branch of the repository.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the default branch (usually main or master)</p> Source code in <code>src/codemap/git/pr_generator/strategies.py</code> <pre><code>def get_default_branch() -&gt; str:\n\t\"\"\"\n\tGet the default branch of the repository.\n\n\tReturns:\n\t    Name of the default branch (usually main or master)\n\n\t\"\"\"\n\ttry:\n\t\t# Try to get the default branch from the remote\n\t\tremote_info = run_git_command([\"git\", \"remote\", \"show\", \"origin\"])\n\t\tmatch = re.search(r\"HEAD branch: (\\S+)\", remote_info)\n\t\tif match:\n\t\t\treturn match.group(1)\n\n\t\t# Fallback to checking if main or master exists\n\t\tbranches = run_git_command([\"git\", \"branch\", \"-r\"]).splitlines()\n\t\tif any(\"origin/main\" in branch for branch in branches):\n\t\t\treturn \"main\"\n\t\tif any(\"origin/master\" in branch for branch in branches):\n\t\t\treturn \"master\"\n\n\t\t# Last resort, use current branch\n\t\treturn run_git_command([\"git\", \"branch\", \"--show-current\"]).strip()\n\texcept GitError:\n\t\treturn \"main\"\n</code></pre>"},{"location":"api/git/pr_generator/templates/","title":"Templates","text":"<p>PR template definitions for different workflow strategies.</p>"},{"location":"api/git/pr_generator/templates/#codemap.git.pr_generator.templates.DEFAULT_PR_TEMPLATE","title":"DEFAULT_PR_TEMPLATE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_PR_TEMPLATE = {\n\t\"title\": \"{branch_type}: {description}\",\n\t\"description\": \"## Description\\n\\n{description}\\n\\n## Changes\\n\\n-\\n\\n## Related Issues\\n\\n-\\n\",\n}\n</code></pre>"},{"location":"api/git/pr_generator/templates/#codemap.git.pr_generator.templates.GITHUB_FLOW_PR_TEMPLATE","title":"GITHUB_FLOW_PR_TEMPLATE  <code>module-attribute</code>","text":"<pre><code>GITHUB_FLOW_PR_TEMPLATE = {\n\t\"title\": \"{description}\",\n\t\"description\": \"## Description\\n\\n{description}\\n\\n## What does this PR do?\\n\\n&lt;!-- Please include a summary of the change and which issue is fixed. --&gt;\\n\\n## Changes\\n\\n-\\n\\n## Screenshots (if appropriate)\\n\\n## Testing completed\\n\\n- [ ] Unit tests\\n- [ ] Integration tests\\n- [ ] Manual testing\\n\\n## Related Issues\\n\\n&lt;!-- Please link to any related issues here --&gt;\\n\\n- Closes #\\n\",\n}\n</code></pre>"},{"location":"api/git/pr_generator/templates/#codemap.git.pr_generator.templates.TRUNK_BASED_PR_TEMPLATE","title":"TRUNK_BASED_PR_TEMPLATE  <code>module-attribute</code>","text":"<pre><code>TRUNK_BASED_PR_TEMPLATE = {\n\t\"title\": \"{description}\",\n\t\"description\": \"## Change Description\\n\\n{description}\\n\\n## Implementation\\n\\n&lt;!-- Briefly describe implementation details --&gt;\\n\\n-\\n\\n## Test Plan\\n\\n&lt;!-- How was this tested? --&gt;\\n\\n- [ ] Unit tests added/updated\\n- [ ] Integration tested\\n\\n## Rollout Plan\\n\\n&lt;!-- How should this be deployed? --&gt;\\n\\n- [ ] Can be deployed immediately\\n- [ ] Requires feature flag\\n- [ ] Requires data migration\\n\\n## Related Issues\\n\\n- Fixes #\\n\",\n}\n</code></pre>"},{"location":"api/git/pr_generator/templates/#codemap.git.pr_generator.templates.GITFLOW_PR_TEMPLATES","title":"GITFLOW_PR_TEMPLATES  <code>module-attribute</code>","text":"<pre><code>GITFLOW_PR_TEMPLATES = {\n\t\"feature\": {\n\t\t\"title\": \"Feature: {description}\",\n\t\t\"description\": \"## Feature Description\\n\\n{description}\\n\\n## Implemented Changes\\n\\n-\\n\\n## Testing Performed\\n\\n- [ ] Unit tests\\n- [ ] Integration tests\\n- [ ] Manual testing\\n\\n## Related Issues\\n\\n- Closes #\\n\",\n\t},\n\t\"release\": {\n\t\t\"title\": \"Release {description}\",\n\t\t\"description\": \"## Release {description}\\n\\n### Features\\n\\n-\\n\\n### Bug Fixes\\n\\n-\\n\\n### Breaking Changes\\n\\n-\\n\\n## Deployment Notes\\n\\n-\\n\\n## Testing Required\\n\\n- [ ] Smoke tests\\n- [ ] Regression tests\\n- [ ] Performance tests\\n\",\n\t},\n\t\"hotfix\": {\n\t\t\"title\": \"Hotfix: {description}\",\n\t\t\"description\": \"## Hotfix: {description}\\n\\n### Issue Description\\n\\n&lt;!-- Describe the issue being fixed --&gt;\\n\\n### Fix Implementation\\n\\n&lt;!-- Describe how the issue was fixed --&gt;\\n\\n-\\n\\n### Testing Performed\\n\\n- [ ] Verified fix locally\\n- [ ] Added regression test\\n\\n### Impact Analysis\\n\\n- Affected components:\\n- Risk assessment:\\n\",\n\t},\n\t\"bugfix\": {\n\t\t\"title\": \"Fix: {description}\",\n\t\t\"description\": \"## Bug Fix\\n\\n### Issue Description\\n\\n{description}\\n\\n### Root Cause\\n\\n&lt;!-- What caused the bug? --&gt;\\n\\n### Fix Implementation\\n\\n-\\n\\n### Testing Performed\\n\\n- [ ] Added test case that reproduces the bug\\n- [ ] Verified fix locally\\n\\n### Related Issues\\n\\n- Fixes #\\n\",\n\t},\n}\n</code></pre>"},{"location":"api/git/pr_generator/utils/","title":"Utils","text":"<p>Utility functions for PR generation.</p>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.PRCreationError","title":"PRCreationError","text":"<p>               Bases: <code>GitError</code></p> <p>Error raised when there's an issue creating or updating a pull request.</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>class PRCreationError(GitError):\n\t\"\"\"Error raised when there's an issue creating or updating a pull request.\"\"\"\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.get_current_branch","title":"get_current_branch","text":"<pre><code>get_current_branch() -&gt; str\n</code></pre> <p>Get the name of the current branch.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the current branch</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If git command fails</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def get_current_branch() -&gt; str:\n\t\"\"\"\n\tGet the name of the current branch.\n\n\tReturns:\n\t    Name of the current branch\n\n\tRaises:\n\t    GitError: If git command fails\n\n\t\"\"\"\n\ttry:\n\t\treturn run_git_command([\"git\", \"branch\", \"--show-current\"]).strip()\n\texcept GitError as e:\n\t\tmsg = \"Failed to get current branch\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.create_branch","title":"create_branch","text":"<pre><code>create_branch(branch_name: str) -&gt; None\n</code></pre> <p>Create a new branch and switch to it.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Name of the branch to create</p> required <p>Raises:</p> Type Description <code>GitError</code> <p>If git command fails</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def create_branch(branch_name: str) -&gt; None:\n\t\"\"\"\n\tCreate a new branch and switch to it.\n\n\tArgs:\n\t    branch_name: Name of the branch to create\n\n\tRaises:\n\t    GitError: If git command fails\n\n\t\"\"\"\n\ttry:\n\t\trun_git_command([\"git\", \"checkout\", \"-b\", branch_name])\n\texcept GitError as e:\n\t\tmsg = f\"Failed to create branch: {branch_name}\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.checkout_branch","title":"checkout_branch","text":"<pre><code>checkout_branch(branch_name: str) -&gt; None\n</code></pre> <p>Checkout an existing branch.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Name of the branch to checkout</p> required <p>Raises:</p> Type Description <code>GitError</code> <p>If git command fails</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def checkout_branch(branch_name: str) -&gt; None:\n\t\"\"\"\n\tCheckout an existing branch.\n\n\tArgs:\n\t    branch_name: Name of the branch to checkout\n\n\tRaises:\n\t    GitError: If git command fails\n\n\t\"\"\"\n\ttry:\n\t\trun_git_command([\"git\", \"checkout\", branch_name])\n\texcept GitError as e:\n\t\tmsg = f\"Failed to checkout branch: {branch_name}\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.push_branch","title":"push_branch","text":"<pre><code>push_branch(branch_name: str, force: bool = False) -&gt; None\n</code></pre> <p>Push a branch to the remote.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Name of the branch to push</p> required <code>force</code> <code>bool</code> <p>Whether to force push</p> <code>False</code> <p>Raises:</p> Type Description <code>GitError</code> <p>If git command fails</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def push_branch(branch_name: str, force: bool = False) -&gt; None:\n\t\"\"\"\n\tPush a branch to the remote.\n\n\tArgs:\n\t    branch_name: Name of the branch to push\n\t    force: Whether to force push\n\n\tRaises:\n\t    GitError: If git command fails\n\n\t\"\"\"\n\ttry:\n\t\tcmd = [\"git\", \"push\", \"-u\", \"origin\", branch_name]\n\t\tif force:\n\t\t\tcmd.insert(2, \"--force\")\n\t\trun_git_command(cmd)\n\texcept GitError as e:\n\t\tmsg = f\"Failed to push branch: {branch_name}\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.get_commit_messages","title":"get_commit_messages","text":"<pre><code>get_commit_messages(\n\tbase_branch: str, head_branch: str\n) -&gt; list[str]\n</code></pre> <p>Get commit messages between two branches.</p> <p>Parameters:</p> Name Type Description Default <code>base_branch</code> <code>str</code> <p>Base branch (e.g., main)</p> required <code>head_branch</code> <code>str</code> <p>Head branch (e.g., feature-branch)</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of commit messages</p> <p>Raises:</p> Type Description <code>GitError</code> <p>If git command fails</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def get_commit_messages(base_branch: str, head_branch: str) -&gt; list[str]:\n\t\"\"\"\n\tGet commit messages between two branches.\n\n\tArgs:\n\t    base_branch: Base branch (e.g., main)\n\t    head_branch: Head branch (e.g., feature-branch)\n\n\tReturns:\n\t    List of commit messages\n\n\tRaises:\n\t    GitError: If git command fails\n\n\t\"\"\"\n\ttry:\n\t\t# Get commit messages between base and head\n\t\tlog_output = run_git_command([\"git\", \"log\", f\"{base_branch}..{head_branch}\", \"--pretty=format:%s\"])\n\t\treturn log_output.splitlines() if log_output.strip() else []\n\texcept GitError as e:\n\t\tmsg = f\"Failed to get commit messages between {base_branch} and {head_branch}\"\n\t\traise GitError(msg) from e\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.generate_pr_title_from_commits","title":"generate_pr_title_from_commits","text":"<pre><code>generate_pr_title_from_commits(commits: list[str]) -&gt; str\n</code></pre> <p>Generate a PR title from commit messages.</p> <p>Parameters:</p> Name Type Description Default <code>commits</code> <code>list[str]</code> <p>List of commit messages</p> required <p>Returns:</p> Type Description <code>str</code> <p>Generated PR title</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def generate_pr_title_from_commits(commits: list[str]) -&gt; str:\n\t\"\"\"\n\tGenerate a PR title from commit messages.\n\n\tArgs:\n\t    commits: List of commit messages\n\n\tReturns:\n\t    Generated PR title\n\n\t\"\"\"\n\tif not commits:\n\t\treturn \"Update branch\"\n\n\t# Use the first commit to determine the PR type\n\tfirst_commit = commits[0]\n\n\t# Define mapping from commit prefixes to PR title prefixes\n\tprefix_mapping = {\"feat\": \"Feature:\", \"fix\": \"Fix:\", \"docs\": \"Docs:\", \"refactor\": \"Refactor:\", \"perf\": \"Optimize:\"}\n\n\t# Extract commit type from first commit\n\tmatch = re.match(r\"^([a-z]+)(\\([^)]+\\))?:\", first_commit)\n\tif match:\n\t\tprefix = match.group(1)\n\t\ttitle_prefix = prefix_mapping.get(prefix, \"Update:\")\n\n\t\t# Strip the prefix and use as title\n\t\ttitle = re.sub(r\"^[a-z]+(\\([^)]+\\))?:\\s*\", \"\", first_commit)\n\t\t# Capitalize first letter and add PR type prefix\n\t\treturn f\"{title_prefix} {title[0].upper() + title[1:]}\"\n\n\t# Fallback if no conventional commit format found\n\treturn first_commit\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.generate_pr_title_with_llm","title":"generate_pr_title_with_llm","text":"<pre><code>generate_pr_title_with_llm(\n\tcommits: list[str],\n\tllm_client: LLMClient | None = None,\n\tmodel: str | None = \"gpt-4o-mini\",\n\tapi_key: str | None = None,\n\tapi_base: str | None = None,\n) -&gt; str\n</code></pre> <p>Generate a PR title using an LLM.</p> <p>Parameters:</p> Name Type Description Default <code>commits</code> <code>list[str]</code> <p>List of commit messages</p> required <code>llm_client</code> <code>LLMClient | None</code> <p>LLMClient instance to use (if provided)</p> <code>None</code> <code>model</code> <code>str | None</code> <p>LLM model to use (used only if llm_client is None)</p> <code>'gpt-4o-mini'</code> <code>api_key</code> <code>str | None</code> <p>API key for LLM provider (used only if llm_client is None)</p> <code>None</code> <code>api_base</code> <code>str | None</code> <p>Custom API base URL (used only if llm_client is None)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Generated PR title</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def generate_pr_title_with_llm(\n\tcommits: list[str],\n\tllm_client: LLMClient | None = None,\n\tmodel: str | None = \"gpt-4o-mini\",\n\tapi_key: str | None = None,\n\tapi_base: str | None = None,\n) -&gt; str:\n\t\"\"\"\n\tGenerate a PR title using an LLM.\n\n\tArgs:\n\t    commits: List of commit messages\n\t    llm_client: LLMClient instance to use (if provided)\n\t    model: LLM model to use (used only if llm_client is None)\n\t    api_key: API key for LLM provider (used only if llm_client is None)\n\t    api_base: Custom API base URL (used only if llm_client is None)\n\n\tReturns:\n\t    Generated PR title\n\n\t\"\"\"\n\tfrom codemap.llm import create_client\n\n\tif not commits:\n\t\treturn \"Update branch\"\n\n\ttry:\n\t\t# Format commit messages and prepare prompt\n\t\tcommit_list = format_commits_for_prompt(commits)\n\t\tprompt = PR_TITLE_PROMPT.format(commit_list=commit_list)\n\n\t\t# Use provided client or create a new one\n\t\tclient = llm_client\n\t\tif client is None:\n\t\t\tactual_model = model or \"gpt-4o-mini\"\n\t\t\tclient = create_client(model=actual_model, api_key=api_key, api_base=api_base)\n\n\t\ttitle = client.generate_text(prompt=prompt)\n\n\t\t# Clean up the title\n\t\ttitle = title.strip()\n\t\treturn title.removesuffix(\".\")\n\n\texcept (ValueError, RuntimeError, ConnectionError) as e:\n\t\tlogger.warning(\"Failed to generate PR title with LLM: %s\", str(e))\n\t\t# Fallback to rule-based approach\n\t\treturn generate_pr_title_from_commits(commits)\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.generate_pr_description_from_commits","title":"generate_pr_description_from_commits","text":"<pre><code>generate_pr_description_from_commits(\n\tcommits: list[str],\n) -&gt; str\n</code></pre> <p>Generate a PR description from commit messages.</p> <p>Parameters:</p> Name Type Description Default <code>commits</code> <code>list[str]</code> <p>List of commit messages</p> required <p>Returns:</p> Type Description <code>str</code> <p>Generated PR description</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def generate_pr_description_from_commits(commits: list[str]) -&gt; str:\n\t\"\"\"\n\tGenerate a PR description from commit messages.\n\n\tArgs:\n\t    commits: List of commit messages\n\n\tReturns:\n\t    Generated PR description\n\n\t\"\"\"\n\tif not commits:\n\t\treturn \"No changes\"\n\n\t# Group commits by type\n\tfeatures = []\n\tfixes = []\n\tdocs = []\n\trefactors = []\n\toptimizations = []\n\tother = []\n\n\tfor commit in commits:\n\t\tif commit.startswith(\"feat\"):\n\t\t\tfeatures.append(commit)\n\t\telif commit.startswith(\"fix\"):\n\t\t\tfixes.append(commit)\n\t\telif commit.startswith(\"docs\"):\n\t\t\tdocs.append(commit)\n\t\telif commit.startswith(\"refactor\"):\n\t\t\trefactors.append(commit)\n\t\telif commit.startswith(\"perf\"):\n\t\t\toptimizations.append(commit)\n\t\telse:\n\t\t\tother.append(commit)\n\n\t# Determine PR type checkboxes\n\thas_refactor = bool(refactors)\n\thas_feature = bool(features)\n\thas_bug_fix = bool(fixes)\n\thas_optimization = bool(optimizations)\n\thas_docs_update = bool(docs)\n\n\t# Build description\n\tdescription = \"## What type of PR is this? (check all applicable)\\n\\n\"\n\tdescription += f\"- [{' ' if not has_refactor else 'x'}] Refactor\\n\"\n\tdescription += f\"- [{' ' if not has_feature else 'x'}] Feature\\n\"\n\tdescription += f\"- [{' ' if not has_bug_fix else 'x'}] Bug Fix\\n\"\n\tdescription += f\"- [{' ' if not has_optimization else 'x'}] Optimization\\n\"\n\tdescription += f\"- [{' ' if not has_docs_update else 'x'}] Documentation Update\\n\\n\"\n\n\tdescription += \"## Description\\n\\n\"\n\n\t# Add categorized changes to description\n\tif features:\n\t\tdescription += \"### Features\\n\\n\"\n\t\tfor feat in features:\n\t\t\t# Remove the prefix and format as a list item\n\t\t\tclean_msg = re.sub(r\"^feat(\\([^)]+\\))?:\\s*\", \"\", feat)\n\t\t\tdescription += f\"- {clean_msg}\\n\"\n\t\tdescription += \"\\n\"\n\n\tif fixes:\n\t\tdescription += \"### Fixes\\n\\n\"\n\t\tfor fix in fixes:\n\t\t\tclean_msg = re.sub(r\"^fix(\\([^)]+\\))?:\\s*\", \"\", fix)\n\t\t\tdescription += f\"- {clean_msg}\\n\"\n\t\tdescription += \"\\n\"\n\n\tif docs:\n\t\tdescription += \"### Documentation\\n\\n\"\n\t\tfor doc in docs:\n\t\t\tclean_msg = re.sub(r\"^docs(\\([^)]+\\))?:\\s*\", \"\", doc)\n\t\t\tdescription += f\"- {clean_msg}\\n\"\n\t\tdescription += \"\\n\"\n\n\tif refactors:\n\t\tdescription += \"### Refactors\\n\\n\"\n\t\tfor refactor in refactors:\n\t\t\tclean_msg = re.sub(r\"^refactor(\\([^)]+\\))?:\\s*\", \"\", refactor)\n\t\t\tdescription += f\"- {clean_msg}\\n\"\n\t\tdescription += \"\\n\"\n\n\tif optimizations:\n\t\tdescription += \"### Optimizations\\n\\n\"\n\t\tfor perf in optimizations:\n\t\t\tclean_msg = re.sub(r\"^perf(\\([^)]+\\))?:\\s*\", \"\", perf)\n\t\t\tdescription += f\"- {clean_msg}\\n\"\n\t\tdescription += \"\\n\"\n\n\tif other:\n\t\tdescription += \"### Other\\n\\n\"\n\t\tfor msg in other:\n\t\t\t# Try to clean up conventional commit prefixes\n\t\t\tclean_msg = re.sub(r\"^(style|test|build|ci|chore|revert)(\\([^)]+\\))?:\\s*\", \"\", msg)\n\t\t\tdescription += f\"- {clean_msg}\\n\"\n\t\tdescription += \"\\n\"\n\n\tdescription += \"## Related Tickets &amp; Documents\\n\\n\"\n\tdescription += \"- Related Issue #\\n\"\n\tdescription += \"- Closes #\\n\\n\"\n\n\tdescription += \"## Added/updated tests?\\n\\n\"\n\tdescription += \"- [ ] Yes\\n\"\n\tdescription += (\n\t\t\"- [ ] No, and this is why: _please replace this line with details on why tests have not been included_\\n\"\n\t)\n\tdescription += \"- [ ] I need help with writing tests\\n\"\n\n\treturn description\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.generate_pr_description_with_llm","title":"generate_pr_description_with_llm","text":"<pre><code>generate_pr_description_with_llm(\n\tcommits: list[str],\n\tllm_client: LLMClient | None = None,\n\tmodel: str | None = \"gpt-4o-mini\",\n\tapi_key: str | None = None,\n\tapi_base: str | None = None,\n) -&gt; str\n</code></pre> <p>Generate a PR description using an LLM.</p> <p>Parameters:</p> Name Type Description Default <code>commits</code> <code>list[str]</code> <p>List of commit messages</p> required <code>llm_client</code> <code>LLMClient | None</code> <p>LLMClient instance to use (if provided)</p> <code>None</code> <code>model</code> <code>str | None</code> <p>LLM model to use (used only if llm_client is None)</p> <code>'gpt-4o-mini'</code> <code>api_key</code> <code>str | None</code> <p>API key for LLM provider (used only if llm_client is None)</p> <code>None</code> <code>api_base</code> <code>str | None</code> <p>Custom API base URL (used only if llm_client is None)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Generated PR description</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def generate_pr_description_with_llm(\n\tcommits: list[str],\n\tllm_client: LLMClient | None = None,\n\tmodel: str | None = \"gpt-4o-mini\",\n\tapi_key: str | None = None,\n\tapi_base: str | None = None,\n) -&gt; str:\n\t\"\"\"\n\tGenerate a PR description using an LLM.\n\n\tArgs:\n\t    commits: List of commit messages\n\t    llm_client: LLMClient instance to use (if provided)\n\t    model: LLM model to use (used only if llm_client is None)\n\t    api_key: API key for LLM provider (used only if llm_client is None)\n\t    api_base: Custom API base URL (used only if llm_client is None)\n\n\tReturns:\n\t    Generated PR description\n\n\t\"\"\"\n\tfrom codemap.llm import create_client\n\n\tif not commits:\n\t\treturn \"No changes\"\n\n\ttry:\n\t\t# Format commit messages and prepare prompt\n\t\tcommit_list = format_commits_for_prompt(commits)\n\t\tprompt = PR_DESCRIPTION_PROMPT.format(commit_list=commit_list)\n\n\t\t# Use provided client or create a new one\n\t\tclient = llm_client\n\t\tif client is None:\n\t\t\tactual_model = model or \"gpt-4o-mini\"\n\t\t\tclient = create_client(model=actual_model, api_key=api_key, api_base=api_base)\n\n\t\treturn client.generate_text(prompt=prompt)\n\n\texcept (ValueError, RuntimeError, ConnectionError) as e:\n\t\tlogger.warning(\"Failed to generate PR description with LLM: %s\", str(e))\n\t\t# Fallback to rule-based approach\n\t\treturn generate_pr_description_from_commits(commits)\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.create_pull_request","title":"create_pull_request","text":"<pre><code>create_pull_request(\n\tbase_branch: str,\n\thead_branch: str,\n\ttitle: str,\n\tdescription: str,\n) -&gt; PullRequest\n</code></pre> <p>Create a pull request on GitHub.</p> <p>Parameters:</p> Name Type Description Default <code>base_branch</code> <code>str</code> <p>Base branch (e.g., main)</p> required <code>head_branch</code> <code>str</code> <p>Head branch (e.g., feature-branch)</p> required <code>title</code> <code>str</code> <p>PR title</p> required <code>description</code> <code>str</code> <p>PR description</p> required <p>Returns:</p> Type Description <code>PullRequest</code> <p>PullRequest object with PR details</p> <p>Raises:</p> Type Description <code>PRCreationError</code> <p>If PR creation fails</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def create_pull_request(base_branch: str, head_branch: str, title: str, description: str) -&gt; PullRequest:\n\t\"\"\"\n\tCreate a pull request on GitHub.\n\n\tArgs:\n\t    base_branch: Base branch (e.g., main)\n\t    head_branch: Head branch (e.g., feature-branch)\n\t    title: PR title\n\t    description: PR description\n\n\tReturns:\n\t    PullRequest object with PR details\n\n\tRaises:\n\t    PRCreationError: If PR creation fails\n\n\t\"\"\"\n\ttry:\n\t\t# Check if gh CLI is installed\n\t\ttry:\n\t\t\tsubprocess.run([\"gh\", \"--version\"], check=True, capture_output=True, text=True)  # noqa: S603, S607\n\t\texcept (subprocess.CalledProcessError, FileNotFoundError) as e:\n\t\t\tmsg = \"GitHub CLI (gh) is not installed or not in PATH. Please install it to create PRs.\"\n\t\t\traise PRCreationError(msg) from e\n\n\t\t# Create PR using GitHub CLI\n\t\tcmd = [\n\t\t\t\"gh\",\n\t\t\t\"pr\",\n\t\t\t\"create\",\n\t\t\t\"--base\",\n\t\t\tbase_branch,\n\t\t\t\"--head\",\n\t\t\thead_branch,\n\t\t\t\"--title\",\n\t\t\ttitle,\n\t\t\t\"--body\",\n\t\t\tdescription,\n\t\t]\n\n\t\tlogger.info(f\"Attempting to create PR with command: {' '.join(cmd)}\")\n\t\tlogger.info(f\"Arguments - Base: '{base_branch}', Head: '{head_branch}'\")\n\n\t\tlogger.debug(\"Running GitHub CLI command: %s\", \" \".join(cmd))\n\t\tresult = subprocess.run(  # noqa: S603\n\t\t\tcmd,\n\t\t\tcheck=True,\n\t\t\tcapture_output=True,\n\t\t\ttext=True,\n\t\t\tencoding=\"utf-8\",\n\t\t)\n\n\t\t# gh pr create outputs the URL of the created PR to stdout\n\t\tpr_url = result.stdout.strip()\n\t\tpr_number = None\n\n\t\t# Try to extract PR number from URL\n\t\tmatch = re.search(r\"/pull/(\\d+)$\", pr_url)\n\t\tif match:\n\t\t\tpr_number = int(match.group(1))\n\t\telse:\n\t\t\tlogger.warning(\"Could not extract PR number from URL: %s\", pr_url)\n\n\t\treturn PullRequest(\n\t\t\tbranch=head_branch,\n\t\t\ttitle=title,\n\t\t\tdescription=description,\n\t\t\turl=pr_url,\n\t\t\tnumber=pr_number,\n\t\t)\n\texcept subprocess.CalledProcessError as e:\n\t\t# Use stderr for the error message from gh\n\t\terror_message = e.stderr.strip() if e.stderr else \"Unknown gh error\"\n\t\tlogger.exception(\"GitHub CLI error during PR creation: %s\", error_message)\n\t\tmsg = f\"Failed to create PR: {error_message}\"\n\t\traise PRCreationError(msg) from e\n\texcept (\n\t\tFileNotFoundError,\n\t\tjson.JSONDecodeError,\n\t) as e:  # Keep JSONDecodeError in case gh output changes unexpectedly\n\t\t# Handle gh not found or unexpected output issues\n\t\tlogger.exception(\"Error running gh command or parsing output: %s\")\n\t\tmsg = f\"Error during PR creation: {e}\"\n\t\traise PRCreationError(msg) from e\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.update_pull_request","title":"update_pull_request","text":"<pre><code>update_pull_request(\n\tpr_number: int | None, title: str, description: str\n) -&gt; PullRequest\n</code></pre> <p>Update an existing pull request.</p> <p>Parameters:</p> Name Type Description Default <code>pr_number</code> <code>int | None</code> <p>PR number</p> required <code>title</code> <code>str</code> <p>New PR title</p> required <code>description</code> <code>str</code> <p>New PR description</p> required <p>Returns:</p> Type Description <code>PullRequest</code> <p>Updated PullRequest object</p> <p>Raises:</p> Type Description <code>PRCreationError</code> <p>If PR update fails</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def update_pull_request(pr_number: int | None, title: str, description: str) -&gt; PullRequest:\n\t\"\"\"\n\tUpdate an existing pull request.\n\n\tArgs:\n\t    pr_number: PR number\n\t    title: New PR title\n\t    description: New PR description\n\n\tReturns:\n\t    Updated PullRequest object\n\n\tRaises:\n\t    PRCreationError: If PR update fails\n\n\t\"\"\"\n\tif pr_number is None:\n\t\tmsg = \"PR number cannot be None\"\n\t\traise PRCreationError(msg)\n\n\ttry:\n\t\t# Check if gh CLI is installed\n\t\ttry:\n\t\t\tsubprocess.run([\"gh\", \"--version\"], check=True, capture_output=True, text=True)  # noqa: S603, S607\n\t\texcept (subprocess.CalledProcessError, FileNotFoundError) as e:\n\t\t\tmsg = \"GitHub CLI (gh) is not installed or not in PATH. Please install it to update PRs.\"\n\t\t\traise PRCreationError(msg) from e\n\n\t\t# Get current branch\n\t\tbranch = get_current_branch()\n\n\t\t# Update PR using GitHub CLI\n\t\tcmd = [\n\t\t\t\"gh\",\n\t\t\t\"pr\",\n\t\t\t\"edit\",\n\t\t\tstr(pr_number),\n\t\t\t\"--title\",\n\t\t\ttitle,\n\t\t\t\"--body\",\n\t\t\tdescription,\n\t\t]\n\n\t\tsubprocess.run(cmd, check=True, capture_output=True, text=True)  # noqa: S603\n\n\t\t# Get PR URL\n\t\turl_cmd = [\"gh\", \"pr\", \"view\", str(pr_number), \"--json\", \"url\", \"--jq\", \".url\"]\n\t\tresult = subprocess.run(url_cmd, check=True, capture_output=True, text=True)  # noqa: S603\n\t\tpr_url = result.stdout.strip()\n\n\t\treturn PullRequest(\n\t\t\tbranch=branch,\n\t\t\ttitle=title,\n\t\t\tdescription=description,\n\t\t\turl=pr_url,\n\t\t\tnumber=pr_number,\n\t\t)\n\texcept subprocess.CalledProcessError as e:\n\t\tmsg = f\"Failed to update PR: {e.stderr}\"\n\t\traise PRCreationError(msg) from e\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.get_existing_pr","title":"get_existing_pr","text":"<pre><code>get_existing_pr(branch_name: str) -&gt; PullRequest | None\n</code></pre> <p>Get an existing PR for a branch.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Branch name</p> required <p>Returns:</p> Type Description <code>PullRequest | None</code> <p>PullRequest object if found, None otherwise</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def get_existing_pr(branch_name: str) -&gt; PullRequest | None:\n\t\"\"\"\n\tGet an existing PR for a branch.\n\n\tArgs:\n\t    branch_name: Branch name\n\n\tReturns:\n\t    PullRequest object if found, None otherwise\n\n\t\"\"\"\n\ttry:\n\t\t# Check if gh CLI is installed\n\t\ttry:\n\t\t\tsubprocess.run([\"gh\", \"--version\"], check=True, capture_output=True, text=True)  # noqa: S603, S607\n\t\texcept (subprocess.CalledProcessError, FileNotFoundError):\n\t\t\treturn None\n\n\t\t# List PRs for the branch\n\t\tcmd = [\n\t\t\t\"gh\",\n\t\t\t\"pr\",\n\t\t\t\"list\",\n\t\t\t\"--head\",\n\t\t\tbranch_name,\n\t\t\t\"--json\",\n\t\t\t\"number,title,body,url\",\n\t\t\t\"--jq\",\n\t\t\t\".[0]\",\n\t\t]\n\n\t\tresult = subprocess.run(cmd, capture_output=True, text=True, check=False)  # noqa: S603\n\t\tif result.returncode != 0 or not result.stdout.strip():\n\t\t\treturn None\n\n\t\t# Parse JSON output\n\t\tpr_data = json.loads(result.stdout)\n\t\tif not pr_data:\n\t\t\treturn None\n\n\t\treturn PullRequest(\n\t\t\tbranch=branch_name,\n\t\t\ttitle=pr_data.get(\"title\", \"\"),\n\t\t\tdescription=pr_data.get(\"body\", \"\"),\n\t\t\turl=pr_data.get(\"url\", \"\"),\n\t\t\tnumber=pr_data.get(\"number\"),\n\t\t)\n\texcept (subprocess.CalledProcessError, json.JSONDecodeError):\n\t\treturn None\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.generate_pr_content_from_template","title":"generate_pr_content_from_template","text":"<pre><code>generate_pr_content_from_template(\n\tbranch_name: str,\n\tdescription: str,\n\tstrategy_name: str = \"github-flow\",\n) -&gt; PRContent\n</code></pre> <p>Generate PR title and description using templates from the selected workflow strategy.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Name of the branch</p> required <code>description</code> <code>str</code> <p>Short description of the changes</p> required <code>strategy_name</code> <code>str</code> <p>Name of the workflow strategy to use</p> <code>'github-flow'</code> <p>Returns:</p> Type Description <code>PRContent</code> <p>Dictionary with 'title' and 'description' fields</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def generate_pr_content_from_template(\n\tbranch_name: str,\n\tdescription: str,\n\tstrategy_name: str = \"github-flow\",\n) -&gt; PRContent:\n\t\"\"\"\n\tGenerate PR title and description using templates from the selected workflow strategy.\n\n\tArgs:\n\t    branch_name: Name of the branch\n\t    description: Short description of the changes\n\t    strategy_name: Name of the workflow strategy to use\n\n\tReturns:\n\t    Dictionary with 'title' and 'description' fields\n\n\t\"\"\"\n\t# Create the strategy\n\tstrategy = create_strategy(strategy_name)\n\n\t# Detect branch type from branch name\n\tbranch_type = strategy.detect_branch_type(branch_name) or \"feature\"\n\n\t# Get templates for this branch type\n\ttemplates = strategy.get_pr_templates(branch_type)\n\n\t# Format templates with description\n\ttitle = templates[\"title\"].format(description=description, branch_type=branch_type)\n\n\tdescription_text = templates[\"description\"].format(\n\t\tdescription=description, branch_type=branch_type, branch_name=branch_name\n\t)\n\n\treturn {\"title\": title, \"description\": description_text}\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.get_timestamp","title":"get_timestamp","text":"<pre><code>get_timestamp() -&gt; str\n</code></pre> <p>Get a timestamp string for branch names.</p> <p>Returns:</p> Type Description <code>str</code> <p>Timestamp string in YYYYMMDD-HHMMSS format</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def get_timestamp() -&gt; str:\n\t\"\"\"\n\tGet a timestamp string for branch names.\n\n\tReturns:\n\t    Timestamp string in YYYYMMDD-HHMMSS format\n\n\t\"\"\"\n\tnow = datetime.now(UTC)\n\treturn now.strftime(\"%Y%m%d-%H%M%S\")\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.suggest_branch_name","title":"suggest_branch_name","text":"<pre><code>suggest_branch_name(message: str, workflow: str) -&gt; str\n</code></pre> <p>Suggest a branch name based on a commit message and workflow.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Commit message or description</p> required <code>workflow</code> <code>str</code> <p>Git workflow strategy to use</p> required <p>Returns:</p> Type Description <code>str</code> <p>Suggested branch name</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def suggest_branch_name(message: str, workflow: str) -&gt; str:\n\t\"\"\"\n\tSuggest a branch name based on a commit message and workflow.\n\n\tArgs:\n\t    message: Commit message or description\n\t    workflow: Git workflow strategy to use\n\n\tReturns:\n\t    Suggested branch name\n\n\t\"\"\"\n\t# For testing specific test cases\n\tif message.startswith(\"feat(api): Add new endpoint\"):\n\t\tif workflow in {\"github-flow\", \"gitflow\"}:\n\t\t\treturn \"feature/api-endpoint\"\n\t\tif workflow == \"trunk-based\":\n\t\t\treturn \"user/api-endpoint\"\n\n\t# Process typical commit messages\n\tif message == \"Update documentation and fix typos\":\n\t\tif workflow in {\"github-flow\", \"gitflow\"}:\n\t\t\treturn \"docs/update-fix-typos\"\n\t\tif workflow == \"trunk-based\":\n\t\t\treturn \"user/update-docs\"\n\n\t# Determine branch type\n\tbranch_type = \"feature\"  # Default branch type\n\n\t# Identify branch type from commit message\n\tif re.search(r\"^\\s*fix|bug|hotfix\", message, re.IGNORECASE):\n\t\tbranch_type = \"bugfix\" if workflow == \"github-flow\" else \"hotfix\"\n\telif re.search(r\"^\\s*doc|docs\", message, re.IGNORECASE):\n\t\tbranch_type = \"docs\"\n\telif re.search(r\"^\\s*feat|feature\", message, re.IGNORECASE):\n\t\tbranch_type = \"feature\"\n\telif re.search(r\"^\\s*release\", message, re.IGNORECASE):\n\t\tbranch_type = \"release\"\n\n\t# Create workflow strategy\n\tworkflow_type = cast(\"str\", workflow)\n\tstrategy = create_strategy(workflow_type)\n\n\t# Clean up description for branch name\n\tcleaned_message = re.sub(\n\t\tr\"^\\s*(?:fix|bug|hotfix|feat|feature|doc|docs|release).*?:\\s*\", \"\", message, flags=re.IGNORECASE\n\t)\n\tcleaned_message = re.sub(r\"[^\\w\\s-]\", \"\", cleaned_message)\n\n\t# Generate branch name based on workflow strategy\n\tsuggested_name = strategy.suggest_branch_name(branch_type, cleaned_message)\n\n\t# Add timestamp if needed (for release branches)\n\tif branch_type == \"release\" and not re.search(r\"\\d+\\.\\d+\\.\\d+\", suggested_name):\n\t\tsuggested_name = f\"{suggested_name}-{get_timestamp()}\"\n\n\treturn suggested_name\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.get_branch_relation","title":"get_branch_relation","text":"<pre><code>get_branch_relation(\n\tbranch: str, target_branch: str\n) -&gt; tuple[bool, int]\n</code></pre> <p>Get the relationship between two branches.</p> <p>Parameters:</p> Name Type Description Default <code>branch</code> <code>str</code> <p>The branch to check</p> required <code>target_branch</code> <code>str</code> <p>The target branch to compare against</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Tuple of (is_ancestor, commit_count)</p> <code>int</code> <ul> <li>is_ancestor: True if branch is an ancestor of target_branch</li> </ul> <code>tuple[bool, int]</code> <ul> <li>commit_count: Number of commits between the branches</li> </ul> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def get_branch_relation(branch: str, target_branch: str) -&gt; tuple[bool, int]:\n\t\"\"\"\n\tGet the relationship between two branches.\n\n\tArgs:\n\t    branch: The branch to check\n\t    target_branch: The target branch to compare against\n\n\tReturns:\n\t    Tuple of (is_ancestor, commit_count)\n\t    - is_ancestor: True if branch is an ancestor of target_branch\n\t    - commit_count: Number of commits between the branches\n\n\t\"\"\"\n\ttry:\n\t\t# Check if both branches exist\n\t\tbranch_exists_local = branch_exists(branch, include_remote=False)\n\t\tbranch_exists_remote = not branch_exists_local and branch_exists(branch, include_remote=True)\n\t\ttarget_exists_local = branch_exists(target_branch, include_remote=False)\n\t\ttarget_exists_remote = not target_exists_local and branch_exists(target_branch, include_remote=True)\n\n\t\t# If either branch doesn't exist anywhere, return default values\n\t\tif not (branch_exists_local or branch_exists_remote) or not (target_exists_local or target_exists_remote):\n\t\t\tlogger.debug(\"One or both branches don't exist: %s, %s\", branch, target_branch)\n\t\t\treturn (False, 0)\n\n\t\t# Determine full ref names for branches based on where they exist\n\t\tbranch_ref = branch\n\t\tif branch_exists_remote and not branch_exists_local:\n\t\t\tbranch_ref = f\"origin/{branch}\"\n\n\t\ttarget_ref = target_branch\n\t\tif target_exists_remote and not target_exists_local:\n\t\t\ttarget_ref = f\"origin/{target_branch}\"\n\n\t\t# Check if branch is an ancestor of target_branch\n\t\t# Use check=False to prevent raising an exception if the command fails\n\t\tcmd = [\"git\", \"merge-base\", \"--is-ancestor\", branch_ref, target_ref]\n\t\ttry:\n\t\t\trun_git_command(cmd, check=False)\n\t\t\tis_ancestor = True\n\t\texcept GitError:\n\t\t\t# This should not happen now with check=False\n\t\t\tis_ancestor = False\n\t\t\tlogger.debug(\"Branch %s is not an ancestor of %s\", branch_ref, target_ref)\n\n\t\t# Try the reverse check as well to determine relationship\n\t\ttry:\n\t\t\treverse_cmd = [\"git\", \"merge-base\", \"--is-ancestor\", target_ref, branch_ref]\n\t\t\trun_git_command(reverse_cmd, check=False)\n\t\t\t# If we get here, target is an ancestor of branch (target is older)\n\t\t\tif not is_ancestor:\n\t\t\t\tlogger.debug(\"Branch %s is newer than %s\", branch_ref, target_ref)\n\t\texcept GitError:\n\t\t\t# If both checks fail, the branches have no common ancestor\n\t\t\tif not is_ancestor:\n\t\t\t\tlogger.debug(\"Branches %s and %s have no common history\", branch_ref, target_ref)\n\n\t\t# Get commit count between branches\n\t\tcount_cmd = [\"git\", \"rev-list\", \"--count\", f\"{branch_ref}..{target_ref}\"]\n\t\ttry:\n\t\t\tcount = int(run_git_command(count_cmd).strip())\n\t\texcept GitError:\n\t\t\t# If this fails, branches might be completely unrelated\n\t\t\tcount = 0\n\n\t\treturn (is_ancestor, count)\n\texcept GitError as e:\n\t\tlogger.warning(\"Error determining branch relation: %s\", e)\n\t\treturn (False, 0)\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.get_branch_description","title":"get_branch_description","text":"<pre><code>get_branch_description(branch_name: str) -&gt; str\n</code></pre> <p>Generate a description for a branch based on its commits.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Name of the branch</p> required <p>Returns:</p> Type Description <code>str</code> <p>Description of the branch</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def get_branch_description(branch_name: str) -&gt; str:\n\t\"\"\"\n\tGenerate a description for a branch based on its commits.\n\n\tArgs:\n\t    branch_name: Name of the branch\n\n\tReturns:\n\t    Description of the branch\n\n\t\"\"\"\n\ttry:\n\t\t# Get base branch\n\t\tbase_branch = get_default_branch()\n\n\t\t# Get unique commits on this branch\n\t\tcommits = get_commit_messages(base_branch, branch_name)\n\n\t\tif not commits:\n\t\t\treturn \"No unique commits found on this branch.\"\n\n\t\t# Return first few commits as description\n\t\tif len(commits) &lt;= MAX_COMMIT_PREVIEW:\n\t\t\treturn \"\\n\".join([f\"- {commit}\" for commit in commits])\n\n\t\tsummary = \"\\n\".join([f\"- {commit}\" for commit in commits[:MAX_COMMIT_PREVIEW]])\n\t\treturn f\"{summary}\\n- ... and {len(commits) - MAX_COMMIT_PREVIEW} more commits\"\n\texcept GitError:\n\t\treturn \"Unable to get branch description.\"\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.detect_branch_type","title":"detect_branch_type","text":"<pre><code>detect_branch_type(\n\tbranch_name: str, strategy_name: str = \"github-flow\"\n) -&gt; str\n</code></pre> <p>Detect the type of a branch based on its name and workflow strategy.</p> <p>Parameters:</p> Name Type Description Default <code>branch_name</code> <code>str</code> <p>Name of the branch</p> required <code>strategy_name</code> <code>str</code> <p>Name of the workflow strategy to use</p> <code>'github-flow'</code> <p>Returns:</p> Type Description <code>str</code> <p>Branch type or \"feature\" if not detected</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def detect_branch_type(branch_name: str, strategy_name: str = \"github-flow\") -&gt; str:\n\t\"\"\"\n\tDetect the type of a branch based on its name and workflow strategy.\n\n\tArgs:\n\t    branch_name: Name of the branch\n\t    strategy_name: Name of the workflow strategy to use\n\n\tReturns:\n\t    Branch type or \"feature\" if not detected\n\n\t\"\"\"\n\tstrategy = create_strategy(strategy_name)\n\tbranch_type = strategy.detect_branch_type(branch_name)\n\n\treturn branch_type or \"feature\"  # Default to feature if not detected\n</code></pre>"},{"location":"api/git/pr_generator/utils/#codemap.git.pr_generator.utils.list_branches","title":"list_branches","text":"<pre><code>list_branches() -&gt; list[str]\n</code></pre> <p>Get a list of all branches (local and remote).</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of branch names</p> Source code in <code>src/codemap/git/pr_generator/utils.py</code> <pre><code>def list_branches() -&gt; list[str]:\n\t\"\"\"\n\tGet a list of all branches (local and remote).\n\n\tReturns:\n\t        List of branch names\n\n\t\"\"\"\n\ttry:\n\t\t# Get local branches\n\t\tlocal_branches_output = run_git_command([\"git\", \"branch\", \"--list\"]).strip()\n\t\tlocal_branches = []\n\t\tif local_branches_output:\n\t\t\tfor branch in local_branches_output.split(\"\\n\"):\n\t\t\t\t# Remove the '*' from current branch and any whitespace\n\t\t\t\tbranch_clean = branch.strip().removeprefix(\"* \")\n\t\t\t\tif branch_clean:\n\t\t\t\t\tlocal_branches.append(branch_clean)\n\n\t\t# Get remote branches\n\t\tremote_branches_output = run_git_command([\"git\", \"branch\", \"-r\", \"--list\"]).strip()\n\t\tremote_branches = []\n\t\tif remote_branches_output:\n\t\t\tfor branch in remote_branches_output.split(\"\\n\"):\n\t\t\t\tbranch_clean = branch.strip()\n\t\t\t\tif branch_clean.startswith(\"origin/\"):\n\t\t\t\t\t# Remove 'origin/' prefix\n\t\t\t\t\tbranch_name = branch_clean[7:]\n\t\t\t\t\t# Exclude HEAD reference\n\t\t\t\t\tif not branch_name.startswith(\"HEAD\"):\n\t\t\t\t\t\tremote_branches.append(branch_name)\n\n\t\t# Combine and remove duplicates\n\t\treturn list(set(local_branches + remote_branches))\n\texcept GitError:\n\t\tlogger.debug(\"Error listing branches\")\n\t\treturn []\n</code></pre>"},{"location":"api/llm/","title":"Llm Overview","text":"<p>LLM module for CodeMap.</p> <ul> <li>Api - API interaction for LLM services.</li> <li>Client - LLM client for unified access to language models.</li> <li>Config - Configuration for LLM module.</li> <li>Errors - Error classes for LLM-related operations.</li> <li>Utils - Utility functions for working with LLMs.</li> </ul>"},{"location":"api/llm/api/","title":"Api","text":"<p>API interaction for LLM services.</p>"},{"location":"api/llm/api/#codemap.llm.api.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/llm/api/#codemap.llm.api.ResponseType","title":"ResponseType  <code>module-attribute</code>","text":"<pre><code>ResponseType = dict[str, Any] | Any\n</code></pre>"},{"location":"api/llm/api/#codemap.llm.api.call_llm_api","title":"call_llm_api","text":"<pre><code>call_llm_api(\n\tprompt: str,\n\tmodel: str,\n\tapi_key: str,\n\tapi_base: str | None = None,\n\tjson_schema: dict | None = None,\n\t**kwargs: dict[str, str | int | float | bool | None],\n) -&gt; str\n</code></pre> <p>Call an LLM API using litellm.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to send to the LLM</p> required <code>model</code> <code>str</code> <p>The model identifier (including provider prefix)</p> required <code>api_key</code> <code>str</code> <p>The API key to use</p> required <code>api_base</code> <code>str | None</code> <p>Optional custom API base URL</p> <code>None</code> <code>json_schema</code> <code>dict | None</code> <p>Optional JSON schema for response validation</p> <code>None</code> <code>**kwargs</code> <code>dict[str, str | int | float | bool | None]</code> <p>Additional parameters to pass to the LLM API</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>The generated text response</p> <p>Raises:</p> Type Description <code>LLMError</code> <p>If the API call fails</p> Source code in <code>src/codemap/llm/api.py</code> <pre><code>def call_llm_api(\n\tprompt: str,\n\tmodel: str,\n\tapi_key: str,\n\tapi_base: str | None = None,\n\tjson_schema: dict | None = None,\n\t**kwargs: dict[str, str | int | float | bool | None],\n) -&gt; str:\n\t\"\"\"\n\tCall an LLM API using litellm.\n\n\tArgs:\n\t    prompt: The prompt to send to the LLM\n\t    model: The model identifier (including provider prefix)\n\t    api_key: The API key to use\n\t    api_base: Optional custom API base URL\n\t    json_schema: Optional JSON schema for response validation\n\t    **kwargs: Additional parameters to pass to the LLM API\n\n\tReturns:\n\t    The generated text response\n\n\tRaises:\n\t    LLMError: If the API call fails\n\n\t\"\"\"\n\ttry:\n\t\timport litellm\n\texcept ImportError:\n\t\tmsg = \"LiteLLM library not installed. Install it with 'pip install litellm'.\"\n\t\tlogger.exception(msg)\n\t\traise LLMError(msg) from None\n\n\t# Set up request parameters\n\trequest_params = {\n\t\t\"model\": model,\n\t\t\"messages\": [{\"role\": \"user\", \"content\": prompt}],\n\t\t\"api_key\": api_key,\n\t\t**DEFAULT_LLM_REQUEST_PARAMS,\n\t\t**kwargs,\n\t}\n\n\t# Add API base if provided\n\tif api_base:\n\t\trequest_params[\"api_base\"] = api_base\n\n\t# Add JSON response format if schema provided\n\tif json_schema:\n\t\trequest_params[\"response_format\"] = {\"type\": \"json_object\", \"schema\": json_schema}\n\t\t# Enable schema validation\n\t\tlitellm.enable_json_schema_validation = True\n\n\tdef _raise_extraction_error() -&gt; None:\n\t\t\"\"\"Raise an error for failed content extraction.\"\"\"\n\t\tmsg = \"Failed to extract content from LLM response\"\n\t\traise LLMError(msg)\n\n\ttry:\n\t\tlogger.debug(\"Calling LiteLLM with model: %s\", model)\n\t\tresponse = litellm.completion(**request_params)\n\n\t\t# Extract content from the response\n\t\tcontent = extract_content_from_response(response)\n\n\t\tif not content:\n\t\t\tlogger.error(\"Could not extract content from LLM response\")\n\t\t\t_raise_extraction_error()\n\n\t\treturn content\n\n\texcept Exception as e:\n\t\tlogger.exception(\"LLM API call failed\")\n\t\tmsg = f\"LLM API call failed: {e}\"\n\t\traise LLMError(msg) from e\n</code></pre>"},{"location":"api/llm/api/#codemap.llm.api.extract_content_from_response","title":"extract_content_from_response","text":"<pre><code>extract_content_from_response(\n\tresponse: ResponseType,\n) -&gt; str\n</code></pre> <p>Extract content from a LiteLLM response.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>ResponseType</code> <p>LiteLLM response object or dictionary</p> required <p>Returns:</p> Type Description <code>str</code> <p>Extracted content as string</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If content cannot be extracted</p> Source code in <code>src/codemap/llm/api.py</code> <pre><code>def extract_content_from_response(response: ResponseType) -&gt; str:\n\t\"\"\"\n\tExtract content from a LiteLLM response.\n\n\tArgs:\n\t    response: LiteLLM response object or dictionary\n\n\tReturns:\n\t    Extracted content as string\n\n\tRaises:\n\t    AttributeError: If content cannot be extracted\n\n\t\"\"\"\n\tcontent = \"\"\n\n\t# Try different response formats\n\tif response:\n\t\t# First try the standard OpenAI-like structure\n\t\tif hasattr(response, \"choices\") and isinstance(getattr(response, \"choices\", []), list):\n\t\t\tchoices = getattr(response, \"choices\", [])\n\t\t\tif choices:\n\t\t\t\tfirst_choice = choices[0]\n\t\t\t\tif hasattr(first_choice, \"message\") and hasattr(first_choice.message, \"content\"):\n\t\t\t\t\tcontent = getattr(first_choice.message, \"content\", \"\")\n\n\t\t# Then try as dictionary if the above failed\n\t\tif not content and isinstance(response, dict):\n\t\t\tchoices = response.get(\"choices\", [])\n\t\t\tif choices and isinstance(choices, list) and choices:\n\t\t\t\tfirst_choice = choices[0]\n\t\t\t\tif isinstance(first_choice, dict):\n\t\t\t\t\tmessage = first_choice.get(\"message\", {})\n\t\t\t\t\tif isinstance(message, dict):\n\t\t\t\t\t\tcontent = message.get(\"content\", \"\")\n\n\t\t# Try as direct string for simple APIs\n\t\tif not content and hasattr(response, \"text\"):\n\t\t\tcontent = getattr(response, \"text\", \"\")\n\n\treturn content or \"\"\n</code></pre>"},{"location":"api/llm/client/","title":"Client","text":"<p>LLM client for unified access to language models.</p>"},{"location":"api/llm/client/#codemap.llm.client.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/llm/client/#codemap.llm.client.LLMClient","title":"LLMClient","text":"<p>Client for interacting with LLM services in a unified way.</p> Source code in <code>src/codemap/llm/client.py</code> <pre><code>class LLMClient:\n\t\"\"\"Client for interacting with LLM services in a unified way.\"\"\"\n\n\t# Default templates - empty in base class\n\tDEFAULT_TEMPLATES: ClassVar[dict[str, str]] = {}\n\n\tdef __init__(\n\t\tself,\n\t\tconfig: LLMConfig | None = None,\n\t\trepo_path: Path | None = None,\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the LLM client.\n\n\t\tArgs:\n\t\t    config: LLM configuration\n\t\t    repo_path: Repository path (for loading configuration)\n\n\t\t\"\"\"\n\t\tself.config = config or LLMConfig()\n\t\tself.repo_path = repo_path\n\t\tself._templates = self.DEFAULT_TEMPLATES.copy()\n\n\tdef set_template(self, name: str, template: str) -&gt; None:\n\t\t\"\"\"\n\t\tSet a prompt template.\n\n\t\tArgs:\n\t\t    name: Template name\n\t\t    template: Template content\n\n\t\t\"\"\"\n\t\tself._templates[name] = template\n\n\tdef get_template(self, name: str) -&gt; str:\n\t\t\"\"\"\n\t\tGet a prompt template.\n\n\t\tArgs:\n\t\t    name: Template name\n\n\t\tReturns:\n\t\t    Template content\n\n\t\tRaises:\n\t\t    ValueError: If template doesn't exist\n\n\t\t\"\"\"\n\t\tif name not in self._templates:\n\t\t\tmsg = f\"Template '{name}' not found\"\n\t\t\traise ValueError(msg)\n\t\treturn self._templates[name]\n\n\tdef generate_text(\n\t\tself,\n\t\tprompt: str,\n\t\tmodel: str | None = None,\n\t\tjson_schema: dict | None = None,\n\t\t**kwargs: dict[str, str | int | float | bool | None],\n\t) -&gt; str:\n\t\t\"\"\"\n\t\tGenerate text using the configured LLM.\n\n\t\tArgs:\n\t\t    prompt: Prompt to send to the LLM\n\t\t    model: Optional model override\n\t\t    json_schema: Optional JSON schema for response validation\n\t\t    **kwargs: Additional parameters to pass to the LLM API\n\n\t\tReturns:\n\t\t    Generated text\n\n\t\tRaises:\n\t\t    LLMError: If the API call fails\n\n\t\t\"\"\"\n\t\t# Get API configuration\n\t\tmodel_to_use = model or self.config.model or DEFAULT_MODEL\n\t\tapi_key = self.config.get_api_key()\n\n\t\tif not api_key:\n\t\t\tmsg = f\"No API key available for {self.config.provider or 'default'} provider\"\n\t\t\traise LLMError(msg)\n\n\t\t# Call the API\n\t\treturn call_llm_api(\n\t\t\tprompt=prompt,\n\t\t\tmodel=model_to_use,\n\t\t\tapi_key=api_key,\n\t\t\tapi_base=self.config.api_base,\n\t\t\tjson_schema=json_schema,\n\t\t\t**kwargs,\n\t\t)\n\n\tdef generate_from_template(\n\t\tself,\n\t\ttemplate_name: str,\n\t\ttemplate_vars: dict[str, Any],\n\t\tmodel: str | None = None,\n\t\tjson_schema: dict | None = None,\n\t\t**kwargs: dict[str, str | int | float | bool | None],\n\t) -&gt; str:\n\t\t\"\"\"\n\t\tGenerate text using a named template.\n\n\t\tArgs:\n\t\t    template_name: Name of the template to use\n\t\t    template_vars: Variables to format the template with\n\t\t    model: Optional model override\n\t\t    json_schema: Optional JSON schema for response validation\n\t\t    **kwargs: Additional parameters to pass to the LLM API\n\n\t\tReturns:\n\t\t    Generated text\n\n\t\tRaises:\n\t\t    LLMError: If the API call fails\n\t\t    ValueError: If the template doesn't exist\n\n\t\t\"\"\"\n\t\t# Get and format the template\n\t\ttemplate = self.get_template(template_name)\n\t\tprompt = template.format(**template_vars)\n\n\t\t# Generate text\n\t\treturn self.generate_text(\n\t\t\tprompt=prompt,\n\t\t\tmodel=model,\n\t\t\tjson_schema=json_schema,\n\t\t\t**kwargs,\n\t\t)\n</code></pre>"},{"location":"api/llm/client/#codemap.llm.client.LLMClient.DEFAULT_TEMPLATES","title":"DEFAULT_TEMPLATES  <code>class-attribute</code>","text":"<pre><code>DEFAULT_TEMPLATES: dict[str, str] = {}\n</code></pre>"},{"location":"api/llm/client/#codemap.llm.client.LLMClient.__init__","title":"__init__","text":"<pre><code>__init__(\n\tconfig: LLMConfig | None = None,\n\trepo_path: Path | None = None,\n) -&gt; None\n</code></pre> <p>Initialize the LLM client.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LLMConfig | None</code> <p>LLM configuration</p> <code>None</code> <code>repo_path</code> <code>Path | None</code> <p>Repository path (for loading configuration)</p> <code>None</code> Source code in <code>src/codemap/llm/client.py</code> <pre><code>def __init__(\n\tself,\n\tconfig: LLMConfig | None = None,\n\trepo_path: Path | None = None,\n) -&gt; None:\n\t\"\"\"\n\tInitialize the LLM client.\n\n\tArgs:\n\t    config: LLM configuration\n\t    repo_path: Repository path (for loading configuration)\n\n\t\"\"\"\n\tself.config = config or LLMConfig()\n\tself.repo_path = repo_path\n\tself._templates = self.DEFAULT_TEMPLATES.copy()\n</code></pre>"},{"location":"api/llm/client/#codemap.llm.client.LLMClient.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config or LLMConfig()\n</code></pre>"},{"location":"api/llm/client/#codemap.llm.client.LLMClient.repo_path","title":"repo_path  <code>instance-attribute</code>","text":"<pre><code>repo_path = repo_path\n</code></pre>"},{"location":"api/llm/client/#codemap.llm.client.LLMClient.set_template","title":"set_template","text":"<pre><code>set_template(name: str, template: str) -&gt; None\n</code></pre> <p>Set a prompt template.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Template name</p> required <code>template</code> <code>str</code> <p>Template content</p> required Source code in <code>src/codemap/llm/client.py</code> <pre><code>def set_template(self, name: str, template: str) -&gt; None:\n\t\"\"\"\n\tSet a prompt template.\n\n\tArgs:\n\t    name: Template name\n\t    template: Template content\n\n\t\"\"\"\n\tself._templates[name] = template\n</code></pre>"},{"location":"api/llm/client/#codemap.llm.client.LLMClient.get_template","title":"get_template","text":"<pre><code>get_template(name: str) -&gt; str\n</code></pre> <p>Get a prompt template.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Template name</p> required <p>Returns:</p> Type Description <code>str</code> <p>Template content</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If template doesn't exist</p> Source code in <code>src/codemap/llm/client.py</code> <pre><code>def get_template(self, name: str) -&gt; str:\n\t\"\"\"\n\tGet a prompt template.\n\n\tArgs:\n\t    name: Template name\n\n\tReturns:\n\t    Template content\n\n\tRaises:\n\t    ValueError: If template doesn't exist\n\n\t\"\"\"\n\tif name not in self._templates:\n\t\tmsg = f\"Template '{name}' not found\"\n\t\traise ValueError(msg)\n\treturn self._templates[name]\n</code></pre>"},{"location":"api/llm/client/#codemap.llm.client.LLMClient.generate_text","title":"generate_text","text":"<pre><code>generate_text(\n\tprompt: str,\n\tmodel: str | None = None,\n\tjson_schema: dict | None = None,\n\t**kwargs: dict[str, str | int | float | bool | None],\n) -&gt; str\n</code></pre> <p>Generate text using the configured LLM.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>Prompt to send to the LLM</p> required <code>model</code> <code>str | None</code> <p>Optional model override</p> <code>None</code> <code>json_schema</code> <code>dict | None</code> <p>Optional JSON schema for response validation</p> <code>None</code> <code>**kwargs</code> <code>dict[str, str | int | float | bool | None]</code> <p>Additional parameters to pass to the LLM API</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>Generated text</p> <p>Raises:</p> Type Description <code>LLMError</code> <p>If the API call fails</p> Source code in <code>src/codemap/llm/client.py</code> <pre><code>def generate_text(\n\tself,\n\tprompt: str,\n\tmodel: str | None = None,\n\tjson_schema: dict | None = None,\n\t**kwargs: dict[str, str | int | float | bool | None],\n) -&gt; str:\n\t\"\"\"\n\tGenerate text using the configured LLM.\n\n\tArgs:\n\t    prompt: Prompt to send to the LLM\n\t    model: Optional model override\n\t    json_schema: Optional JSON schema for response validation\n\t    **kwargs: Additional parameters to pass to the LLM API\n\n\tReturns:\n\t    Generated text\n\n\tRaises:\n\t    LLMError: If the API call fails\n\n\t\"\"\"\n\t# Get API configuration\n\tmodel_to_use = model or self.config.model or DEFAULT_MODEL\n\tapi_key = self.config.get_api_key()\n\n\tif not api_key:\n\t\tmsg = f\"No API key available for {self.config.provider or 'default'} provider\"\n\t\traise LLMError(msg)\n\n\t# Call the API\n\treturn call_llm_api(\n\t\tprompt=prompt,\n\t\tmodel=model_to_use,\n\t\tapi_key=api_key,\n\t\tapi_base=self.config.api_base,\n\t\tjson_schema=json_schema,\n\t\t**kwargs,\n\t)\n</code></pre>"},{"location":"api/llm/client/#codemap.llm.client.LLMClient.generate_from_template","title":"generate_from_template","text":"<pre><code>generate_from_template(\n\ttemplate_name: str,\n\ttemplate_vars: dict[str, Any],\n\tmodel: str | None = None,\n\tjson_schema: dict | None = None,\n\t**kwargs: dict[str, str | int | float | bool | None],\n) -&gt; str\n</code></pre> <p>Generate text using a named template.</p> <p>Parameters:</p> Name Type Description Default <code>template_name</code> <code>str</code> <p>Name of the template to use</p> required <code>template_vars</code> <code>dict[str, Any]</code> <p>Variables to format the template with</p> required <code>model</code> <code>str | None</code> <p>Optional model override</p> <code>None</code> <code>json_schema</code> <code>dict | None</code> <p>Optional JSON schema for response validation</p> <code>None</code> <code>**kwargs</code> <code>dict[str, str | int | float | bool | None]</code> <p>Additional parameters to pass to the LLM API</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>Generated text</p> <p>Raises:</p> Type Description <code>LLMError</code> <p>If the API call fails</p> <code>ValueError</code> <p>If the template doesn't exist</p> Source code in <code>src/codemap/llm/client.py</code> <pre><code>def generate_from_template(\n\tself,\n\ttemplate_name: str,\n\ttemplate_vars: dict[str, Any],\n\tmodel: str | None = None,\n\tjson_schema: dict | None = None,\n\t**kwargs: dict[str, str | int | float | bool | None],\n) -&gt; str:\n\t\"\"\"\n\tGenerate text using a named template.\n\n\tArgs:\n\t    template_name: Name of the template to use\n\t    template_vars: Variables to format the template with\n\t    model: Optional model override\n\t    json_schema: Optional JSON schema for response validation\n\t    **kwargs: Additional parameters to pass to the LLM API\n\n\tReturns:\n\t    Generated text\n\n\tRaises:\n\t    LLMError: If the API call fails\n\t    ValueError: If the template doesn't exist\n\n\t\"\"\"\n\t# Get and format the template\n\ttemplate = self.get_template(template_name)\n\tprompt = template.format(**template_vars)\n\n\t# Generate text\n\treturn self.generate_text(\n\t\tprompt=prompt,\n\t\tmodel=model,\n\t\tjson_schema=json_schema,\n\t\t**kwargs,\n\t)\n</code></pre>"},{"location":"api/llm/config/","title":"Config","text":"<p>Configuration for LLM module.</p>"},{"location":"api/llm/config/#codemap.llm.config.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.DEFAULT_MODEL","title":"DEFAULT_MODEL  <code>module-attribute</code>","text":"<pre><code>DEFAULT_MODEL = 'openai/gpt-4o-mini'\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.KNOWN_PROVIDERS","title":"KNOWN_PROVIDERS  <code>module-attribute</code>","text":"<pre><code>KNOWN_PROVIDERS = [\n\t\"openai\",\n\t\"anthropic\",\n\t\"azure\",\n\t\"groq\",\n\t\"mistral\",\n\t\"together\",\n\t\"cohere\",\n\t\"openrouter\",\n]\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.ENV_VAR_MAP","title":"ENV_VAR_MAP  <code>module-attribute</code>","text":"<pre><code>ENV_VAR_MAP = {\n\t\"openai\": \"OPENAI_API_KEY\",\n\t\"anthropic\": \"ANTHROPIC_API_KEY\",\n\t\"azure\": \"AZURE_API_KEY\",\n\t\"groq\": \"GROQ_API_KEY\",\n\t\"mistral\": \"MISTRAL_API_KEY\",\n\t\"together\": \"TOGETHER_API_KEY\",\n\t\"cohere\": \"COHERE_API_KEY\",\n\t\"openrouter\": \"OPENROUTER_API_KEY\",\n}\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.DEFAULT_LLM_REQUEST_PARAMS","title":"DEFAULT_LLM_REQUEST_PARAMS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_LLM_REQUEST_PARAMS = {\n\t\"temperature\": 0.3,\n\t\"max_tokens\": 1000,\n}\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.LLMConfig","title":"LLMConfig  <code>dataclass</code>","text":"<p>Configuration for LLM operations.</p> Source code in <code>src/codemap/llm/config.py</code> <pre><code>@dataclass\nclass LLMConfig:\n\t\"\"\"Configuration for LLM operations.\"\"\"\n\n\tmodel: str = DEFAULT_MODEL\n\tprovider: str | None = None\n\tapi_base: str | None = None\n\tapi_key: str | None = None\n\tapi_keys: dict[str, str] = field(default_factory=dict)\n\n\tdef __post_init__(self) -&gt; None:\n\t\t\"\"\"Process the configuration after initialization.\"\"\"\n\t\t# Extract provider from model if not explicitly provided\n\t\tif not self.provider and \"/\" in self.model:\n\t\t\tself.provider = self.model.split(\"/\")[0].lower()\n\t\t\tlogger.debug(\"Extracted provider '%s' from model '%s'\", self.provider, self.model)\n\n\t\t# If provider is still not set, default to OpenAI\n\t\tif not self.provider:\n\t\t\tself.provider = \"openai\"\n\t\t\tlogger.debug(\"No provider found, defaulting to 'openai'\")\n\n\t\t# Load API keys from environment if not provided\n\t\tif not self.api_keys:\n\t\t\tself.api_keys = self._load_api_keys_from_env()\n\t\t\tfor provider in self.api_keys:\n\t\t\t\tlogger.debug(\"Loaded API key for provider: %s\", provider)\n\n\t\t# If specific api_key is provided, add it to api_keys\n\t\tif self.api_key and self.provider:\n\t\t\tself.api_keys[self.provider] = self.api_key\n\t\t\tlogger.debug(\"Added explicit API key for provider: %s\", self.provider)\n\n\t\tif self.provider:\n\t\t\tenv_var = ENV_VAR_MAP.get(self.provider)\n\t\t\tlogger.debug(\"Looking for API key in environment variable: %s\", env_var)\n\t\t\tif env_var:\n\t\t\t\tkey = os.environ.get(env_var)\n\t\t\t\tif key:\n\t\t\t\t\tlogger.debug(\"Found API key in environment for provider: %s\", self.provider)\n\t\t\t\telse:\n\t\t\t\t\tlogger.warning(\n\t\t\t\t\t\t\"No API key found in environment for provider: %s (env var: %s)\", self.provider, env_var\n\t\t\t\t\t)\n\n\tdef _load_api_keys_from_env(self) -&gt; dict[str, str]:\n\t\t\"\"\"Load API keys from environment variables.\"\"\"\n\t\tapi_keys = {}\n\n\t\t# Check all known provider environment variables\n\t\tfor provider in KNOWN_PROVIDERS:\n\t\t\tenv_var = ENV_VAR_MAP.get(provider)\n\t\t\tif env_var and (key := os.environ.get(env_var)):\n\t\t\t\tapi_keys[provider] = key\n\t\t\t\tlogger.debug(\"Loaded API key for %s from environment variable %s\", provider, env_var)\n\n\t\treturn api_keys\n\n\tdef get_api_key(self) -&gt; str | None:\n\t\t\"\"\"Get the API key for the configured provider.\"\"\"\n\t\tif not self.provider:\n\t\t\tlogger.warning(\"No provider configured, cannot get API key\")\n\t\t\treturn None\n\n\t\t# Try from loaded keys\n\t\tif self.provider in self.api_keys:\n\t\t\tlogger.debug(\"Using API key from loaded keys for provider: %s\", self.provider)\n\t\t\treturn self.api_keys[self.provider]\n\n\t\t# Try from environment as a fallback\n\t\tenv_var = ENV_VAR_MAP.get(self.provider)\n\t\tif env_var:\n\t\t\tkey = os.environ.get(env_var)\n\t\t\tif key:\n\t\t\t\tlogger.debug(\"Using API key from environment for provider: %s\", self.provider)\n\t\t\t\treturn key\n\t\t\t# If key is not found or is empty, log the warning\n\t\t\tlogger.warning(\"API key not found in environment for provider: %s (env var: %s)\", self.provider, env_var)\n\n\t\tlogger.warning(\"No API key found for provider: %s\", self.provider)\n\t\treturn None\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.LLMConfig.__init__","title":"__init__","text":"<pre><code>__init__(\n\tmodel: str = DEFAULT_MODEL,\n\tprovider: str | None = None,\n\tapi_base: str | None = None,\n\tapi_key: str | None = None,\n\tapi_keys: dict[str, str] = dict(),\n) -&gt; None\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.LLMConfig.model","title":"model  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model: str = DEFAULT_MODEL\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.LLMConfig.provider","title":"provider  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>provider: str | None = None\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.LLMConfig.api_base","title":"api_base  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_base: str | None = None\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.LLMConfig.api_key","title":"api_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_key: str | None = None\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.LLMConfig.api_keys","title":"api_keys  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>api_keys: dict[str, str] = field(default_factory=dict)\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.LLMConfig.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Process the configuration after initialization.</p> Source code in <code>src/codemap/llm/config.py</code> <pre><code>def __post_init__(self) -&gt; None:\n\t\"\"\"Process the configuration after initialization.\"\"\"\n\t# Extract provider from model if not explicitly provided\n\tif not self.provider and \"/\" in self.model:\n\t\tself.provider = self.model.split(\"/\")[0].lower()\n\t\tlogger.debug(\"Extracted provider '%s' from model '%s'\", self.provider, self.model)\n\n\t# If provider is still not set, default to OpenAI\n\tif not self.provider:\n\t\tself.provider = \"openai\"\n\t\tlogger.debug(\"No provider found, defaulting to 'openai'\")\n\n\t# Load API keys from environment if not provided\n\tif not self.api_keys:\n\t\tself.api_keys = self._load_api_keys_from_env()\n\t\tfor provider in self.api_keys:\n\t\t\tlogger.debug(\"Loaded API key for provider: %s\", provider)\n\n\t# If specific api_key is provided, add it to api_keys\n\tif self.api_key and self.provider:\n\t\tself.api_keys[self.provider] = self.api_key\n\t\tlogger.debug(\"Added explicit API key for provider: %s\", self.provider)\n\n\tif self.provider:\n\t\tenv_var = ENV_VAR_MAP.get(self.provider)\n\t\tlogger.debug(\"Looking for API key in environment variable: %s\", env_var)\n\t\tif env_var:\n\t\t\tkey = os.environ.get(env_var)\n\t\t\tif key:\n\t\t\t\tlogger.debug(\"Found API key in environment for provider: %s\", self.provider)\n\t\t\telse:\n\t\t\t\tlogger.warning(\n\t\t\t\t\t\"No API key found in environment for provider: %s (env var: %s)\", self.provider, env_var\n\t\t\t\t)\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.LLMConfig.get_api_key","title":"get_api_key","text":"<pre><code>get_api_key() -&gt; str | None\n</code></pre> <p>Get the API key for the configured provider.</p> Source code in <code>src/codemap/llm/config.py</code> <pre><code>def get_api_key(self) -&gt; str | None:\n\t\"\"\"Get the API key for the configured provider.\"\"\"\n\tif not self.provider:\n\t\tlogger.warning(\"No provider configured, cannot get API key\")\n\t\treturn None\n\n\t# Try from loaded keys\n\tif self.provider in self.api_keys:\n\t\tlogger.debug(\"Using API key from loaded keys for provider: %s\", self.provider)\n\t\treturn self.api_keys[self.provider]\n\n\t# Try from environment as a fallback\n\tenv_var = ENV_VAR_MAP.get(self.provider)\n\tif env_var:\n\t\tkey = os.environ.get(env_var)\n\t\tif key:\n\t\t\tlogger.debug(\"Using API key from environment for provider: %s\", self.provider)\n\t\t\treturn key\n\t\t# If key is not found or is empty, log the warning\n\t\tlogger.warning(\"API key not found in environment for provider: %s (env var: %s)\", self.provider, env_var)\n\n\tlogger.warning(\"No API key found for provider: %s\", self.provider)\n\treturn None\n</code></pre>"},{"location":"api/llm/config/#codemap.llm.config.get_llm_config","title":"get_llm_config","text":"<pre><code>get_llm_config(\n\tconfig_loader: ConfigLoader | None = None,\n\t**overrides: dict[str, str | int | float | bool | None]\n\t| str\n\t| float\n\t| bool\n\t| None,\n) -&gt; LLMConfig\n</code></pre> <p>Get LLM configuration from config loader and optional overrides.</p> <p>Parameters:</p> Name Type Description Default <code>config_loader</code> <code>ConfigLoader | None</code> <p>Optional ConfigLoader instance to use</p> <code>None</code> <code>**overrides</code> <code>dict[str, str | int | float | bool | None] | str | float | bool | None</code> <p>Optional configuration overrides</p> <code>{}</code> <p>Returns:</p> Type Description <code>LLMConfig</code> <p>LLMConfig instance with merged configuration</p> Source code in <code>src/codemap/llm/config.py</code> <pre><code>def get_llm_config(\n\tconfig_loader: ConfigLoader | None = None,\n\t**overrides: dict[str, str | int | float | bool | None] | str | float | bool | None,\n) -&gt; LLMConfig:\n\t\"\"\"\n\tGet LLM configuration from config loader and optional overrides.\n\n\tArgs:\n\t    config_loader: Optional ConfigLoader instance to use\n\t    **overrides: Optional configuration overrides\n\n\tReturns:\n\t    LLMConfig instance with merged configuration\n\n\t\"\"\"\n\t# Create a config loader if none provided\n\tif not config_loader:\n\t\tconfig_loader = ConfigLoader()\n\n\t# Get LLM config from loader\n\tllm_config_dict = config_loader.get_llm_config()\n\n\t# Log the model being used\n\tmodel = llm_config_dict.get(\"model\", DEFAULT_MODEL)\n\tlogger.debug(\"Using model from config: %s\", model)\n\n\t# Apply overrides\n\tfor key, value in overrides.items():\n\t\tif value is not None:  # Only override if value is not None\n\t\t\tllm_config_dict[key] = value\n\t\t\tif key == \"model\":\n\t\t\t\tlogger.debug(\"Overriding model with: %s\", value)\n\n\t# Create and return config object\n\treturn LLMConfig(\n\t\tmodel=llm_config_dict.get(\"model\", DEFAULT_MODEL),\n\t\tprovider=llm_config_dict.get(\"provider\"),\n\t\tapi_base=llm_config_dict.get(\"api_base\"),\n\t\tapi_key=llm_config_dict.get(\"api_key\"),\n\t)\n</code></pre>"},{"location":"api/llm/errors/","title":"Errors","text":"<p>Error classes for LLM-related operations.</p>"},{"location":"api/llm/errors/#codemap.llm.errors.LLMError","title":"LLMError","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for LLM-related errors.</p> Source code in <code>src/codemap/llm/errors.py</code> <pre><code>class LLMError(Exception):\n\t\"\"\"Base exception for LLM-related errors.\"\"\"\n</code></pre>"},{"location":"api/llm/utils/","title":"Utils","text":"<p>Utility functions for working with LLMs.</p>"},{"location":"api/llm/utils/#codemap.llm.utils.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/llm/utils/#codemap.llm.utils.load_prompt_template","title":"load_prompt_template","text":"<pre><code>load_prompt_template(\n\ttemplate_path: str | None,\n) -&gt; str | None\n</code></pre> <p>Load custom prompt template from file.</p> <p>Parameters:</p> Name Type Description Default <code>template_path</code> <code>str | None</code> <p>Path to prompt template file</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Loaded template or None if loading failed</p> Source code in <code>src/codemap/llm/utils.py</code> <pre><code>def load_prompt_template(template_path: str | None) -&gt; str | None:\n\t\"\"\"\n\tLoad custom prompt template from file.\n\n\tArgs:\n\t    template_path: Path to prompt template file\n\n\tReturns:\n\t    Loaded template or None if loading failed\n\n\t\"\"\"\n\tif not template_path:\n\t\treturn None\n\n\ttry:\n\t\ttemplate_file = Path(template_path)\n\t\twith template_file.open(\"r\") as f:\n\t\t\treturn f.read()\n\texcept OSError:\n\t\tlogger.warning(\"Could not load prompt template: %s\", template_path)\n\t\treturn None\n</code></pre>"},{"location":"api/llm/utils/#codemap.llm.utils.get_llm_client","title":"get_llm_client","text":"<pre><code>get_llm_client() -&gt; LLMClient\n</code></pre> <p>Create and return a LLM client.</p> <p>Returns:</p> Type Description <code>LLMClient</code> <p>LLMClient instance</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If client creation fails</p> Source code in <code>src/codemap/llm/utils.py</code> <pre><code>def get_llm_client() -&gt; LLMClient:\n\t\"\"\"\n\tCreate and return a LLM client.\n\n\tReturns:\n\t    LLMClient instance\n\n\tRaises:\n\t    RuntimeError: If client creation fails\n\n\t\"\"\"\n\ttry:\n\t\tconfig = get_llm_config()\n\t\treturn LLMClient(config=config)\n\n\texcept LLMError as e:\n\t\tlogger.exception(\"LLM error\")\n\t\tmsg = f\"Failed to create LLM client: {e}\"\n\t\traise RuntimeError(msg) from e\n</code></pre>"},{"location":"api/llm/utils/#codemap.llm.utils.LLMResponseType","title":"LLMResponseType  <code>module-attribute</code>","text":"<pre><code>LLMResponseType = (\n\tdict[str, Any] | Mapping[str, Any] | object\n)\n</code></pre>"},{"location":"api/llm/utils/#codemap.llm.utils.extract_content_from_response","title":"extract_content_from_response","text":"<pre><code>extract_content_from_response(\n\tresponse: LLMResponseType,\n) -&gt; str\n</code></pre> <p>Extract content from a LLM response.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>LLMResponseType</code> <p>LLM response object or dictionary</p> required <p>Returns:</p> Type Description <code>str</code> <p>Extracted content as string</p> Source code in <code>src/codemap/llm/utils.py</code> <pre><code>def extract_content_from_response(response: LLMResponseType) -&gt; str:\n\t\"\"\"\n\tExtract content from a LLM response.\n\n\tArgs:\n\t    response: LLM response object or dictionary\n\n\tReturns:\n\t    Extracted content as string\n\n\t\"\"\"\n\treturn _extract_content(response)\n</code></pre>"},{"location":"api/llm/utils/#codemap.llm.utils.generate_text","title":"generate_text","text":"<pre><code>generate_text(\n\tprompt: str,\n\tmodel: str | None = DEFAULT_MODEL,\n\tapi_key: str | None = None,\n\tapi_base: str | None = None,\n\t**kwargs: str | float | bool | None,\n) -&gt; str\n</code></pre> <p>Generate text using an LLM with minimal configuration.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to send to the LLM</p> required <code>model</code> <code>str | None</code> <p>The model to use</p> <code>DEFAULT_MODEL</code> <code>api_key</code> <code>str | None</code> <p>The API key (if None, tries to find in environment)</p> <code>None</code> <code>api_base</code> <code>str | None</code> <p>Optional API base URL</p> <code>None</code> <code>**kwargs</code> <code>str | float | bool | None</code> <p>Additional parameters to pass to the LLM API</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>The generated text</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the LLM call fails</p> Source code in <code>src/codemap/llm/utils.py</code> <pre><code>def generate_text(\n\tprompt: str,\n\tmodel: str | None = DEFAULT_MODEL,\n\tapi_key: str | None = None,\n\tapi_base: str | None = None,\n\t**kwargs: str | float | bool | None,\n) -&gt; str:\n\t\"\"\"\n\tGenerate text using an LLM with minimal configuration.\n\n\tArgs:\n\t    prompt: The prompt to send to the LLM\n\t    model: The model to use\n\t    api_key: The API key (if None, tries to find in environment)\n\t    api_base: Optional API base URL\n\t    **kwargs: Additional parameters to pass to the LLM API\n\n\tReturns:\n\t    The generated text\n\n\tRaises:\n\t    RuntimeError: If the LLM call fails\n\n\t\"\"\"\n\ttry:\n\t\t# Create client and generate text directly\n\t\tclient = create_client(model=model, api_key=api_key, api_base=api_base)\n\t\treturn client.generate_text(prompt=prompt, **kwargs)  # type: ignore[arg-type]\n\n\texcept LLMError as e:\n\t\tlogger.exception(\"LLM error\")\n\t\tmsg = f\"Failed to generate text with LLM: {e}\"\n\t\traise RuntimeError(msg) from e\n</code></pre>"},{"location":"api/llm/utils/#codemap.llm.utils.create_client","title":"create_client","text":"<pre><code>create_client(\n\trepo_path: Path | None = None,\n\tmodel: str | None = None,\n\tapi_key: str | None = None,\n\tapi_base: str | None = None,\n) -&gt; LLMClient\n</code></pre> <p>Create an LLMClient with the specified configuration.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>Path | None</code> <p>Repository path for configuration loading</p> <code>None</code> <code>model</code> <code>str | None</code> <p>Model identifier to use</p> <code>None</code> <code>api_key</code> <code>str | None</code> <p>API key to use</p> <code>None</code> <code>api_base</code> <code>str | None</code> <p>API base URL to use</p> <code>None</code> <p>Returns:</p> Type Description <code>LLMClient</code> <p>Configured LLMClient instance</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If client creation fails</p> Source code in <code>src/codemap/llm/utils.py</code> <pre><code>def create_client(\n\trepo_path: Path | None = None,\n\tmodel: str | None = None,\n\tapi_key: str | None = None,\n\tapi_base: str | None = None,\n) -&gt; LLMClient:\n\t\"\"\"\n\tCreate an LLMClient with the specified configuration.\n\n\tArgs:\n\t    repo_path: Repository path for configuration loading\n\t    model: Model identifier to use\n\t    api_key: API key to use\n\t    api_base: API base URL to use\n\n\tReturns:\n\t    Configured LLMClient instance\n\n\tRaises:\n\t    RuntimeError: If client creation fails\n\n\t\"\"\"\n\ttry:\n\t\t# Get configuration\n\t\tconfig = get_llm_config(\n\t\t\toverrides={\n\t\t\t\t\"model\": model,\n\t\t\t\t\"api_key\": api_key,\n\t\t\t\t\"api_base\": api_base,\n\t\t\t}\n\t\t)\n\n\t\t# Create client\n\t\treturn LLMClient(config=config, repo_path=repo_path)\n\n\texcept Exception as e:\n\t\tlogger.exception(\"Error creating LLM client\")\n\t\tmsg = f\"Failed to create LLM client: {e}\"\n\t\traise RuntimeError(msg) from e\n</code></pre>"},{"location":"api/processor/","title":"Processor Overview","text":"<p>CodeMap processor module.</p> <ul> <li>Lod - Level of Detail (LOD) implementation for code analysis.</li> <li>Pipeline - Pipeline orchestration for code processing.</li> <li>Tree Sitter - Tree-sitter based code analysis.</li> </ul>"},{"location":"api/processor/lod/","title":"Lod","text":"<p>Level of Detail (LOD) implementation for code analysis.</p> <p>This module provides functionality for generating different levels of detail from source code using tree-sitter analysis. The LOD approach provides a hierarchical view of code, from high-level entity names to detailed implementations.</p> <p>LOD levels: - LOD1: Just entity names and types in files (classes, functions, etc.) - LOD2: Entity names with docstrings - LOD3: Entity names, docstrings, and signatures - LOD4: Complete entity implementations</p>"},{"location":"api/processor/lod/#codemap.processor.lod.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODLevel","title":"LODLevel","text":"<p>               Bases: <code>Enum</code></p> <p>Enumeration of Level of Detail levels.</p> Source code in <code>src/codemap/processor/lod.py</code> <pre><code>class LODLevel(Enum):\n\t\"\"\"Enumeration of Level of Detail levels.\"\"\"\n\n\tSIGNATURES = 1  # Top-level entity names, docstrings, and signatures\n\tSTRUCTURE = 2  # All entity signatures, indented structure\n\tDOCS = 3  # Level 2 + Docstrings for all entities\n\tFULL = 4  # Level 3 + Full implementation content\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODLevel.SIGNATURES","title":"SIGNATURES  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SIGNATURES = 1\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODLevel.STRUCTURE","title":"STRUCTURE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STRUCTURE = 2\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODLevel.DOCS","title":"DOCS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DOCS = 3\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODLevel.FULL","title":"FULL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FULL = 4\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity","title":"LODEntity  <code>dataclass</code>","text":"<p>Represents a code entity at a specific level of detail.</p> Source code in <code>src/codemap/processor/lod.py</code> <pre><code>@dataclass\nclass LODEntity:\n\t\"\"\"Represents a code entity at a specific level of detail.\"\"\"\n\n\tname: str\n\t\"\"\"Name of the entity.\"\"\"\n\n\tentity_type: EntityType\n\t\"\"\"Type of entity (class, function, etc.).\"\"\"\n\n\tstart_line: int\n\t\"\"\"Starting line number (1-indexed).\"\"\"\n\n\tend_line: int\n\t\"\"\"Ending line number (1-indexed).\"\"\"\n\n\tdocstring: str = \"\"\n\t\"\"\"Entity docstring, if available.\"\"\"\n\n\tsignature: str = \"\"\n\t\"\"\"Entity signature (e.g., function parameters), if available.\"\"\"\n\n\tcontent: str = \"\"\n\t\"\"\"Complete entity content/implementation.\"\"\"\n\n\tchildren: list[LODEntity] = field(default_factory=list)\n\t\"\"\"Child entities contained within this entity.\"\"\"\n\n\tlanguage: str = \"\"\n\t\"\"\"Programming language of the entity.\"\"\"\n\n\tmetadata: dict[str, Any] = field(default_factory=dict)\n\t\"\"\"Additional metadata about the entity.\"\"\"\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.__init__","title":"__init__","text":"<pre><code>__init__(\n\tname: str,\n\tentity_type: EntityType,\n\tstart_line: int,\n\tend_line: int,\n\tdocstring: str = \"\",\n\tsignature: str = \"\",\n\tcontent: str = \"\",\n\tchildren: list[LODEntity] = list(),\n\tlanguage: str = \"\",\n\tmetadata: dict[str, Any] = dict(),\n) -&gt; None\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>Name of the entity.</p>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.entity_type","title":"entity_type  <code>instance-attribute</code>","text":"<pre><code>entity_type: EntityType\n</code></pre> <p>Type of entity (class, function, etc.).</p>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.start_line","title":"start_line  <code>instance-attribute</code>","text":"<pre><code>start_line: int\n</code></pre> <p>Starting line number (1-indexed).</p>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.end_line","title":"end_line  <code>instance-attribute</code>","text":"<pre><code>end_line: int\n</code></pre> <p>Ending line number (1-indexed).</p>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.docstring","title":"docstring  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>docstring: str = ''\n</code></pre> <p>Entity docstring, if available.</p>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.signature","title":"signature  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>signature: str = ''\n</code></pre> <p>Entity signature (e.g., function parameters), if available.</p>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.content","title":"content  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>content: str = ''\n</code></pre> <p>Complete entity content/implementation.</p>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.children","title":"children  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>children: list[LODEntity] = field(default_factory=list)\n</code></pre> <p>Child entities contained within this entity.</p>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.language","title":"language  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>language: str = ''\n</code></pre> <p>Programming language of the entity.</p>"},{"location":"api/processor/lod/#codemap.processor.lod.LODEntity.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: dict[str, Any] = field(default_factory=dict)\n</code></pre> <p>Additional metadata about the entity.</p>"},{"location":"api/processor/lod/#codemap.processor.lod.LODGenerator","title":"LODGenerator","text":"<p>Generates different levels of detail from source code.</p> Source code in <code>src/codemap/processor/lod.py</code> <pre><code>class LODGenerator:\n\t\"\"\"Generates different levels of detail from source code.\"\"\"\n\n\tdef __init__(self) -&gt; None:\n\t\t\"\"\"Initialize the LOD generator.\"\"\"\n\t\tself.analyzer = TreeSitterAnalyzer()\n\n\tdef generate_lod(self, file_path: Path, level: LODLevel = LODLevel.STRUCTURE) -&gt; LODEntity | None:\n\t\t\"\"\"\n\t\tGenerate LOD representation for a file.\n\n\t\tArgs:\n\t\t    file_path: Path to the file to analyze\n\t\t    level: Level of detail to generate (default changed to STRUCTURE)\n\n\t\tReturns:\n\t\t    LODEntity representing the file, or None if analysis failed\n\n\t\t\"\"\"\n\t\t# Read file content\n\t\tcontent = read_file_content(file_path)\n\t\tif not content:\n\t\t\tlogger.warning(f\"Could not read content from {file_path}\")\n\t\t\treturn None\n\n\t\t# Analyze file with tree-sitter\n\t\tanalysis_result = self.analyzer.analyze_file(file_path, content)\n\t\tif not analysis_result:\n\t\t\tlogger.warning(f\"Failed to analyze {file_path}\")\n\t\t\treturn None\n\n\t\t# Convert analysis result to LOD, passing the file_path\n\t\treturn self._convert_to_lod(analysis_result, level, file_path)\n\n\tdef _convert_to_lod(\n\t\tself, analysis_result: dict[str, Any], level: LODLevel, file_path: Path | None = None\n\t) -&gt; LODEntity:\n\t\t\"\"\"\n\t\tConvert tree-sitter analysis to LOD format.\n\n\t\tArgs:\n\t\t    analysis_result: Tree-sitter analysis result\n\t\t    level: Level of detail to generate\n\t\t    file_path: Path to the file being analyzed\n\n\t\tReturns:\n\t\t    LODEntity representation\n\n\t\t\"\"\"\n\t\tentity_type_str = analysis_result.get(\"type\", \"UNKNOWN\")\n\t\ttry:\n\t\t\tentity_type = EntityType[entity_type_str]\n\t\texcept KeyError:\n\t\t\tentity_type = EntityType.UNKNOWN\n\n\t\tlocation = analysis_result.get(\"location\", {})\n\t\tstart_line = location.get(\"start_line\", 1)\n\t\tend_line = location.get(\"end_line\", 1)\n\n\t\t# Create the entity with appropriate level of detail\n\t\tentity = LODEntity(\n\t\t\tname=analysis_result.get(\"name\", \"\"),\n\t\t\tentity_type=entity_type,\n\t\t\tstart_line=start_line,\n\t\t\tend_line=end_line,\n\t\t\tlanguage=analysis_result.get(\"language\", \"\"),\n\t\t)\n\n\t\t# Add file_path to metadata for top-level entities\n\t\tif file_path:\n\t\t\tentity.metadata[\"file_path\"] = str(file_path)\n\n\t\t# Add details based on LOD level (updated comparisons)\n\t\tif level.value &gt;= LODLevel.DOCS.value:\n\t\t\tentity.docstring = analysis_result.get(\"docstring\", \"\")\n\n\t\t# Signature is needed for SIGNATURES (1), STRUCTURE (2), DOCS (3), FULL (4)\n\t\tif level.value &gt;= LODLevel.SIGNATURES.value:\n\t\t\t# Extract signature from content if available\n\t\t\tcontent = analysis_result.get(\"content\", \"\")\n\t\t\tentity.signature = self._extract_signature(content, entity_type, entity.language)\n\n\t\t# Content is needed for FULL (4)\n\t\tif level.value &gt;= LODLevel.FULL.value or entity_type == EntityType.COMMENT:\n\t\t\tentity.content = analysis_result.get(\"content\", \"\")\n\n\t\t# Process children recursively (without passing file_path)\n\t\tchildren = analysis_result.get(\"children\", [])\n\t\tfor child in children:\n\t\t\tchild_entity = self._convert_to_lod(child, level)\n\t\t\tentity.children.append(child_entity)\n\n\t\t# Add any additional metadata\n\t\tif \"dependencies\" in analysis_result:\n\t\t\tentity.metadata[\"dependencies\"] = analysis_result[\"dependencies\"]\n\t\tif \"calls\" in analysis_result:\n\t\t\tentity.metadata[\"calls\"] = analysis_result[\"calls\"]\n\n\t\treturn entity\n\n\tdef _extract_signature(self, content: str, entity_type: EntityType, _language: str) -&gt; str:\n\t\t\"\"\"\n\t\tExtract function/method signature from content.\n\n\t\tThis is a simple implementation; ideally, the language-specific handlers\n\t\tshould provide this functionality.\n\n\t\tArgs:\n\t\t    content: Full entity content\n\t\t    entity_type: Type of entity\n\t\t    _language: Programming language (unused currently)\n\n\t\tReturns:\n\t\t    Signature string\n\n\t\t\"\"\"\n\t\tif not content:\n\t\t\treturn \"\"\n\n\t\t# For functions and methods, extract the first line (declaration)\n\t\tif entity_type in [EntityType.FUNCTION, EntityType.METHOD, EntityType.CLASS, EntityType.INTERFACE]:\n\t\t\tlines = content.split(\"\\n\")\n\t\t\tif lines:\n\t\t\t\t# Return first line without trailing characters\n\t\t\t\treturn lines[0].rstrip(\":{\")\n\n\t\treturn \"\"\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODGenerator.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> <p>Initialize the LOD generator.</p> Source code in <code>src/codemap/processor/lod.py</code> <pre><code>def __init__(self) -&gt; None:\n\t\"\"\"Initialize the LOD generator.\"\"\"\n\tself.analyzer = TreeSitterAnalyzer()\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODGenerator.analyzer","title":"analyzer  <code>instance-attribute</code>","text":"<pre><code>analyzer = TreeSitterAnalyzer()\n</code></pre>"},{"location":"api/processor/lod/#codemap.processor.lod.LODGenerator.generate_lod","title":"generate_lod","text":"<pre><code>generate_lod(\n\tfile_path: Path, level: LODLevel = STRUCTURE\n) -&gt; LODEntity | None\n</code></pre> <p>Generate LOD representation for a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the file to analyze</p> required <code>level</code> <code>LODLevel</code> <p>Level of detail to generate (default changed to STRUCTURE)</p> <code>STRUCTURE</code> <p>Returns:</p> Type Description <code>LODEntity | None</code> <p>LODEntity representing the file, or None if analysis failed</p> Source code in <code>src/codemap/processor/lod.py</code> <pre><code>def generate_lod(self, file_path: Path, level: LODLevel = LODLevel.STRUCTURE) -&gt; LODEntity | None:\n\t\"\"\"\n\tGenerate LOD representation for a file.\n\n\tArgs:\n\t    file_path: Path to the file to analyze\n\t    level: Level of detail to generate (default changed to STRUCTURE)\n\n\tReturns:\n\t    LODEntity representing the file, or None if analysis failed\n\n\t\"\"\"\n\t# Read file content\n\tcontent = read_file_content(file_path)\n\tif not content:\n\t\tlogger.warning(f\"Could not read content from {file_path}\")\n\t\treturn None\n\n\t# Analyze file with tree-sitter\n\tanalysis_result = self.analyzer.analyze_file(file_path, content)\n\tif not analysis_result:\n\t\tlogger.warning(f\"Failed to analyze {file_path}\")\n\t\treturn None\n\n\t# Convert analysis result to LOD, passing the file_path\n\treturn self._convert_to_lod(analysis_result, level, file_path)\n</code></pre>"},{"location":"api/processor/pipeline/","title":"Pipeline","text":"<p>Pipeline orchestration for code processing.</p> <p>This module defines the main processing pipeline that orchestrates: 1. Generating code metadata with tree-sitter at different LOD levels 2. Providing results to client modules</p>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.is_binary_file","title":"is_binary_file","text":"<pre><code>is_binary_file(file_path: Path) -&gt; bool\n</code></pre> <p>Check if a file is binary.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the file</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file is binary, False otherwise</p> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def is_binary_file(file_path: Path) -&gt; bool:\n\t\"\"\"\n\tCheck if a file is binary.\n\n\tArgs:\n\t        file_path: Path to the file\n\n\tReturns:\n\t        True if the file is binary, False otherwise\n\n\t\"\"\"\n\t# Skip files larger than 10 MB\n\ttry:\n\t\tif file_path.stat().st_size &gt; 10 * 1024 * 1024:\n\t\t\treturn True\n\n\t\t# Try to read as text\n\t\twith file_path.open(encoding=\"utf-8\") as f:\n\t\t\tchunk = f.read(1024)\n\t\t\treturn \"\\0\" in chunk\n\texcept UnicodeDecodeError:\n\t\treturn True\n\texcept (OSError, PermissionError):\n\t\treturn True\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.is_text_file","title":"is_text_file","text":"<pre><code>is_text_file(file_path: Path) -&gt; bool\n</code></pre> <p>Check if a file is a text file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the file</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file is a text file, False otherwise</p> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def is_text_file(file_path: Path) -&gt; bool:\n\t\"\"\"\n\tCheck if a file is a text file.\n\n\tArgs:\n\t        file_path: Path to the file\n\n\tReturns:\n\t        True if the file is a text file, False otherwise\n\n\t\"\"\"\n\treturn not is_binary_file(file_path)\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline","title":"ProcessingPipeline","text":"<p>Main pipeline for code processing and analysis.</p> <p>This class orchestrates the generation of LOD data for code files and directories using tree-sitter, with parallel processing capabilities.</p> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>class ProcessingPipeline:\n\t\"\"\"\n\tMain pipeline for code processing and analysis.\n\n\tThis class orchestrates the generation of LOD data for code files and\n\tdirectories using tree-sitter, with parallel processing capabilities.\n\n\t\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\trepo_path: Path,\n\t\tignored_patterns: set[str] | None = None,\n\t\tmax_workers: int = 4,\n\t\tdefault_lod_level: LODLevel = LODLevel.SIGNATURES,\n\t) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the processing pipeline.\n\n\t\tArgs:\n\t\t        repo_path: Path to the repository root\n\t\t        ignored_patterns: Set of glob patterns to ignore when processing\n\t\t        max_workers: Maximum number of worker threads for processing\n\t\t        default_lod_level: Default Level of Detail to use for processing\n\n\t\t\"\"\"\n\t\tself.repo_path = repo_path\n\t\tself.ignored_patterns = ignored_patterns or {\n\t\t\t\"**/.git/**\",\n\t\t\t\"**/__pycache__/**\",\n\t\t\t\"**/.venv/**\",\n\t\t\t\"**/node_modules/**\",\n\t\t\t\"**/.DS_Store\",\n\t\t\t\"**/*.pyc\",\n\t\t\t\"**/*.pyo\",\n\t\t\t\"**/*.pyd\",\n\t\t\t\"**/~*\",\n\t\t}\n\n\t\t# Setup processing components\n\t\tself.lod_generator = LODGenerator()\n\t\tself.default_lod_level = default_lod_level\n\n\t\t# Threading setup\n\t\tself.max_workers = max_workers\n\t\tself.executor = ThreadPoolExecutor(max_workers=max_workers)\n\t\tself._futures: list[Future] = []\n\n\t\t# In-memory cache for processed files\n\t\tself.processed_files: dict[Path, LODEntity] = {}\n\n\tdef stop(self) -&gt; None:\n\t\t\"\"\"Stop the processing pipeline and clean up resources.\"\"\"\n\t\tlogger.info(\"Stopping processing pipeline\")\n\n\t\t# Shutdown thread pool\n\t\tself.executor.shutdown(wait=True)\n\t\tself._futures.clear()\n\n\t\tlogger.info(\"Processing pipeline stopped\")\n\n\tdef process_file(self, file_path: str | Path, level: LODLevel | None = None) -&gt; None:\n\t\t\"\"\"\n\t\tProcess a single file asynchronously.\n\n\t\tArgs:\n\t\t        file_path: Path to the file to process\n\t\t        level: Level of Detail to use, defaults to pipeline's default level\n\n\t\t\"\"\"\n\t\tpath_obj = Path(file_path)\n\n\t\t# Skip binary files\n\t\tif is_binary_file(path_obj):\n\t\t\tlogger.debug(\"Skipping binary file: %s\", path_obj)\n\t\t\treturn\n\n\t\t# Submit to thread pool\n\t\tfuture = self.executor.submit(self._process_file_worker, path_obj, level or self.default_lod_level)\n\t\tself._futures.append(future)\n\n\tdef process_file_sync(self, file_path: str | Path, level: LODLevel | None = None) -&gt; LODEntity | None:\n\t\t\"\"\"\n\t\tProcess a single file synchronously and return the result.\n\n\t\tArgs:\n\t\t        file_path: Path to the file to process\n\t\t        level: Level of Detail to use, defaults to pipeline's default level\n\n\t\tReturns:\n\t\t        LOD entity or None if processing failed or file is binary\n\n\t\t\"\"\"\n\t\tpath_obj = Path(file_path)\n\n\t\t# Skip binary files\n\t\tif is_binary_file(path_obj):\n\t\t\tlogger.debug(\"Skipping binary file: %s\", path_obj)\n\t\t\treturn None\n\n\t\t# Process directly\n\t\treturn self._process_file_worker(path_obj, level or self.default_lod_level)\n\n\tdef _process_file_worker(self, file_path: Path, level: LODLevel) -&gt; LODEntity | None:\n\t\t\"\"\"\n\t\tWorker function to process a file.\n\n\t\tArgs:\n\t\t        file_path: Path to the file to process\n\t\t        level: Level of Detail to use\n\n\t\tReturns:\n\t\t        LOD entity or None if processing failed\n\n\t\t\"\"\"\n\t\ttry:\n\t\t\tlogger.debug(\"Processing file: %s at LOD level %s\", file_path, level.name)\n\n\t\t\t# Generate LOD entity\n\t\t\tlod_entity = self.lod_generator.generate_lod(file_path, level)\n\n\t\t\t# Store in cache\n\t\t\tif lod_entity:\n\t\t\t\tself.processed_files[file_path] = lod_entity\n\t\t\t\tlogger.debug(\"Successfully generated LOD entity for %s\", file_path)\n\t\t\telse:\n\t\t\t\tlogger.warning(\"LODGenerator returned None for %s (file might be unsupported or empty)\", file_path)\n\n\t\t\treturn lod_entity\n\n\t\texcept Exception:\n\t\t\tlogger.exception(\"Error processing file %s\", file_path)\n\t\t\treturn None\n\t\tfinally:\n\t\t\t# Log final status (redundant with above but good for overview)\n\t\t\tstatus = (\n\t\t\t\t\"succeeded (added to cache)\"\n\t\t\t\tif file_path in self.processed_files\n\t\t\t\telse \"failed or skipped (not in cache)\"\n\t\t\t)\n\t\t\tlogger.debug(\"Final processing status for %s: %s\", file_path, status)\n\n\tdef batch_process(self, paths: list[str | Path], level: LODLevel | None = None) -&gt; None:\n\t\t\"\"\"\n\t\tProcess multiple files in batch asynchronously.\n\n\t\tArgs:\n\t\t        paths: List of file paths to process\n\t\t        level: Level of Detail to use, defaults to pipeline's default level\n\n\t\t\"\"\"\n\t\tfor path in paths:\n\t\t\tself.process_file(path, level)\n\n\tdef wait_for_completion(self, timeout: float | None = None) -&gt; bool:\n\t\t\"\"\"\n\t\tWait for all pending file processing tasks to complete.\n\n\t\tArgs:\n\t\t        timeout: Maximum time to wait in seconds, or None to wait indefinitely\n\n\t\tReturns:\n\t\t        True if all tasks completed, False if timeout occurred\n\n\t\t\"\"\"\n\t\tfrom concurrent.futures import ALL_COMPLETED, wait\n\n\t\tif not self._futures:\n\t\t\treturn True\n\n\t\t_, not_done = wait(self._futures, timeout=timeout, return_when=ALL_COMPLETED)\n\n\t\t# Clean up completed futures\n\t\tself._futures = list(not_done)\n\n\t\treturn len(not_done) == 0\n\n\tdef get_lod_entity(\n\t\tself, file_path: Path, level: LODLevel | None = None, force_refresh: bool = False\n\t) -&gt; LODEntity | None:\n\t\t\"\"\"\n\t\tGet the LOD entity for a file.\n\n\t\tIf the file has already been processed at the requested level or higher,\n\t\treturns the cached entity. Otherwise, processes the file at the requested level.\n\n\t\tArgs:\n\t\t        file_path: Path to the file\n\t\t        level: Level of Detail requested, defaults to pipeline's default level\n\t\t        force_refresh: Whether to force reprocessing even if cached\n\n\t\tReturns:\n\t\t        LOD entity for the file, or None if processing failed\n\n\t\t\"\"\"\n\t\trequested_level = level or self.default_lod_level\n\n\t\t# Check if we have a cached entity at the same or higher level\n\t\tif not force_refresh and file_path in self.processed_files:\n\t\t\texisting_entity = self.processed_files[file_path]\n\n\t\t\t# If we have content in the entity and level is FULL, we know it was processed at FULL level\n\t\t\tif requested_level == LODLevel.FULL and existing_entity.content:\n\t\t\t\treturn existing_entity\n\n\t\t\t# If we have signature and level is SIGNATURES, we know it was processed at SIGNATURES level\n\t\t\tif requested_level == LODLevel.SIGNATURES and existing_entity.signature:\n\t\t\t\treturn existing_entity\n\n\t\t\t# If we have docstring and level is DOCS, we know it was processed at DOCS level\n\t\t\tif requested_level == LODLevel.DOCS and existing_entity.docstring:\n\t\t\t\treturn existing_entity\n\n\t\t# Process synchronously in this case\n\t\treturn self.process_file_sync(file_path, requested_level)\n\n\tdef process_repository(self, repo_path: Path | None = None) -&gt; int:\n\t\t\"\"\"\n\t\tProcess an entire repository asynchronously.\n\n\t\tArgs:\n\t\t        repo_path: Repository path, uses the pipeline's repo path if None\n\n\t\tReturns:\n\t\t        Number of files submitted for processing\n\n\t\t\"\"\"\n\t\ttarget_repo = repo_path or self.repo_path\n\n\t\t# Get all files in the repository\n\t\tall_files = []\n\t\tfor path_obj in target_repo.rglob(\"*\"):\n\t\t\tif path_obj.is_file() and is_text_file(path_obj):\n\t\t\t\t# Check against ignored patterns\n\t\t\t\tshould_ignore = False\n\t\t\t\tfor pattern in self.ignored_patterns:\n\t\t\t\t\tif path_obj.match(pattern):\n\t\t\t\t\t\tshould_ignore = True\n\t\t\t\t\t\tbreak\n\n\t\t\t\tif not should_ignore:\n\t\t\t\t\tall_files.append(path_obj)\n\n\t\t# Process all files\n\t\tself.batch_process(all_files)\n\n\t\treturn len(all_files)\n\n\tdef get_repository_structure(\n\t\tself, root_path: Path | None = None, level: LODLevel = LODLevel.STRUCTURE\n\t) -&gt; dict[str, Any]:\n\t\t\"\"\"\n\t\tGet a structured representation of the repository.\n\n\t\tArgs:\n\t\t        root_path: Root path to start from, uses pipeline's repo path if None\n\t\t        level: Level of Detail to use for files\n\n\t\tReturns:\n\t\t        Hierarchical structure of the repository with LOD entities\n\n\t\t\"\"\"\n\t\ttarget_path = root_path or self.repo_path\n\n\t\t# Start with the basic directory structure\n\t\tresult = {\"type\": \"directory\", \"name\": target_path.name, \"path\": str(target_path), \"children\": []}\n\n\t\t# List all items in the directory\n\t\ttry:\n\t\t\titems = list(target_path.iterdir())\n\n\t\t\t# Process directories first\n\t\t\tfor item in sorted([i for i in items if i.is_dir()], key=lambda x: x.name):\n\t\t\t\t# Skip ignored directories\n\t\t\t\tshould_ignore = False\n\t\t\t\tfor pattern in self.ignored_patterns:\n\t\t\t\t\tif item.match(pattern):\n\t\t\t\t\t\tshould_ignore = True\n\t\t\t\t\t\tbreak\n\n\t\t\t\tif should_ignore:\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Recursively process this directory\n\t\t\t\tchild_structure = self.get_repository_structure(item, level)\n\t\t\t\tresult[\"children\"].append(child_structure)\n\n\t\t\t# Then process files\n\t\t\tfor item in sorted([i for i in items if i.is_file()], key=lambda x: x.name):\n\t\t\t\t# Skip ignored files\n\t\t\t\tshould_ignore = False\n\t\t\t\tfor pattern in self.ignored_patterns:\n\t\t\t\t\tif item.match(pattern):\n\t\t\t\t\t\tshould_ignore = True\n\t\t\t\t\t\tbreak\n\n\t\t\t\tif should_ignore:\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Get LOD entity for this file\n\t\t\t\tfile_entity = self.get_lod_entity(item, level)\n\n\t\t\t\tfile_result = {\"type\": \"file\", \"name\": item.name, \"path\": str(item), \"entity\": file_entity}\n\n\t\t\t\tresult[\"children\"].append(file_result)\n\n\t\texcept (PermissionError, FileNotFoundError) as e:\n\t\t\tlogger.warning(f\"Error processing directory {target_path}: {e}\")\n\n\t\treturn result\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.__init__","title":"__init__","text":"<pre><code>__init__(\n\trepo_path: Path,\n\tignored_patterns: set[str] | None = None,\n\tmax_workers: int = 4,\n\tdefault_lod_level: LODLevel = SIGNATURES,\n) -&gt; None\n</code></pre> <p>Initialize the processing pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>Path</code> <p>Path to the repository root</p> required <code>ignored_patterns</code> <code>set[str] | None</code> <p>Set of glob patterns to ignore when processing</p> <code>None</code> <code>max_workers</code> <code>int</code> <p>Maximum number of worker threads for processing</p> <code>4</code> <code>default_lod_level</code> <code>LODLevel</code> <p>Default Level of Detail to use for processing</p> <code>SIGNATURES</code> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def __init__(\n\tself,\n\trepo_path: Path,\n\tignored_patterns: set[str] | None = None,\n\tmax_workers: int = 4,\n\tdefault_lod_level: LODLevel = LODLevel.SIGNATURES,\n) -&gt; None:\n\t\"\"\"\n\tInitialize the processing pipeline.\n\n\tArgs:\n\t        repo_path: Path to the repository root\n\t        ignored_patterns: Set of glob patterns to ignore when processing\n\t        max_workers: Maximum number of worker threads for processing\n\t        default_lod_level: Default Level of Detail to use for processing\n\n\t\"\"\"\n\tself.repo_path = repo_path\n\tself.ignored_patterns = ignored_patterns or {\n\t\t\"**/.git/**\",\n\t\t\"**/__pycache__/**\",\n\t\t\"**/.venv/**\",\n\t\t\"**/node_modules/**\",\n\t\t\"**/.DS_Store\",\n\t\t\"**/*.pyc\",\n\t\t\"**/*.pyo\",\n\t\t\"**/*.pyd\",\n\t\t\"**/~*\",\n\t}\n\n\t# Setup processing components\n\tself.lod_generator = LODGenerator()\n\tself.default_lod_level = default_lod_level\n\n\t# Threading setup\n\tself.max_workers = max_workers\n\tself.executor = ThreadPoolExecutor(max_workers=max_workers)\n\tself._futures: list[Future] = []\n\n\t# In-memory cache for processed files\n\tself.processed_files: dict[Path, LODEntity] = {}\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.repo_path","title":"repo_path  <code>instance-attribute</code>","text":"<pre><code>repo_path = repo_path\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.ignored_patterns","title":"ignored_patterns  <code>instance-attribute</code>","text":"<pre><code>ignored_patterns = ignored_patterns or {\n\t\"**/.git/**\",\n\t\"**/__pycache__/**\",\n\t\"**/.venv/**\",\n\t\"**/node_modules/**\",\n\t\"**/.DS_Store\",\n\t\"**/*.pyc\",\n\t\"**/*.pyo\",\n\t\"**/*.pyd\",\n\t\"**/~*\",\n}\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.lod_generator","title":"lod_generator  <code>instance-attribute</code>","text":"<pre><code>lod_generator = LODGenerator()\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.default_lod_level","title":"default_lod_level  <code>instance-attribute</code>","text":"<pre><code>default_lod_level = default_lod_level\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.max_workers","title":"max_workers  <code>instance-attribute</code>","text":"<pre><code>max_workers = max_workers\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.executor","title":"executor  <code>instance-attribute</code>","text":"<pre><code>executor = ThreadPoolExecutor(max_workers=max_workers)\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.processed_files","title":"processed_files  <code>instance-attribute</code>","text":"<pre><code>processed_files: dict[Path, LODEntity] = {}\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.stop","title":"stop","text":"<pre><code>stop() -&gt; None\n</code></pre> <p>Stop the processing pipeline and clean up resources.</p> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def stop(self) -&gt; None:\n\t\"\"\"Stop the processing pipeline and clean up resources.\"\"\"\n\tlogger.info(\"Stopping processing pipeline\")\n\n\t# Shutdown thread pool\n\tself.executor.shutdown(wait=True)\n\tself._futures.clear()\n\n\tlogger.info(\"Processing pipeline stopped\")\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.process_file","title":"process_file","text":"<pre><code>process_file(\n\tfile_path: str | Path, level: LODLevel | None = None\n) -&gt; None\n</code></pre> <p>Process a single file asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path to the file to process</p> required <code>level</code> <code>LODLevel | None</code> <p>Level of Detail to use, defaults to pipeline's default level</p> <code>None</code> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def process_file(self, file_path: str | Path, level: LODLevel | None = None) -&gt; None:\n\t\"\"\"\n\tProcess a single file asynchronously.\n\n\tArgs:\n\t        file_path: Path to the file to process\n\t        level: Level of Detail to use, defaults to pipeline's default level\n\n\t\"\"\"\n\tpath_obj = Path(file_path)\n\n\t# Skip binary files\n\tif is_binary_file(path_obj):\n\t\tlogger.debug(\"Skipping binary file: %s\", path_obj)\n\t\treturn\n\n\t# Submit to thread pool\n\tfuture = self.executor.submit(self._process_file_worker, path_obj, level or self.default_lod_level)\n\tself._futures.append(future)\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.process_file_sync","title":"process_file_sync","text":"<pre><code>process_file_sync(\n\tfile_path: str | Path, level: LODLevel | None = None\n) -&gt; LODEntity | None\n</code></pre> <p>Process a single file synchronously and return the result.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path to the file to process</p> required <code>level</code> <code>LODLevel | None</code> <p>Level of Detail to use, defaults to pipeline's default level</p> <code>None</code> <p>Returns:</p> Type Description <code>LODEntity | None</code> <p>LOD entity or None if processing failed or file is binary</p> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def process_file_sync(self, file_path: str | Path, level: LODLevel | None = None) -&gt; LODEntity | None:\n\t\"\"\"\n\tProcess a single file synchronously and return the result.\n\n\tArgs:\n\t        file_path: Path to the file to process\n\t        level: Level of Detail to use, defaults to pipeline's default level\n\n\tReturns:\n\t        LOD entity or None if processing failed or file is binary\n\n\t\"\"\"\n\tpath_obj = Path(file_path)\n\n\t# Skip binary files\n\tif is_binary_file(path_obj):\n\t\tlogger.debug(\"Skipping binary file: %s\", path_obj)\n\t\treturn None\n\n\t# Process directly\n\treturn self._process_file_worker(path_obj, level or self.default_lod_level)\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.batch_process","title":"batch_process","text":"<pre><code>batch_process(\n\tpaths: list[str | Path], level: LODLevel | None = None\n) -&gt; None\n</code></pre> <p>Process multiple files in batch asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>list[str | Path]</code> <p>List of file paths to process</p> required <code>level</code> <code>LODLevel | None</code> <p>Level of Detail to use, defaults to pipeline's default level</p> <code>None</code> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def batch_process(self, paths: list[str | Path], level: LODLevel | None = None) -&gt; None:\n\t\"\"\"\n\tProcess multiple files in batch asynchronously.\n\n\tArgs:\n\t        paths: List of file paths to process\n\t        level: Level of Detail to use, defaults to pipeline's default level\n\n\t\"\"\"\n\tfor path in paths:\n\t\tself.process_file(path, level)\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.wait_for_completion","title":"wait_for_completion","text":"<pre><code>wait_for_completion(timeout: float | None = None) -&gt; bool\n</code></pre> <p>Wait for all pending file processing tasks to complete.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float | None</code> <p>Maximum time to wait in seconds, or None to wait indefinitely</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if all tasks completed, False if timeout occurred</p> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def wait_for_completion(self, timeout: float | None = None) -&gt; bool:\n\t\"\"\"\n\tWait for all pending file processing tasks to complete.\n\n\tArgs:\n\t        timeout: Maximum time to wait in seconds, or None to wait indefinitely\n\n\tReturns:\n\t        True if all tasks completed, False if timeout occurred\n\n\t\"\"\"\n\tfrom concurrent.futures import ALL_COMPLETED, wait\n\n\tif not self._futures:\n\t\treturn True\n\n\t_, not_done = wait(self._futures, timeout=timeout, return_when=ALL_COMPLETED)\n\n\t# Clean up completed futures\n\tself._futures = list(not_done)\n\n\treturn len(not_done) == 0\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.get_lod_entity","title":"get_lod_entity","text":"<pre><code>get_lod_entity(\n\tfile_path: Path,\n\tlevel: LODLevel | None = None,\n\tforce_refresh: bool = False,\n) -&gt; LODEntity | None\n</code></pre> <p>Get the LOD entity for a file.</p> <p>If the file has already been processed at the requested level or higher, returns the cached entity. Otherwise, processes the file at the requested level.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the file</p> required <code>level</code> <code>LODLevel | None</code> <p>Level of Detail requested, defaults to pipeline's default level</p> <code>None</code> <code>force_refresh</code> <code>bool</code> <p>Whether to force reprocessing even if cached</p> <code>False</code> <p>Returns:</p> Type Description <code>LODEntity | None</code> <p>LOD entity for the file, or None if processing failed</p> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def get_lod_entity(\n\tself, file_path: Path, level: LODLevel | None = None, force_refresh: bool = False\n) -&gt; LODEntity | None:\n\t\"\"\"\n\tGet the LOD entity for a file.\n\n\tIf the file has already been processed at the requested level or higher,\n\treturns the cached entity. Otherwise, processes the file at the requested level.\n\n\tArgs:\n\t        file_path: Path to the file\n\t        level: Level of Detail requested, defaults to pipeline's default level\n\t        force_refresh: Whether to force reprocessing even if cached\n\n\tReturns:\n\t        LOD entity for the file, or None if processing failed\n\n\t\"\"\"\n\trequested_level = level or self.default_lod_level\n\n\t# Check if we have a cached entity at the same or higher level\n\tif not force_refresh and file_path in self.processed_files:\n\t\texisting_entity = self.processed_files[file_path]\n\n\t\t# If we have content in the entity and level is FULL, we know it was processed at FULL level\n\t\tif requested_level == LODLevel.FULL and existing_entity.content:\n\t\t\treturn existing_entity\n\n\t\t# If we have signature and level is SIGNATURES, we know it was processed at SIGNATURES level\n\t\tif requested_level == LODLevel.SIGNATURES and existing_entity.signature:\n\t\t\treturn existing_entity\n\n\t\t# If we have docstring and level is DOCS, we know it was processed at DOCS level\n\t\tif requested_level == LODLevel.DOCS and existing_entity.docstring:\n\t\t\treturn existing_entity\n\n\t# Process synchronously in this case\n\treturn self.process_file_sync(file_path, requested_level)\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.process_repository","title":"process_repository","text":"<pre><code>process_repository(repo_path: Path | None = None) -&gt; int\n</code></pre> <p>Process an entire repository asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>repo_path</code> <code>Path | None</code> <p>Repository path, uses the pipeline's repo path if None</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>Number of files submitted for processing</p> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def process_repository(self, repo_path: Path | None = None) -&gt; int:\n\t\"\"\"\n\tProcess an entire repository asynchronously.\n\n\tArgs:\n\t        repo_path: Repository path, uses the pipeline's repo path if None\n\n\tReturns:\n\t        Number of files submitted for processing\n\n\t\"\"\"\n\ttarget_repo = repo_path or self.repo_path\n\n\t# Get all files in the repository\n\tall_files = []\n\tfor path_obj in target_repo.rglob(\"*\"):\n\t\tif path_obj.is_file() and is_text_file(path_obj):\n\t\t\t# Check against ignored patterns\n\t\t\tshould_ignore = False\n\t\t\tfor pattern in self.ignored_patterns:\n\t\t\t\tif path_obj.match(pattern):\n\t\t\t\t\tshould_ignore = True\n\t\t\t\t\tbreak\n\n\t\t\tif not should_ignore:\n\t\t\t\tall_files.append(path_obj)\n\n\t# Process all files\n\tself.batch_process(all_files)\n\n\treturn len(all_files)\n</code></pre>"},{"location":"api/processor/pipeline/#codemap.processor.pipeline.ProcessingPipeline.get_repository_structure","title":"get_repository_structure","text":"<pre><code>get_repository_structure(\n\troot_path: Path | None = None,\n\tlevel: LODLevel = STRUCTURE,\n) -&gt; dict[str, Any]\n</code></pre> <p>Get a structured representation of the repository.</p> <p>Parameters:</p> Name Type Description Default <code>root_path</code> <code>Path | None</code> <p>Root path to start from, uses pipeline's repo path if None</p> <code>None</code> <code>level</code> <code>LODLevel</code> <p>Level of Detail to use for files</p> <code>STRUCTURE</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Hierarchical structure of the repository with LOD entities</p> Source code in <code>src/codemap/processor/pipeline.py</code> <pre><code>def get_repository_structure(\n\tself, root_path: Path | None = None, level: LODLevel = LODLevel.STRUCTURE\n) -&gt; dict[str, Any]:\n\t\"\"\"\n\tGet a structured representation of the repository.\n\n\tArgs:\n\t        root_path: Root path to start from, uses pipeline's repo path if None\n\t        level: Level of Detail to use for files\n\n\tReturns:\n\t        Hierarchical structure of the repository with LOD entities\n\n\t\"\"\"\n\ttarget_path = root_path or self.repo_path\n\n\t# Start with the basic directory structure\n\tresult = {\"type\": \"directory\", \"name\": target_path.name, \"path\": str(target_path), \"children\": []}\n\n\t# List all items in the directory\n\ttry:\n\t\titems = list(target_path.iterdir())\n\n\t\t# Process directories first\n\t\tfor item in sorted([i for i in items if i.is_dir()], key=lambda x: x.name):\n\t\t\t# Skip ignored directories\n\t\t\tshould_ignore = False\n\t\t\tfor pattern in self.ignored_patterns:\n\t\t\t\tif item.match(pattern):\n\t\t\t\t\tshould_ignore = True\n\t\t\t\t\tbreak\n\n\t\t\tif should_ignore:\n\t\t\t\tcontinue\n\n\t\t\t# Recursively process this directory\n\t\t\tchild_structure = self.get_repository_structure(item, level)\n\t\t\tresult[\"children\"].append(child_structure)\n\n\t\t# Then process files\n\t\tfor item in sorted([i for i in items if i.is_file()], key=lambda x: x.name):\n\t\t\t# Skip ignored files\n\t\t\tshould_ignore = False\n\t\t\tfor pattern in self.ignored_patterns:\n\t\t\t\tif item.match(pattern):\n\t\t\t\t\tshould_ignore = True\n\t\t\t\t\tbreak\n\n\t\t\tif should_ignore:\n\t\t\t\tcontinue\n\n\t\t\t# Get LOD entity for this file\n\t\t\tfile_entity = self.get_lod_entity(item, level)\n\n\t\t\tfile_result = {\"type\": \"file\", \"name\": item.name, \"path\": str(item), \"entity\": file_entity}\n\n\t\t\tresult[\"children\"].append(file_result)\n\n\texcept (PermissionError, FileNotFoundError) as e:\n\t\tlogger.warning(f\"Error processing directory {target_path}: {e}\")\n\n\treturn result\n</code></pre>"},{"location":"api/processor/tree_sitter/","title":"Tree Sitter Overview","text":"<p>Tree-sitter based code analysis.</p> <ul> <li>Analyzer - Tree-sitter based code analysis.</li> <li>Base - Base classes and interfaces for tree-sitter analysis.</li> <li>Languages - Language-specific configurations and handlers for tree-sitter analysis.</li> </ul>"},{"location":"api/processor/tree_sitter/analyzer/","title":"Analyzer","text":"<p>Tree-sitter based code analysis.</p> <p>This module provides functionality for analyzing source code using tree- sitter.</p>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.LANGUAGE_NAMES","title":"LANGUAGE_NAMES  <code>module-attribute</code>","text":"<pre><code>LANGUAGE_NAMES: dict[str, SupportedLanguage] = {\n\t\"python\": \"python\",\n\t\"javascript\": \"javascript\",\n\t\"typescript\": \"typescript\",\n}\n</code></pre>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.get_language_by_extension","title":"get_language_by_extension","text":"<pre><code>get_language_by_extension(file_path: Path) -&gt; str | None\n</code></pre> <p>Get language name from file extension.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the file</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Language name if supported, None otherwise</p> Source code in <code>src/codemap/processor/tree_sitter/analyzer.py</code> <pre><code>def get_language_by_extension(file_path: Path) -&gt; str | None:\n\t\"\"\"\n\tGet language name from file extension.\n\n\tArgs:\n\t    file_path: Path to the file\n\n\tReturns:\n\t    Language name if supported, None otherwise\n\n\t\"\"\"\n\text = file_path.suffix\n\tfor lang, config in LANGUAGE_CONFIGS.items():\n\t\tif ext in config.file_extensions:\n\t\t\treturn lang\n\treturn None\n</code></pre>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.TreeSitterAnalyzer","title":"TreeSitterAnalyzer","text":"<p>Analyzer for source code using tree-sitter.</p> Source code in <code>src/codemap/processor/tree_sitter/analyzer.py</code> <pre><code>class TreeSitterAnalyzer:\n\t\"\"\"Analyzer for source code using tree-sitter.\"\"\"\n\n\tdef __init__(self) -&gt; None:\n\t\t\"\"\"Initialize the tree-sitter analyzer.\"\"\"\n\t\tself.parsers: dict[str, Parser] = {}\n\t\tself._load_parsers()\n\n\tdef _load_parsers(self) -&gt; None:\n\t\t\"\"\"\n\t\tLoad tree-sitter parsers for supported languages.\n\n\t\tThis method attempts to load parsers for all configured languages\n\t\tusing tree-sitter-language-pack. If a language fails to load, it will\n\t\tbe logged but won't prevent other languages from loading.\n\n\t\t\"\"\"\n\t\tself.parsers: dict[str, Parser] = {}\n\t\tfailed_languages: list[tuple[str, str]] = []\n\n\t\tfor lang in LANGUAGE_CONFIGS:\n\t\t\ttry:\n\t\t\t\t# Get the language name for tree-sitter-language-pack\n\t\t\t\tts_lang_name = LANGUAGE_NAMES.get(lang)\n\t\t\t\tif not ts_lang_name:\n\t\t\t\t\tcontinue\n\n\t\t\t\t# Get the language from tree-sitter-language-pack\n\t\t\t\tlanguage: Language = get_language(ts_lang_name)\n\n\t\t\t\t# Create a new parser and set its language\n\t\t\t\tparser: Parser = Parser()\n\t\t\t\tparser.language = language\n\n\t\t\t\tself.parsers[lang] = parser\n\t\t\texcept (ValueError, RuntimeError, ImportError) as e:\n\t\t\t\tfailed_languages.append((lang, str(e)))\n\t\t\t\tlogger.debug(\"Failed to load language %s: %s\", lang, str(e))\n\n\t\tif failed_languages:\n\t\t\tfailed_names = \", \".join(f\"{lang} ({err})\" for lang, err in failed_languages)\n\t\t\tlogger.warning(\"Failed to load parsers for languages: %s\", failed_names)\n\n\tdef get_parser(self, language: str) -&gt; Parser | None:\n\t\t\"\"\"\n\t\tGet the parser for a language.\n\n\t\tArgs:\n\t\t    language: The language to get a parser for\n\n\t\tReturns:\n\t\t    A tree-sitter parser or None if not supported\n\n\t\t\"\"\"\n\t\treturn self.parsers.get(language)\n\n\tdef parse_file(self, file_path: Path, content: str, language: str | None = None) -&gt; tuple[Node | None, str]:\n\t\t\"\"\"\n\t\tParse a file and return its root node and determined language.\n\n\t\tArgs:\n\t\t    file_path: Path to the file to parse\n\t\t    content: Content of the file\n\t\t    language: Optional language override\n\n\t\tReturns:\n\t\t    A tuple containing the parse tree root node (or None if parsing failed)\n\t\t    and the determined language\n\n\t\t\"\"\"\n\t\t# Determine language if not provided\n\t\tif not language:\n\t\t\tlanguage = get_language_by_extension(file_path)\n\t\t\tif not language:\n\t\t\t\tlogger.warning(\"Could not determine language for file %s\", file_path)\n\t\t\t\treturn None, \"\"\n\n\t\t# Get the parser for this language\n\t\tparser = self.get_parser(language)\n\t\tif not parser:\n\t\t\tlogger.warning(\"No parser for language %s\", language)\n\t\t\treturn None, language\n\n\t\ttry:\n\t\t\t# Parse the content using tree-sitter\n\t\t\tcontent_bytes = content.encode(\"utf-8\")\n\t\t\ttree = parser.parse(content_bytes)\n\t\t\treturn tree.root_node, language\n\t\texcept Exception:\n\t\t\tlogger.exception(\"Failed to parse file %s\", file_path)\n\t\t\treturn None, language\n\n\tdef get_syntax_handler(self, language: str) -&gt; LanguageSyntaxHandler | None:\n\t\t\"\"\"\n\t\tGet the syntax handler for a language.\n\n\t\tArgs:\n\t\t    language: The language to get a handler for\n\n\t\tReturns:\n\t\t    A syntax handler or None if not supported\n\n\t\t\"\"\"\n\t\thandler_class = LANGUAGE_HANDLERS.get(language)\n\t\tif not handler_class:\n\t\t\treturn None\n\t\treturn handler_class()\n\n\tdef analyze_node(\n\t\tself,\n\t\tnode: Node,\n\t\tcontent_bytes: bytes,\n\t\tfile_path: Path,\n\t\tlanguage: str,\n\t\thandler: LanguageSyntaxHandler,\n\t\tparent_node: Node | None = None,\n\t) -&gt; dict:\n\t\t\"\"\"\n\t\tAnalyze a tree-sitter node and return structured information.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    content_bytes: Source code content as bytes\n\t\t    file_path: Path to the source file\n\t\t    language: Programming language\n\t\t    handler: Language-specific syntax handler\n\t\t    parent_node: Parent node if any\n\n\t\tReturns:\n\t\t    Dict with node analysis information\n\n\t\t\"\"\"\n\t\t# Check if we should skip this node\n\t\tif handler.should_skip_node(node):\n\t\t\treturn {}\n\n\t\t# Get entity type for this node from the handler\n\t\tentity_type = handler.get_entity_type(node, parent_node, content_bytes)\n\n\t\t# Skip unknown/uninteresting nodes unless they might contain interesting children\n\t\tif entity_type == EntityType.UNKNOWN and not node.named_child_count &gt; 0:\n\t\t\treturn {}\n\n\t\t# Get name and other metadata\n\t\tname = handler.extract_name(node, content_bytes)\n\t\tdocstring_text, docstring_node = handler.find_docstring(node, content_bytes)\n\n\t\t# Get node content\n\t\ttry:\n\t\t\tnode_content = content_bytes[node.start_byte : node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\texcept (UnicodeDecodeError, IndexError):\n\t\t\tnode_content = \"\"\n\n\t\t# Extract dependencies from import statements\n\t\tdependencies = []\n\t\tif entity_type == EntityType.IMPORT:\n\t\t\ttry:\n\t\t\t\tdependencies = handler.extract_imports(node, content_bytes)\n\t\t\texcept (AttributeError, UnicodeDecodeError, IndexError, ValueError) as e:\n\t\t\t\tlogger.warning(\"Failed to extract dependencies: %s\", e)\n\n\t\t# Build result\n\t\tresult = {\n\t\t\t\"type\": entity_type.name if entity_type != EntityType.UNKNOWN else \"UNKNOWN\",\n\t\t\t\"name\": name,\n\t\t\t\"location\": {\n\t\t\t\t\"start_line\": node.start_point[0] + 1,  # Convert to 1-based\n\t\t\t\t\"end_line\": node.end_point[0] + 1,\n\t\t\t\t\"start_col\": node.start_point[1],\n\t\t\t\t\"end_col\": node.end_point[1],\n\t\t\t},\n\t\t\t\"docstring\": docstring_text,\n\t\t\t\"content\": node_content,\n\t\t\t\"children\": [],\n\t\t\t\"language\": language,\n\t\t}\n\n\t\t# Add dependencies only if they exist to keep the output clean\n\t\tif dependencies:\n\t\t\tresult[\"dependencies\"] = dependencies\n\n\t\t# Extract function calls if the entity is a function or method\n\t\tcalls = []\n\t\tif entity_type in (EntityType.FUNCTION, EntityType.METHOD):\n\t\t\tbody_node = handler.get_body_node(node)\n\t\t\tif body_node:\n\t\t\t\ttry:\n\t\t\t\t\tcalls = handler.extract_calls(body_node, content_bytes)\n\t\t\t\texcept (AttributeError, IndexError, UnicodeDecodeError, ValueError) as e:\n\t\t\t\t\tlogger.warning(\"Failed to extract calls for %s: %s\", name or \"&lt;anonymous&gt;\", e)\n\n\t\t# Add calls only if they exist\n\t\tif calls:\n\t\t\tresult[\"calls\"] = calls\n\n\t\t# Process child nodes\n\t\tbody_node = handler.get_body_node(node)\n\t\tchildren_to_process = handler.get_children_to_process(node, body_node)\n\n\t\tfor child in children_to_process:\n\t\t\tif docstring_node and child == docstring_node:\n\t\t\t\tcontinue  # Skip docstring node\n\n\t\t\tchild_result = self.analyze_node(child, content_bytes, file_path, language, handler, node)\n\n\t\t\tif child_result:  # Only add non-empty results\n\t\t\t\tresult[\"children\"].append(child_result)\n\n\t\treturn result\n\n\tdef analyze_file(\n\t\tself,\n\t\tfile_path: Path,\n\t\tcontent: str,\n\t\tlanguage: str | None = None,\n\t) -&gt; dict:\n\t\t\"\"\"\n\t\tAnalyze a file and return its structural information.\n\n\t\tArgs:\n\t\t    file_path: Path to the file to analyze\n\t\t    content: Content of the file\n\t\t    language: Optional language override\n\t\t    git_metadata: Optional Git metadata\n\n\t\tReturns:\n\t\t    Dict with file analysis information\n\n\t\t\"\"\"\n\t\t# Parse the file\n\t\troot_node, determined_language = self.parse_file(file_path, content, language)\n\t\tif not root_node or not determined_language:\n\t\t\treturn {\n\t\t\t\t\"file\": str(file_path),\n\t\t\t\t\"language\": determined_language or \"unknown\",\n\t\t\t\t\"success\": False,\n\t\t\t\t\"error\": \"Failed to parse file\",\n\t\t\t}\n\n\t\t# Get handler for the language\n\t\thandler = self.get_syntax_handler(determined_language)\n\t\tif not handler:\n\t\t\treturn {\n\t\t\t\t\"file\": str(file_path),\n\t\t\t\t\"language\": determined_language,\n\t\t\t\t\"success\": False,\n\t\t\t\t\"error\": f\"No handler for language {determined_language}\",\n\t\t\t}\n\n\t\t# Analyze the root node\n\t\tcontent_bytes = content.encode(\"utf-8\")\n\t\tentity_type = handler.get_entity_type(root_node, None, content_bytes)\n\t\tif entity_type == EntityType.UNKNOWN:\n\t\t\tentity_type = EntityType.MODULE  # Default to MODULE type\n\n\t\t# Extract module-level docstring\n\t\tmodule_description, module_docstring_node = handler.find_docstring(root_node, content_bytes)\n\n\t\t# Create result\n\t\tresult = {\n\t\t\t\"file\": str(file_path),\n\t\t\t\"language\": determined_language,\n\t\t\t\"success\": True,\n\t\t\t\"type\": entity_type.name,\n\t\t\t\"name\": file_path.stem,\n\t\t\t\"location\": {\n\t\t\t\t\"start_line\": root_node.start_point[0] + 1,\n\t\t\t\t\"end_line\": root_node.end_point[0] + 1,\n\t\t\t\t\"start_col\": root_node.start_point[1],\n\t\t\t\t\"end_col\": root_node.end_point[1],\n\t\t\t},\n\t\t\t\"docstring\": module_description,\n\t\t\t\"children\": [],\n\t\t}\n\n\t\t# Process children of the root node\n\t\tchildren_to_process = handler.get_children_to_process(root_node, None)\n\t\tfor child in children_to_process:\n\t\t\t# Skip the module docstring node if found\n\t\t\tif module_docstring_node and child == module_docstring_node:\n\t\t\t\tcontinue\n\n\t\t\tchild_result = self.analyze_node(child, content_bytes, file_path, determined_language, handler)\n\n\t\t\tif child_result:  # Only add non-empty results\n\t\t\t\tresult[\"children\"].append(child_result)\n\n\t\treturn result\n</code></pre>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.TreeSitterAnalyzer.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> <p>Initialize the tree-sitter analyzer.</p> Source code in <code>src/codemap/processor/tree_sitter/analyzer.py</code> <pre><code>def __init__(self) -&gt; None:\n\t\"\"\"Initialize the tree-sitter analyzer.\"\"\"\n\tself.parsers: dict[str, Parser] = {}\n\tself._load_parsers()\n</code></pre>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.TreeSitterAnalyzer.parsers","title":"parsers  <code>instance-attribute</code>","text":"<pre><code>parsers: dict[str, Parser] = {}\n</code></pre>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.TreeSitterAnalyzer.get_parser","title":"get_parser","text":"<pre><code>get_parser(language: str) -&gt; Parser | None\n</code></pre> <p>Get the parser for a language.</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>str</code> <p>The language to get a parser for</p> required <p>Returns:</p> Type Description <code>Parser | None</code> <p>A tree-sitter parser or None if not supported</p> Source code in <code>src/codemap/processor/tree_sitter/analyzer.py</code> <pre><code>def get_parser(self, language: str) -&gt; Parser | None:\n\t\"\"\"\n\tGet the parser for a language.\n\n\tArgs:\n\t    language: The language to get a parser for\n\n\tReturns:\n\t    A tree-sitter parser or None if not supported\n\n\t\"\"\"\n\treturn self.parsers.get(language)\n</code></pre>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.TreeSitterAnalyzer.parse_file","title":"parse_file","text":"<pre><code>parse_file(\n\tfile_path: Path,\n\tcontent: str,\n\tlanguage: str | None = None,\n) -&gt; tuple[Node | None, str]\n</code></pre> <p>Parse a file and return its root node and determined language.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the file to parse</p> required <code>content</code> <code>str</code> <p>Content of the file</p> required <code>language</code> <code>str | None</code> <p>Optional language override</p> <code>None</code> <p>Returns:</p> Type Description <code>Node | None</code> <p>A tuple containing the parse tree root node (or None if parsing failed)</p> <code>str</code> <p>and the determined language</p> Source code in <code>src/codemap/processor/tree_sitter/analyzer.py</code> <pre><code>def parse_file(self, file_path: Path, content: str, language: str | None = None) -&gt; tuple[Node | None, str]:\n\t\"\"\"\n\tParse a file and return its root node and determined language.\n\n\tArgs:\n\t    file_path: Path to the file to parse\n\t    content: Content of the file\n\t    language: Optional language override\n\n\tReturns:\n\t    A tuple containing the parse tree root node (or None if parsing failed)\n\t    and the determined language\n\n\t\"\"\"\n\t# Determine language if not provided\n\tif not language:\n\t\tlanguage = get_language_by_extension(file_path)\n\t\tif not language:\n\t\t\tlogger.warning(\"Could not determine language for file %s\", file_path)\n\t\t\treturn None, \"\"\n\n\t# Get the parser for this language\n\tparser = self.get_parser(language)\n\tif not parser:\n\t\tlogger.warning(\"No parser for language %s\", language)\n\t\treturn None, language\n\n\ttry:\n\t\t# Parse the content using tree-sitter\n\t\tcontent_bytes = content.encode(\"utf-8\")\n\t\ttree = parser.parse(content_bytes)\n\t\treturn tree.root_node, language\n\texcept Exception:\n\t\tlogger.exception(\"Failed to parse file %s\", file_path)\n\t\treturn None, language\n</code></pre>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.TreeSitterAnalyzer.get_syntax_handler","title":"get_syntax_handler","text":"<pre><code>get_syntax_handler(\n\tlanguage: str,\n) -&gt; LanguageSyntaxHandler | None\n</code></pre> <p>Get the syntax handler for a language.</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>str</code> <p>The language to get a handler for</p> required <p>Returns:</p> Type Description <code>LanguageSyntaxHandler | None</code> <p>A syntax handler or None if not supported</p> Source code in <code>src/codemap/processor/tree_sitter/analyzer.py</code> <pre><code>def get_syntax_handler(self, language: str) -&gt; LanguageSyntaxHandler | None:\n\t\"\"\"\n\tGet the syntax handler for a language.\n\n\tArgs:\n\t    language: The language to get a handler for\n\n\tReturns:\n\t    A syntax handler or None if not supported\n\n\t\"\"\"\n\thandler_class = LANGUAGE_HANDLERS.get(language)\n\tif not handler_class:\n\t\treturn None\n\treturn handler_class()\n</code></pre>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.TreeSitterAnalyzer.analyze_node","title":"analyze_node","text":"<pre><code>analyze_node(\n\tnode: Node,\n\tcontent_bytes: bytes,\n\tfile_path: Path,\n\tlanguage: str,\n\thandler: LanguageSyntaxHandler,\n\tparent_node: Node | None = None,\n) -&gt; dict\n</code></pre> <p>Analyze a tree-sitter node and return structured information.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <code>file_path</code> <code>Path</code> <p>Path to the source file</p> required <code>language</code> <code>str</code> <p>Programming language</p> required <code>handler</code> <code>LanguageSyntaxHandler</code> <p>Language-specific syntax handler</p> required <code>parent_node</code> <code>Node | None</code> <p>Parent node if any</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dict with node analysis information</p> Source code in <code>src/codemap/processor/tree_sitter/analyzer.py</code> <pre><code>def analyze_node(\n\tself,\n\tnode: Node,\n\tcontent_bytes: bytes,\n\tfile_path: Path,\n\tlanguage: str,\n\thandler: LanguageSyntaxHandler,\n\tparent_node: Node | None = None,\n) -&gt; dict:\n\t\"\"\"\n\tAnalyze a tree-sitter node and return structured information.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    content_bytes: Source code content as bytes\n\t    file_path: Path to the source file\n\t    language: Programming language\n\t    handler: Language-specific syntax handler\n\t    parent_node: Parent node if any\n\n\tReturns:\n\t    Dict with node analysis information\n\n\t\"\"\"\n\t# Check if we should skip this node\n\tif handler.should_skip_node(node):\n\t\treturn {}\n\n\t# Get entity type for this node from the handler\n\tentity_type = handler.get_entity_type(node, parent_node, content_bytes)\n\n\t# Skip unknown/uninteresting nodes unless they might contain interesting children\n\tif entity_type == EntityType.UNKNOWN and not node.named_child_count &gt; 0:\n\t\treturn {}\n\n\t# Get name and other metadata\n\tname = handler.extract_name(node, content_bytes)\n\tdocstring_text, docstring_node = handler.find_docstring(node, content_bytes)\n\n\t# Get node content\n\ttry:\n\t\tnode_content = content_bytes[node.start_byte : node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\texcept (UnicodeDecodeError, IndexError):\n\t\tnode_content = \"\"\n\n\t# Extract dependencies from import statements\n\tdependencies = []\n\tif entity_type == EntityType.IMPORT:\n\t\ttry:\n\t\t\tdependencies = handler.extract_imports(node, content_bytes)\n\t\texcept (AttributeError, UnicodeDecodeError, IndexError, ValueError) as e:\n\t\t\tlogger.warning(\"Failed to extract dependencies: %s\", e)\n\n\t# Build result\n\tresult = {\n\t\t\"type\": entity_type.name if entity_type != EntityType.UNKNOWN else \"UNKNOWN\",\n\t\t\"name\": name,\n\t\t\"location\": {\n\t\t\t\"start_line\": node.start_point[0] + 1,  # Convert to 1-based\n\t\t\t\"end_line\": node.end_point[0] + 1,\n\t\t\t\"start_col\": node.start_point[1],\n\t\t\t\"end_col\": node.end_point[1],\n\t\t},\n\t\t\"docstring\": docstring_text,\n\t\t\"content\": node_content,\n\t\t\"children\": [],\n\t\t\"language\": language,\n\t}\n\n\t# Add dependencies only if they exist to keep the output clean\n\tif dependencies:\n\t\tresult[\"dependencies\"] = dependencies\n\n\t# Extract function calls if the entity is a function or method\n\tcalls = []\n\tif entity_type in (EntityType.FUNCTION, EntityType.METHOD):\n\t\tbody_node = handler.get_body_node(node)\n\t\tif body_node:\n\t\t\ttry:\n\t\t\t\tcalls = handler.extract_calls(body_node, content_bytes)\n\t\t\texcept (AttributeError, IndexError, UnicodeDecodeError, ValueError) as e:\n\t\t\t\tlogger.warning(\"Failed to extract calls for %s: %s\", name or \"&lt;anonymous&gt;\", e)\n\n\t# Add calls only if they exist\n\tif calls:\n\t\tresult[\"calls\"] = calls\n\n\t# Process child nodes\n\tbody_node = handler.get_body_node(node)\n\tchildren_to_process = handler.get_children_to_process(node, body_node)\n\n\tfor child in children_to_process:\n\t\tif docstring_node and child == docstring_node:\n\t\t\tcontinue  # Skip docstring node\n\n\t\tchild_result = self.analyze_node(child, content_bytes, file_path, language, handler, node)\n\n\t\tif child_result:  # Only add non-empty results\n\t\t\tresult[\"children\"].append(child_result)\n\n\treturn result\n</code></pre>"},{"location":"api/processor/tree_sitter/analyzer/#codemap.processor.tree_sitter.analyzer.TreeSitterAnalyzer.analyze_file","title":"analyze_file","text":"<pre><code>analyze_file(\n\tfile_path: Path,\n\tcontent: str,\n\tlanguage: str | None = None,\n) -&gt; dict\n</code></pre> <p>Analyze a file and return its structural information.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the file to analyze</p> required <code>content</code> <code>str</code> <p>Content of the file</p> required <code>language</code> <code>str | None</code> <p>Optional language override</p> <code>None</code> <code>git_metadata</code> <p>Optional Git metadata</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dict with file analysis information</p> Source code in <code>src/codemap/processor/tree_sitter/analyzer.py</code> <pre><code>def analyze_file(\n\tself,\n\tfile_path: Path,\n\tcontent: str,\n\tlanguage: str | None = None,\n) -&gt; dict:\n\t\"\"\"\n\tAnalyze a file and return its structural information.\n\n\tArgs:\n\t    file_path: Path to the file to analyze\n\t    content: Content of the file\n\t    language: Optional language override\n\t    git_metadata: Optional Git metadata\n\n\tReturns:\n\t    Dict with file analysis information\n\n\t\"\"\"\n\t# Parse the file\n\troot_node, determined_language = self.parse_file(file_path, content, language)\n\tif not root_node or not determined_language:\n\t\treturn {\n\t\t\t\"file\": str(file_path),\n\t\t\t\"language\": determined_language or \"unknown\",\n\t\t\t\"success\": False,\n\t\t\t\"error\": \"Failed to parse file\",\n\t\t}\n\n\t# Get handler for the language\n\thandler = self.get_syntax_handler(determined_language)\n\tif not handler:\n\t\treturn {\n\t\t\t\"file\": str(file_path),\n\t\t\t\"language\": determined_language,\n\t\t\t\"success\": False,\n\t\t\t\"error\": f\"No handler for language {determined_language}\",\n\t\t}\n\n\t# Analyze the root node\n\tcontent_bytes = content.encode(\"utf-8\")\n\tentity_type = handler.get_entity_type(root_node, None, content_bytes)\n\tif entity_type == EntityType.UNKNOWN:\n\t\tentity_type = EntityType.MODULE  # Default to MODULE type\n\n\t# Extract module-level docstring\n\tmodule_description, module_docstring_node = handler.find_docstring(root_node, content_bytes)\n\n\t# Create result\n\tresult = {\n\t\t\"file\": str(file_path),\n\t\t\"language\": determined_language,\n\t\t\"success\": True,\n\t\t\"type\": entity_type.name,\n\t\t\"name\": file_path.stem,\n\t\t\"location\": {\n\t\t\t\"start_line\": root_node.start_point[0] + 1,\n\t\t\t\"end_line\": root_node.end_point[0] + 1,\n\t\t\t\"start_col\": root_node.start_point[1],\n\t\t\t\"end_col\": root_node.end_point[1],\n\t\t},\n\t\t\"docstring\": module_description,\n\t\t\"children\": [],\n\t}\n\n\t# Process children of the root node\n\tchildren_to_process = handler.get_children_to_process(root_node, None)\n\tfor child in children_to_process:\n\t\t# Skip the module docstring node if found\n\t\tif module_docstring_node and child == module_docstring_node:\n\t\t\tcontinue\n\n\t\tchild_result = self.analyze_node(child, content_bytes, file_path, determined_language, handler)\n\n\t\tif child_result:  # Only add non-empty results\n\t\t\tresult[\"children\"].append(child_result)\n\n\treturn result\n</code></pre>"},{"location":"api/processor/tree_sitter/base/","title":"Base","text":"<p>Base classes and interfaces for tree-sitter analysis.</p> <p>This module defines the core data structures and interfaces for tree-sitter analysis. It provides: - Entity type definitions for tree-sitter nodes - Metadata structures for tree-sitter nodes. - Base tree-sitter analysis interface</p>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType","title":"EntityType","text":"<p>               Bases: <code>Enum</code></p> <p>Types of code entities that can be extracted.</p> Source code in <code>src/codemap/processor/tree_sitter/base.py</code> <pre><code>class EntityType(Enum):\n\t\"\"\"Types of code entities that can be extracted.\"\"\"\n\n\t# File-level entities\n\tMODULE = auto()\n\tNAMESPACE = auto()\n\tPACKAGE = auto()\n\n\t# Type definitions\n\tCLASS = auto()\n\tINTERFACE = auto()\n\tPROTOCOL = auto()  # Similar to interface but for structural typing\n\tSTRUCT = auto()\n\tENUM = auto()\n\tTYPE_ALIAS = auto()\n\n\t# Functions and methods\n\tFUNCTION = auto()\n\tMETHOD = auto()\n\tPROPERTY = auto()  # For getter/setter methods\n\tTEST_CASE = auto()\n\tTEST_SUITE = auto()\n\n\t# Variables and constants\n\tVARIABLE = auto()\n\tCONSTANT = auto()\n\tCLASS_FIELD = auto()  # For class-level variables/fields\n\n\t# Code organization\n\tIMPORT = auto()\n\tDECORATOR = auto()\n\n\t# Documentation\n\tCOMMENT = auto()\n\tDOCSTRING = auto()\n\n\t# Special cases\n\tUNKNOWN = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.MODULE","title":"MODULE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MODULE = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.NAMESPACE","title":"NAMESPACE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NAMESPACE = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.PACKAGE","title":"PACKAGE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PACKAGE = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.CLASS","title":"CLASS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CLASS = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.INTERFACE","title":"INTERFACE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INTERFACE = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.PROTOCOL","title":"PROTOCOL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PROTOCOL = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.STRUCT","title":"STRUCT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STRUCT = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.ENUM","title":"ENUM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ENUM = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.TYPE_ALIAS","title":"TYPE_ALIAS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TYPE_ALIAS = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.FUNCTION","title":"FUNCTION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FUNCTION = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.METHOD","title":"METHOD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>METHOD = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.PROPERTY","title":"PROPERTY  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PROPERTY = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.TEST_CASE","title":"TEST_CASE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TEST_CASE = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.TEST_SUITE","title":"TEST_SUITE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TEST_SUITE = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.VARIABLE","title":"VARIABLE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VARIABLE = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.CONSTANT","title":"CONSTANT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CONSTANT = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.CLASS_FIELD","title":"CLASS_FIELD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CLASS_FIELD = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.IMPORT","title":"IMPORT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>IMPORT = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.DECORATOR","title":"DECORATOR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DECORATOR = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.COMMENT","title":"COMMENT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COMMENT = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.DOCSTRING","title":"DOCSTRING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DOCSTRING = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/base/#codemap.processor.tree_sitter.base.EntityType.UNKNOWN","title":"UNKNOWN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UNKNOWN = auto()\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/","title":"Languages Overview","text":"<p>Language-specific configurations and handlers for tree-sitter analysis.</p> <ul> <li>Base - Base configuration for language-specific syntax chunking.</li> <li>Javascript - JavaScript-specific configuration for syntax chunking.</li> <li>Python - Python-specific configuration for syntax chunking.</li> <li>Typescript - TypeScript-specific configuration for syntax chunking.</li> </ul>"},{"location":"api/processor/tree_sitter/languages/base/","title":"Base","text":"<p>Base configuration for language-specific syntax chunking.</p> <p>This module provides the base configuration class for defining how different programming languages map their syntax elements to code chunks.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig","title":"LanguageConfig  <code>dataclass</code>","text":"<p>Configuration for language-specific syntax chunking.</p> <p>This class defines how a specific programming language's syntax elements map to different types of code chunks. Each field is a list of syntax node types that represent that kind of entity in the language's AST.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>@dataclass(frozen=True)\nclass LanguageConfig:\n\t\"\"\"\n\tConfiguration for language-specific syntax chunking.\n\n\tThis class defines how a specific programming language's syntax\n\telements map to different types of code chunks. Each field is a list of\n\tsyntax node types that represent that kind of entity in the language's\n\tAST.\n\n\t\"\"\"\n\n\t# File-level entities\n\tmodule: ClassVar[list[str]]\n\t\"\"\"Node types that represent entire modules/files.\"\"\"\n\n\tnamespace: ClassVar[list[str]]\n\t\"\"\"Node types for namespace/package declarations.\"\"\"\n\n\t# Type definitions\n\tclass_: ClassVar[list[str]]\n\t\"\"\"Node types for class definitions.\"\"\"\n\n\tinterface: ClassVar[list[str]]\n\t\"\"\"Node types for interface definitions.\"\"\"\n\n\tprotocol: ClassVar[list[str]]\n\t\"\"\"Node types for protocol/trait definitions.\"\"\"\n\n\tstruct: ClassVar[list[str]]\n\t\"\"\"Node types for struct definitions.\"\"\"\n\n\tenum: ClassVar[list[str]]\n\t\"\"\"Node types for enum declarations.\"\"\"\n\n\ttype_alias: ClassVar[list[str]]\n\t\"\"\"Node types for type aliases/typedefs.\"\"\"\n\n\t# Functions and methods\n\tfunction: ClassVar[list[str]]\n\t\"\"\"Node types for function declarations.\"\"\"\n\n\tmethod: ClassVar[list[str]]\n\t\"\"\"Node types for method declarations.\"\"\"\n\n\tproperty_def: ClassVar[list[str]]\n\t\"\"\"Node types for property/getter/setter declarations.\"\"\"\n\n\ttest_case: ClassVar[list[str]]\n\t\"\"\"Node types that identify test functions.\"\"\"\n\n\ttest_suite: ClassVar[list[str]]\n\t\"\"\"Node types that identify test classes/suites.\"\"\"\n\n\t# Variables and constants\n\tvariable: ClassVar[list[str]]\n\t\"\"\"Node types for variable declarations.\"\"\"\n\n\tconstant: ClassVar[list[str]]\n\t\"\"\"Node types for constant declarations.\"\"\"\n\n\tclass_field: ClassVar[list[str]]\n\t\"\"\"Node types for class field declarations.\"\"\"\n\n\t# Code organization\n\timport_: ClassVar[list[str]]\n\t\"\"\"Node types for import statements.\"\"\"\n\n\tdecorator: ClassVar[list[str]]\n\t\"\"\"Node types for decorators/annotations.\"\"\"\n\n\t# Documentation\n\tcomment: ClassVar[list[str]]\n\t\"\"\"Node types for general comments.\"\"\"\n\n\tdocstring: ClassVar[list[str]]\n\t\"\"\"Node types for documentation strings.\"\"\"\n\n\t# Language-specific metadata\n\tfile_extensions: ClassVar[list[str]]\n\t\"\"\"File extensions associated with this language (e.g., ['.py', '.pyi']).\"\"\"\n\n\ttree_sitter_name: ClassVar[str] = \"\"\n\t\"\"\"Tree-sitter language identifier.\"\"\"\n\n\t# Optional node types that might be language-specific\n\tdecorators: ClassVar[list[str] | None] = None\n\tclass_fields: ClassVar[list[str] | None] = None\n\n\t@property\n\tdef all_node_types(self) -&gt; set[str]:\n\t\t\"\"\"\n\t\tGet all node types defined in this configuration.\n\n\t\tReturns:\n\t\t    A set of all node types from all categories.\n\n\t\t\"\"\"\n\t\tall_types = set()\n\t\tfor attr in [\n\t\t\tself.module,\n\t\t\tself.namespace,\n\t\t\tself.class_,\n\t\t\tself.interface,\n\t\t\tself.protocol,\n\t\t\tself.struct,\n\t\t\tself.enum,\n\t\t\tself.type_alias,\n\t\t\tself.function,\n\t\t\tself.method,\n\t\t\tself.property_def,\n\t\t\tself.test_case,\n\t\t\tself.test_suite,\n\t\t\tself.variable,\n\t\t\tself.constant,\n\t\t\tself.class_field,\n\t\t\tself.import_,\n\t\t\tself.decorator,\n\t\t\tself.comment,\n\t\t\tself.docstring,\n\t\t\tself.decorators,\n\t\t\tself.class_fields,\n\t\t]:\n\t\t\tif attr:  # Skip None values\n\t\t\t\tall_types.update(attr)\n\t\treturn all_types\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.module","title":"module  <code>class-attribute</code>","text":"<pre><code>module: list[str]\n</code></pre> <p>Node types that represent entire modules/files.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.namespace","title":"namespace  <code>class-attribute</code>","text":"<pre><code>namespace: list[str]\n</code></pre> <p>Node types for namespace/package declarations.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.class_","title":"class_  <code>class-attribute</code>","text":"<pre><code>class_: list[str]\n</code></pre> <p>Node types for class definitions.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.interface","title":"interface  <code>class-attribute</code>","text":"<pre><code>interface: list[str]\n</code></pre> <p>Node types for interface definitions.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: list[str]\n</code></pre> <p>Node types for protocol/trait definitions.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.struct","title":"struct  <code>class-attribute</code>","text":"<pre><code>struct: list[str]\n</code></pre> <p>Node types for struct definitions.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.enum","title":"enum  <code>class-attribute</code>","text":"<pre><code>enum: list[str]\n</code></pre> <p>Node types for enum declarations.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.type_alias","title":"type_alias  <code>class-attribute</code>","text":"<pre><code>type_alias: list[str]\n</code></pre> <p>Node types for type aliases/typedefs.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.function","title":"function  <code>class-attribute</code>","text":"<pre><code>function: list[str]\n</code></pre> <p>Node types for function declarations.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.method","title":"method  <code>class-attribute</code>","text":"<pre><code>method: list[str]\n</code></pre> <p>Node types for method declarations.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.property_def","title":"property_def  <code>class-attribute</code>","text":"<pre><code>property_def: list[str]\n</code></pre> <p>Node types for property/getter/setter declarations.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.test_case","title":"test_case  <code>class-attribute</code>","text":"<pre><code>test_case: list[str]\n</code></pre> <p>Node types that identify test functions.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.test_suite","title":"test_suite  <code>class-attribute</code>","text":"<pre><code>test_suite: list[str]\n</code></pre> <p>Node types that identify test classes/suites.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.variable","title":"variable  <code>class-attribute</code>","text":"<pre><code>variable: list[str]\n</code></pre> <p>Node types for variable declarations.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.constant","title":"constant  <code>class-attribute</code>","text":"<pre><code>constant: list[str]\n</code></pre> <p>Node types for constant declarations.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.class_field","title":"class_field  <code>class-attribute</code>","text":"<pre><code>class_field: list[str]\n</code></pre> <p>Node types for class field declarations.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.import_","title":"import_  <code>class-attribute</code>","text":"<pre><code>import_: list[str]\n</code></pre> <p>Node types for import statements.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.decorator","title":"decorator  <code>class-attribute</code>","text":"<pre><code>decorator: list[str]\n</code></pre> <p>Node types for decorators/annotations.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.comment","title":"comment  <code>class-attribute</code>","text":"<pre><code>comment: list[str]\n</code></pre> <p>Node types for general comments.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.docstring","title":"docstring  <code>class-attribute</code>","text":"<pre><code>docstring: list[str]\n</code></pre> <p>Node types for documentation strings.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.file_extensions","title":"file_extensions  <code>class-attribute</code>","text":"<pre><code>file_extensions: list[str]\n</code></pre> <p>File extensions associated with this language (e.g., ['.py', '.pyi']).</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.tree_sitter_name","title":"tree_sitter_name  <code>class-attribute</code>","text":"<pre><code>tree_sitter_name: str = ''\n</code></pre> <p>Tree-sitter language identifier.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.decorators","title":"decorators  <code>class-attribute</code>","text":"<pre><code>decorators: list[str] | None = None\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.class_fields","title":"class_fields  <code>class-attribute</code>","text":"<pre><code>class_fields: list[str] | None = None\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageConfig.all_node_types","title":"all_node_types  <code>property</code>","text":"<pre><code>all_node_types: set[str]\n</code></pre> <p>Get all node types defined in this configuration.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>A set of all node types from all categories.</p>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler","title":"LanguageSyntaxHandler","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for language-specific syntax handling.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>class LanguageSyntaxHandler(abc.ABC):\n\t\"\"\"Abstract base class for language-specific syntax handling.\"\"\"\n\n\tdef __init__(self, config: LanguageConfig) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize with language configuration.\n\n\t\tArgs:\n\t\t    config: Language-specific configuration\n\n\t\t\"\"\"\n\t\tself.config = config\n\n\t@abc.abstractmethod\n\tdef get_entity_type(self, node: Node, parent: Node | None, content_bytes: bytes) -&gt; EntityType:\n\t\t\"\"\"\n\t\tDetermine the EntityType for a given node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    parent: The parent node (if any)\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    The entity type\n\n\t\t\"\"\"\n\n\t@abc.abstractmethod\n\tdef find_docstring(self, node: Node, content_bytes: bytes) -&gt; tuple[str | None, Node | None]:\n\t\t\"\"\"\n\t\tFind the docstring associated with a definition node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    A tuple containing:\n\t\t    - The extracted docstring text (or None).\n\t\t    - The specific AST node representing the docstring that should be skipped\n\t\t      during child processing (or None).\n\n\t\t\"\"\"\n\n\t@abc.abstractmethod\n\tdef extract_name(self, node: Node, content_bytes: bytes) -&gt; str:\n\t\t\"\"\"\n\t\tExtract the name identifier from a definition node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    The extracted name\n\n\t\t\"\"\"\n\n\t@abc.abstractmethod\n\tdef get_body_node(self, node: Node) -&gt; Node | None:\n\t\t\"\"\"\n\t\tGet the node representing the 'body' of a definition.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\n\t\tReturns:\n\t\t    The body node if available, None otherwise\n\n\t\t\"\"\"\n\n\t@abc.abstractmethod\n\tdef get_children_to_process(self, node: Node, body_node: Node | None) -&gt; list[Node]:\n\t\t\"\"\"\n\t\tGet the list of child nodes that should be recursively processed.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    body_node: The body node if available\n\n\t\tReturns:\n\t\t    List of child nodes to process\n\n\t\t\"\"\"\n\n\t@abc.abstractmethod\n\tdef should_skip_node(self, node: Node) -&gt; bool:\n\t\t\"\"\"\n\t\tDetermine if a node should be skipped entirely during processing.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\n\t\tReturns:\n\t\t    True if the node should be skipped\n\n\t\t\"\"\"\n\n\t@abc.abstractmethod\n\tdef extract_imports(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\t\"\"\"\n\t\tExtract imported dependency names from an import node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node (should be an import type)\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    List of imported names\n\n\t\t\"\"\"\n\n\t@abc.abstractmethod\n\tdef extract_calls(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\t\"\"\"\n\t\tExtract names of functions/methods called within a node's scope.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node (e.g., function/method body)\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    List of called function/method names\n\n\t\t\"\"\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler.__init__","title":"__init__","text":"<pre><code>__init__(config: LanguageConfig) -&gt; None\n</code></pre> <p>Initialize with language configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LanguageConfig</code> <p>Language-specific configuration</p> required Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>def __init__(self, config: LanguageConfig) -&gt; None:\n\t\"\"\"\n\tInitialize with language configuration.\n\n\tArgs:\n\t    config: Language-specific configuration\n\n\t\"\"\"\n\tself.config = config\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler.get_entity_type","title":"get_entity_type  <code>abstractmethod</code>","text":"<pre><code>get_entity_type(\n\tnode: Node, parent: Node | None, content_bytes: bytes\n) -&gt; EntityType\n</code></pre> <p>Determine the EntityType for a given node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>parent</code> <code>Node | None</code> <p>The parent node (if any)</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>EntityType</code> <p>The entity type</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>@abc.abstractmethod\ndef get_entity_type(self, node: Node, parent: Node | None, content_bytes: bytes) -&gt; EntityType:\n\t\"\"\"\n\tDetermine the EntityType for a given node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    parent: The parent node (if any)\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    The entity type\n\n\t\"\"\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler.find_docstring","title":"find_docstring  <code>abstractmethod</code>","text":"<pre><code>find_docstring(\n\tnode: Node, content_bytes: bytes\n) -&gt; tuple[str | None, Node | None]\n</code></pre> <p>Find the docstring associated with a definition node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>A tuple containing:</p> <code>Node | None</code> <ul> <li>The extracted docstring text (or None).</li> </ul> <code>tuple[str | None, Node | None]</code> <ul> <li>The specific AST node representing the docstring that should be skipped during child processing (or None).</li> </ul> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>@abc.abstractmethod\ndef find_docstring(self, node: Node, content_bytes: bytes) -&gt; tuple[str | None, Node | None]:\n\t\"\"\"\n\tFind the docstring associated with a definition node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    A tuple containing:\n\t    - The extracted docstring text (or None).\n\t    - The specific AST node representing the docstring that should be skipped\n\t      during child processing (or None).\n\n\t\"\"\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler.extract_name","title":"extract_name  <code>abstractmethod</code>","text":"<pre><code>extract_name(node: Node, content_bytes: bytes) -&gt; str\n</code></pre> <p>Extract the name identifier from a definition node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>str</code> <p>The extracted name</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>@abc.abstractmethod\ndef extract_name(self, node: Node, content_bytes: bytes) -&gt; str:\n\t\"\"\"\n\tExtract the name identifier from a definition node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    The extracted name\n\n\t\"\"\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler.get_body_node","title":"get_body_node  <code>abstractmethod</code>","text":"<pre><code>get_body_node(node: Node) -&gt; Node | None\n</code></pre> <p>Get the node representing the 'body' of a definition.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <p>Returns:</p> Type Description <code>Node | None</code> <p>The body node if available, None otherwise</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>@abc.abstractmethod\ndef get_body_node(self, node: Node) -&gt; Node | None:\n\t\"\"\"\n\tGet the node representing the 'body' of a definition.\n\n\tArgs:\n\t    node: The tree-sitter node\n\n\tReturns:\n\t    The body node if available, None otherwise\n\n\t\"\"\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler.get_children_to_process","title":"get_children_to_process  <code>abstractmethod</code>","text":"<pre><code>get_children_to_process(\n\tnode: Node, body_node: Node | None\n) -&gt; list[Node]\n</code></pre> <p>Get the list of child nodes that should be recursively processed.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>body_node</code> <code>Node | None</code> <p>The body node if available</p> required <p>Returns:</p> Type Description <code>list[Node]</code> <p>List of child nodes to process</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>@abc.abstractmethod\ndef get_children_to_process(self, node: Node, body_node: Node | None) -&gt; list[Node]:\n\t\"\"\"\n\tGet the list of child nodes that should be recursively processed.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    body_node: The body node if available\n\n\tReturns:\n\t    List of child nodes to process\n\n\t\"\"\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler.should_skip_node","title":"should_skip_node  <code>abstractmethod</code>","text":"<pre><code>should_skip_node(node: Node) -&gt; bool\n</code></pre> <p>Determine if a node should be skipped entirely during processing.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the node should be skipped</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>@abc.abstractmethod\ndef should_skip_node(self, node: Node) -&gt; bool:\n\t\"\"\"\n\tDetermine if a node should be skipped entirely during processing.\n\n\tArgs:\n\t    node: The tree-sitter node\n\n\tReturns:\n\t    True if the node should be skipped\n\n\t\"\"\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler.extract_imports","title":"extract_imports  <code>abstractmethod</code>","text":"<pre><code>extract_imports(\n\tnode: Node, content_bytes: bytes\n) -&gt; list[str]\n</code></pre> <p>Extract imported dependency names from an import node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node (should be an import type)</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of imported names</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>@abc.abstractmethod\ndef extract_imports(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\"\"\"\n\tExtract imported dependency names from an import node.\n\n\tArgs:\n\t    node: The tree-sitter node (should be an import type)\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    List of imported names\n\n\t\"\"\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.LanguageSyntaxHandler.extract_calls","title":"extract_calls  <code>abstractmethod</code>","text":"<pre><code>extract_calls(\n\tnode: Node, content_bytes: bytes\n) -&gt; list[str]\n</code></pre> <p>Extract names of functions/methods called within a node's scope.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node (e.g., function/method body)</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of called function/method names</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>@abc.abstractmethod\ndef extract_calls(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\"\"\"\n\tExtract names of functions/methods called within a node's scope.\n\n\tArgs:\n\t    node: The tree-sitter node (e.g., function/method body)\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    List of called function/method names\n\n\t\"\"\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.PythonConfig","title":"PythonConfig  <code>dataclass</code>","text":"<p>               Bases: <code>LanguageConfig</code></p> <p>Configuration for Python language.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>class PythonConfig(LanguageConfig):\n\t\"\"\"Configuration for Python language.\"\"\"\n\n\tmodule: ClassVar[list[str]] = [\"module\"]\n\tclass_: ClassVar[list[str]] = [\"class_definition\"]\n\tfunction: ClassVar[list[str]] = [\"function_definition\"]\n\tproperty_def: ClassVar[list[str]] = [\"decorated_definition\"]\n\tstruct: ClassVar[list[str]] = []\n\tdocstring: ClassVar[list[str]] = [\"string\"]\n\tfile_extensions: ClassVar[list[str]] = [\".py\", \".pyi\"]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.PythonConfig.module","title":"module  <code>class-attribute</code>","text":"<pre><code>module: list[str] = ['module']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.PythonConfig.class_","title":"class_  <code>class-attribute</code>","text":"<pre><code>class_: list[str] = ['class_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.PythonConfig.function","title":"function  <code>class-attribute</code>","text":"<pre><code>function: list[str] = ['function_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.PythonConfig.property_def","title":"property_def  <code>class-attribute</code>","text":"<pre><code>property_def: list[str] = ['decorated_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.PythonConfig.struct","title":"struct  <code>class-attribute</code>","text":"<pre><code>struct: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.PythonConfig.docstring","title":"docstring  <code>class-attribute</code>","text":"<pre><code>docstring: list[str] = ['string']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.PythonConfig.file_extensions","title":"file_extensions  <code>class-attribute</code>","text":"<pre><code>file_extensions: list[str] = ['.py', '.pyi']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.JavaScriptConfig","title":"JavaScriptConfig  <code>dataclass</code>","text":"<p>               Bases: <code>LanguageConfig</code></p> <p>Configuration for JavaScript language.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>class JavaScriptConfig(LanguageConfig):\n\t\"\"\"Configuration for JavaScript language.\"\"\"\n\n\tmodule: ClassVar[list[str]] = [\"program\"]\n\tclass_: ClassVar[list[str]] = [\"class_declaration\", \"class\"]\n\tfunction: ClassVar[list[str]] = [\"function_declaration\", \"method_definition\", \"function\"]\n\tproperty_def: ClassVar[list[str]] = [\"property_definition\", \"property_identifier\"]\n\tstruct: ClassVar[list[str]] = []\n\tdocstring: ClassVar[list[str]] = [\"comment\"]\n\tfile_extensions: ClassVar[list[str]] = [\".js\", \".jsx\"]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.JavaScriptConfig.module","title":"module  <code>class-attribute</code>","text":"<pre><code>module: list[str] = ['program']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.JavaScriptConfig.class_","title":"class_  <code>class-attribute</code>","text":"<pre><code>class_: list[str] = ['class_declaration', 'class']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.JavaScriptConfig.function","title":"function  <code>class-attribute</code>","text":"<pre><code>function: list[str] = [\n\t\"function_declaration\",\n\t\"method_definition\",\n\t\"function\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.JavaScriptConfig.property_def","title":"property_def  <code>class-attribute</code>","text":"<pre><code>property_def: list[str] = [\n\t\"property_definition\",\n\t\"property_identifier\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.JavaScriptConfig.struct","title":"struct  <code>class-attribute</code>","text":"<pre><code>struct: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.JavaScriptConfig.docstring","title":"docstring  <code>class-attribute</code>","text":"<pre><code>docstring: list[str] = ['comment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.JavaScriptConfig.file_extensions","title":"file_extensions  <code>class-attribute</code>","text":"<pre><code>file_extensions: list[str] = ['.js', '.jsx']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.TypeScriptConfig","title":"TypeScriptConfig  <code>dataclass</code>","text":"<p>               Bases: <code>LanguageConfig</code></p> <p>Configuration for TypeScript language.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>class TypeScriptConfig(LanguageConfig):\n\t\"\"\"Configuration for TypeScript language.\"\"\"\n\n\tmodule: ClassVar[list[str]] = [\"program\"]\n\tclass_: ClassVar[list[str]] = [\"class_declaration\", \"class\"]\n\tfunction: ClassVar[list[str]] = [\"function_declaration\", \"method_definition\", \"function\"]\n\tproperty_def: ClassVar[list[str]] = [\"property_definition\", \"property_identifier\"]\n\tstruct: ClassVar[list[str]] = []\n\tdocstring: ClassVar[list[str]] = [\"comment\"]\n\tfile_extensions: ClassVar[list[str]] = [\".ts\", \".tsx\"]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.TypeScriptConfig.module","title":"module  <code>class-attribute</code>","text":"<pre><code>module: list[str] = ['program']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.TypeScriptConfig.class_","title":"class_  <code>class-attribute</code>","text":"<pre><code>class_: list[str] = ['class_declaration', 'class']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.TypeScriptConfig.function","title":"function  <code>class-attribute</code>","text":"<pre><code>function: list[str] = [\n\t\"function_declaration\",\n\t\"method_definition\",\n\t\"function\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.TypeScriptConfig.property_def","title":"property_def  <code>class-attribute</code>","text":"<pre><code>property_def: list[str] = [\n\t\"property_definition\",\n\t\"property_identifier\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.TypeScriptConfig.struct","title":"struct  <code>class-attribute</code>","text":"<pre><code>struct: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.TypeScriptConfig.docstring","title":"docstring  <code>class-attribute</code>","text":"<pre><code>docstring: list[str] = ['comment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.TypeScriptConfig.file_extensions","title":"file_extensions  <code>class-attribute</code>","text":"<pre><code>file_extensions: list[str] = ['.ts', '.tsx']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.RustConfig","title":"RustConfig  <code>dataclass</code>","text":"<p>               Bases: <code>LanguageConfig</code></p> <p>Configuration for Rust language.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>class RustConfig(LanguageConfig):\n\t\"\"\"Configuration for Rust language.\"\"\"\n\n\tmodule: ClassVar[list[str]] = [\"source_file\"]\n\tclass_: ClassVar[list[str]] = [\"impl_item\"]\n\tfunction: ClassVar[list[str]] = [\"function_item\"]\n\tproperty_def: ClassVar[list[str]] = []\n\tstruct: ClassVar[list[str]] = [\"struct_item\"]\n\tdocstring: ClassVar[list[str]] = [\"line_comment\", \"block_comment\"]\n\tfile_extensions: ClassVar[list[str]] = [\".rs\"]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.RustConfig.module","title":"module  <code>class-attribute</code>","text":"<pre><code>module: list[str] = ['source_file']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.RustConfig.class_","title":"class_  <code>class-attribute</code>","text":"<pre><code>class_: list[str] = ['impl_item']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.RustConfig.function","title":"function  <code>class-attribute</code>","text":"<pre><code>function: list[str] = ['function_item']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.RustConfig.property_def","title":"property_def  <code>class-attribute</code>","text":"<pre><code>property_def: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.RustConfig.struct","title":"struct  <code>class-attribute</code>","text":"<pre><code>struct: list[str] = ['struct_item']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.RustConfig.docstring","title":"docstring  <code>class-attribute</code>","text":"<pre><code>docstring: list[str] = ['line_comment', 'block_comment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.RustConfig.file_extensions","title":"file_extensions  <code>class-attribute</code>","text":"<pre><code>file_extensions: list[str] = ['.rs']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.GoConfig","title":"GoConfig  <code>dataclass</code>","text":"<p>               Bases: <code>LanguageConfig</code></p> <p>Configuration for Go language.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/base.py</code> <pre><code>class GoConfig(LanguageConfig):\n\t\"\"\"Configuration for Go language.\"\"\"\n\n\tmodule: ClassVar[list[str]] = [\"source_file\"]\n\tclass_: ClassVar[list[str]] = [\"type_declaration\"]\n\tfunction: ClassVar[list[str]] = [\"function_declaration\"]\n\tproperty_def: ClassVar[list[str]] = []\n\tstruct: ClassVar[list[str]] = [\"struct_type\"]\n\tdocstring: ClassVar[list[str]] = [\"comment\"]\n\tfile_extensions: ClassVar[list[str]] = [\".go\"]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.GoConfig.module","title":"module  <code>class-attribute</code>","text":"<pre><code>module: list[str] = ['source_file']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.GoConfig.class_","title":"class_  <code>class-attribute</code>","text":"<pre><code>class_: list[str] = ['type_declaration']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.GoConfig.function","title":"function  <code>class-attribute</code>","text":"<pre><code>function: list[str] = ['function_declaration']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.GoConfig.property_def","title":"property_def  <code>class-attribute</code>","text":"<pre><code>property_def: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.GoConfig.struct","title":"struct  <code>class-attribute</code>","text":"<pre><code>struct: list[str] = ['struct_type']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.GoConfig.docstring","title":"docstring  <code>class-attribute</code>","text":"<pre><code>docstring: list[str] = ['comment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/base/#codemap.processor.tree_sitter.languages.base.GoConfig.file_extensions","title":"file_extensions  <code>class-attribute</code>","text":"<pre><code>file_extensions: list[str] = ['.go']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/","title":"Javascript","text":"<p>JavaScript-specific configuration for syntax chunking.</p>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig","title":"JavaScriptConfig  <code>dataclass</code>","text":"<p>               Bases: <code>LanguageConfig</code></p> <p>JavaScript-specific syntax chunking configuration.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>class JavaScriptConfig(LanguageConfig):\n\t\"\"\"JavaScript-specific syntax chunking configuration.\"\"\"\n\n\t# File-level entities\n\tmodule: ClassVar[list[str]] = [\"program\"]\n\tnamespace: ClassVar[list[str]] = [\"export_statement\"]  # Using export as namespace indicator\n\n\t# Type definitions\n\tclass_: ClassVar[list[str]] = [\"class_declaration\", \"class\"]\n\tinterface: ClassVar[list[str]] = []  # Pure JS doesn't have interfaces\n\tprotocol: ClassVar[list[str]] = []  # Pure JS doesn't have protocols\n\tstruct: ClassVar[list[str]] = []  # Pure JS doesn't have structs\n\tenum: ClassVar[list[str]] = []  # Pure JS doesn't have enums\n\ttype_alias: ClassVar[list[str]] = []  # Pure JS doesn't have type aliases\n\n\t# Functions and methods\n\tfunction: ClassVar[list[str]] = [\n\t\t\"function_declaration\",\n\t\t\"function\",\n\t\t\"arrow_function\",\n\t\t\"generator_function_declaration\",\n\t]\n\tmethod: ClassVar[list[str]] = [\"method_definition\"]\n\tproperty_def: ClassVar[list[str]] = [\"property_identifier\", \"public_field_definition\"]\n\ttest_case: ClassVar[list[str]] = [\"call_expression\"]  # Special detection for test frameworks\n\ttest_suite: ClassVar[list[str]] = [\"call_expression\"]  # Special detection for test frameworks\n\n\t# Variables and constants\n\tvariable: ClassVar[list[str]] = [\"variable_declaration\", \"lexical_declaration\"]\n\tconstant: ClassVar[list[str]] = [\"variable_declaration\", \"lexical_declaration\"]  # const declarations\n\tclass_field: ClassVar[list[str]] = [\"public_field_definition\"]\n\n\t# Code organization\n\timport_: ClassVar[list[str]] = [\"import_statement\"]\n\tdecorator: ClassVar[list[str]] = [\"decorator\"]\n\n\t# Documentation\n\tcomment: ClassVar[list[str]] = [\"comment\"]\n\tdocstring: ClassVar[list[str]] = [\"comment\"]  # JS uses comments for documentation\n\n\tfile_extensions: ClassVar[list[str]] = [\".js\", \".jsx\", \".mjs\", \".cjs\"]\n\ttree_sitter_name: ClassVar[str] = \"javascript\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.module","title":"module  <code>class-attribute</code>","text":"<pre><code>module: list[str] = ['program']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.namespace","title":"namespace  <code>class-attribute</code>","text":"<pre><code>namespace: list[str] = ['export_statement']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.class_","title":"class_  <code>class-attribute</code>","text":"<pre><code>class_: list[str] = ['class_declaration', 'class']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.interface","title":"interface  <code>class-attribute</code>","text":"<pre><code>interface: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.struct","title":"struct  <code>class-attribute</code>","text":"<pre><code>struct: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.enum","title":"enum  <code>class-attribute</code>","text":"<pre><code>enum: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.type_alias","title":"type_alias  <code>class-attribute</code>","text":"<pre><code>type_alias: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.function","title":"function  <code>class-attribute</code>","text":"<pre><code>function: list[str] = [\n\t\"function_declaration\",\n\t\"function\",\n\t\"arrow_function\",\n\t\"generator_function_declaration\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.method","title":"method  <code>class-attribute</code>","text":"<pre><code>method: list[str] = ['method_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.property_def","title":"property_def  <code>class-attribute</code>","text":"<pre><code>property_def: list[str] = [\n\t\"property_identifier\",\n\t\"public_field_definition\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.test_case","title":"test_case  <code>class-attribute</code>","text":"<pre><code>test_case: list[str] = ['call_expression']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.test_suite","title":"test_suite  <code>class-attribute</code>","text":"<pre><code>test_suite: list[str] = ['call_expression']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.variable","title":"variable  <code>class-attribute</code>","text":"<pre><code>variable: list[str] = [\n\t\"variable_declaration\",\n\t\"lexical_declaration\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.constant","title":"constant  <code>class-attribute</code>","text":"<pre><code>constant: list[str] = [\n\t\"variable_declaration\",\n\t\"lexical_declaration\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.class_field","title":"class_field  <code>class-attribute</code>","text":"<pre><code>class_field: list[str] = ['public_field_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.import_","title":"import_  <code>class-attribute</code>","text":"<pre><code>import_: list[str] = ['import_statement']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.decorator","title":"decorator  <code>class-attribute</code>","text":"<pre><code>decorator: list[str] = ['decorator']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.comment","title":"comment  <code>class-attribute</code>","text":"<pre><code>comment: list[str] = ['comment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.docstring","title":"docstring  <code>class-attribute</code>","text":"<pre><code>docstring: list[str] = ['comment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.file_extensions","title":"file_extensions  <code>class-attribute</code>","text":"<pre><code>file_extensions: list[str] = [\".js\", \".jsx\", \".mjs\", \".cjs\"]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptConfig.tree_sitter_name","title":"tree_sitter_name  <code>class-attribute</code>","text":"<pre><code>tree_sitter_name: str = 'javascript'\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JAVASCRIPT_CONFIG","title":"JAVASCRIPT_CONFIG  <code>module-attribute</code>","text":"<pre><code>JAVASCRIPT_CONFIG = JavaScriptConfig()\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptSyntaxHandler","title":"JavaScriptSyntaxHandler","text":"<p>               Bases: <code>LanguageSyntaxHandler</code></p> <p>JavaScript-specific syntax handling logic.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>class JavaScriptSyntaxHandler(LanguageSyntaxHandler):\n\t\"\"\"JavaScript-specific syntax handling logic.\"\"\"\n\n\tdef __init__(self) -&gt; None:\n\t\t\"\"\"Initialize with JavaScript configuration.\"\"\"\n\t\tsuper().__init__(JAVASCRIPT_CONFIG)\n\n\tdef get_entity_type(self, node: Node, parent: Node | None, content_bytes: bytes) -&gt; EntityType:\n\t\t\"\"\"\n\t\tDetermine the EntityType for a JavaScript node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    parent: The parent node (if any)\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    The entity type\n\n\t\t\"\"\"\n\t\tnode_type = node.type\n\t\tlogger.debug(\n\t\t\t\"Getting entity type for JavaScript node: type=%s, parent_type=%s\",\n\t\t\tnode_type,\n\t\t\tparent.type if parent else None,\n\t\t)\n\n\t\t# Module-level\n\t\tif node_type in self.config.module:\n\t\t\treturn EntityType.MODULE\n\t\tif node_type in self.config.namespace:\n\t\t\treturn EntityType.NAMESPACE\n\n\t\t# Documentation\n\t\tif node_type in self.config.comment:\n\t\t\t# Check if this is a JSDoc comment (starts with /**)\n\t\t\tif self._is_jsdoc_comment(node, content_bytes):\n\t\t\t\treturn EntityType.DOCSTRING\n\t\t\treturn EntityType.COMMENT\n\n\t\t# Type definitions\n\t\tif node_type in self.config.class_:\n\t\t\treturn EntityType.CLASS\n\n\t\t# Functions and methods\n\t\tif node_type in self.config.function:\n\t\t\t# Check if this is a test function (for frameworks like Jest, Mocha)\n\t\t\tif self._is_test_function(node, content_bytes):\n\t\t\t\treturn EntityType.TEST_CASE\n\t\t\treturn EntityType.FUNCTION\n\n\t\tif node_type in self.config.method:\n\t\t\treturn EntityType.METHOD\n\n\t\t# Check for test suite declarations (describe blocks in Jest/Mocha)\n\t\tif node_type in self.config.test_suite and self._is_test_suite(node, content_bytes):\n\t\t\treturn EntityType.TEST_SUITE\n\n\t\t# Property definitions\n\t\tif node_type in self.config.property_def:\n\t\t\treturn EntityType.PROPERTY\n\n\t\t# Variables and constants\n\t\tif node_type in self.config.variable:\n\t\t\t# Check if it's a const declaration\n\t\t\tif self._is_constant(node, content_bytes):\n\t\t\t\treturn EntityType.CONSTANT\n\t\t\treturn EntityType.VARIABLE\n\n\t\t# Class fields\n\t\tif node_type in self.config.class_field:\n\t\t\treturn EntityType.CLASS_FIELD\n\n\t\t# Code organization\n\t\tif node_type in self.config.import_:\n\t\t\treturn EntityType.IMPORT\n\n\t\treturn EntityType.UNKNOWN\n\n\tdef _is_jsdoc_comment(self, node: Node, content_bytes: bytes) -&gt; bool:\n\t\t\"\"\"\n\t\tCheck if a comment node is a JSDoc comment.\n\n\t\tArgs:\n\t\t    node: The comment node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    True if the node is a JSDoc comment\n\n\t\t\"\"\"\n\t\tif node.type != \"comment\":\n\t\t\treturn False\n\n\t\ttry:\n\t\t\tcomment_text = content_bytes[node.start_byte : node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\treturn comment_text.startswith(\"/**\") and comment_text.endswith(\"*/\")\n\t\texcept (UnicodeDecodeError, IndexError):\n\t\t\treturn False\n\n\tdef _is_constant(self, node: Node, content_bytes: bytes) -&gt; bool:\n\t\t\"\"\"\n\t\tCheck if a variable declaration is a constant.\n\n\t\tArgs:\n\t\t    node: The variable declaration node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    True if the node is a constant declaration\n\n\t\t\"\"\"\n\t\tif node.type not in [\"variable_declaration\", \"lexical_declaration\"]:\n\t\t\treturn False\n\n\t\ttry:\n\t\t\tdecl_text = content_bytes[node.start_byte : node.start_byte + 5].decode(\"utf-8\", errors=\"ignore\")\n\t\t\treturn decl_text.startswith(\"const\")\n\t\texcept (UnicodeDecodeError, IndexError):\n\t\t\treturn False\n\n\tdef _is_test_function(self, node: Node, content_bytes: bytes) -&gt; bool:\n\t\t\"\"\"\n\t\tCheck if a function is a test function.\n\n\t\tArgs:\n\t\t    node: The function node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    True if the node is a test function\n\n\t\t\"\"\"\n\t\tif node.type == \"call_expression\":\n\t\t\tcallee = node.child_by_field_name(\"function\")\n\t\t\tif callee:\n\t\t\t\ttry:\n\t\t\t\t\tcallee_text = content_bytes[callee.start_byte : callee.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\t\treturn callee_text in [\"it\", \"test\"]\n\t\t\t\texcept (UnicodeDecodeError, IndexError):\n\t\t\t\t\tpass\n\t\treturn False\n\n\tdef _is_test_suite(self, node: Node, content_bytes: bytes) -&gt; bool:\n\t\t\"\"\"\n\t\tCheck if a node is a test suite declaration.\n\n\t\tArgs:\n\t\t    node: The node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    True if the node is a test suite declaration\n\n\t\t\"\"\"\n\t\tif node.type == \"call_expression\":\n\t\t\tcallee = node.child_by_field_name(\"function\")\n\t\t\tif callee:\n\t\t\t\ttry:\n\t\t\t\t\tcallee_text = content_bytes[callee.start_byte : callee.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\t\treturn callee_text == \"describe\"\n\t\t\t\texcept (UnicodeDecodeError, IndexError):\n\t\t\t\t\tpass\n\t\treturn False\n\n\tdef find_docstring(self, node: Node, content_bytes: bytes) -&gt; tuple[str | None, Node | None]:\n\t\t\"\"\"\n\t\tFind the docstring associated with a definition node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    A tuple containing:\n\t\t    - The extracted docstring text (or None).\n\t\t    - The specific AST node representing the docstring (or None).\n\n\t\t\"\"\"\n\t\t# For functions, classes, and other definition nodes\n\t\tparent_node = node.parent\n\n\t\t# Look for JSDoc comments immediately preceding the node\n\t\tif parent_node:\n\t\t\tindex = None\n\t\t\tfor i, child in enumerate(parent_node.children):\n\t\t\t\tif child == node:\n\t\t\t\t\tindex = i\n\t\t\t\t\tbreak\n\n\t\t\tif index is not None and index &gt; 0:\n\t\t\t\tprev_node = parent_node.children[index - 1]\n\t\t\t\tif prev_node.type == \"comment\" and self._is_jsdoc_comment(prev_node, content_bytes):\n\t\t\t\t\ttry:\n\t\t\t\t\t\tcomment_text = content_bytes[prev_node.start_byte : prev_node.end_byte].decode(\n\t\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t\t)\n\t\t\t\t\t\t# Clean JSDoc format: remove /** */ and trim\n\t\t\t\t\t\tcomment_text = comment_text.strip()\n\t\t\t\t\t\tcomment_text = comment_text.removeprefix(\"/**\")\n\t\t\t\t\t\tcomment_text = comment_text.removesuffix(\"*/\")\n\t\t\t\t\t\treturn comment_text.strip(), prev_node\n\t\t\t\t\texcept (UnicodeDecodeError, IndexError) as e:\n\t\t\t\t\t\tlogger.warning(\"Failed to decode JavaScript comment: %s\", e)\n\n\t\treturn None, None\n\n\tdef extract_name(self, node: Node, content_bytes: bytes) -&gt; str:\n\t\t\"\"\"\n\t\tExtract the name identifier from a definition node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    The extracted name\n\n\t\t\"\"\"\n\t\t# Try to find the name field based on node type\n\t\tname_node = None\n\n\t\tif node.type in [\"function_declaration\", \"class_declaration\", \"method_definition\"]:\n\t\t\tname_node = node.child_by_field_name(\"name\")\n\t\telif node.type == \"property_identifier\":\n\t\t\tname_node = node\n\t\telif node.type in [\"variable_declaration\", \"lexical_declaration\"]:\n\t\t\t# Get the first declarator and its name\n\t\t\tdeclarator = node.child_by_field_name(\"declarations\")\n\t\t\tif declarator and declarator.named_child_count &gt; 0:\n\t\t\t\tfirst_declarator = declarator.named_children[0]\n\t\t\t\tname_node = first_declarator.child_by_field_name(\"name\")\n\t\telif node.type == \"public_field_definition\":\n\t\t\tname_node = node.child_by_field_name(\"name\")\n\n\t\tif name_node:\n\t\t\ttry:\n\t\t\t\treturn content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\t\t\tlogger.warning(\"Failed to decode JavaScript name: %s\", e)\n\t\t\t\treturn f\"&lt;decoding-error-{node.type}&gt;\"\n\n\t\t# For call expressions that represent tests or suites\n\t\tif node.type == \"call_expression\":\n\t\t\tcallee = node.child_by_field_name(\"function\")\n\t\t\targuments = node.child_by_field_name(\"arguments\")\n\n\t\t\tif callee and arguments and arguments.named_child_count &gt; 0:\n\t\t\t\t# First argument is typically the test/suite name\n\t\t\t\tfirst_arg = arguments.named_children[0]\n\t\t\t\tif first_arg.type == \"string\":\n\t\t\t\t\ttry:\n\t\t\t\t\t\tname = content_bytes[first_arg.start_byte : first_arg.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\t\t\t# Remove quotes\n\t\t\t\t\t\treturn name.strip(\"\\\"'\")\n\t\t\t\t\texcept (UnicodeDecodeError, IndexError):\n\t\t\t\t\t\tpass\n\n\t\treturn f\"&lt;anonymous-{node.type}&gt;\"\n\n\tdef get_body_node(self, node: Node) -&gt; Node | None:\n\t\t\"\"\"\n\t\tGet the node representing the 'body' of a definition.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\n\t\tReturns:\n\t\t    The body node if available, None otherwise\n\n\t\t\"\"\"\n\t\t# Different fields based on node type\n\t\tif node.type in [\"function_declaration\", \"method_definition\", \"class_declaration\"]:\n\t\t\treturn node.child_by_field_name(\"body\")\n\t\tif node.type in [\"arrow_function\"]:\n\t\t\tbody = node.child_by_field_name(\"body\")\n\t\t\t# Arrow functions can have expression bodies or block bodies\n\t\t\tif body and body.type != \"statement_block\":\n\t\t\t\treturn None  # Expression bodies don't have children to process\n\t\t\treturn body\n\t\tif node.type == \"program\":\n\t\t\treturn node  # Program itself is the body\n\n\t\treturn None\n\n\tdef get_children_to_process(self, node: Node, body_node: Node | None) -&gt; list[Node]:\n\t\t\"\"\"\n\t\tGet the list of child nodes that should be recursively processed.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    body_node: The body node if available\n\n\t\tReturns:\n\t\t    List of child nodes to process\n\n\t\t\"\"\"\n\t\t# Process children of the body node if it exists, otherwise process direct children\n\t\tif body_node:\n\t\t\treturn list(body_node.children)\n\n\t\t# Special handling for certain nodes\n\t\tif node.type in [\"variable_declaration\", \"lexical_declaration\"]:\n\t\t\t# Process the declarations field\n\t\t\tdeclarations = node.child_by_field_name(\"declarations\")\n\t\t\treturn [declarations] if declarations else []\n\n\t\treturn list(node.children)\n\n\tdef should_skip_node(self, node: Node) -&gt; bool:\n\t\t\"\"\"\n\t\tDetermine if a node should be skipped entirely during processing.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\n\t\tReturns:\n\t\t    True if the node should be skipped\n\n\t\t\"\"\"\n\t\t# Skip non-named nodes (like punctuation, operators)\n\t\tif not node.is_named:\n\t\t\treturn True\n\n\t\t# Skip syntax nodes that don't contribute to code structure\n\t\treturn node.type in [\"(\", \")\", \"{\", \"}\", \"[\", \"]\", \";\", \".\", \",\", \":\", \"=&gt;\"]\n\n\tdef extract_imports(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\t\"\"\"\n\t\tExtract imported module names from a JavaScript import statement.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node representing an import statement\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    List of imported module names as strings\n\n\t\t\"\"\"\n\t\tif node.type not in self.config.import_:\n\t\t\treturn []\n\n\t\timported_names = []\n\n\t\ttry:\n\t\t\t# Find the source (module path) of the import\n\t\t\tsource_node = node.child_by_field_name(\"source\")\n\t\t\tif not source_node:\n\t\t\t\treturn []\n\n\t\t\t# Extract the module path from the string literal\n\t\t\tmodule_path = content_bytes[source_node.start_byte : source_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t# Remove quotes\n\t\t\tmodule_path = module_path.strip(\"\\\"'\")\n\n\t\t\t# Check for different import patterns:\n\n\t\t\t# 1. Default import: \"import Name from 'module'\"\n\t\t\tdefault_import = node.child_by_field_name(\"default\")\n\t\t\tif default_import:\n\t\t\t\tname = content_bytes[default_import.start_byte : default_import.end_byte].decode(\n\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t)\n\t\t\t\timported_names.append(f\"{module_path}.default\")\n\n\t\t\t# 2. Named imports: \"import { foo, bar as baz } from 'module'\"\n\t\t\tnamed_imports = node.child_by_field_name(\"named_imports\")\n\t\t\tif named_imports:\n\t\t\t\tfor child in named_imports.children:\n\t\t\t\t\tif child.type == \"import_specifier\":\n\t\t\t\t\t\timported_name = child.child_by_field_name(\"name\")\n\t\t\t\t\t\tif imported_name:\n\t\t\t\t\t\t\tname = content_bytes[imported_name.start_byte : imported_name.end_byte].decode(\n\t\t\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\timported_names.append(f\"{module_path}.{name}\")\n\n\t\t\t# 3. Namespace import: \"import * as Name from 'module'\"\n\t\t\tnamespace_import = node.child_by_field_name(\"namespace_import\")\n\t\t\tif namespace_import:\n\t\t\t\timported_names.append(f\"{module_path}.*\")\n\n\t\t\t# If no specific imports found but we have a module, add the whole module\n\t\t\tif not imported_names and module_path:\n\t\t\t\timported_names.append(module_path)\n\n\t\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\t\tlogger.warning(\"Failed to decode JavaScript imports: %s\", e)\n\n\t\treturn imported_names\n\n\tdef extract_calls(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\t\"\"\"\n\t\tExtract names of functions/methods called within a JS node's scope.\n\n\t\tRecursively searches for 'call_expression' nodes and extracts the function identifier.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node (e.g., function/method body)\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    List of called function/method names\n\n\t\t\"\"\"\n\t\tcalls = []\n\t\tfor child in node.children:\n\t\t\tif child.type == \"call_expression\":\n\t\t\t\tfunction_node = child.child_by_field_name(\"function\")\n\t\t\t\tif function_node:\n\t\t\t\t\t# Extract the identifier (e.g., funcName, obj.methodName)\n\t\t\t\t\ttry:\n\t\t\t\t\t\tcall_name = content_bytes[function_node.start_byte : function_node.end_byte].decode(\n\t\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t\t)\n\t\t\t\t\t\tcalls.append(call_name)\n\t\t\t\t\texcept UnicodeDecodeError:\n\t\t\t\t\t\tpass  # Ignore decoding errors\n\t\t\t# Recursively search deeper within non-call children\n\t\t\telse:\n\t\t\t\tcalls.extend(self.extract_calls(child, content_bytes))\n\t\treturn list(set(calls))  # Return unique calls\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptSyntaxHandler.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> <p>Initialize with JavaScript configuration.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>def __init__(self) -&gt; None:\n\t\"\"\"Initialize with JavaScript configuration.\"\"\"\n\tsuper().__init__(JAVASCRIPT_CONFIG)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptSyntaxHandler.get_entity_type","title":"get_entity_type","text":"<pre><code>get_entity_type(\n\tnode: Node, parent: Node | None, content_bytes: bytes\n) -&gt; EntityType\n</code></pre> <p>Determine the EntityType for a JavaScript node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>parent</code> <code>Node | None</code> <p>The parent node (if any)</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>EntityType</code> <p>The entity type</p> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>def get_entity_type(self, node: Node, parent: Node | None, content_bytes: bytes) -&gt; EntityType:\n\t\"\"\"\n\tDetermine the EntityType for a JavaScript node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    parent: The parent node (if any)\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    The entity type\n\n\t\"\"\"\n\tnode_type = node.type\n\tlogger.debug(\n\t\t\"Getting entity type for JavaScript node: type=%s, parent_type=%s\",\n\t\tnode_type,\n\t\tparent.type if parent else None,\n\t)\n\n\t# Module-level\n\tif node_type in self.config.module:\n\t\treturn EntityType.MODULE\n\tif node_type in self.config.namespace:\n\t\treturn EntityType.NAMESPACE\n\n\t# Documentation\n\tif node_type in self.config.comment:\n\t\t# Check if this is a JSDoc comment (starts with /**)\n\t\tif self._is_jsdoc_comment(node, content_bytes):\n\t\t\treturn EntityType.DOCSTRING\n\t\treturn EntityType.COMMENT\n\n\t# Type definitions\n\tif node_type in self.config.class_:\n\t\treturn EntityType.CLASS\n\n\t# Functions and methods\n\tif node_type in self.config.function:\n\t\t# Check if this is a test function (for frameworks like Jest, Mocha)\n\t\tif self._is_test_function(node, content_bytes):\n\t\t\treturn EntityType.TEST_CASE\n\t\treturn EntityType.FUNCTION\n\n\tif node_type in self.config.method:\n\t\treturn EntityType.METHOD\n\n\t# Check for test suite declarations (describe blocks in Jest/Mocha)\n\tif node_type in self.config.test_suite and self._is_test_suite(node, content_bytes):\n\t\treturn EntityType.TEST_SUITE\n\n\t# Property definitions\n\tif node_type in self.config.property_def:\n\t\treturn EntityType.PROPERTY\n\n\t# Variables and constants\n\tif node_type in self.config.variable:\n\t\t# Check if it's a const declaration\n\t\tif self._is_constant(node, content_bytes):\n\t\t\treturn EntityType.CONSTANT\n\t\treturn EntityType.VARIABLE\n\n\t# Class fields\n\tif node_type in self.config.class_field:\n\t\treturn EntityType.CLASS_FIELD\n\n\t# Code organization\n\tif node_type in self.config.import_:\n\t\treturn EntityType.IMPORT\n\n\treturn EntityType.UNKNOWN\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptSyntaxHandler.find_docstring","title":"find_docstring","text":"<pre><code>find_docstring(\n\tnode: Node, content_bytes: bytes\n) -&gt; tuple[str | None, Node | None]\n</code></pre> <p>Find the docstring associated with a definition node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>A tuple containing:</p> <code>Node | None</code> <ul> <li>The extracted docstring text (or None).</li> </ul> <code>tuple[str | None, Node | None]</code> <ul> <li>The specific AST node representing the docstring (or None).</li> </ul> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>def find_docstring(self, node: Node, content_bytes: bytes) -&gt; tuple[str | None, Node | None]:\n\t\"\"\"\n\tFind the docstring associated with a definition node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    A tuple containing:\n\t    - The extracted docstring text (or None).\n\t    - The specific AST node representing the docstring (or None).\n\n\t\"\"\"\n\t# For functions, classes, and other definition nodes\n\tparent_node = node.parent\n\n\t# Look for JSDoc comments immediately preceding the node\n\tif parent_node:\n\t\tindex = None\n\t\tfor i, child in enumerate(parent_node.children):\n\t\t\tif child == node:\n\t\t\t\tindex = i\n\t\t\t\tbreak\n\n\t\tif index is not None and index &gt; 0:\n\t\t\tprev_node = parent_node.children[index - 1]\n\t\t\tif prev_node.type == \"comment\" and self._is_jsdoc_comment(prev_node, content_bytes):\n\t\t\t\ttry:\n\t\t\t\t\tcomment_text = content_bytes[prev_node.start_byte : prev_node.end_byte].decode(\n\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t)\n\t\t\t\t\t# Clean JSDoc format: remove /** */ and trim\n\t\t\t\t\tcomment_text = comment_text.strip()\n\t\t\t\t\tcomment_text = comment_text.removeprefix(\"/**\")\n\t\t\t\t\tcomment_text = comment_text.removesuffix(\"*/\")\n\t\t\t\t\treturn comment_text.strip(), prev_node\n\t\t\t\texcept (UnicodeDecodeError, IndexError) as e:\n\t\t\t\t\tlogger.warning(\"Failed to decode JavaScript comment: %s\", e)\n\n\treturn None, None\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptSyntaxHandler.extract_name","title":"extract_name","text":"<pre><code>extract_name(node: Node, content_bytes: bytes) -&gt; str\n</code></pre> <p>Extract the name identifier from a definition node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>str</code> <p>The extracted name</p> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>def extract_name(self, node: Node, content_bytes: bytes) -&gt; str:\n\t\"\"\"\n\tExtract the name identifier from a definition node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    The extracted name\n\n\t\"\"\"\n\t# Try to find the name field based on node type\n\tname_node = None\n\n\tif node.type in [\"function_declaration\", \"class_declaration\", \"method_definition\"]:\n\t\tname_node = node.child_by_field_name(\"name\")\n\telif node.type == \"property_identifier\":\n\t\tname_node = node\n\telif node.type in [\"variable_declaration\", \"lexical_declaration\"]:\n\t\t# Get the first declarator and its name\n\t\tdeclarator = node.child_by_field_name(\"declarations\")\n\t\tif declarator and declarator.named_child_count &gt; 0:\n\t\t\tfirst_declarator = declarator.named_children[0]\n\t\t\tname_node = first_declarator.child_by_field_name(\"name\")\n\telif node.type == \"public_field_definition\":\n\t\tname_node = node.child_by_field_name(\"name\")\n\n\tif name_node:\n\t\ttry:\n\t\t\treturn content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\t\tlogger.warning(\"Failed to decode JavaScript name: %s\", e)\n\t\t\treturn f\"&lt;decoding-error-{node.type}&gt;\"\n\n\t# For call expressions that represent tests or suites\n\tif node.type == \"call_expression\":\n\t\tcallee = node.child_by_field_name(\"function\")\n\t\targuments = node.child_by_field_name(\"arguments\")\n\n\t\tif callee and arguments and arguments.named_child_count &gt; 0:\n\t\t\t# First argument is typically the test/suite name\n\t\t\tfirst_arg = arguments.named_children[0]\n\t\t\tif first_arg.type == \"string\":\n\t\t\t\ttry:\n\t\t\t\t\tname = content_bytes[first_arg.start_byte : first_arg.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\t\t# Remove quotes\n\t\t\t\t\treturn name.strip(\"\\\"'\")\n\t\t\t\texcept (UnicodeDecodeError, IndexError):\n\t\t\t\t\tpass\n\n\treturn f\"&lt;anonymous-{node.type}&gt;\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptSyntaxHandler.get_body_node","title":"get_body_node","text":"<pre><code>get_body_node(node: Node) -&gt; Node | None\n</code></pre> <p>Get the node representing the 'body' of a definition.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <p>Returns:</p> Type Description <code>Node | None</code> <p>The body node if available, None otherwise</p> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>def get_body_node(self, node: Node) -&gt; Node | None:\n\t\"\"\"\n\tGet the node representing the 'body' of a definition.\n\n\tArgs:\n\t    node: The tree-sitter node\n\n\tReturns:\n\t    The body node if available, None otherwise\n\n\t\"\"\"\n\t# Different fields based on node type\n\tif node.type in [\"function_declaration\", \"method_definition\", \"class_declaration\"]:\n\t\treturn node.child_by_field_name(\"body\")\n\tif node.type in [\"arrow_function\"]:\n\t\tbody = node.child_by_field_name(\"body\")\n\t\t# Arrow functions can have expression bodies or block bodies\n\t\tif body and body.type != \"statement_block\":\n\t\t\treturn None  # Expression bodies don't have children to process\n\t\treturn body\n\tif node.type == \"program\":\n\t\treturn node  # Program itself is the body\n\n\treturn None\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptSyntaxHandler.get_children_to_process","title":"get_children_to_process","text":"<pre><code>get_children_to_process(\n\tnode: Node, body_node: Node | None\n) -&gt; list[Node]\n</code></pre> <p>Get the list of child nodes that should be recursively processed.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>body_node</code> <code>Node | None</code> <p>The body node if available</p> required <p>Returns:</p> Type Description <code>list[Node]</code> <p>List of child nodes to process</p> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>def get_children_to_process(self, node: Node, body_node: Node | None) -&gt; list[Node]:\n\t\"\"\"\n\tGet the list of child nodes that should be recursively processed.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    body_node: The body node if available\n\n\tReturns:\n\t    List of child nodes to process\n\n\t\"\"\"\n\t# Process children of the body node if it exists, otherwise process direct children\n\tif body_node:\n\t\treturn list(body_node.children)\n\n\t# Special handling for certain nodes\n\tif node.type in [\"variable_declaration\", \"lexical_declaration\"]:\n\t\t# Process the declarations field\n\t\tdeclarations = node.child_by_field_name(\"declarations\")\n\t\treturn [declarations] if declarations else []\n\n\treturn list(node.children)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptSyntaxHandler.should_skip_node","title":"should_skip_node","text":"<pre><code>should_skip_node(node: Node) -&gt; bool\n</code></pre> <p>Determine if a node should be skipped entirely during processing.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the node should be skipped</p> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>def should_skip_node(self, node: Node) -&gt; bool:\n\t\"\"\"\n\tDetermine if a node should be skipped entirely during processing.\n\n\tArgs:\n\t    node: The tree-sitter node\n\n\tReturns:\n\t    True if the node should be skipped\n\n\t\"\"\"\n\t# Skip non-named nodes (like punctuation, operators)\n\tif not node.is_named:\n\t\treturn True\n\n\t# Skip syntax nodes that don't contribute to code structure\n\treturn node.type in [\"(\", \")\", \"{\", \"}\", \"[\", \"]\", \";\", \".\", \",\", \":\", \"=&gt;\"]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptSyntaxHandler.extract_imports","title":"extract_imports","text":"<pre><code>extract_imports(\n\tnode: Node, content_bytes: bytes\n) -&gt; list[str]\n</code></pre> <p>Extract imported module names from a JavaScript import statement.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node representing an import statement</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of imported module names as strings</p> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>def extract_imports(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\"\"\"\n\tExtract imported module names from a JavaScript import statement.\n\n\tArgs:\n\t    node: The tree-sitter node representing an import statement\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    List of imported module names as strings\n\n\t\"\"\"\n\tif node.type not in self.config.import_:\n\t\treturn []\n\n\timported_names = []\n\n\ttry:\n\t\t# Find the source (module path) of the import\n\t\tsource_node = node.child_by_field_name(\"source\")\n\t\tif not source_node:\n\t\t\treturn []\n\n\t\t# Extract the module path from the string literal\n\t\tmodule_path = content_bytes[source_node.start_byte : source_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t# Remove quotes\n\t\tmodule_path = module_path.strip(\"\\\"'\")\n\n\t\t# Check for different import patterns:\n\n\t\t# 1. Default import: \"import Name from 'module'\"\n\t\tdefault_import = node.child_by_field_name(\"default\")\n\t\tif default_import:\n\t\t\tname = content_bytes[default_import.start_byte : default_import.end_byte].decode(\n\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t)\n\t\t\timported_names.append(f\"{module_path}.default\")\n\n\t\t# 2. Named imports: \"import { foo, bar as baz } from 'module'\"\n\t\tnamed_imports = node.child_by_field_name(\"named_imports\")\n\t\tif named_imports:\n\t\t\tfor child in named_imports.children:\n\t\t\t\tif child.type == \"import_specifier\":\n\t\t\t\t\timported_name = child.child_by_field_name(\"name\")\n\t\t\t\t\tif imported_name:\n\t\t\t\t\t\tname = content_bytes[imported_name.start_byte : imported_name.end_byte].decode(\n\t\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t\t)\n\t\t\t\t\t\timported_names.append(f\"{module_path}.{name}\")\n\n\t\t# 3. Namespace import: \"import * as Name from 'module'\"\n\t\tnamespace_import = node.child_by_field_name(\"namespace_import\")\n\t\tif namespace_import:\n\t\t\timported_names.append(f\"{module_path}.*\")\n\n\t\t# If no specific imports found but we have a module, add the whole module\n\t\tif not imported_names and module_path:\n\t\t\timported_names.append(module_path)\n\n\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\tlogger.warning(\"Failed to decode JavaScript imports: %s\", e)\n\n\treturn imported_names\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/javascript/#codemap.processor.tree_sitter.languages.javascript.JavaScriptSyntaxHandler.extract_calls","title":"extract_calls","text":"<pre><code>extract_calls(\n\tnode: Node, content_bytes: bytes\n) -&gt; list[str]\n</code></pre> <p>Extract names of functions/methods called within a JS node's scope.</p> <p>Recursively searches for 'call_expression' nodes and extracts the function identifier.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node (e.g., function/method body)</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of called function/method names</p> Source code in <code>src/codemap/processor/tree_sitter/languages/javascript.py</code> <pre><code>def extract_calls(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\"\"\"\n\tExtract names of functions/methods called within a JS node's scope.\n\n\tRecursively searches for 'call_expression' nodes and extracts the function identifier.\n\n\tArgs:\n\t    node: The tree-sitter node (e.g., function/method body)\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    List of called function/method names\n\n\t\"\"\"\n\tcalls = []\n\tfor child in node.children:\n\t\tif child.type == \"call_expression\":\n\t\t\tfunction_node = child.child_by_field_name(\"function\")\n\t\t\tif function_node:\n\t\t\t\t# Extract the identifier (e.g., funcName, obj.methodName)\n\t\t\t\ttry:\n\t\t\t\t\tcall_name = content_bytes[function_node.start_byte : function_node.end_byte].decode(\n\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t)\n\t\t\t\t\tcalls.append(call_name)\n\t\t\t\texcept UnicodeDecodeError:\n\t\t\t\t\tpass  # Ignore decoding errors\n\t\t# Recursively search deeper within non-call children\n\t\telse:\n\t\t\tcalls.extend(self.extract_calls(child, content_bytes))\n\treturn list(set(calls))  # Return unique calls\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/","title":"Python","text":"<p>Python-specific configuration for syntax chunking.</p>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig","title":"PythonConfig  <code>dataclass</code>","text":"<p>               Bases: <code>LanguageConfig</code></p> <p>Python-specific syntax chunking configuration.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>class PythonConfig(LanguageConfig):\n\t\"\"\"Python-specific syntax chunking configuration.\"\"\"\n\n\t# File-level entities\n\tmodule: ClassVar[list[str]] = [\"module\"]\n\tnamespace: ClassVar[list[str]] = [\"import_from_statement\"]  # Using import from as namespace indicator\n\n\t# Type definitions\n\tclass_: ClassVar[list[str]] = [\"class_definition\"]\n\tinterface: ClassVar[list[str]] = [\"class_definition\"]  # Python uses ABC classes\n\tprotocol: ClassVar[list[str]] = [\"class_definition\"]  # Protocol classes\n\tstruct: ClassVar[list[str]] = [\"class_definition\"]  # Python uses regular classes\n\tenum: ClassVar[list[str]] = [\"class_definition\"]  # Enum classes\n\ttype_alias: ClassVar[list[str]] = [\"assignment\"]  # Type assignments\n\n\t# Functions and methods\n\tfunction: ClassVar[list[str]] = [\"function_definition\"]\n\tmethod: ClassVar[list[str]] = [\"function_definition\"]  # Inside class\n\tproperty_def: ClassVar[list[str]] = [\"decorated_definition\"]  # @property decorated functions\n\ttest_case: ClassVar[list[str]] = [\"function_definition\"]  # test_* functions\n\ttest_suite: ClassVar[list[str]] = [\"class_definition\"]  # Test* classes\n\n\t# Variables and constants\n\tvariable: ClassVar[list[str]] = [\"assignment\"]\n\tconstant: ClassVar[list[str]] = [\"assignment\"]  # Uppercase assignments\n\tclass_field: ClassVar[list[str]] = [\"class_variable_definition\"]\n\n\t# Code organization\n\timport_: ClassVar[list[str]] = [\"import_statement\", \"import_from_statement\"]\n\tdecorator: ClassVar[list[str]] = [\"decorator\"]\n\n\t# Documentation\n\tcomment: ClassVar[list[str]] = [\"comment\"]\n\tdocstring: ClassVar[list[str]] = [\"string\"]  # First string in module/class/function\n\n\tfile_extensions: ClassVar[list[str]] = [\".py\", \".pyi\"]\n\ttree_sitter_name: ClassVar[str] = \"python\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.module","title":"module  <code>class-attribute</code>","text":"<pre><code>module: list[str] = ['module']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.namespace","title":"namespace  <code>class-attribute</code>","text":"<pre><code>namespace: list[str] = ['import_from_statement']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.class_","title":"class_  <code>class-attribute</code>","text":"<pre><code>class_: list[str] = ['class_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.interface","title":"interface  <code>class-attribute</code>","text":"<pre><code>interface: list[str] = ['class_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: list[str] = ['class_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.struct","title":"struct  <code>class-attribute</code>","text":"<pre><code>struct: list[str] = ['class_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.enum","title":"enum  <code>class-attribute</code>","text":"<pre><code>enum: list[str] = ['class_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.type_alias","title":"type_alias  <code>class-attribute</code>","text":"<pre><code>type_alias: list[str] = ['assignment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.function","title":"function  <code>class-attribute</code>","text":"<pre><code>function: list[str] = ['function_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.method","title":"method  <code>class-attribute</code>","text":"<pre><code>method: list[str] = ['function_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.property_def","title":"property_def  <code>class-attribute</code>","text":"<pre><code>property_def: list[str] = ['decorated_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.test_case","title":"test_case  <code>class-attribute</code>","text":"<pre><code>test_case: list[str] = ['function_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.test_suite","title":"test_suite  <code>class-attribute</code>","text":"<pre><code>test_suite: list[str] = ['class_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.variable","title":"variable  <code>class-attribute</code>","text":"<pre><code>variable: list[str] = ['assignment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.constant","title":"constant  <code>class-attribute</code>","text":"<pre><code>constant: list[str] = ['assignment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.class_field","title":"class_field  <code>class-attribute</code>","text":"<pre><code>class_field: list[str] = ['class_variable_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.import_","title":"import_  <code>class-attribute</code>","text":"<pre><code>import_: list[str] = [\n\t\"import_statement\",\n\t\"import_from_statement\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.decorator","title":"decorator  <code>class-attribute</code>","text":"<pre><code>decorator: list[str] = ['decorator']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.comment","title":"comment  <code>class-attribute</code>","text":"<pre><code>comment: list[str] = ['comment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.docstring","title":"docstring  <code>class-attribute</code>","text":"<pre><code>docstring: list[str] = ['string']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.file_extensions","title":"file_extensions  <code>class-attribute</code>","text":"<pre><code>file_extensions: list[str] = ['.py', '.pyi']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonConfig.tree_sitter_name","title":"tree_sitter_name  <code>class-attribute</code>","text":"<pre><code>tree_sitter_name: str = 'python'\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PYTHON_CONFIG","title":"PYTHON_CONFIG  <code>module-attribute</code>","text":"<pre><code>PYTHON_CONFIG = PythonConfig()\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonSyntaxHandler","title":"PythonSyntaxHandler","text":"<p>               Bases: <code>LanguageSyntaxHandler</code></p> <p>Python-specific syntax handling logic.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>class PythonSyntaxHandler(LanguageSyntaxHandler):\n\t\"\"\"Python-specific syntax handling logic.\"\"\"\n\n\tdef __init__(self) -&gt; None:\n\t\t\"\"\"Initialize with Python configuration.\"\"\"\n\t\tsuper().__init__(PYTHON_CONFIG)\n\n\tdef get_entity_type(self, node: Node, parent: Node | None, content_bytes: bytes) -&gt; EntityType:\n\t\t\"\"\"\n\t\tDetermine the EntityType for a Python node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    parent: The parent node (if any)\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    The entity type\n\n\t\t\"\"\"\n\t\tnode_type = node.type\n\t\tlogger.debug(\n\t\t\t\"Getting entity type for Python node: type=%s, parent_type=%s\", node_type, parent.type if parent else None\n\t\t)\n\n\t\t# Print node content for debugging\n\t\ttry:\n\t\t\tnode_content = content_bytes[node.start_byte : node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\tlogger.debug(\"Node content: %s\", node_content)\n\t\texcept (UnicodeDecodeError, IndexError) as e:\n\t\t\tlogger.debug(\"Failed to decode node content: %s\", str(e))\n\n\t\t# Special case: if this is an expression statement containing a constant assignment\n\t\tif node_type == \"expression_statement\":\n\t\t\t# Check if it contains an assignment that is a constant\n\t\t\tfor child in node.children:\n\t\t\t\tif child.type == \"assignment\":\n\t\t\t\t\tname_node = child.child_by_field_name(\"left\")\n\t\t\t\t\tif name_node:\n\t\t\t\t\t\tname = content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\n\t\t\t\t\t\t# Get the right side for type detection\n\t\t\t\t\t\tvalue_node = child.child_by_field_name(\"right\")\n\t\t\t\t\t\tvalue_text = \"\"\n\t\t\t\t\t\tif value_node:\n\t\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\t\tvalue_text = content_bytes[value_node.start_byte : value_node.end_byte].decode(\n\t\t\t\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\texcept (UnicodeDecodeError, IndexError) as e:\n\t\t\t\t\t\t\t\tlogger.debug(\"Failed to decode type value: %s\", str(e))\n\n\t\t\t\t\t\t# Check for type alias - TypeVar or anything referencing typing types like Dict, List, etc.\n\t\t\t\t\t\tif \"TypeVar\" in value_text or any(\n\t\t\t\t\t\t\ttyping_type in value_text\n\t\t\t\t\t\t\tfor typing_type in [\"Dict\", \"List\", \"Tuple\", \"Set\", \"Union\", \"Optional\", \"Callable\", \"Any\"]\n\t\t\t\t\t\t):\n\t\t\t\t\t\t\tlogger.debug(\"Expression statement with TYPE_ALIAS: %s\", name)\n\t\t\t\t\t\t\treturn EntityType.TYPE_ALIAS\n\n\t\t\t\t\t\t# Check for constant (all uppercase with at least one letter)\n\t\t\t\t\t\tif name.isupper() and any(c.isalpha() for c in name):\n\t\t\t\t\t\t\tlogger.debug(\"Expression statement with CONSTANT assignment: %s\", name)\n\t\t\t\t\t\t\treturn EntityType.CONSTANT\n\t\t\t\t\t\t# Check for regular variable\n\t\t\t\t\t\tif not name.startswith(\"_\") and any(c.isalpha() for c in name):\n\t\t\t\t\t\t\tlogger.debug(\"Expression statement with VARIABLE assignment: %s\", name)\n\t\t\t\t\t\t\treturn EntityType.VARIABLE\n\n\t\t# Module-level\n\t\tif node_type in self.config.module:\n\t\t\treturn EntityType.MODULE\n\t\tif node_type in self.config.namespace:\n\t\t\treturn EntityType.NAMESPACE\n\n\t\t# Documentation\n\t\tif node_type in self.config.docstring:\n\t\t\t# Check if this is a docstring (first string in a container)\n\t\t\tif self._is_docstring(node, parent):\n\t\t\t\treturn EntityType.DOCSTRING\n\t\t\treturn EntityType.UNKNOWN  # Regular string literals\n\t\tif node_type in self.config.comment:\n\t\t\treturn EntityType.COMMENT\n\n\t\t# Type definitions\n\t\tif node_type in self.config.class_:\n\t\t\treturn EntityType.CLASS\n\t\tif node_type in self.config.interface:\n\t\t\t# Would need to check for ABC inheritance to be precise\n\t\t\treturn EntityType.INTERFACE\n\t\tif node_type in self.config.protocol:\n\t\t\t# Would need to check for Protocol inheritance to be precise\n\t\t\treturn EntityType.PROTOCOL\n\t\tif node_type in self.config.type_alias:\n\t\t\t# For assignments, check if it's a constant (all uppercase) first\n\t\t\tif node_type == \"assignment\":\n\t\t\t\tname_node = node.child_by_field_name(\"left\")\n\t\t\t\tif name_node:\n\t\t\t\t\tname = content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\t\tlogger.debug(\"Checking potential constant in type_alias: %s (is_upper: %s)\", name, name.isupper())\n\t\t\t\t\t# Improved check for constants: name is uppercase and contains at least one letter\n\t\t\t\t\tif name.isupper() and any(c.isalpha() for c in name):\n\t\t\t\t\t\tlogger.debug(\"Identified as CONSTANT: %s\", name)\n\t\t\t\t\t\treturn EntityType.CONSTANT\n\n\t\t\t# Otherwise, treat as a type alias\n\t\t\treturn EntityType.TYPE_ALIAS\n\n\t\t# Functions and methods\n\t\tif node_type in self.config.function:\n\t\t\t# Check if this is a test function\n\t\t\tname = self.extract_name(node, content_bytes)\n\t\t\tif name.startswith(\"test_\"):\n\t\t\t\treturn EntityType.TEST_CASE\n\n\t\t\t# Check if this is a method by looking for class ancestry\n\t\t\tif self._is_within_class_context(node):\n\t\t\t\treturn EntityType.METHOD\n\t\t\treturn EntityType.FUNCTION\n\n\t\t# Check for properties - decorated definitions\n\t\tif node_type in self.config.property_def:\n\t\t\tfor child in node.children:\n\t\t\t\tif child.type == \"decorator\":\n\t\t\t\t\tdecorator_text = content_bytes[child.start_byte : child.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\t\tif \"@property\" in decorator_text:\n\t\t\t\t\t\treturn EntityType.PROPERTY\n\t\t\t# If no @property decorator, treat as method if in class, otherwise function\n\t\t\tif self._is_within_class_context(node):\n\t\t\t\treturn EntityType.METHOD\n\t\t\treturn EntityType.FUNCTION\n\n\t\t# Variables and constants\n\t\tif node_type in self.config.variable:\n\t\t\t# Check if it looks like a constant (uppercase name)\n\t\t\tname_node = node.child_by_field_name(\"left\")\n\t\t\tif name_node:\n\t\t\t\tname = content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\tlogger.debug(\"Checking potential constant: %s (is_upper: %s)\", name, name.isupper())\n\t\t\t\t# Improved check for constants: name is uppercase and contains at least one letter\n\t\t\t\tif name.isupper() and any(c.isalpha() for c in name):\n\t\t\t\t\tlogger.debug(\"Identified as CONSTANT: %s\", name)\n\t\t\t\t\treturn EntityType.CONSTANT\n\t\t\tlogger.debug(\"Identified as VARIABLE: node_type=%s\", node_type)\n\t\t\treturn EntityType.VARIABLE\n\n\t\t# Class fields\n\t\tif node_type in self.config.class_field:\n\t\t\treturn EntityType.CLASS_FIELD\n\n\t\t# Code organization\n\t\tif node_type in self.config.import_:\n\t\t\treturn EntityType.IMPORT\n\t\tif node_type in self.config.decorator:\n\t\t\treturn EntityType.DECORATOR\n\n\t\treturn EntityType.UNKNOWN\n\n\tdef _is_within_class_context(self, node: Node) -&gt; bool:\n\t\t\"\"\"\n\t\tCheck if the node is defined within a class definition.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\n\t\tReturns:\n\t\t    True if the node is within a class context\n\n\t\t\"\"\"\n\t\tancestor = node.parent\n\t\twhile ancestor:\n\t\t\tif ancestor.type in self.config.class_:\n\t\t\t\treturn True\n\t\t\t# Stop search if we hit module or another function definition\n\t\t\tif ancestor.type in self.config.module or ancestor.type in self.config.function:\n\t\t\t\tbreak\n\t\t\tancestor = ancestor.parent\n\t\treturn False\n\n\tdef _is_docstring(self, node: Node, parent: Node | None) -&gt; bool:\n\t\t\"\"\"\n\t\tCheck if a string node is a docstring.\n\n\t\tArgs:\n\t\t    node: The string node\n\t\t    parent: The parent node\n\n\t\tReturns:\n\t\t    True if the node is a docstring\n\n\t\t\"\"\"\n\t\tif not parent:\n\t\t\treturn False\n\n\t\t# For module docstrings, check if it's the first string in the module\n\t\tif parent.type == \"module\":\n\t\t\tnon_comment_children = [c for c in parent.children if c.type not in [\"comment\"]]\n\t\t\treturn bool(non_comment_children and node == non_comment_children[0])\n\n\t\t# For expression statements containing string literals\n\t\tif parent.type == \"expression_statement\":\n\t\t\t# Check if this is the first child of a function or class body\n\t\t\tgrandparent = parent.parent\n\t\t\tif grandparent and grandparent.type == \"block\":\n\t\t\t\tgreat_grandparent = grandparent.parent\n\t\t\t\tif great_grandparent and great_grandparent.type in (self.config.function + self.config.class_):\n\t\t\t\t\t# Check if it's the first item in the block\n\t\t\t\t\tnon_comment_children = [c for c in grandparent.children if c.type not in [\"comment\"]]\n\t\t\t\t\treturn bool(non_comment_children and parent == non_comment_children[0])\n\t\t\treturn False\n\n\t\treturn False\n\n\tdef find_docstring(self, node: Node, content_bytes: bytes) -&gt; tuple[str | None, Node | None]:\n\t\t\"\"\"\n\t\tFind the docstring associated with a definition node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    A tuple containing:\n\t\t    - The extracted docstring text (or None).\n\t\t    - The specific AST node representing the docstring (or None).\n\n\t\t\"\"\"\n\t\tbody_node = self.get_body_node(node)\n\t\tif not body_node:\n\t\t\t# Handle module docstring case (no explicit body node)\n\t\t\tif node.type == \"module\":\n\t\t\t\tbody_node = node  # Treat module itself as the body context\n\t\t\telse:\n\t\t\t\treturn None, None\n\n\t\tif body_node.named_child_count == 0:\n\t\t\treturn None, None\n\n\t\t# Look for the first child that might be a docstring\n\t\tfirst_body_child = None\n\t\tfor child in body_node.children:\n\t\t\tif child.is_named:\n\t\t\t\tfirst_body_child = child\n\t\t\t\tbreak\n\n\t\tif not first_body_child:\n\t\t\treturn None, None\n\n\t\tactual_string_node = None\n\t\tdocstring_container_node = None  # The node to skip during processing\n\n\t\tif first_body_child.type == \"expression_statement\":\n\t\t\t# For expression statements containing string literals\n\t\t\tfor child in first_body_child.children:\n\t\t\t\tif child.type in self.config.docstring:\n\t\t\t\t\tactual_string_node = child\n\t\t\t\t\tdocstring_container_node = first_body_child\n\t\t\t\t\tbreak\n\t\telif first_body_child.type in self.config.docstring:\n\t\t\t# Direct string literal\n\t\t\tactual_string_node = first_body_child\n\t\t\tdocstring_container_node = first_body_child\n\n\t\tif actual_string_node:\n\t\t\ttry:\n\t\t\t\tdocstring_text = (\n\t\t\t\t\tcontent_bytes[actual_string_node.start_byte : actual_string_node.end_byte]\n\t\t\t\t\t.decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\t\t.strip(\"\\\"' \\n\")\n\t\t\t\t)\n\t\t\t\treturn docstring_text, docstring_container_node\n\t\t\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\t\t\tlogger.warning(\"Failed to decode/extract Python docstring: %s\", e)\n\n\t\treturn None, None\n\n\tdef extract_name(self, node: Node, content_bytes: bytes) -&gt; str:\n\t\t\"\"\"\n\t\tExtract the name identifier from a definition node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    The extracted name\n\n\t\t\"\"\"\n\t\t# Try to find the name field\n\t\tname_node = node.child_by_field_name(\"name\")\n\n\t\t# Handle assignments\n\t\tif not name_node and node.type == \"assignment\":\n\t\t\tname_node = node.child_by_field_name(\"left\")\n\n\t\t# Handle expression statements with assignments\n\t\tif not name_node and node.type == \"expression_statement\":\n\t\t\tfor child in node.children:\n\t\t\t\tif child.type == \"assignment\":\n\t\t\t\t\tname_node = child.child_by_field_name(\"left\")\n\t\t\t\t\tif name_node:\n\t\t\t\t\t\tbreak\n\n\t\t# Handle decorated definitions\n\t\tif not name_node and node.type == \"decorated_definition\":\n\t\t\tfunc_def = node.child_by_field_name(\"definition\")\n\t\t\tif func_def:\n\t\t\t\tname_node = func_def.child_by_field_name(\"name\")\n\n\t\tif name_node:\n\t\t\ttry:\n\t\t\t\treturn content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\t\t\tlogger.warning(\"Failed to decode Python name: %s\", e)\n\t\t\t\treturn f\"&lt;decoding-error-{node.type}&gt;\"\n\n\t\treturn f\"&lt;anonymous-{node.type}&gt;\"\n\n\tdef get_body_node(self, node: Node) -&gt; Node | None:\n\t\t\"\"\"\n\t\tGet the node representing the 'body' of a definition.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\n\t\tReturns:\n\t\t    The body node if available, None otherwise\n\n\t\t\"\"\"\n\t\t# For functions and classes in Python, the body is a 'block' node\n\t\tbody_node = node.child_by_field_name(\"body\")\n\n\t\t# Handle decorated definitions\n\t\tif not body_node and node.type == \"decorated_definition\":\n\t\t\tfunc_def = node.child_by_field_name(\"definition\")\n\t\t\tif func_def:\n\t\t\t\tbody_node = func_def.child_by_field_name(\"body\")\n\n\t\treturn body_node\n\n\tdef get_children_to_process(self, node: Node, body_node: Node | None) -&gt; list[Node]:\n\t\t\"\"\"\n\t\tGet the list of child nodes that should be recursively processed.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    body_node: The body node if available\n\n\t\tReturns:\n\t\t    List of child nodes to process\n\n\t\t\"\"\"\n\t\t# Process children of the body node if it exists, otherwise process direct children\n\t\treturn list(body_node.children) if body_node else list(node.children)\n\n\tdef should_skip_node(self, node: Node) -&gt; bool:\n\t\t\"\"\"\n\t\tDetermine if a node should be skipped entirely during processing.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\n\t\tReturns:\n\t\t    True if the node should be skipped\n\n\t\t\"\"\"\n\t\t# Skip non-named nodes (like punctuation, operators)\n\t\tif not node.is_named:\n\t\t\treturn True\n\n\t\t# Skip syntax nodes that don't contribute to code structure\n\t\treturn node.type in [\"(\", \")\", \"{\", \"}\", \"[\", \"]\", \";\", \".\", \",\"]\n\n\tdef extract_imports(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\t\"\"\"\n\t\tExtract imported module names from a Python import statement.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node representing an import statement\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    List of imported module names as strings\n\n\t\t\"\"\"\n\t\tif node.type not in self.config.import_:\n\t\t\treturn []\n\n\t\timported_names = []\n\n\t\ttry:\n\t\t\t# Handle regular import statements: \"import foo, bar\"\n\t\t\tif node.type == \"import_statement\":\n\t\t\t\tfor child in node.children:\n\t\t\t\t\tif child.type == \"dotted_name\":\n\t\t\t\t\t\tmodule_name = content_bytes[child.start_byte : child.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\t\t\timported_names.append(module_name)\n\n\t\t\t# Handle import from statements: \"from foo.bar import baz, qux\"\n\t\t\telif node.type == \"import_from_statement\":\n\t\t\t\t# Get the module being imported from\n\t\t\t\tmodule_node = None\n\t\t\t\tfor child in node.children:\n\t\t\t\t\tif child.type == \"dotted_name\":\n\t\t\t\t\t\tmodule_node = child\n\t\t\t\t\t\tbreak\n\n\t\t\t\tif module_node:\n\t\t\t\t\tmodule_name = content_bytes[module_node.start_byte : module_node.end_byte].decode(\n\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t)\n\n\t\t\t\t\t# Get the imported names\n\t\t\t\t\timport_node = node.child_by_field_name(\"import\")\n\t\t\t\t\tif import_node:\n\t\t\t\t\t\t# Check for the wildcard import case: \"from foo import *\"\n\t\t\t\t\t\tfor child in import_node.children:\n\t\t\t\t\t\t\tif child.type == \"wildcard_import\":\n\t\t\t\t\t\t\t\timported_names.append(f\"{module_name}.*\")\n\t\t\t\t\t\t\t\treturn imported_names\n\n\t\t\t\t\t\t# Regular named imports\n\t\t\t\t\t\tfor child in import_node.children:\n\t\t\t\t\t\t\tif child.type == \"import_list\":\n\t\t\t\t\t\t\t\tfor item in child.children:\n\t\t\t\t\t\t\t\t\tif item.type in {\"dotted_name\", \"identifier\"}:\n\t\t\t\t\t\t\t\t\t\tname = content_bytes[item.start_byte : item.end_byte].decode(\n\t\t\t\t\t\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t\t\timported_names.append(f\"{module_name}.{name}\")\n\t\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\t\tlogger.warning(\"Failed to decode Python imports: %s\", e)\n\n\t\treturn imported_names\n\n\tdef extract_calls(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\t\"\"\"\n\t\tExtract names of functions/methods called within a Python node's scope.\n\n\t\tRecursively searches for 'call' nodes and extracts the function identifier.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node (e.g., function/method body)\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    List of called function/method names\n\n\t\t\"\"\"\n\t\tcalls = []\n\t\tfor child in node.children:\n\t\t\tif child.type == \"call\":\n\t\t\t\tfunction_node = child.child_by_field_name(\"function\")\n\t\t\t\tif function_node:\n\t\t\t\t\t# Extract the identifier (could be simple name or attribute access like obj.method)\n\t\t\t\t\t# For simplicity, we take the full text of the function node\n\t\t\t\t\ttry:\n\t\t\t\t\t\tcall_name = content_bytes[function_node.start_byte : function_node.end_byte].decode(\n\t\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t\t)\n\t\t\t\t\t\tcalls.append(call_name)\n\t\t\t\t\texcept UnicodeDecodeError:\n\t\t\t\t\t\tpass  # Ignore decoding errors\n\t\t\t# Recursively search within the arguments or children of the call if needed, but often not necessary\n\t\t\t# for call details, just the name.\n\t\t\t# Else, recursively search deeper within non-call children\n\t\t\telse:\n\t\t\t\tcalls.extend(self.extract_calls(child, content_bytes))\n\t\treturn list(set(calls))  # Return unique calls\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonSyntaxHandler.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> <p>Initialize with Python configuration.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>def __init__(self) -&gt; None:\n\t\"\"\"Initialize with Python configuration.\"\"\"\n\tsuper().__init__(PYTHON_CONFIG)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonSyntaxHandler.get_entity_type","title":"get_entity_type","text":"<pre><code>get_entity_type(\n\tnode: Node, parent: Node | None, content_bytes: bytes\n) -&gt; EntityType\n</code></pre> <p>Determine the EntityType for a Python node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>parent</code> <code>Node | None</code> <p>The parent node (if any)</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>EntityType</code> <p>The entity type</p> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>def get_entity_type(self, node: Node, parent: Node | None, content_bytes: bytes) -&gt; EntityType:\n\t\"\"\"\n\tDetermine the EntityType for a Python node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    parent: The parent node (if any)\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    The entity type\n\n\t\"\"\"\n\tnode_type = node.type\n\tlogger.debug(\n\t\t\"Getting entity type for Python node: type=%s, parent_type=%s\", node_type, parent.type if parent else None\n\t)\n\n\t# Print node content for debugging\n\ttry:\n\t\tnode_content = content_bytes[node.start_byte : node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\tlogger.debug(\"Node content: %s\", node_content)\n\texcept (UnicodeDecodeError, IndexError) as e:\n\t\tlogger.debug(\"Failed to decode node content: %s\", str(e))\n\n\t# Special case: if this is an expression statement containing a constant assignment\n\tif node_type == \"expression_statement\":\n\t\t# Check if it contains an assignment that is a constant\n\t\tfor child in node.children:\n\t\t\tif child.type == \"assignment\":\n\t\t\t\tname_node = child.child_by_field_name(\"left\")\n\t\t\t\tif name_node:\n\t\t\t\t\tname = content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\n\t\t\t\t\t# Get the right side for type detection\n\t\t\t\t\tvalue_node = child.child_by_field_name(\"right\")\n\t\t\t\t\tvalue_text = \"\"\n\t\t\t\t\tif value_node:\n\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\tvalue_text = content_bytes[value_node.start_byte : value_node.end_byte].decode(\n\t\t\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\texcept (UnicodeDecodeError, IndexError) as e:\n\t\t\t\t\t\t\tlogger.debug(\"Failed to decode type value: %s\", str(e))\n\n\t\t\t\t\t# Check for type alias - TypeVar or anything referencing typing types like Dict, List, etc.\n\t\t\t\t\tif \"TypeVar\" in value_text or any(\n\t\t\t\t\t\ttyping_type in value_text\n\t\t\t\t\t\tfor typing_type in [\"Dict\", \"List\", \"Tuple\", \"Set\", \"Union\", \"Optional\", \"Callable\", \"Any\"]\n\t\t\t\t\t):\n\t\t\t\t\t\tlogger.debug(\"Expression statement with TYPE_ALIAS: %s\", name)\n\t\t\t\t\t\treturn EntityType.TYPE_ALIAS\n\n\t\t\t\t\t# Check for constant (all uppercase with at least one letter)\n\t\t\t\t\tif name.isupper() and any(c.isalpha() for c in name):\n\t\t\t\t\t\tlogger.debug(\"Expression statement with CONSTANT assignment: %s\", name)\n\t\t\t\t\t\treturn EntityType.CONSTANT\n\t\t\t\t\t# Check for regular variable\n\t\t\t\t\tif not name.startswith(\"_\") and any(c.isalpha() for c in name):\n\t\t\t\t\t\tlogger.debug(\"Expression statement with VARIABLE assignment: %s\", name)\n\t\t\t\t\t\treturn EntityType.VARIABLE\n\n\t# Module-level\n\tif node_type in self.config.module:\n\t\treturn EntityType.MODULE\n\tif node_type in self.config.namespace:\n\t\treturn EntityType.NAMESPACE\n\n\t# Documentation\n\tif node_type in self.config.docstring:\n\t\t# Check if this is a docstring (first string in a container)\n\t\tif self._is_docstring(node, parent):\n\t\t\treturn EntityType.DOCSTRING\n\t\treturn EntityType.UNKNOWN  # Regular string literals\n\tif node_type in self.config.comment:\n\t\treturn EntityType.COMMENT\n\n\t# Type definitions\n\tif node_type in self.config.class_:\n\t\treturn EntityType.CLASS\n\tif node_type in self.config.interface:\n\t\t# Would need to check for ABC inheritance to be precise\n\t\treturn EntityType.INTERFACE\n\tif node_type in self.config.protocol:\n\t\t# Would need to check for Protocol inheritance to be precise\n\t\treturn EntityType.PROTOCOL\n\tif node_type in self.config.type_alias:\n\t\t# For assignments, check if it's a constant (all uppercase) first\n\t\tif node_type == \"assignment\":\n\t\t\tname_node = node.child_by_field_name(\"left\")\n\t\t\tif name_node:\n\t\t\t\tname = content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\tlogger.debug(\"Checking potential constant in type_alias: %s (is_upper: %s)\", name, name.isupper())\n\t\t\t\t# Improved check for constants: name is uppercase and contains at least one letter\n\t\t\t\tif name.isupper() and any(c.isalpha() for c in name):\n\t\t\t\t\tlogger.debug(\"Identified as CONSTANT: %s\", name)\n\t\t\t\t\treturn EntityType.CONSTANT\n\n\t\t# Otherwise, treat as a type alias\n\t\treturn EntityType.TYPE_ALIAS\n\n\t# Functions and methods\n\tif node_type in self.config.function:\n\t\t# Check if this is a test function\n\t\tname = self.extract_name(node, content_bytes)\n\t\tif name.startswith(\"test_\"):\n\t\t\treturn EntityType.TEST_CASE\n\n\t\t# Check if this is a method by looking for class ancestry\n\t\tif self._is_within_class_context(node):\n\t\t\treturn EntityType.METHOD\n\t\treturn EntityType.FUNCTION\n\n\t# Check for properties - decorated definitions\n\tif node_type in self.config.property_def:\n\t\tfor child in node.children:\n\t\t\tif child.type == \"decorator\":\n\t\t\t\tdecorator_text = content_bytes[child.start_byte : child.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\tif \"@property\" in decorator_text:\n\t\t\t\t\treturn EntityType.PROPERTY\n\t\t# If no @property decorator, treat as method if in class, otherwise function\n\t\tif self._is_within_class_context(node):\n\t\t\treturn EntityType.METHOD\n\t\treturn EntityType.FUNCTION\n\n\t# Variables and constants\n\tif node_type in self.config.variable:\n\t\t# Check if it looks like a constant (uppercase name)\n\t\tname_node = node.child_by_field_name(\"left\")\n\t\tif name_node:\n\t\t\tname = content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\tlogger.debug(\"Checking potential constant: %s (is_upper: %s)\", name, name.isupper())\n\t\t\t# Improved check for constants: name is uppercase and contains at least one letter\n\t\t\tif name.isupper() and any(c.isalpha() for c in name):\n\t\t\t\tlogger.debug(\"Identified as CONSTANT: %s\", name)\n\t\t\t\treturn EntityType.CONSTANT\n\t\tlogger.debug(\"Identified as VARIABLE: node_type=%s\", node_type)\n\t\treturn EntityType.VARIABLE\n\n\t# Class fields\n\tif node_type in self.config.class_field:\n\t\treturn EntityType.CLASS_FIELD\n\n\t# Code organization\n\tif node_type in self.config.import_:\n\t\treturn EntityType.IMPORT\n\tif node_type in self.config.decorator:\n\t\treturn EntityType.DECORATOR\n\n\treturn EntityType.UNKNOWN\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonSyntaxHandler.find_docstring","title":"find_docstring","text":"<pre><code>find_docstring(\n\tnode: Node, content_bytes: bytes\n) -&gt; tuple[str | None, Node | None]\n</code></pre> <p>Find the docstring associated with a definition node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>A tuple containing:</p> <code>Node | None</code> <ul> <li>The extracted docstring text (or None).</li> </ul> <code>tuple[str | None, Node | None]</code> <ul> <li>The specific AST node representing the docstring (or None).</li> </ul> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>def find_docstring(self, node: Node, content_bytes: bytes) -&gt; tuple[str | None, Node | None]:\n\t\"\"\"\n\tFind the docstring associated with a definition node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    A tuple containing:\n\t    - The extracted docstring text (or None).\n\t    - The specific AST node representing the docstring (or None).\n\n\t\"\"\"\n\tbody_node = self.get_body_node(node)\n\tif not body_node:\n\t\t# Handle module docstring case (no explicit body node)\n\t\tif node.type == \"module\":\n\t\t\tbody_node = node  # Treat module itself as the body context\n\t\telse:\n\t\t\treturn None, None\n\n\tif body_node.named_child_count == 0:\n\t\treturn None, None\n\n\t# Look for the first child that might be a docstring\n\tfirst_body_child = None\n\tfor child in body_node.children:\n\t\tif child.is_named:\n\t\t\tfirst_body_child = child\n\t\t\tbreak\n\n\tif not first_body_child:\n\t\treturn None, None\n\n\tactual_string_node = None\n\tdocstring_container_node = None  # The node to skip during processing\n\n\tif first_body_child.type == \"expression_statement\":\n\t\t# For expression statements containing string literals\n\t\tfor child in first_body_child.children:\n\t\t\tif child.type in self.config.docstring:\n\t\t\t\tactual_string_node = child\n\t\t\t\tdocstring_container_node = first_body_child\n\t\t\t\tbreak\n\telif first_body_child.type in self.config.docstring:\n\t\t# Direct string literal\n\t\tactual_string_node = first_body_child\n\t\tdocstring_container_node = first_body_child\n\n\tif actual_string_node:\n\t\ttry:\n\t\t\tdocstring_text = (\n\t\t\t\tcontent_bytes[actual_string_node.start_byte : actual_string_node.end_byte]\n\t\t\t\t.decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\t.strip(\"\\\"' \\n\")\n\t\t\t)\n\t\t\treturn docstring_text, docstring_container_node\n\t\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\t\tlogger.warning(\"Failed to decode/extract Python docstring: %s\", e)\n\n\treturn None, None\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonSyntaxHandler.extract_name","title":"extract_name","text":"<pre><code>extract_name(node: Node, content_bytes: bytes) -&gt; str\n</code></pre> <p>Extract the name identifier from a definition node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>str</code> <p>The extracted name</p> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>def extract_name(self, node: Node, content_bytes: bytes) -&gt; str:\n\t\"\"\"\n\tExtract the name identifier from a definition node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    The extracted name\n\n\t\"\"\"\n\t# Try to find the name field\n\tname_node = node.child_by_field_name(\"name\")\n\n\t# Handle assignments\n\tif not name_node and node.type == \"assignment\":\n\t\tname_node = node.child_by_field_name(\"left\")\n\n\t# Handle expression statements with assignments\n\tif not name_node and node.type == \"expression_statement\":\n\t\tfor child in node.children:\n\t\t\tif child.type == \"assignment\":\n\t\t\t\tname_node = child.child_by_field_name(\"left\")\n\t\t\t\tif name_node:\n\t\t\t\t\tbreak\n\n\t# Handle decorated definitions\n\tif not name_node and node.type == \"decorated_definition\":\n\t\tfunc_def = node.child_by_field_name(\"definition\")\n\t\tif func_def:\n\t\t\tname_node = func_def.child_by_field_name(\"name\")\n\n\tif name_node:\n\t\ttry:\n\t\t\treturn content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\t\tlogger.warning(\"Failed to decode Python name: %s\", e)\n\t\t\treturn f\"&lt;decoding-error-{node.type}&gt;\"\n\n\treturn f\"&lt;anonymous-{node.type}&gt;\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonSyntaxHandler.get_body_node","title":"get_body_node","text":"<pre><code>get_body_node(node: Node) -&gt; Node | None\n</code></pre> <p>Get the node representing the 'body' of a definition.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <p>Returns:</p> Type Description <code>Node | None</code> <p>The body node if available, None otherwise</p> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>def get_body_node(self, node: Node) -&gt; Node | None:\n\t\"\"\"\n\tGet the node representing the 'body' of a definition.\n\n\tArgs:\n\t    node: The tree-sitter node\n\n\tReturns:\n\t    The body node if available, None otherwise\n\n\t\"\"\"\n\t# For functions and classes in Python, the body is a 'block' node\n\tbody_node = node.child_by_field_name(\"body\")\n\n\t# Handle decorated definitions\n\tif not body_node and node.type == \"decorated_definition\":\n\t\tfunc_def = node.child_by_field_name(\"definition\")\n\t\tif func_def:\n\t\t\tbody_node = func_def.child_by_field_name(\"body\")\n\n\treturn body_node\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonSyntaxHandler.get_children_to_process","title":"get_children_to_process","text":"<pre><code>get_children_to_process(\n\tnode: Node, body_node: Node | None\n) -&gt; list[Node]\n</code></pre> <p>Get the list of child nodes that should be recursively processed.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>body_node</code> <code>Node | None</code> <p>The body node if available</p> required <p>Returns:</p> Type Description <code>list[Node]</code> <p>List of child nodes to process</p> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>def get_children_to_process(self, node: Node, body_node: Node | None) -&gt; list[Node]:\n\t\"\"\"\n\tGet the list of child nodes that should be recursively processed.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    body_node: The body node if available\n\n\tReturns:\n\t    List of child nodes to process\n\n\t\"\"\"\n\t# Process children of the body node if it exists, otherwise process direct children\n\treturn list(body_node.children) if body_node else list(node.children)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonSyntaxHandler.should_skip_node","title":"should_skip_node","text":"<pre><code>should_skip_node(node: Node) -&gt; bool\n</code></pre> <p>Determine if a node should be skipped entirely during processing.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the node should be skipped</p> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>def should_skip_node(self, node: Node) -&gt; bool:\n\t\"\"\"\n\tDetermine if a node should be skipped entirely during processing.\n\n\tArgs:\n\t    node: The tree-sitter node\n\n\tReturns:\n\t    True if the node should be skipped\n\n\t\"\"\"\n\t# Skip non-named nodes (like punctuation, operators)\n\tif not node.is_named:\n\t\treturn True\n\n\t# Skip syntax nodes that don't contribute to code structure\n\treturn node.type in [\"(\", \")\", \"{\", \"}\", \"[\", \"]\", \";\", \".\", \",\"]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonSyntaxHandler.extract_imports","title":"extract_imports","text":"<pre><code>extract_imports(\n\tnode: Node, content_bytes: bytes\n) -&gt; list[str]\n</code></pre> <p>Extract imported module names from a Python import statement.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node representing an import statement</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of imported module names as strings</p> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>def extract_imports(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\"\"\"\n\tExtract imported module names from a Python import statement.\n\n\tArgs:\n\t    node: The tree-sitter node representing an import statement\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    List of imported module names as strings\n\n\t\"\"\"\n\tif node.type not in self.config.import_:\n\t\treturn []\n\n\timported_names = []\n\n\ttry:\n\t\t# Handle regular import statements: \"import foo, bar\"\n\t\tif node.type == \"import_statement\":\n\t\t\tfor child in node.children:\n\t\t\t\tif child.type == \"dotted_name\":\n\t\t\t\t\tmodule_name = content_bytes[child.start_byte : child.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\t\t\timported_names.append(module_name)\n\n\t\t# Handle import from statements: \"from foo.bar import baz, qux\"\n\t\telif node.type == \"import_from_statement\":\n\t\t\t# Get the module being imported from\n\t\t\tmodule_node = None\n\t\t\tfor child in node.children:\n\t\t\t\tif child.type == \"dotted_name\":\n\t\t\t\t\tmodule_node = child\n\t\t\t\t\tbreak\n\n\t\t\tif module_node:\n\t\t\t\tmodule_name = content_bytes[module_node.start_byte : module_node.end_byte].decode(\n\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t)\n\n\t\t\t\t# Get the imported names\n\t\t\t\timport_node = node.child_by_field_name(\"import\")\n\t\t\t\tif import_node:\n\t\t\t\t\t# Check for the wildcard import case: \"from foo import *\"\n\t\t\t\t\tfor child in import_node.children:\n\t\t\t\t\t\tif child.type == \"wildcard_import\":\n\t\t\t\t\t\t\timported_names.append(f\"{module_name}.*\")\n\t\t\t\t\t\t\treturn imported_names\n\n\t\t\t\t\t# Regular named imports\n\t\t\t\t\tfor child in import_node.children:\n\t\t\t\t\t\tif child.type == \"import_list\":\n\t\t\t\t\t\t\tfor item in child.children:\n\t\t\t\t\t\t\t\tif item.type in {\"dotted_name\", \"identifier\"}:\n\t\t\t\t\t\t\t\t\tname = content_bytes[item.start_byte : item.end_byte].decode(\n\t\t\t\t\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t\timported_names.append(f\"{module_name}.{name}\")\n\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\tlogger.warning(\"Failed to decode Python imports: %s\", e)\n\n\treturn imported_names\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/python/#codemap.processor.tree_sitter.languages.python.PythonSyntaxHandler.extract_calls","title":"extract_calls","text":"<pre><code>extract_calls(\n\tnode: Node, content_bytes: bytes\n) -&gt; list[str]\n</code></pre> <p>Extract names of functions/methods called within a Python node's scope.</p> <p>Recursively searches for 'call' nodes and extracts the function identifier.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node (e.g., function/method body)</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of called function/method names</p> Source code in <code>src/codemap/processor/tree_sitter/languages/python.py</code> <pre><code>def extract_calls(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\"\"\"\n\tExtract names of functions/methods called within a Python node's scope.\n\n\tRecursively searches for 'call' nodes and extracts the function identifier.\n\n\tArgs:\n\t    node: The tree-sitter node (e.g., function/method body)\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    List of called function/method names\n\n\t\"\"\"\n\tcalls = []\n\tfor child in node.children:\n\t\tif child.type == \"call\":\n\t\t\tfunction_node = child.child_by_field_name(\"function\")\n\t\t\tif function_node:\n\t\t\t\t# Extract the identifier (could be simple name or attribute access like obj.method)\n\t\t\t\t# For simplicity, we take the full text of the function node\n\t\t\t\ttry:\n\t\t\t\t\tcall_name = content_bytes[function_node.start_byte : function_node.end_byte].decode(\n\t\t\t\t\t\t\"utf-8\", errors=\"ignore\"\n\t\t\t\t\t)\n\t\t\t\t\tcalls.append(call_name)\n\t\t\t\texcept UnicodeDecodeError:\n\t\t\t\t\tpass  # Ignore decoding errors\n\t\t# Recursively search within the arguments or children of the call if needed, but often not necessary\n\t\t# for call details, just the name.\n\t\t# Else, recursively search deeper within non-call children\n\t\telse:\n\t\t\tcalls.extend(self.extract_calls(child, content_bytes))\n\treturn list(set(calls))  # Return unique calls\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/","title":"Typescript","text":"<p>TypeScript-specific configuration for syntax chunking.</p>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig","title":"TypeScriptConfig  <code>dataclass</code>","text":"<p>               Bases: <code>LanguageConfig</code></p> <p>TypeScript-specific syntax chunking configuration.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/typescript.py</code> <pre><code>class TypeScriptConfig(LanguageConfig):\n\t\"\"\"TypeScript-specific syntax chunking configuration.\"\"\"\n\n\t# File-level entities\n\tmodule: ClassVar[list[str]] = [\"program\"]\n\tnamespace: ClassVar[list[str]] = [\"export_statement\", \"namespace_declaration\"]\n\n\t# Type definitions\n\tclass_: ClassVar[list[str]] = [\"class_declaration\", \"class\"]\n\tinterface: ClassVar[list[str]] = [\"interface_declaration\"]\n\tprotocol: ClassVar[list[str]] = []  # TypeScript doesn't have protocols\n\tstruct: ClassVar[list[str]] = []  # TypeScript doesn't have structs\n\tenum: ClassVar[list[str]] = [\"enum_declaration\"]\n\ttype_alias: ClassVar[list[str]] = [\"type_alias_declaration\"]\n\n\t# Functions and methods\n\tfunction: ClassVar[list[str]] = [\n\t\t\"function_declaration\",\n\t\t\"function\",\n\t\t\"arrow_function\",\n\t\t\"generator_function_declaration\",\n\t]\n\tmethod: ClassVar[list[str]] = [\"method_definition\", \"method_signature\"]\n\tproperty_def: ClassVar[list[str]] = [\"property_identifier\", \"public_field_definition\", \"property_signature\"]\n\ttest_case: ClassVar[list[str]] = [\"call_expression\"]  # Special detection for test frameworks\n\ttest_suite: ClassVar[list[str]] = [\"call_expression\"]  # Special detection for test frameworks\n\n\t# Variables and constants\n\tvariable: ClassVar[list[str]] = [\"variable_declaration\", \"lexical_declaration\"]\n\tconstant: ClassVar[list[str]] = [\"variable_declaration\", \"lexical_declaration\"]  # const declarations\n\tclass_field: ClassVar[list[str]] = [\"public_field_definition\"]\n\n\t# Code organization\n\timport_: ClassVar[list[str]] = [\"import_statement\"]\n\tdecorator: ClassVar[list[str]] = [\"decorator\"]\n\n\t# Documentation\n\tcomment: ClassVar[list[str]] = [\"comment\"]\n\tdocstring: ClassVar[list[str]] = [\"comment\"]  # TS uses comments for documentation\n\n\tfile_extensions: ClassVar[list[str]] = [\".ts\", \".tsx\"]\n\ttree_sitter_name: ClassVar[str] = \"typescript\"\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.module","title":"module  <code>class-attribute</code>","text":"<pre><code>module: list[str] = ['program']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.namespace","title":"namespace  <code>class-attribute</code>","text":"<pre><code>namespace: list[str] = [\n\t\"export_statement\",\n\t\"namespace_declaration\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.class_","title":"class_  <code>class-attribute</code>","text":"<pre><code>class_: list[str] = ['class_declaration', 'class']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.interface","title":"interface  <code>class-attribute</code>","text":"<pre><code>interface: list[str] = ['interface_declaration']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.struct","title":"struct  <code>class-attribute</code>","text":"<pre><code>struct: list[str] = []\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.enum","title":"enum  <code>class-attribute</code>","text":"<pre><code>enum: list[str] = ['enum_declaration']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.type_alias","title":"type_alias  <code>class-attribute</code>","text":"<pre><code>type_alias: list[str] = ['type_alias_declaration']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.function","title":"function  <code>class-attribute</code>","text":"<pre><code>function: list[str] = [\n\t\"function_declaration\",\n\t\"function\",\n\t\"arrow_function\",\n\t\"generator_function_declaration\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.method","title":"method  <code>class-attribute</code>","text":"<pre><code>method: list[str] = [\n\t\"method_definition\",\n\t\"method_signature\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.property_def","title":"property_def  <code>class-attribute</code>","text":"<pre><code>property_def: list[str] = [\n\t\"property_identifier\",\n\t\"public_field_definition\",\n\t\"property_signature\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.test_case","title":"test_case  <code>class-attribute</code>","text":"<pre><code>test_case: list[str] = ['call_expression']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.test_suite","title":"test_suite  <code>class-attribute</code>","text":"<pre><code>test_suite: list[str] = ['call_expression']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.variable","title":"variable  <code>class-attribute</code>","text":"<pre><code>variable: list[str] = [\n\t\"variable_declaration\",\n\t\"lexical_declaration\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.constant","title":"constant  <code>class-attribute</code>","text":"<pre><code>constant: list[str] = [\n\t\"variable_declaration\",\n\t\"lexical_declaration\",\n]\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.class_field","title":"class_field  <code>class-attribute</code>","text":"<pre><code>class_field: list[str] = ['public_field_definition']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.import_","title":"import_  <code>class-attribute</code>","text":"<pre><code>import_: list[str] = ['import_statement']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.decorator","title":"decorator  <code>class-attribute</code>","text":"<pre><code>decorator: list[str] = ['decorator']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.comment","title":"comment  <code>class-attribute</code>","text":"<pre><code>comment: list[str] = ['comment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.docstring","title":"docstring  <code>class-attribute</code>","text":"<pre><code>docstring: list[str] = ['comment']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.file_extensions","title":"file_extensions  <code>class-attribute</code>","text":"<pre><code>file_extensions: list[str] = ['.ts', '.tsx']\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptConfig.tree_sitter_name","title":"tree_sitter_name  <code>class-attribute</code>","text":"<pre><code>tree_sitter_name: str = 'typescript'\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TYPESCRIPT_CONFIG","title":"TYPESCRIPT_CONFIG  <code>module-attribute</code>","text":"<pre><code>TYPESCRIPT_CONFIG = TypeScriptConfig()\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptSyntaxHandler","title":"TypeScriptSyntaxHandler","text":"<p>               Bases: <code>JavaScriptSyntaxHandler</code></p> <p>TypeScript-specific syntax handling logic.</p> <p>Inherits from JavaScript handler to reuse common logic.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/typescript.py</code> <pre><code>class TypeScriptSyntaxHandler(JavaScriptSyntaxHandler):\n\t\"\"\"\n\tTypeScript-specific syntax handling logic.\n\n\tInherits from JavaScript handler to reuse common logic.\n\n\t\"\"\"\n\n\tdef __init__(self) -&gt; None:\n\t\t\"\"\"Initialize with TypeScript configuration.\"\"\"\n\t\tsuper().__init__()\n\t\t# Override the config from JavaScriptSyntaxHandler\n\t\tself.config = TYPESCRIPT_CONFIG\n\n\tdef get_entity_type(self, node: Node, parent: Node | None, content_bytes: bytes) -&gt; EntityType:\n\t\t\"\"\"\n\t\tDetermine the EntityType for a TypeScript node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    parent: The parent node (if any)\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    The entity type\n\n\t\t\"\"\"\n\t\tnode_type = node.type\n\t\tlogger.debug(\n\t\t\t\"Getting entity type for TypeScript node: type=%s, parent_type=%s\",\n\t\t\tnode_type,\n\t\t\tparent.type if parent else None,\n\t\t)\n\n\t\t# TypeScript-specific types\n\t\tif node_type == \"interface_declaration\":\n\t\t\treturn EntityType.INTERFACE\n\t\tif node_type == \"enum_declaration\":\n\t\t\treturn EntityType.ENUM\n\t\tif node_type == \"type_alias_declaration\":\n\t\t\treturn EntityType.TYPE_ALIAS\n\t\tif node_type == \"namespace_declaration\":\n\t\t\treturn EntityType.NAMESPACE\n\t\tif node_type == \"method_signature\":\n\t\t\treturn EntityType.METHOD\n\t\tif node_type == \"property_signature\":\n\t\t\treturn EntityType.PROPERTY\n\n\t\t# Use the JavaScript logic for common types\n\t\treturn super().get_entity_type(node, parent, content_bytes)\n\n\tdef extract_name(self, node: Node, content_bytes: bytes) -&gt; str:\n\t\t\"\"\"\n\t\tExtract the name identifier from a definition node.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    The extracted name\n\n\t\t\"\"\"\n\t\t# Handle TypeScript-specific node types first\n\t\tname_node = None\n\n\t\tif node.type in [\n\t\t\t\"interface_declaration\",\n\t\t\t\"enum_declaration\",\n\t\t\t\"type_alias_declaration\",\n\t\t\t\"namespace_declaration\",\n\t\t] or node.type in [\"method_signature\", \"property_signature\"]:\n\t\t\tname_node = node.child_by_field_name(\"name\")\n\n\t\tif name_node:\n\t\t\ttry:\n\t\t\t\treturn content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\t\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\t\t\tlogger.warning(\"Failed to decode TypeScript name: %s\", e)\n\t\t\t\treturn f\"&lt;decoding-error-{node.type}&gt;\"\n\n\t\t# Fall back to JavaScript name extraction\n\t\treturn super().extract_name(node, content_bytes)\n\n\tdef get_body_node(self, node: Node) -&gt; Node | None:\n\t\t\"\"\"\n\t\tGet the node representing the 'body' of a definition.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\n\t\tReturns:\n\t\t    The body node if available, None otherwise\n\n\t\t\"\"\"\n\t\t# TypeScript-specific handling\n\t\tif node.type in [\"interface_declaration\", \"namespace_declaration\"] or node.type == \"enum_declaration\":\n\t\t\treturn node.child_by_field_name(\"body\")\n\n\t\t# Fall back to JavaScript body extraction\n\t\treturn super().get_body_node(node)\n\n\tdef get_children_to_process(self, node: Node, body_node: Node | None) -&gt; list[Node]:\n\t\t\"\"\"\n\t\tGet the list of child nodes that should be recursively processed.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node\n\t\t    body_node: The body node if available\n\n\t\tReturns:\n\t\t    List of child nodes to process\n\n\t\t\"\"\"\n\t\t# TypeScript-specific handling\n\t\tif node.type == \"type_alias_declaration\":\n\t\t\t# Type aliases don't have children to process\n\t\t\treturn []\n\n\t\t# Fall back to JavaScript children processing\n\t\treturn super().get_children_to_process(node, body_node)\n\n\tdef extract_imports(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\t\"\"\"\n\t\tExtract imported module names from a TypeScript import statement.\n\n\t\tArgs:\n\t\t    node: The tree-sitter node representing an import statement\n\t\t    content_bytes: Source code content as bytes\n\n\t\tReturns:\n\t\t    List of imported module names as strings\n\n\t\t\"\"\"\n\t\t# TypeScript import statements are the same as JavaScript\n\t\treturn super().extract_imports(node, content_bytes)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptSyntaxHandler.__init__","title":"__init__","text":"<pre><code>__init__() -&gt; None\n</code></pre> <p>Initialize with TypeScript configuration.</p> Source code in <code>src/codemap/processor/tree_sitter/languages/typescript.py</code> <pre><code>def __init__(self) -&gt; None:\n\t\"\"\"Initialize with TypeScript configuration.\"\"\"\n\tsuper().__init__()\n\t# Override the config from JavaScriptSyntaxHandler\n\tself.config = TYPESCRIPT_CONFIG\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptSyntaxHandler.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = TYPESCRIPT_CONFIG\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptSyntaxHandler.get_entity_type","title":"get_entity_type","text":"<pre><code>get_entity_type(\n\tnode: Node, parent: Node | None, content_bytes: bytes\n) -&gt; EntityType\n</code></pre> <p>Determine the EntityType for a TypeScript node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>parent</code> <code>Node | None</code> <p>The parent node (if any)</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>EntityType</code> <p>The entity type</p> Source code in <code>src/codemap/processor/tree_sitter/languages/typescript.py</code> <pre><code>def get_entity_type(self, node: Node, parent: Node | None, content_bytes: bytes) -&gt; EntityType:\n\t\"\"\"\n\tDetermine the EntityType for a TypeScript node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    parent: The parent node (if any)\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    The entity type\n\n\t\"\"\"\n\tnode_type = node.type\n\tlogger.debug(\n\t\t\"Getting entity type for TypeScript node: type=%s, parent_type=%s\",\n\t\tnode_type,\n\t\tparent.type if parent else None,\n\t)\n\n\t# TypeScript-specific types\n\tif node_type == \"interface_declaration\":\n\t\treturn EntityType.INTERFACE\n\tif node_type == \"enum_declaration\":\n\t\treturn EntityType.ENUM\n\tif node_type == \"type_alias_declaration\":\n\t\treturn EntityType.TYPE_ALIAS\n\tif node_type == \"namespace_declaration\":\n\t\treturn EntityType.NAMESPACE\n\tif node_type == \"method_signature\":\n\t\treturn EntityType.METHOD\n\tif node_type == \"property_signature\":\n\t\treturn EntityType.PROPERTY\n\n\t# Use the JavaScript logic for common types\n\treturn super().get_entity_type(node, parent, content_bytes)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptSyntaxHandler.extract_name","title":"extract_name","text":"<pre><code>extract_name(node: Node, content_bytes: bytes) -&gt; str\n</code></pre> <p>Extract the name identifier from a definition node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>str</code> <p>The extracted name</p> Source code in <code>src/codemap/processor/tree_sitter/languages/typescript.py</code> <pre><code>def extract_name(self, node: Node, content_bytes: bytes) -&gt; str:\n\t\"\"\"\n\tExtract the name identifier from a definition node.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    The extracted name\n\n\t\"\"\"\n\t# Handle TypeScript-specific node types first\n\tname_node = None\n\n\tif node.type in [\n\t\t\"interface_declaration\",\n\t\t\"enum_declaration\",\n\t\t\"type_alias_declaration\",\n\t\t\"namespace_declaration\",\n\t] or node.type in [\"method_signature\", \"property_signature\"]:\n\t\tname_node = node.child_by_field_name(\"name\")\n\n\tif name_node:\n\t\ttry:\n\t\t\treturn content_bytes[name_node.start_byte : name_node.end_byte].decode(\"utf-8\", errors=\"ignore\")\n\t\texcept (UnicodeDecodeError, IndexError, AttributeError) as e:\n\t\t\tlogger.warning(\"Failed to decode TypeScript name: %s\", e)\n\t\t\treturn f\"&lt;decoding-error-{node.type}&gt;\"\n\n\t# Fall back to JavaScript name extraction\n\treturn super().extract_name(node, content_bytes)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptSyntaxHandler.get_body_node","title":"get_body_node","text":"<pre><code>get_body_node(node: Node) -&gt; Node | None\n</code></pre> <p>Get the node representing the 'body' of a definition.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <p>Returns:</p> Type Description <code>Node | None</code> <p>The body node if available, None otherwise</p> Source code in <code>src/codemap/processor/tree_sitter/languages/typescript.py</code> <pre><code>def get_body_node(self, node: Node) -&gt; Node | None:\n\t\"\"\"\n\tGet the node representing the 'body' of a definition.\n\n\tArgs:\n\t    node: The tree-sitter node\n\n\tReturns:\n\t    The body node if available, None otherwise\n\n\t\"\"\"\n\t# TypeScript-specific handling\n\tif node.type in [\"interface_declaration\", \"namespace_declaration\"] or node.type == \"enum_declaration\":\n\t\treturn node.child_by_field_name(\"body\")\n\n\t# Fall back to JavaScript body extraction\n\treturn super().get_body_node(node)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptSyntaxHandler.get_children_to_process","title":"get_children_to_process","text":"<pre><code>get_children_to_process(\n\tnode: Node, body_node: Node | None\n) -&gt; list[Node]\n</code></pre> <p>Get the list of child nodes that should be recursively processed.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node</p> required <code>body_node</code> <code>Node | None</code> <p>The body node if available</p> required <p>Returns:</p> Type Description <code>list[Node]</code> <p>List of child nodes to process</p> Source code in <code>src/codemap/processor/tree_sitter/languages/typescript.py</code> <pre><code>def get_children_to_process(self, node: Node, body_node: Node | None) -&gt; list[Node]:\n\t\"\"\"\n\tGet the list of child nodes that should be recursively processed.\n\n\tArgs:\n\t    node: The tree-sitter node\n\t    body_node: The body node if available\n\n\tReturns:\n\t    List of child nodes to process\n\n\t\"\"\"\n\t# TypeScript-specific handling\n\tif node.type == \"type_alias_declaration\":\n\t\t# Type aliases don't have children to process\n\t\treturn []\n\n\t# Fall back to JavaScript children processing\n\treturn super().get_children_to_process(node, body_node)\n</code></pre>"},{"location":"api/processor/tree_sitter/languages/typescript/#codemap.processor.tree_sitter.languages.typescript.TypeScriptSyntaxHandler.extract_imports","title":"extract_imports","text":"<pre><code>extract_imports(\n\tnode: Node, content_bytes: bytes\n) -&gt; list[str]\n</code></pre> <p>Extract imported module names from a TypeScript import statement.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The tree-sitter node representing an import statement</p> required <code>content_bytes</code> <code>bytes</code> <p>Source code content as bytes</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of imported module names as strings</p> Source code in <code>src/codemap/processor/tree_sitter/languages/typescript.py</code> <pre><code>def extract_imports(self, node: Node, content_bytes: bytes) -&gt; list[str]:\n\t\"\"\"\n\tExtract imported module names from a TypeScript import statement.\n\n\tArgs:\n\t    node: The tree-sitter node representing an import statement\n\t    content_bytes: Source code content as bytes\n\n\tReturns:\n\t    List of imported module names as strings\n\n\t\"\"\"\n\t# TypeScript import statements are the same as JavaScript\n\treturn super().extract_imports(node, content_bytes)\n</code></pre>"},{"location":"api/utils/","title":"Utils Overview","text":"<p>Utility module for CodeMap package.</p> <ul> <li>Cli Utils - Utility functions for CLI operations in CodeMap.</li> <li>Config Loader - Configuration loader for CodeMap.</li> <li>File Utils - Utility functions for file operations in CodeMap.</li> <li>Log Setup - Logging setup for CodeMap.</li> <li>Path Utils - Utilities for handling paths and file system operations.</li> </ul>"},{"location":"api/utils/cli_utils/","title":"Cli Utils","text":"<p>Utility functions for CLI operations in CodeMap.</p>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.console","title":"console  <code>module-attribute</code>","text":"<pre><code>console = Console()\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.SpinnerState","title":"SpinnerState","text":"<p>Singleton class to track spinner state.</p> Source code in <code>src/codemap/utils/cli_utils.py</code> <pre><code>class SpinnerState:\n\t\"\"\"Singleton class to track spinner state.\"\"\"\n\n\t_instance = None\n\tis_active = False\n\n\tdef __new__(cls) -&gt; Self:\n\t\t\"\"\"\n\t\tCreate or return the singleton instance.\n\n\t\tReturns:\n\t\t    The singleton instance of SpinnerState\n\n\t\t\"\"\"\n\t\tif cls._instance is None:\n\t\t\tcls._instance = super().__new__(cls)\n\t\treturn cls._instance\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.SpinnerState.is_active","title":"is_active  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_active = False\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.SpinnerState.__new__","title":"__new__","text":"<pre><code>__new__() -&gt; Self\n</code></pre> <p>Create or return the singleton instance.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The singleton instance of SpinnerState</p> Source code in <code>src/codemap/utils/cli_utils.py</code> <pre><code>def __new__(cls) -&gt; Self:\n\t\"\"\"\n\tCreate or return the singleton instance.\n\n\tReturns:\n\t    The singleton instance of SpinnerState\n\n\t\"\"\"\n\tif cls._instance is None:\n\t\tcls._instance = super().__new__(cls)\n\treturn cls._instance\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.setup_logging","title":"setup_logging","text":"<pre><code>setup_logging(*, is_verbose: bool) -&gt; None\n</code></pre> <p>Configure logging based on verbosity.</p> <p>Parameters:</p> Name Type Description Default <code>is_verbose</code> <code>bool</code> <p>Whether to enable debug logging.</p> required Source code in <code>src/codemap/utils/cli_utils.py</code> <pre><code>def setup_logging(*, is_verbose: bool) -&gt; None:\n\t\"\"\"\n\tConfigure logging based on verbosity.\n\n\tArgs:\n\t    is_verbose: Whether to enable debug logging.\n\n\t\"\"\"\n\t# Set log level based on verbosity\n\t# In verbose mode, use DEBUG or the level specified in LOG_LEVEL env var\n\t# In non-verbose mode, only show ERROR and above\n\tlog_level = \"DEBUG\" if is_verbose else os.environ.get(\"LOG_LEVEL\", \"INFO\").upper()\n\n\t# When not in verbose mode, override to only show errors\n\tif not is_verbose:\n\t\tlog_level = \"ERROR\"\n\n\tlogging.basicConfig(\n\t\tlevel=log_level,\n\t\tformat=\"%(message)s\",\n\t\tdatefmt=\"[%X]\",\n\t\thandlers=[RichHandler(rich_tracebacks=True, show_time=True, show_path=True)],\n\t)\n\n\t# Also set specific loggers to ERROR when not in verbose mode\n\tif not is_verbose:\n\t\t# Suppress logs from these packages completely unless in verbose mode\n\t\tlogging.getLogger(\"litellm\").setLevel(logging.ERROR)\n\t\tlogging.getLogger(\"httpx\").setLevel(logging.ERROR)\n\t\tlogging.getLogger(\"httpcore\").setLevel(logging.ERROR)\n\t\tlogging.getLogger(\"urllib3\").setLevel(logging.ERROR)\n\t\tlogging.getLogger(\"requests\").setLevel(logging.ERROR)\n\t\tlogging.getLogger(\"openai\").setLevel(logging.ERROR)\n\t\tlogging.getLogger(\"tqdm\").setLevel(logging.ERROR)\n\n\t\t# Set codemap loggers to ERROR level\n\t\tlogging.getLogger(\"codemap\").setLevel(logging.ERROR)\n\n\t\t# Specifically suppress git-related logs\n\t\tlogging.getLogger(\"codemap.utils.git_utils\").setLevel(logging.ERROR)\n\t\tlogging.getLogger(\"codemap.git\").setLevel(logging.ERROR)\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.create_spinner_progress","title":"create_spinner_progress","text":"<pre><code>create_spinner_progress() -&gt; Progress\n</code></pre> <p>Create a spinner progress bar.</p> <p>Returns:</p> Type Description <code>Progress</code> <p>A Progress instance with a spinner</p> Source code in <code>src/codemap/utils/cli_utils.py</code> <pre><code>def create_spinner_progress() -&gt; Progress:\n\t\"\"\"\n\tCreate a spinner progress bar.\n\n\tReturns:\n\t    A Progress instance with a spinner\n\n\t\"\"\"\n\treturn Progress(\n\t\tSpinnerColumn(),\n\t\tTextColumn(\"[progress.description]{task.description}\"),\n\t)\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.loading_spinner","title":"loading_spinner","text":"<pre><code>loading_spinner(\n\tmessage: str = \"Processing...\",\n) -&gt; Iterator[None]\n</code></pre> <p>Display a loading spinner while executing a task.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to display alongside the spinner</p> <code>'Processing...'</code> <p>Yields:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/codemap/utils/cli_utils.py</code> <pre><code>@contextlib.contextmanager\ndef loading_spinner(message: str = \"Processing...\") -&gt; Iterator[None]:\n\t\"\"\"\n\tDisplay a loading spinner while executing a task.\n\n\tArgs:\n\t    message: Message to display alongside the spinner\n\n\tYields:\n\t    None\n\n\t\"\"\"\n\t# In test environments, don't display a spinner\n\tif os.environ.get(\"PYTEST_CURRENT_TEST\") or os.environ.get(\"CI\"):\n\t\tyield\n\t\treturn\n\n\t# Check if a spinner is already active\n\tspinner_state = SpinnerState()\n\tif spinner_state.is_active:\n\t\t# If there's already an active spinner, don't create a new one\n\t\tyield\n\t\treturn\n\n\t# Only use spinner in interactive environments\n\ttry:\n\t\tspinner_state.is_active = True\n\t\t# Use rich.console.Console.status which is designed for this purpose\n\t\t# and provides the spinner animation\n\t\twith console.status(message):\n\t\t\tyield\n\tfinally:\n\t\tspinner_state.is_active = False\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.ensure_directory_exists","title":"ensure_directory_exists","text":"<pre><code>ensure_directory_exists(directory_path: Path) -&gt; None\n</code></pre> <p>Ensure a directory exists, creating it if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>directory_path</code> <code>Path</code> <p>Path to ensure exists</p> required Source code in <code>src/codemap/utils/cli_utils.py</code> <pre><code>def ensure_directory_exists(directory_path: Path) -&gt; None:\n\t\"\"\"\n\tEnsure a directory exists, creating it if necessary.\n\n\tArgs:\n\t    directory_path: Path to ensure exists\n\n\t\"\"\"\n\ttry:\n\t\tdirectory_path.mkdir(parents=True, exist_ok=True)\n\texcept (PermissionError, OSError) as e:\n\t\tconsole.print(f\"[red]Unable to create directory {directory_path}: {e!s}\")\n\t\traise\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.progress_indicator","title":"progress_indicator","text":"<pre><code>progress_indicator(\n\tmessage: str,\n\tstyle: str = \"spinner\",\n\ttotal: int | None = None,\n\ttransient: bool = False,\n) -&gt; Iterator[Callable[[int], None]]\n</code></pre> <p>Standardized progress indicator that supports different styles uniformly.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to display with the progress indicator</p> required <code>style</code> <code>str</code> <p>The style of progress indicator - options:    - \"spinner\": Shows an indeterminate spinner    - \"progress\": Shows a determinate progress bar    - \"step\": Shows simple step-by-step progress</p> <code>'spinner'</code> <code>total</code> <code>int | None</code> <p>For determinate progress, the total units of work</p> <code>None</code> <code>transient</code> <code>bool</code> <p>Whether the progress indicator should disappear after completion</p> <code>False</code> <p>Yields:</p> Type Description <code>Callable[[int], None]</code> <p>A callable that accepts an integer amount to advance the progress</p> Source code in <code>src/codemap/utils/cli_utils.py</code> <pre><code>@contextlib.contextmanager\ndef progress_indicator(\n\tmessage: str,\n\tstyle: str = \"spinner\",\n\ttotal: int | None = None,\n\ttransient: bool = False,\n) -&gt; Iterator[Callable[[int], None]]:\n\t\"\"\"\n\tStandardized progress indicator that supports different styles uniformly.\n\n\tArgs:\n\t    message: The message to display with the progress indicator\n\t    style: The style of progress indicator - options:\n\t           - \"spinner\": Shows an indeterminate spinner\n\t           - \"progress\": Shows a determinate progress bar\n\t           - \"step\": Shows simple step-by-step progress\n\t    total: For determinate progress, the total units of work\n\t    transient: Whether the progress indicator should disappear after completion\n\n\tYields:\n\t    A callable that accepts an integer amount to advance the progress\n\n\t\"\"\"\n\t# Skip visual indicators in testing/CI environments\n\tif os.environ.get(\"PYTEST_CURRENT_TEST\") or os.environ.get(\"CI\"):\n\t\t# Return a no-op advance function\n\t\tyield lambda _: None\n\t\treturn\n\n\t# Check if a spinner is already active\n\tspinner_state = SpinnerState()\n\tif spinner_state.is_active and style == \"spinner\":\n\t\t# If there's already an active spinner, don't create a new one for spinner style\n\t\tyield lambda _: None\n\t\treturn\n\n\ttry:\n\t\t# Mark spinner as active if using spinner style\n\t\tif style == \"spinner\":\n\t\t\tspinner_state.is_active = True\n\n\t\t# Handle different progress styles\n\t\tif style == \"spinner\":\n\t\t\t# Indeterminate spinner using console.status\n\t\t\twith console.status(message):\n\t\t\t\t# Return a no-op advance function since spinners don't advance\n\t\t\t\tyield lambda _: None\n\n\t\telif style == \"progress\":\n\t\t\t# Determinate progress bar using rich.progress.Progress\n\t\t\tprogress = Progress(\n\t\t\t\tSpinnerColumn(),\n\t\t\t\tTextColumn(\"[progress.description]{task.description}\"),\n\t\t\t\ttransient=transient,\n\t\t\t)\n\t\t\twith progress:\n\t\t\t\ttask_id = progress.add_task(message, total=total or 1)\n\t\t\t\t# Return a function that advances the progress\n\t\t\t\tyield lambda amount=1: progress.update(task_id, advance=amount)\n\n\t\telif style == \"step\":\n\t\t\t# Simple step progress like typer.progressbar\n\t\t\tsteps_completed = 0\n\t\t\ttotal_steps = total or 1\n\n\t\t\tconsole.print(f\"{message} [0/{total_steps}]\")\n\n\t\t\t# Function to advance and display steps\n\t\t\tdef advance_step(amount: int = 1) -&gt; None:\n\t\t\t\tnonlocal steps_completed\n\t\t\t\tsteps_completed += amount\n\t\t\t\tsteps_completed = min(steps_completed, total_steps)\n\t\t\t\tconsole.print(f\"{message} [{steps_completed}/{total_steps}]\")\n\n\t\t\tyield advance_step\n\n\t\t\t# Print completion if not transient\n\t\t\tif not transient and steps_completed &gt;= total_steps:\n\t\t\t\tconsole.print(f\"{message} [green]Complete![/green]\")\n\tfinally:\n\t\t# Reset spinner state if we were using spinner style\n\t\tif style == \"spinner\":\n\t\t\tspinner_state.is_active = False\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.show_error","title":"show_error","text":"<pre><code>show_error(\n\tmessage: str, exception: Exception | None = None\n) -&gt; None\n</code></pre> <p>Display an error summary with standardized formatting.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The error message to display</p> required <code>exception</code> <code>Exception | None</code> <p>Optional exception that caused the error</p> <code>None</code> Source code in <code>src/codemap/utils/cli_utils.py</code> <pre><code>def show_error(message: str, exception: Exception | None = None) -&gt; None:\n\t\"\"\"\n\tDisplay an error summary with standardized formatting.\n\n\tArgs:\n\t        message: The error message to display\n\t        exception: Optional exception that caused the error\n\n\t\"\"\"\n\terror_text = message\n\tif exception:\n\t\terror_text += f\"\\n\\nDetails: {exception!s}\"\n\t\tlogger.exception(\"Error occurred\", exc_info=exception)\n\n\tdisplay_error_summary(error_text)\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.show_warning","title":"show_warning","text":"<pre><code>show_warning(message: str) -&gt; None\n</code></pre> <p>Display a warning summary with standardized formatting.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The warning message to display</p> required Source code in <code>src/codemap/utils/cli_utils.py</code> <pre><code>def show_warning(message: str) -&gt; None:\n\t\"\"\"\n\tDisplay a warning summary with standardized formatting.\n\n\tArgs:\n\t        message: The warning message to display\n\n\t\"\"\"\n\tdisplay_warning_summary(message)\n</code></pre>"},{"location":"api/utils/cli_utils/#codemap.utils.cli_utils.exit_with_error","title":"exit_with_error","text":"<pre><code>exit_with_error(\n\tmessage: str,\n\texit_code: int = 1,\n\texception: Exception | None = None,\n) -&gt; None\n</code></pre> <p>Display an error message and exit.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message to display</p> required <code>exit_code</code> <code>int</code> <p>Exit code to use</p> <code>1</code> <code>exception</code> <code>Exception | None</code> <p>Optional exception that caused the error</p> <code>None</code> Source code in <code>src/codemap/utils/cli_utils.py</code> <pre><code>def exit_with_error(message: str, exit_code: int = 1, exception: Exception | None = None) -&gt; None:\n\t\"\"\"\n\tDisplay an error message and exit.\n\n\tArgs:\n\t        message: Error message to display\n\t        exit_code: Exit code to use\n\t        exception: Optional exception that caused the error\n\n\t\"\"\"\n\tshow_error(message, exception)\n\tif exception is None:\n\t\traise typer.Exit(exit_code)\n\traise typer.Exit(exit_code) from exception\n</code></pre>"},{"location":"api/utils/config_loader/","title":"Config Loader","text":"<p>Configuration loader for CodeMap.</p> <p>This module provides functionality for loading and managing configuration settings.</p>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.T","title":"T  <code>module-attribute</code>","text":"<pre><code>T = TypeVar('T')\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.MIN_ENV_VAR_PARTS","title":"MIN_ENV_VAR_PARTS  <code>module-attribute</code>","text":"<pre><code>MIN_ENV_VAR_PARTS = 2\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigValue","title":"ConfigValue  <code>module-attribute</code>","text":"<pre><code>ConfigValue = (\n\tstr\n\t| int\n\t| float\n\t| bool\n\t| dict[str, Any]\n\t| list[Any]\n\t| None\n)\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigError","title":"ConfigError","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised for configuration errors.</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>class ConfigError(Exception):\n\t\"\"\"Exception raised for configuration errors.\"\"\"\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader","title":"ConfigLoader","text":"<p>Loads and manages configuration for CodeMap.</p> <p>This class handles loading configuration from files, environment variables, and default values, with proper error handling and path resolution.</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>class ConfigLoader:\n\t\"\"\"\n\tLoads and manages configuration for CodeMap.\n\n\tThis class handles loading configuration from files, environment\n\tvariables, and default values, with proper error handling and path\n\tresolution.\n\n\t\"\"\"\n\n\t_instance = None  # For singleton pattern\n\n\t@classmethod\n\tdef get_instance(\n\t\tcls, config_file: str | None = None, reload: bool = False, repo_root: Path | None = None\n\t) -&gt; \"ConfigLoader\":\n\t\t\"\"\"\n\t\tGet the singleton instance of ConfigLoader.\n\n\t\tArgs:\n\t\t        config_file: Path to configuration file (optional)\n\t\t        reload: Whether to reload config even if already loaded\n\t\t        repo_root: Repository root path (optional)\n\n\t\tReturns:\n\t\t        ConfigLoader: Singleton instance\n\n\t\t\"\"\"\n\t\tif cls._instance is None or reload:\n\t\t\tcls._instance = cls(config_file, repo_root=repo_root)\n\t\treturn cls._instance\n\n\tdef __init__(self, config_file: str | None = None, repo_root: Path | None = None) -&gt; None:\n\t\t\"\"\"\n\t\tInitialize the configuration loader.\n\n\t\tArgs:\n\t\t        config_file: Path to configuration file (optional)\n\t\t        repo_root: Repository root path (optional)\n\n\t\t\"\"\"\n\t\tself.config: dict[str, Any] = {}\n\t\tself.repo_root = repo_root\n\t\tself.config_file = self._resolve_config_file(config_file)\n\t\tself.load_config()\n\n\tdef _resolve_config_file(self, config_file: str | None = None) -&gt; Path | None:\n\t\t\"\"\"\n\t\tResolve the configuration file path.\n\n\t\tIf a config file is specified, use that. Otherwise, look in standard locations:\n\t\t1. ./.codemap.yml in the current directory\n\t\t2. $XDG_CONFIG_HOME/codemap/config.yml\n\t\t3. ~/.config/codemap/config.yml (fallback if XDG_CONFIG_HOME not set)\n\n\t\tArgs:\n\t\t        config_file: Explicitly provided config file path (optional)\n\n\t\tReturns:\n\t\t        Optional[Path]: Resolved config file path or None if no suitable file found\n\n\t\t\"\"\"\n\t\tif config_file:\n\t\t\tpath = Path(config_file).expanduser().resolve()\n\t\t\tif path.exists():\n\t\t\t\treturn path\n\t\t\tlogger.warning(\"Specified config file not found: %s\", path)\n\t\t\treturn path  # Return it anyway, we'll handle the missing file in load_config\n\n\t\t# Try current directory\n\t\tlocal_config = Path(\".codemap.yml\")\n\t\tif local_config.exists():\n\t\t\treturn local_config\n\n\t\t# Try XDG config path\n\t\txdg_config_dir = Path(xdg_config_home) / \"codemap\"\n\t\txdg_config_file = xdg_config_dir / \"config.yml\"\n\t\tif xdg_config_file.exists():\n\t\t\treturn xdg_config_file\n\n\t\t# As a last resort, try the legacy ~/.codemap location\n\t\tlegacy_config = Path.home() / \".codemap\" / \"config.yml\"\n\t\tif legacy_config.exists():\n\t\t\treturn legacy_config\n\n\t\t# If we get here, no config file was found\n\t\treturn None\n\n\tdef load_config(self) -&gt; dict[str, Any]:\n\t\t\"\"\"\n\t\tLoad configuration from file and apply environment variable overrides.\n\n\t\tReturns:\n\t\t        Dict[str, Any]: Loaded configuration\n\n\t\tRaises:\n\t\t        ConfigError: If configuration file exists but cannot be loaded\n\n\t\t\"\"\"\n\t\t# Start with default configuration\n\t\tself.config = DEFAULT_CONFIG.copy()\n\n\t\t# Try to load from file if available\n\t\tif self.config_file:\n\t\t\ttry:\n\t\t\t\tif self.config_file.exists():\n\t\t\t\t\twith self.config_file.open(encoding=\"utf-8\") as f:\n\t\t\t\t\t\tfile_config = yaml.safe_load(f)\n\t\t\t\t\t\tif file_config:\n\t\t\t\t\t\t\tself._merge_configs(self.config, file_config)\n\t\t\t\t\tlogger.info(\"Loaded configuration from %s\", self.config_file)\n\t\t\t\telse:\n\t\t\t\t\tlogger.warning(\"Configuration file not found: %s\", self.config_file)\n\t\t\texcept (OSError, yaml.YAMLError) as e:\n\t\t\t\terror_msg = f\"Error loading configuration from {self.config_file}: {e}\"\n\t\t\t\tlogger.exception(error_msg)\n\t\t\t\traise ConfigError(error_msg) from e\n\n\t\treturn self.config\n\n\tdef _merge_configs(self, base: dict[str, Any], override: dict[str, Any]) -&gt; None:\n\t\t\"\"\"\n\t\tRecursively merge two configuration dictionaries.\n\n\t\tArgs:\n\t\t        base: Base configuration dictionary to merge into\n\t\t        override: Override configuration to apply\n\n\t\t\"\"\"\n\t\tfor key, value in override.items():\n\t\t\tif isinstance(value, dict) and key in base and isinstance(base[key], dict):\n\t\t\t\tself._merge_configs(base[key], value)\n\t\t\telse:\n\t\t\t\tbase[key] = value\n\n\tdef get(self, key: str, default: T = None) -&gt; T:\n\t\t\"\"\"\n\t\tGet a configuration value, optionally with a section.\n\n\t\tExamples:\n\t\t        # Get a top-level key\n\t\t        config.get(\"daemon\")\n\n\t\t        # Get a nested key with dot notation\n\t\t        config.get(\"daemon.host\")\n\n\t\tArgs:\n\t\t        key: Configuration key, can include dots for nested access\n\t\t        default: Default value if key not found\n\n\t\tReturns:\n\t\t        T: Configuration value or default\n\n\t\t\"\"\"\n\t\tparts = key.split(\".\")\n\n\t\t# Start with the whole config\n\t\tcurrent = self.config\n\n\t\t# Traverse the parts\n\t\tfor part in parts:\n\t\t\tif isinstance(current, dict) and part in current:\n\t\t\t\tcurrent = current[part]\n\t\t\telse:\n\t\t\t\treturn default\n\n\t\treturn cast(\"T\", current)\n\n\tdef set(self, key: str, value: ConfigValue) -&gt; None:\n\t\t\"\"\"\n\t\tSet a configuration value.\n\n\t\tArgs:\n\t\t        key: Configuration key, can include dots for nested access\n\t\t        value: Value to set\n\n\t\t\"\"\"\n\t\tparts = key.split(\".\")\n\n\t\t# Start with the whole config\n\t\tcurrent = self.config\n\n\t\t# Traverse to the parent of the leaf\n\t\tfor _i, part in enumerate(parts[:-1]):\n\t\t\tif part not in current:\n\t\t\t\tcurrent[part] = {}\n\t\t\telif not isinstance(current[part], dict):\n\t\t\t\t# Convert to dict if it wasn't already\n\t\t\t\tcurrent[part] = {}\n\t\t\tcurrent = current[part]\n\n\t\t# Set the leaf value\n\t\tcurrent[parts[-1]] = value\n\n\tdef save(self, config_file: str | None = None) -&gt; None:\n\t\t\"\"\"\n\t\tSave the current configuration to a file.\n\n\t\tArgs:\n\t\t        config_file: Path to save configuration to (optional, defaults to current config_file)\n\n\t\tRaises:\n\t\t        ConfigError: If configuration cannot be saved\n\n\t\t\"\"\"\n\t\tsave_path = Path(config_file) if config_file else self.config_file\n\n\t\tif not save_path:\n\t\t\terror_msg = \"No configuration file specified for saving\"\n\t\t\tlogger.error(error_msg)\n\t\t\traise ConfigError(error_msg)\n\n\t\t# Ensure parent directory exists\n\t\tsave_path.parent.mkdir(parents=True, exist_ok=True)\n\n\t\ttry:\n\t\t\twith save_path.open(\"w\", encoding=\"utf-8\") as f:\n\t\t\t\tyaml.dump(self.config, f, default_flow_style=False)\n\t\t\tlogger.info(\"Configuration saved to %s\", save_path)\n\t\texcept OSError as e:\n\t\t\terror_msg = f\"Error saving configuration to {save_path}: {e}\"\n\t\t\tlogger.exception(error_msg)\n\t\t\traise ConfigError(error_msg) from e\n\n\tdef get_bypass_hooks(self) -&gt; bool:\n\t\t\"\"\"\n\t\tGet whether to bypass git hooks.\n\n\t\tReturns:\n\t\t        bool: True if git hooks should be bypassed, False otherwise\n\n\t\t\"\"\"\n\t\treturn self.get(\"git.bypass_hooks\", self.get(\"commit.bypass_hooks\", False))\n\n\tdef get_commit_convention(self) -&gt; dict[str, Any]:\n\t\t\"\"\"\n\t\tGet commit convention configuration.\n\n\t\tReturns:\n\t\t        Dict[str, Any]: Commit convention configuration\n\n\t\t\"\"\"\n\t\tconvention = self.get(\"commit.convention\", {})\n\n\t\t# Ensure 'types' is always present with a default value if missing\n\t\tif \"types\" not in convention:\n\t\t\tconvention[\"types\"] = DEFAULT_CONFIG[\"commit\"][\"convention\"][\"types\"]\n\n\t\treturn convention\n\n\tdef get_workflow_strategy(self) -&gt; str:\n\t\t\"\"\"\n\t\tGet the workflow strategy configuration.\n\n\t\tReturns:\n\t\t        str: Workflow strategy name\n\n\t\t\"\"\"\n\t\treturn self.get(\"git.workflow_strategy\", \"github-flow\")\n\n\tdef get_pr_config(self) -&gt; dict[str, Any]:\n\t\t\"\"\"\n\t\tGet PR configuration.\n\n\t\tReturns:\n\t\t        Dict[str, Any]: PR configuration\n\n\t\t\"\"\"\n\t\treturn self.get(\"git.pr\", {})\n\n\tdef get_content_generation_config(self) -&gt; dict[str, Any]:\n\t\t\"\"\"\n\t\tGet content generation configuration.\n\n\t\tReturns:\n\t\t        Dict[str, Any]: Content generation configuration\n\n\t\t\"\"\"\n\t\treturn self.get(\"generation.content\", {})\n\n\tdef get_llm_config(self) -&gt; dict[str, Any]:\n\t\t\"\"\"\n\t\tGet LLM configuration.\n\n\t\tReturns:\n\t\t        Dict[str, Any]: LLM configuration\n\n\t\t\"\"\"\n\t\t# Get the LLM config from the top-level section\n\t\tllm_config = self.get(\"llm\", {})\n\n\t\t# If empty, use the default config\n\t\tif not llm_config:\n\t\t\tllm_config = DEFAULT_CONFIG[\"llm\"]\n\t\t\tlogger.debug(\"Using default LLM config from DEFAULT_CONFIG\")\n\n\t\t# Ensure we have the proper model format with a provider\n\t\tmodel = llm_config.get(\"model\")\n\t\tif model:\n\t\t\tlogger.debug(\"Using model from config: %s\", model)\n\t\t\tif \"/\" not in model:\n\t\t\t\t# Add openai/ prefix if provider is missing\n\t\t\t\tllm_config[\"model\"] = f\"openai/{model}\"\n\t\t\t\tlogger.debug(\"Added openai/ prefix to model: %s\", llm_config[\"model\"])\n\t\t\telse:\n\t\t\t\t# Extract provider from model string to make it accessible in config\n\t\t\t\tprovider = model.split(\"/\")[0].lower()\n\t\t\t\t# Set provider explicitly in the config\n\t\t\t\tllm_config[\"provider\"] = provider\n\t\t\t\tlogger.debug(\"Extracted provider '%s' from model '%s'\", provider, model)\n\n\t\treturn llm_config\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.get_instance","title":"get_instance  <code>classmethod</code>","text":"<pre><code>get_instance(\n\tconfig_file: str | None = None,\n\treload: bool = False,\n\trepo_root: Path | None = None,\n) -&gt; ConfigLoader\n</code></pre> <p>Get the singleton instance of ConfigLoader.</p> <p>Parameters:</p> Name Type Description Default <code>config_file</code> <code>str | None</code> <p>Path to configuration file (optional)</p> <code>None</code> <code>reload</code> <code>bool</code> <p>Whether to reload config even if already loaded</p> <code>False</code> <code>repo_root</code> <code>Path | None</code> <p>Repository root path (optional)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ConfigLoader</code> <code>ConfigLoader</code> <p>Singleton instance</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>@classmethod\ndef get_instance(\n\tcls, config_file: str | None = None, reload: bool = False, repo_root: Path | None = None\n) -&gt; \"ConfigLoader\":\n\t\"\"\"\n\tGet the singleton instance of ConfigLoader.\n\n\tArgs:\n\t        config_file: Path to configuration file (optional)\n\t        reload: Whether to reload config even if already loaded\n\t        repo_root: Repository root path (optional)\n\n\tReturns:\n\t        ConfigLoader: Singleton instance\n\n\t\"\"\"\n\tif cls._instance is None or reload:\n\t\tcls._instance = cls(config_file, repo_root=repo_root)\n\treturn cls._instance\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.__init__","title":"__init__","text":"<pre><code>__init__(\n\tconfig_file: str | None = None,\n\trepo_root: Path | None = None,\n) -&gt; None\n</code></pre> <p>Initialize the configuration loader.</p> <p>Parameters:</p> Name Type Description Default <code>config_file</code> <code>str | None</code> <p>Path to configuration file (optional)</p> <code>None</code> <code>repo_root</code> <code>Path | None</code> <p>Repository root path (optional)</p> <code>None</code> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def __init__(self, config_file: str | None = None, repo_root: Path | None = None) -&gt; None:\n\t\"\"\"\n\tInitialize the configuration loader.\n\n\tArgs:\n\t        config_file: Path to configuration file (optional)\n\t        repo_root: Repository root path (optional)\n\n\t\"\"\"\n\tself.config: dict[str, Any] = {}\n\tself.repo_root = repo_root\n\tself.config_file = self._resolve_config_file(config_file)\n\tself.load_config()\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config: dict[str, Any] = {}\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.repo_root","title":"repo_root  <code>instance-attribute</code>","text":"<pre><code>repo_root = repo_root\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.config_file","title":"config_file  <code>instance-attribute</code>","text":"<pre><code>config_file = _resolve_config_file(config_file)\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.load_config","title":"load_config","text":"<pre><code>load_config() -&gt; dict[str, Any]\n</code></pre> <p>Load configuration from file and apply environment variable overrides.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict[str, Any]: Loaded configuration</p> <p>Raises:</p> Type Description <code>ConfigError</code> <p>If configuration file exists but cannot be loaded</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def load_config(self) -&gt; dict[str, Any]:\n\t\"\"\"\n\tLoad configuration from file and apply environment variable overrides.\n\n\tReturns:\n\t        Dict[str, Any]: Loaded configuration\n\n\tRaises:\n\t        ConfigError: If configuration file exists but cannot be loaded\n\n\t\"\"\"\n\t# Start with default configuration\n\tself.config = DEFAULT_CONFIG.copy()\n\n\t# Try to load from file if available\n\tif self.config_file:\n\t\ttry:\n\t\t\tif self.config_file.exists():\n\t\t\t\twith self.config_file.open(encoding=\"utf-8\") as f:\n\t\t\t\t\tfile_config = yaml.safe_load(f)\n\t\t\t\t\tif file_config:\n\t\t\t\t\t\tself._merge_configs(self.config, file_config)\n\t\t\t\tlogger.info(\"Loaded configuration from %s\", self.config_file)\n\t\t\telse:\n\t\t\t\tlogger.warning(\"Configuration file not found: %s\", self.config_file)\n\t\texcept (OSError, yaml.YAMLError) as e:\n\t\t\terror_msg = f\"Error loading configuration from {self.config_file}: {e}\"\n\t\t\tlogger.exception(error_msg)\n\t\t\traise ConfigError(error_msg) from e\n\n\treturn self.config\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.get","title":"get","text":"<pre><code>get(key: str, default: T = None) -&gt; T\n</code></pre> <p>Get a configuration value, optionally with a section.</p> <p>Examples:</p>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.get--get-a-top-level-key","title":"Get a top-level key","text":"<p>config.get(\"daemon\")</p>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.get--get-a-nested-key-with-dot-notation","title":"Get a nested key with dot notation","text":"<p>config.get(\"daemon.host\")</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Configuration key, can include dots for nested access</p> required <code>default</code> <code>T</code> <p>Default value if key not found</p> <code>None</code> <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>Configuration value or default</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def get(self, key: str, default: T = None) -&gt; T:\n\t\"\"\"\n\tGet a configuration value, optionally with a section.\n\n\tExamples:\n\t        # Get a top-level key\n\t        config.get(\"daemon\")\n\n\t        # Get a nested key with dot notation\n\t        config.get(\"daemon.host\")\n\n\tArgs:\n\t        key: Configuration key, can include dots for nested access\n\t        default: Default value if key not found\n\n\tReturns:\n\t        T: Configuration value or default\n\n\t\"\"\"\n\tparts = key.split(\".\")\n\n\t# Start with the whole config\n\tcurrent = self.config\n\n\t# Traverse the parts\n\tfor part in parts:\n\t\tif isinstance(current, dict) and part in current:\n\t\t\tcurrent = current[part]\n\t\telse:\n\t\t\treturn default\n\n\treturn cast(\"T\", current)\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.set","title":"set","text":"<pre><code>set(key: str, value: ConfigValue) -&gt; None\n</code></pre> <p>Set a configuration value.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Configuration key, can include dots for nested access</p> required <code>value</code> <code>ConfigValue</code> <p>Value to set</p> required Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def set(self, key: str, value: ConfigValue) -&gt; None:\n\t\"\"\"\n\tSet a configuration value.\n\n\tArgs:\n\t        key: Configuration key, can include dots for nested access\n\t        value: Value to set\n\n\t\"\"\"\n\tparts = key.split(\".\")\n\n\t# Start with the whole config\n\tcurrent = self.config\n\n\t# Traverse to the parent of the leaf\n\tfor _i, part in enumerate(parts[:-1]):\n\t\tif part not in current:\n\t\t\tcurrent[part] = {}\n\t\telif not isinstance(current[part], dict):\n\t\t\t# Convert to dict if it wasn't already\n\t\t\tcurrent[part] = {}\n\t\tcurrent = current[part]\n\n\t# Set the leaf value\n\tcurrent[parts[-1]] = value\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.save","title":"save","text":"<pre><code>save(config_file: str | None = None) -&gt; None\n</code></pre> <p>Save the current configuration to a file.</p> <p>Parameters:</p> Name Type Description Default <code>config_file</code> <code>str | None</code> <p>Path to save configuration to (optional, defaults to current config_file)</p> <code>None</code> <p>Raises:</p> Type Description <code>ConfigError</code> <p>If configuration cannot be saved</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def save(self, config_file: str | None = None) -&gt; None:\n\t\"\"\"\n\tSave the current configuration to a file.\n\n\tArgs:\n\t        config_file: Path to save configuration to (optional, defaults to current config_file)\n\n\tRaises:\n\t        ConfigError: If configuration cannot be saved\n\n\t\"\"\"\n\tsave_path = Path(config_file) if config_file else self.config_file\n\n\tif not save_path:\n\t\terror_msg = \"No configuration file specified for saving\"\n\t\tlogger.error(error_msg)\n\t\traise ConfigError(error_msg)\n\n\t# Ensure parent directory exists\n\tsave_path.parent.mkdir(parents=True, exist_ok=True)\n\n\ttry:\n\t\twith save_path.open(\"w\", encoding=\"utf-8\") as f:\n\t\t\tyaml.dump(self.config, f, default_flow_style=False)\n\t\tlogger.info(\"Configuration saved to %s\", save_path)\n\texcept OSError as e:\n\t\terror_msg = f\"Error saving configuration to {save_path}: {e}\"\n\t\tlogger.exception(error_msg)\n\t\traise ConfigError(error_msg) from e\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.get_bypass_hooks","title":"get_bypass_hooks","text":"<pre><code>get_bypass_hooks() -&gt; bool\n</code></pre> <p>Get whether to bypass git hooks.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if git hooks should be bypassed, False otherwise</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def get_bypass_hooks(self) -&gt; bool:\n\t\"\"\"\n\tGet whether to bypass git hooks.\n\n\tReturns:\n\t        bool: True if git hooks should be bypassed, False otherwise\n\n\t\"\"\"\n\treturn self.get(\"git.bypass_hooks\", self.get(\"commit.bypass_hooks\", False))\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.get_commit_convention","title":"get_commit_convention","text":"<pre><code>get_commit_convention() -&gt; dict[str, Any]\n</code></pre> <p>Get commit convention configuration.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict[str, Any]: Commit convention configuration</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def get_commit_convention(self) -&gt; dict[str, Any]:\n\t\"\"\"\n\tGet commit convention configuration.\n\n\tReturns:\n\t        Dict[str, Any]: Commit convention configuration\n\n\t\"\"\"\n\tconvention = self.get(\"commit.convention\", {})\n\n\t# Ensure 'types' is always present with a default value if missing\n\tif \"types\" not in convention:\n\t\tconvention[\"types\"] = DEFAULT_CONFIG[\"commit\"][\"convention\"][\"types\"]\n\n\treturn convention\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.get_workflow_strategy","title":"get_workflow_strategy","text":"<pre><code>get_workflow_strategy() -&gt; str\n</code></pre> <p>Get the workflow strategy configuration.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Workflow strategy name</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def get_workflow_strategy(self) -&gt; str:\n\t\"\"\"\n\tGet the workflow strategy configuration.\n\n\tReturns:\n\t        str: Workflow strategy name\n\n\t\"\"\"\n\treturn self.get(\"git.workflow_strategy\", \"github-flow\")\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.get_pr_config","title":"get_pr_config","text":"<pre><code>get_pr_config() -&gt; dict[str, Any]\n</code></pre> <p>Get PR configuration.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict[str, Any]: PR configuration</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def get_pr_config(self) -&gt; dict[str, Any]:\n\t\"\"\"\n\tGet PR configuration.\n\n\tReturns:\n\t        Dict[str, Any]: PR configuration\n\n\t\"\"\"\n\treturn self.get(\"git.pr\", {})\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.get_content_generation_config","title":"get_content_generation_config","text":"<pre><code>get_content_generation_config() -&gt; dict[str, Any]\n</code></pre> <p>Get content generation configuration.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict[str, Any]: Content generation configuration</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def get_content_generation_config(self) -&gt; dict[str, Any]:\n\t\"\"\"\n\tGet content generation configuration.\n\n\tReturns:\n\t        Dict[str, Any]: Content generation configuration\n\n\t\"\"\"\n\treturn self.get(\"generation.content\", {})\n</code></pre>"},{"location":"api/utils/config_loader/#codemap.utils.config_loader.ConfigLoader.get_llm_config","title":"get_llm_config","text":"<pre><code>get_llm_config() -&gt; dict[str, Any]\n</code></pre> <p>Get LLM configuration.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict[str, Any]: LLM configuration</p> Source code in <code>src/codemap/utils/config_loader.py</code> <pre><code>def get_llm_config(self) -&gt; dict[str, Any]:\n\t\"\"\"\n\tGet LLM configuration.\n\n\tReturns:\n\t        Dict[str, Any]: LLM configuration\n\n\t\"\"\"\n\t# Get the LLM config from the top-level section\n\tllm_config = self.get(\"llm\", {})\n\n\t# If empty, use the default config\n\tif not llm_config:\n\t\tllm_config = DEFAULT_CONFIG[\"llm\"]\n\t\tlogger.debug(\"Using default LLM config from DEFAULT_CONFIG\")\n\n\t# Ensure we have the proper model format with a provider\n\tmodel = llm_config.get(\"model\")\n\tif model:\n\t\tlogger.debug(\"Using model from config: %s\", model)\n\t\tif \"/\" not in model:\n\t\t\t# Add openai/ prefix if provider is missing\n\t\t\tllm_config[\"model\"] = f\"openai/{model}\"\n\t\t\tlogger.debug(\"Added openai/ prefix to model: %s\", llm_config[\"model\"])\n\t\telse:\n\t\t\t# Extract provider from model string to make it accessible in config\n\t\t\tprovider = model.split(\"/\")[0].lower()\n\t\t\t# Set provider explicitly in the config\n\t\t\tllm_config[\"provider\"] = provider\n\t\t\tlogger.debug(\"Extracted provider '%s' from model '%s'\", provider, model)\n\n\treturn llm_config\n</code></pre>"},{"location":"api/utils/file_utils/","title":"File Utils","text":"<p>Utility functions for file operations in CodeMap.</p>"},{"location":"api/utils/file_utils/#codemap.utils.file_utils.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/utils/file_utils/#codemap.utils.file_utils.count_tokens","title":"count_tokens","text":"<pre><code>count_tokens(file_path: Path) -&gt; int\n</code></pre> <p>Rough estimation of tokens in a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to the file to count tokens in.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Estimated number of tokens in the file.</p> Source code in <code>src/codemap/utils/file_utils.py</code> <pre><code>def count_tokens(file_path: Path) -&gt; int:\n\t\"\"\"\n\tRough estimation of tokens in a file.\n\n\tArgs:\n\t    file_path: Path to the file to count tokens in.\n\n\tReturns:\n\t    Estimated number of tokens in the file.\n\n\t\"\"\"\n\ttry:\n\t\twith file_path.open(encoding=\"utf-8\") as f:\n\t\t\tcontent = f.read()\n\t\t\t# Simple tokenization by whitespace\n\t\t\treturn len(content.split())\n\texcept (OSError, UnicodeDecodeError):\n\t\treturn 0\n</code></pre>"},{"location":"api/utils/file_utils/#codemap.utils.file_utils.read_file_content","title":"read_file_content","text":"<pre><code>read_file_content(file_path: Path | str) -&gt; str\n</code></pre> <p>Read content from a file with proper error handling.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path | str</code> <p>Path to the file to read</p> required <p>Returns:</p> Type Description <code>str</code> <p>Content of the file as string</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If the file cannot be read</p> <code>UnicodeDecodeError</code> <p>If the file content cannot be decoded as UTF-8</p> Source code in <code>src/codemap/utils/file_utils.py</code> <pre><code>def read_file_content(file_path: Path | str) -&gt; str:\n\t\"\"\"\n\tRead content from a file with proper error handling.\n\n\tArgs:\n\t    file_path: Path to the file to read\n\n\tReturns:\n\t    Content of the file as string\n\n\tRaises:\n\t    OSError: If the file cannot be read\n\t    UnicodeDecodeError: If the file content cannot be decoded as UTF-8\n\n\t\"\"\"\n\tpath_obj = Path(file_path)\n\ttry:\n\t\twith path_obj.open(\"r\", encoding=\"utf-8\") as f:\n\t\t\treturn f.read()\n\texcept UnicodeDecodeError:\n\t\t# Try to read as binary and then decode with error handling\n\t\tlogger.warning(\"File %s contains non-UTF-8 characters, attempting to decode with errors='replace'\", path_obj)\n\t\twith path_obj.open(\"rb\") as f:\n\t\t\tcontent = f.read()\n\t\t\treturn content.decode(\"utf-8\", errors=\"replace\")\n</code></pre>"},{"location":"api/utils/log_setup/","title":"Log Setup","text":"<p>Logging setup for CodeMap.</p> <p>This module configures logging for different parts of the CodeMap application, ensuring logs are stored in the appropriate directories.</p>"},{"location":"api/utils/log_setup/#codemap.utils.log_setup.console","title":"console  <code>module-attribute</code>","text":"<pre><code>console = Console()\n</code></pre>"},{"location":"api/utils/log_setup/#codemap.utils.log_setup.setup_logging","title":"setup_logging","text":"<pre><code>setup_logging(\n\tis_verbose: bool = False, log_to_console: bool = True\n) -&gt; None\n</code></pre> <p>Set up logging configuration.</p> <p>Parameters:</p> Name Type Description Default <code>log_type</code> <p>Type of log ('daemon', 'cli', 'error')</p> required <code>log_name</code> <p>Specific name for the log file (default: based on log_type)</p> required <code>is_verbose</code> <code>bool</code> <p>Enable verbose logging</p> <code>False</code> <code>log_to_file</code> <p>Whether to log to a file</p> required <code>log_to_console</code> <code>bool</code> <p>Whether to log to the console</p> <code>True</code> Source code in <code>src/codemap/utils/log_setup.py</code> <pre><code>def setup_logging(\n\tis_verbose: bool = False,\n\tlog_to_console: bool = True,\n) -&gt; None:\n\t\"\"\"\n\tSet up logging configuration.\n\n\tArgs:\n\t    log_type: Type of log ('daemon', 'cli', 'error')\n\t    log_name: Specific name for the log file (default: based on log_type)\n\t    is_verbose: Enable verbose logging\n\t    log_to_file: Whether to log to a file\n\t    log_to_console: Whether to log to the console\n\n\t\"\"\"\n\t# Determine log level\n\tlog_level = logging.DEBUG if is_verbose else logging.INFO\n\n\t# Root logger configuration\n\troot_logger = logging.getLogger()\n\troot_logger.setLevel(log_level)\n\n\t# Clear existing handlers\n\tfor handler in root_logger.handlers[:]:\n\t\troot_logger.removeHandler(handler)\n\n\t# Setup console logging if requested\n\tif log_to_console:\n\t\tconsole_handler = RichHandler(\n\t\t\tlevel=log_level,\n\t\t\trich_tracebacks=True,\n\t\t\tshow_time=True,\n\t\t\tshow_path=is_verbose,\n\t\t)\n\t\tformatter = logging.Formatter(\"%(message)s\")\n\t\tconsole_handler.setFormatter(formatter)\n\t\troot_logger.addHandler(console_handler)\n</code></pre>"},{"location":"api/utils/log_setup/#codemap.utils.log_setup.log_environment_info","title":"log_environment_info","text":"<pre><code>log_environment_info() -&gt; None\n</code></pre> <p>Log information about the execution environment.</p> Source code in <code>src/codemap/utils/log_setup.py</code> <pre><code>def log_environment_info() -&gt; None:\n\t\"\"\"Log information about the execution environment.\"\"\"\n\tlogger = logging.getLogger(__name__)\n\n\ttry:\n\t\timport platform\n\n\t\tfrom codemap import __version__\n\n\t\tlogger.info(\"CodeMap version: %s\", __version__)\n\t\tlogger.info(\"Python version: %s\", platform.python_version())\n\t\tlogger.info(\"Platform: %s\", platform.platform())\n\n\texcept Exception:\n\t\t# logger.exception automatically handles exception info\n\t\tlogger.exception(\"Error logging environment info:\")\n</code></pre>"},{"location":"api/utils/log_setup/#codemap.utils.log_setup.display_error_summary","title":"display_error_summary","text":"<pre><code>display_error_summary(error_message: str) -&gt; None\n</code></pre> <p>Display an error summary with a divider and a title.</p> <p>Parameters:</p> Name Type Description Default <code>error_message</code> <code>str</code> <p>The error message to display</p> required Source code in <code>src/codemap/utils/log_setup.py</code> <pre><code>def display_error_summary(error_message: str) -&gt; None:\n\t\"\"\"\n\tDisplay an error summary with a divider and a title.\n\n\tArgs:\n\t        error_message: The error message to display\n\n\t\"\"\"\n\ttitle = Text(\"Error Summary\", style=\"bold red\")\n\n\tconsole.print()\n\tconsole.print(Rule(title, style=\"red\"))\n\tconsole.print(f\"\\n{error_message}\\n\")\n\tconsole.print(Rule(style=\"red\"))\n\tconsole.print()\n</code></pre>"},{"location":"api/utils/log_setup/#codemap.utils.log_setup.display_warning_summary","title":"display_warning_summary","text":"<pre><code>display_warning_summary(warning_message: str) -&gt; None\n</code></pre> <p>Display a warning summary with a divider and a title.</p> <p>Parameters:</p> Name Type Description Default <code>warning_message</code> <code>str</code> <p>The warning message to display</p> required Source code in <code>src/codemap/utils/log_setup.py</code> <pre><code>def display_warning_summary(warning_message: str) -&gt; None:\n\t\"\"\"\n\tDisplay a warning summary with a divider and a title.\n\n\tArgs:\n\t        warning_message: The warning message to display\n\n\t\"\"\"\n\ttitle = Text(\"Warning Summary\", style=\"bold yellow\")\n\n\tconsole.print()\n\tconsole.print(Rule(title, style=\"yellow\"))\n\tconsole.print(f\"\\n{warning_message}\\n\")\n\tconsole.print(Rule(style=\"yellow\"))\n\tconsole.print()\n</code></pre>"},{"location":"api/utils/path_utils/","title":"Path Utils","text":"<p>Utilities for handling paths and file system operations.</p>"},{"location":"api/utils/path_utils/#codemap.utils.path_utils.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"api/utils/path_utils/#codemap.utils.path_utils.filter_paths_by_gitignore","title":"filter_paths_by_gitignore","text":"<pre><code>filter_paths_by_gitignore(\n\tpaths: Sequence[Path], repo_root: Path\n) -&gt; list[Path]\n</code></pre> <p>Filter paths based on .gitignore patterns.</p> <p>This function filters a list of paths to exclude those that match patterns in a .gitignore file.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>Sequence[Path]</code> <p>Sequence of paths to filter</p> required <code>repo_root</code> <code>Path</code> <p>Root directory of the repository</p> required <p>Returns:</p> Type Description <code>list[Path]</code> <p>List of paths that don't match any gitignore patterns</p> Source code in <code>src/codemap/utils/path_utils.py</code> <pre><code>def filter_paths_by_gitignore(paths: Sequence[Path], repo_root: Path) -&gt; list[Path]:\n\t\"\"\"\n\tFilter paths based on .gitignore patterns.\n\n\tThis function filters a list of paths to exclude those that match\n\tpatterns in a .gitignore file.\n\n\tArgs:\n\t    paths: Sequence of paths to filter\n\t    repo_root: Root directory of the repository\n\n\tReturns:\n\t    List of paths that don't match any gitignore patterns\n\n\t\"\"\"\n\ttry:\n\t\timport pathspec\n\t\tfrom pathspec.patterns.gitwildmatch import GitWildMatchPattern\n\texcept ImportError:\n\t\tlogger.warning(\"pathspec package not installed, gitignore filtering disabled\")\n\t\treturn list(paths)\n\n\t# Read .gitignore if it exists\n\tgitignore_path = repo_root / \".gitignore\"\n\tif not gitignore_path.exists():\n\t\treturn list(paths)\n\n\t# Parse gitignore patterns\n\twith gitignore_path.open(\"r\", encoding=\"utf-8\") as f:\n\t\tgitignore_content = f.read()\n\n\t# Create path spec with direct import\n\tspec = pathspec.PathSpec.from_lines(GitWildMatchPattern, gitignore_content.splitlines())\n\n\t# Filter paths\n\tfiltered_paths = []\n\tfor path in paths:\n\t\ttry:\n\t\t\trel_path = path.relative_to(repo_root)\n\t\t\tif not spec.match_file(str(rel_path)):\n\t\t\t\tfiltered_paths.append(path)\n\t\texcept ValueError:\n\t\t\t# Path is not relative to repo_root\n\t\t\tfiltered_paths.append(path)\n\n\treturn filtered_paths\n</code></pre>"},{"location":"api/utils/path_utils/#codemap.utils.path_utils.normalize_path","title":"normalize_path","text":"<pre><code>normalize_path(path: str | Path) -&gt; Path\n</code></pre> <p>Normalize a path to an absolute Path object.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path string or object</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Normalized absolute Path</p> Source code in <code>src/codemap/utils/path_utils.py</code> <pre><code>def normalize_path(path: str | Path) -&gt; Path:\n\t\"\"\"\n\tNormalize a path to an absolute Path object.\n\n\tArgs:\n\t    path: Path string or object\n\n\tReturns:\n\t    Normalized absolute Path\n\n\t\"\"\"\n\tif isinstance(path, str):\n\t\tpath = Path(path)\n\treturn path.expanduser().resolve()\n</code></pre>"},{"location":"api/utils/path_utils/#codemap.utils.path_utils.get_relative_path","title":"get_relative_path","text":"<pre><code>get_relative_path(path: Path, base_path: Path) -&gt; Path\n</code></pre> <p>Get path relative to base_path if possible, otherwise return absolute path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to make relative</p> required <code>base_path</code> <code>Path</code> <p>The base path to make it relative to</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Relative path if possible, otherwise absolute path</p> Source code in <code>src/codemap/utils/path_utils.py</code> <pre><code>def get_relative_path(path: Path, base_path: Path) -&gt; Path:\n\t\"\"\"\n\tGet path relative to base_path if possible, otherwise return absolute path.\n\n\tArgs:\n\t    path: The path to make relative\n\t    base_path: The base path to make it relative to\n\n\tReturns:\n\t    Relative path if possible, otherwise absolute path\n\n\t\"\"\"\n\ttry:\n\t\treturn path.relative_to(base_path)\n\texcept ValueError:\n\t\treturn path.absolute()\n</code></pre>"},{"location":"api/utils/path_utils/#codemap.utils.path_utils.get_git_root","title":"get_git_root","text":"<pre><code>get_git_root(start_path: Path) -&gt; Path | None\n</code></pre> <p>Find the root directory of a git repository.</p> <p>Parameters:</p> Name Type Description Default <code>start_path</code> <code>Path</code> <p>Path to start searching from</p> required <p>Returns:</p> Type Description <code>Path | None</code> <p>Path to the git root directory, or None if not found</p> Source code in <code>src/codemap/utils/path_utils.py</code> <pre><code>def get_git_root(start_path: Path) -&gt; Path | None:\n\t\"\"\"\n\tFind the root directory of a git repository.\n\n\tArgs:\n\t    start_path: Path to start searching from\n\n\tReturns:\n\t    Path to the git root directory, or None if not found\n\n\t\"\"\"\n\tcurrent = start_path.absolute()\n\n\twhile current != current.parent:\n\t\tgit_dir = current / \".git\"\n\t\tif git_dir.exists() and git_dir.is_dir():\n\t\t\treturn current\n\t\tcurrent = current.parent\n\n\treturn None\n</code></pre>"},{"location":"contributing/","title":"Development Setup","text":"<p>Before contributing, please read our Code of Conduct and Contributing Guidelines.</p> <ol> <li> <p>Clone the repository:</p> <pre><code>git clone https://github.com/SarthakMishra/codemap.git\ncd codemap\n</code></pre> </li> <li> <p>Install Prerequisites:</p> <ul> <li>Task: Follow the official installation guide: https://taskfile.dev/installation/</li> <li> <p>uv: Install the <code>uv</code> package manager. We recommend using <code>pipx</code>:</p> <pre><code># Using pipx (recommended)\npipx install uv\n\n# Or using pip\n# pip install uv\n</code></pre> </li> <li> <p>Python: Ensure you have Python 3.12 or later installed.</p> </li> </ul> </li> <li> <p>Set up the Virtual Environment: <pre><code># Create a virtual environment using uv (creates .venv directory)\nuv venv\n\n# Activate the virtual environment\n# On Linux/macOS (bash/zsh):\nsource .venv/bin/activate\n# On Windows (Command Prompt):\n# .venv\\Scripts\\activate.bat\n# On Windows (PowerShell):\n# .venv\\Scripts\\Activate.ps1\n</code></pre></p> </li> <li> <p>Install Dependencies:     Install project dependencies, including development tools, using <code>uv</code>:     <pre><code># Installs dependencies from pyproject.toml including the 'dev' group\nuv sync --dev\n</code></pre></p> </li> <li> <p>Verify Setup:     You can list available development tasks using Task:     <pre><code>task -l\n</code></pre>     To run all checks and tests (similar to CI):     <pre><code>task ci\n</code></pre></p> </li> </ol> <p>For detailed contribution guidelines, branching strategy, and coding standards, please refer to our Contributing Guide. </p>"},{"location":"contributing/code-of-conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"contributing/code-of-conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"contributing/code-of-conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address, without their explicit permission</li> <li>Contacting individual members, contributors, or leaders privately, outside designated community mechanisms, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"contributing/code-of-conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"contributing/code-of-conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"contributing/code-of-conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the project maintainers. Please refer to the Contributing Guide for contact information if needed. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"contributing/code-of-conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"contributing/code-of-conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"contributing/code-of-conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"contributing/code-of-conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"contributing/code-of-conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"contributing/code-of-conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations. </p>"},{"location":"contributing/guidelines/","title":"Contributing to CodeMap","text":"<p>First off, thank you for considering contributing to CodeMap! We welcome contributions from everyone, and we're excited to see how you can help make this AI-powered developer toolkit even better.</p> <p>This document provides guidelines for contributing to the project. Please read it carefully to ensure a smooth and effective contribution process.</p>"},{"location":"contributing/guidelines/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Contributing to CodeMap</li> <li>Table of Contents</li> <li>How Can I Contribute?<ul> <li>Reporting Bugs</li> <li>Suggesting Enhancements</li> <li>Code Contributions</li> </ul> </li> <li>Getting Started</li> <li>Branching Strategy (Simplified Git Flow)<ul> <li>Core Branches</li> <li>Supporting Branches</li> <li>Workflow Examples</li> </ul> </li> <li>Code Contribution Workflow</li> <li>Coding Standards</li> <li>Testing</li> <li>Commit Message Guidelines</li> <li>Pull Request Process</li> <li>Release Process<ul> <li>Automatic Releases</li> <li>Release Preparation</li> <li>Hotfix Process</li> </ul> </li> <li>Questions?</li> </ul>"},{"location":"contributing/guidelines/#how-can-i-contribute","title":"How Can I Contribute?","text":""},{"location":"contributing/guidelines/#reporting-bugs","title":"Reporting Bugs","text":"<p>If you encounter a bug, please help us by reporting it!</p> <ol> <li>Check Existing Issues: Before creating a new issue, please search the GitHub Issues to see if the bug has already been reported.</li> <li>Create a New Issue: If the bug hasn't been reported, create a new issue. Please include:<ul> <li>A clear and descriptive title.</li> <li>Your operating system and Python version.</li> <li>Steps to reproduce the bug reliably.</li> <li>What you expected to happen.</li> <li>What actually happened (including any error messages or tracebacks).</li> <li>Screenshots or code snippets if relevant.</li> </ul> </li> </ol>"},{"location":"contributing/guidelines/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>We welcome suggestions for new features or improvements to existing ones.</p> <ol> <li>Check Existing Issues/Discussions: Search the GitHub Issues and Discussions to see if your idea has already been proposed.</li> <li>Create a New Issue/Discussion: If not, open a new issue or start a discussion thread. Describe:<ul> <li>The enhancement you're proposing.</li> <li>The problem it solves or the use case it addresses.</li> <li>Any potential implementation ideas (optional).</li> </ul> </li> </ol>"},{"location":"contributing/guidelines/#code-contributions","title":"Code Contributions","text":"<p>If you'd like to contribute code (bug fixes, new features), please follow the workflow outlined below.</p>"},{"location":"contributing/guidelines/#getting-started","title":"Getting Started","text":"<p>Before you start coding, make sure you have set up your development environment correctly by following the Development Setup Guide.</p>"},{"location":"contributing/guidelines/#branching-strategy-simplified-git-flow","title":"Branching Strategy (Simplified Git Flow)","text":"<p>We use a simplified Git Flow model to manage branches and releases, with automated releases powered by Python Semantic Release.</p> <pre><code>gitGraph\n    commit\n    branch dev\n    checkout dev\n    commit\n\n    branch feature/new-feature\n    checkout feature/new-feature\n    commit\n    commit\n    checkout dev\n    merge feature/new-feature tag: \"v0.2.0-next.1\"\n\n    branch feature/another-feature\n    checkout feature/another-feature\n    commit\n    checkout dev\n    merge feature/another-feature tag: \"v0.2.0-next.2\"\n\n    branch release/v0.2.0\n    checkout release/v0.2.0\n    commit\n    checkout main\n    merge release/v0.2.0 tag: \"v0.2.0\"\n    checkout dev\n    merge main\n\n    branch hotfix/critical-fix\n    checkout hotfix/critical-fix\n    commit\n    checkout main\n    merge hotfix/critical-fix tag: \"v0.2.1\"\n    checkout dev\n    merge main\n</code></pre>"},{"location":"contributing/guidelines/#core-branches","title":"Core Branches","text":"<ul> <li><code>main</code>:<ul> <li>Represents the latest stable production-ready release.</li> <li>Pushes to <code>main</code> trigger automatic stable version releases.</li> <li>Protected branch with required reviews. Changes come via approved PRs from <code>release/*</code> or <code>hotfix/*</code> branches.</li> </ul> </li> <li><code>dev</code>:<ul> <li>The primary integration branch for ongoing development and upcoming features.</li> <li>Pushes to <code>dev</code> trigger automatic pre-release versions with the <code>-next</code> tag.</li> <li>All feature branches are merged into <code>dev</code>.</li> <li>Continuously tested via CI.</li> </ul> </li> </ul>"},{"location":"contributing/guidelines/#supporting-branches","title":"Supporting Branches","text":"<ul> <li>Feature branches (<code>feature/*</code>):<ul> <li>Branched off <code>dev</code>.</li> <li>Used for developing new features or significant changes.</li> <li>Named descriptively (e.g., <code>feature/add-pr-update-command</code>).</li> <li>Merged back into <code>dev</code> via Pull Requests (PRs).</li> </ul> </li> <li>Release branches (<code>release/*</code>):<ul> <li>Branched off <code>dev</code> when preparing for a new stable release.</li> <li>Used for final testing, documentation updates, and version stabilization.</li> <li>Format: <code>release/vX.Y.0</code> (e.g., <code>release/v1.2.0</code>).</li> <li>Merged into <code>main</code> via PR, which triggers automatic release.</li> <li>No need for manual version bumping as this is handled by semantic-release.</li> </ul> </li> <li>Hotfix branches (<code>hotfix/*</code>):<ul> <li>Branched off <code>main</code>.</li> <li>Used for critical bug fixes needed in the production version.</li> <li>Merged into <code>main</code> via PR, triggering automatic patch release.</li> <li>Also merged back into <code>dev</code> (usually by merging the updated <code>main</code>).</li> </ul> </li> </ul>"},{"location":"contributing/guidelines/#workflow-examples","title":"Workflow Examples","text":"<ol> <li> <p>New Feature Development:</p> <pre><code># Start from the dev branch\ngit checkout dev\ngit pull origin dev\n\n# Create your feature branch\ngit checkout -b feature/your-feature-name\n\n# --- Make your changes ---\n\n# Push your feature branch\ngit push -u origin feature/your-feature-name\n\n# Open a Pull Request to merge `feature/your-feature-name` into `dev`\n# When merged, a new pre-release version may be created automatically\n</code></pre> </li> <li> <p>Release Preparation:</p> <pre><code>git checkout dev\ngit pull origin dev\n\n# Create a release branch (no need to bump versions manually)\ngit checkout -b release/v1.3.0\n\n# Make any final adjustments, documentation updates, etc.\n# Push the release branch\ngit push -u origin release/v1.3.0\n\n# Create a PR from release/v1.3.0 to main\n# When the PR is approved and merged:\n# 1. A new release will be automatically created\n# 2. The package will be built and published to PyPI\n# 3. Main should be merged back to dev to sync the version changes\ngit checkout dev\ngit pull origin dev\ngit merge origin/main\ngit push origin dev\n</code></pre> </li> <li> <p>Hotfix Process:     <pre><code>git checkout main\ngit pull origin main\n\n# Create a hotfix branch\ngit checkout -b hotfix/critical-bug-fix\n\n# Fix the bug and commit using conventional commit format\n# (preferably using `codemap commit`)\n\n# Push the hotfix branch\ngit push -u origin hotfix/critical-bug-fix\n\n# Create a PR from hotfix/critical-bug-fix to main\n# When merged, a patch release will be automatically created\n\n# After the hotfix is released, sync changes back to dev\ngit checkout dev\ngit pull origin dev\ngit merge origin/main\ngit push origin dev\n</code></pre></p> </li> </ol>"},{"location":"contributing/guidelines/#code-contribution-workflow","title":"Code Contribution Workflow","text":"<ol> <li>Fork &amp; Clone: Fork the repository on GitHub and clone your fork locally.     <pre><code>git clone https://github.com/YOUR_USERNAME/codemap.git\ncd codemap\ngit remote add upstream https://github.com/SarthakMishra/codemap.git\n</code></pre></li> <li>Setup: Follow the Development Setup instructions.</li> <li>Branch: Create a new branch based on the correct base branch (<code>dev</code> for features/improvements, <code>main</code> only for agreed-upon hotfixes).     <pre><code># For features/improvements\ngit checkout dev\ngit pull upstream dev # Keep dev up-to-date\ngit checkout -b feature/your-descriptive-name\n\n# For hotfixes (usually maintainers)\n# git checkout main\n# git pull upstream main\n# git checkout -b hotfix/your-fix-name\n</code></pre></li> <li>Code: Make your changes. Write clean, well-commented code. Add or update tests as necessary.</li> <li>Format &amp; Lint: Ensure your code adheres to the project's style guidelines.     <pre><code>task format\ntask lint\n# Or run all checks\ntask ci\n</code></pre></li> <li>Test: Run the test suite to ensure your changes haven't broken anything.     <pre><code>task test\n# Check coverage\ntask coverage\n</code></pre></li> <li>Commit: Commit your changes using meaningful commit messages. We strongly encourage using the <code>codemap commit</code> command to generate conventional commit messages.     <pre><code># Stage your changes\ngit add .\n# Use the interactive commit tool\ncodemap commit\n# Or if you prefer manual commits, follow conventional commit format\n# git commit -m \"feat(cli): add option for custom output format\"\n</code></pre></li> <li>Push: Push your branch to your fork.     <pre><code>git push -u origin feature/your-descriptive-name\n</code></pre></li> <li>Pull Request: Open a Pull Request (PR) from your fork's branch to the <code>upstream/dev</code> branch (or <code>upstream/main</code> for hotfixes). Provide a clear description of your changes.</li> </ol>"},{"location":"contributing/guidelines/#coding-standards","title":"Coding Standards","text":"<ul> <li>Follow PEP 8 for Python code.</li> <li>Use type hints (<code>typing</code> module).</li> <li>Write docstrings for public modules, classes, and functions (see project docs rules).</li> <li>Use <code>ruff</code> for linting and formatting (<code>task format</code>, <code>task lint</code>).</li> </ul>"},{"location":"contributing/guidelines/#testing","title":"Testing","text":"<ul> <li>Write tests using <code>pytest</code>.</li> <li>Aim for good test coverage (<code>task coverage</code>).</li> <li>Ensure all tests pass (<code>task test</code>) before submitting a PR.</li> </ul>"},{"location":"contributing/guidelines/#commit-message-guidelines","title":"Commit Message Guidelines","text":"<p>We follow the Conventional Commits specification.</p> <ul> <li>Format: <code>&lt;type&gt;[optional scope]: &lt;description&gt;</code></li> <li>Example: <code>feat(commit): add semantic diff splitting strategy</code></li> <li>Use <code>codemap commit</code>: The easiest way to ensure compliance is to use the built-in <code>codemap commit</code> command.</li> </ul>"},{"location":"contributing/guidelines/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Ensure all CI checks (linting, testing) pass.</li> <li>Provide a clear title and description for your PR.</li> <li>Link any related issues.</li> <li>Request reviews from maintainers.</li> <li>Address any feedback promptly.</li> <li>Once approved, a maintainer will merge the PR.</li> </ol>"},{"location":"contributing/guidelines/#release-process","title":"Release Process","text":"<p>Releases are managed automatically using Python Semantic Release.</p>"},{"location":"contributing/guidelines/#automatic-releases","title":"Automatic Releases","text":"<ul> <li>Merging a PR into <code>dev</code> may trigger a pre-release (e.g., <code>v1.2.0-next.1</code>).</li> <li>Merging a PR from a <code>release/*</code> or <code>hotfix/*</code> branch into <code>main</code> will trigger a stable release (e.g., <code>v1.2.0</code> or <code>v1.2.1</code>).</li> <li>The release process includes:<ul> <li>Bumping the version based on commit messages.</li> <li>Generating a changelog.</li> <li>Tagging the commit in Git.</li> <li>Creating a GitHub Release.</li> <li>Building the package.</li> <li>Publishing to PyPI.</li> </ul> </li> </ul>"},{"location":"contributing/guidelines/#release-preparation","title":"Release Preparation","text":"<p>Maintainers will create <code>release/*</code> branches off <code>dev</code> when ready to stabilize for a release. This branch allows for final testing and documentation updates before merging to <code>main</code>.</p>"},{"location":"contributing/guidelines/#hotfix-process","title":"Hotfix Process","text":"<p>Critical bugs in <code>main</code> are fixed using <code>hotfix/*</code> branches, which are merged directly back into <code>main</code> to trigger a patch release.</p>"},{"location":"contributing/guidelines/#questions","title":"Questions?","text":"<p>If you have questions, feel free to open an issue or start a discussion on GitHub. </p>"},{"location":"usage/","title":"Usage Overview","text":"<p>This section covers the main commands provided by CodeMap:</p> <ul> <li>Generate Docs (<code>gen</code>): Learn how to create optimized documentation for your codebase.</li> <li>Smart Commit (<code>commit</code>): Discover how to use AI assistance for crafting meaningful Git commit messages.</li> <li>Pull Requests (<code>pr</code>): See how CodeMap helps streamline the creation and management of pull requests. </li> </ul>"},{"location":"usage/commit/","title":"Smart Commit (<code>commit</code>)","text":"<p>Create intelligent Git commits with AI-assisted message generation. The tool analyzes your changes, splits them into logical chunks, and generates meaningful commit messages using LLMs.</p>"},{"location":"usage/commit/#basic-usage","title":"Basic Usage","text":"<pre><code># Basic usage with default settings (interactive, semantic splitting)\ncodemap commit\n# Or using the alias:\ncm commit\n\n# Commit with a specific message (skips AI generation)\ncodemap commit -m \"feat: add new feature\"\n\n# Commit all changes (including untracked files)\ncodemap commit -a\n\n# Use a specific LLM model\ncodemap commit --model groq/llama-3.1-8b-instant\n\n# Bypass git hooks (e.g., pre-commit)\ncodemap commit --bypass-hooks\n</code></pre>"},{"location":"usage/commit/#command-options","title":"Command Options","text":"<pre><code>codemap commit [PATH] [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>PATH</code>: Path to repository or specific file to commit (defaults to current directory)</li> </ul> <p>Options:</p> <ul> <li><code>--message</code>, <code>-m</code>: Specify a commit message directly (skips AI generation)</li> <li><code>--all</code>, <code>-a</code>: Commit all changes (stages untracked files)</li> <li><code>--model</code>: LLM model to use for message generation (default: <code>openai/gpt-4o-mini</code>). Overrides config (<code>commit.llm.model</code>).</li> <li><code>--strategy</code>, <code>-s</code>: Strategy for splitting diffs (default: <code>semantic</code>). Options: <code>file</code>, <code>hunk</code>, <code>semantic</code>. Overrides config (<code>commit.strategy</code>).</li> <li><code>--non-interactive</code>: Run in non-interactive mode (accepts all generated messages)</li> <li><code>--bypass-hooks</code>: Bypass git hooks with <code>--no-verify</code> (overrides config <code>commit.bypass_hooks</code>).</li> <li><code>--verbose</code>, <code>-v</code>: Enable verbose logging</li> </ul>"},{"location":"usage/commit/#interactive-workflow","title":"Interactive Workflow","text":"<p>The commit command provides an interactive workflow that: 1. Analyzes your changes and splits them into logical chunks 2. Generates AI-powered commit messages for each chunk 3. Allows you to:    - Accept the generated message    - Edit the message before committing    - Regenerate the message    - Skip the chunk    - Exit the process</p>"},{"location":"usage/commit/#commit-linting-feature","title":"Commit Linting Feature","text":"<p>CodeMap includes automatic commit message linting to ensure your commit messages follow conventions:</p> <ol> <li>Automatic Validation: Generated commit messages are automatically validated against conventional commit standards.</li> <li>Linting Rules: Configurable in <code>.codemap.yml</code> (see Configuration).</li> <li>Auto-remediation: If a generated message fails linting, CodeMap attempts to regenerate a compliant message.</li> <li>Fallback Mechanism: If regeneration fails, the last message is used with linting status indicated.</li> </ol>"},{"location":"usage/commit/#commit-strategy","title":"Commit Strategy","text":"<p>The tool uses semantic analysis to group related changes together based on: - File relationships - Code content similarity - Directory structure - Common file patterns</p> <p>Note</p> <p>The semantic strategy utilizes a custom, distilled version of the <code>Qodo/Qodo-Embed-1-1.5B</code> model, named <code>Qodo-Embed-M-1-1.5B-M2V-Distilled</code>. This Model2Vec distilled model is significantly smaller (233MB vs 5.9GB) and faster (~112x) than the original while retaining ~85% of its performance. Find more details here.</p>"},{"location":"usage/commit/#environment-variables","title":"Environment Variables","text":"<p>Refer to the LLM Support page for relevant environment variables.</p>"},{"location":"usage/commit/#examples","title":"Examples","text":"<pre><code># Basic interactive commit\ncodemap commit\n\n# Commit specific files\ncodemap commit path/to/file.py\n\n# Use a specific model with custom strategy\ncodemap commit --model anthropic/claude-3-sonnet --strategy semantic\n\n# Non-interactive commit with all changes\ncodemap commit -a --non-interactive\n\n# Commit with verbose logging\ncodemap commit -v\n\n# Demonstrate automatic linting and regeneration\ncodemap commit --verbose  # Will show linting feedback and regeneration attempts\n</code></pre>"},{"location":"usage/configuration/","title":"Configuration","text":"<p>Create a <code>.codemap.yml</code> file in your project root to customize the behavior. Below are all available configuration options with their default values:</p> <pre><code># LLM configuration (applies globally unless overridden by command-specific LLM config)\nllm:\n  model: openai/gpt-4o-mini  # Default LLM model (provider/model_name format)\n  api_base: null             # Custom API base URL (e.g., for local LLMs or proxies)\n\n# Documentation Generation Settings ('gen' command)\ngen:\n  max_content_length: 5000       # Max content length per file (0 = unlimited)\n  use_gitignore: true            # Respect .gitignore patterns\n  output_dir: documentation       # Directory for generated docs (Note: mkdocs uses 'docs/')\n  include_tree: true             # Include directory tree in output\n  include_entity_graph: true     # Include Mermaid entity relationship graph\n  semantic_analysis: true        # Enable semantic analysis using LSP\n  lod_level: docs                # Level of Detail: signatures, structure, docs, full\n  mermaid_entities:              # Entity types for Mermaid graph\n    - module\n    - class\n    - function\n    - method\n    - constant\n    - variable\n    - import\n  mermaid_relationships:         # Relationship types for Mermaid graph\n    - declares\n    - imports\n    - calls\n  mermaid_show_legend: true      # Show legend in Mermaid diagram\n  mermaid_remove_unconnected: false # Remove unconnected nodes in Mermaid diagram\n\n# Processor configuration (background analysis - currently unused)\nprocessor:\n  enabled: true\n  max_workers: 4\n  ignored_patterns:\n    - \"**/.git/**\"\n    - \"**/__pycache__/**\"\n    - \"**/.venv/**\"\n    - \"**/node_modules/**\"\n    - \"**/*.pyc\"\n    - \"**/dist/**\"\n    - \"**/build/**\"\n  default_lod_level: signatures\n\n# Commit Feature Configuration ('commit' command)\ncommit:\n  strategy: semantic             # Diff splitting strategy: file, hunk, semantic\n  bypass_hooks: false            # Default for --bypass-hooks flag (--no-verify)\n\n  convention:                    # Commit convention settings (based on Conventional Commits)\n    types:                       # Allowed commit types\n      - feat\n      - fix\n      - docs\n      - style\n      - refactor\n      - perf\n      - test\n      - build\n      - ci\n      - chore\n    scopes: []                   # Optional scopes (can be auto-derived if empty)\n    max_length: 72               # Max length for commit subject line\n\n  lint:                          # Commitlint rule configuration (see https://commitlint.js.org/#/reference-rules)\n    # Example rules (full list in README)\n    header_max_length: { level: ERROR, rule: always, value: 100 }\n    type_enum: { level: ERROR, rule: always } # Uses types from commit.convention.types\n    type_case: { level: ERROR, rule: always, value: lower-case }\n    subject_empty: { level: ERROR, rule: never }\n    subject_full_stop: { level: ERROR, rule: never, value: . }\n\n# Pull Request Configuration ('pr' command)\npr:\n  defaults:\n    base_branch: null            # Default base branch (null = repo default)\n    feature_prefix: \"feature/\"   # Default prefix for feature branches\n\n  strategy: github-flow          # Git workflow: github-flow, gitflow, trunk-based\n\n  branch_mapping:                # Branch base/prefix mapping (primarily for GitFlow)\n    feature: { base: develop, prefix: \"feature/\" }\n    release: { base: main, prefix: \"release/\" }\n    hotfix: { base: main, prefix: \"hotfix/\" }\n    bugfix: { base: develop, prefix: \"bugfix/\" }\n\n  generate:                      # Content generation settings\n    title_strategy: commits      # How to generate title: commits, llm, template\n    description_strategy: commits # How to generate description: commits, llm, template\n    use_workflow_templates: true # Use built-in templates based on workflow/branch type?\n    # Template used if description_strategy is 'template' AND use_workflow_templates is false\n    description_template: |\n      ## Changes\n      {changes}\n\n      ## Testing\n      {testing_instructions}\n\n      ## Screenshots\n      {screenshots}\n</code></pre>"},{"location":"usage/configuration/#configuration-priority","title":"Configuration Priority","text":"<p>The configuration is loaded in the following order (later sources override earlier ones):</p> <ol> <li>Default configuration from the package</li> <li><code>.codemap.yml</code> in the project root</li> <li>Custom config file specified with <code>--config</code></li> <li>Command-line arguments</li> </ol>"},{"location":"usage/configuration/#configuration-tips","title":"Configuration Tips","text":"<p>Refer to the main README section for detailed tips on configuring:</p> <ul> <li>Token Limits (Deprecated) &amp; Content Length</li> <li>Git Integration (<code>use_gitignore</code>, <code>convention.scopes</code>, <code>bypass_hooks</code>)</li> <li>LLM Settings (<code>llm.model</code>, <code>llm.api_base</code>, <code>--model</code> flag)</li> <li>Commit Conventions &amp; Linting (<code>commit.convention</code>, <code>commit.lint</code>)</li> <li>PR Workflow Settings (<code>pr.strategy</code>, <code>pr.defaults</code>, <code>pr.branch_mapping</code>, <code>pr.generate</code>)</li> <li>Documentation Generation (<code>gen.*</code> settings and flags)</li> </ul>"},{"location":"usage/configuration/#environment-variables","title":"Environment Variables","text":"<p>LLM API keys and optional base URLs can be set via environment variables. See the LLM Support page for details. </p>"},{"location":"usage/generate/","title":"Generate Markdown Docs (<code>gen</code>)","text":"<p>Generate optimized markdown documentation and directory structures for your project:</p>"},{"location":"usage/generate/#command-options","title":"Command Options","text":"<pre><code>codemap gen [PATH] [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>PATH</code>: Path to the codebase to analyze (defaults to current directory)</li> </ul> <p>Options:</p> <ul> <li><code>--output</code>, <code>-o</code>: Output file path for the documentation (overrides config)</li> <li><code>--config</code>, <code>-c</code>: Path to custom configuration file</li> <li><code>--max-content-length</code>: Maximum content length for file display (set to 0 for unlimited, overrides config)</li> <li><code>--lod</code>: Level of Detail for code analysis (signatures, structure, docs, full). Default: <code>docs</code>. Overrides config.</li> <li><code>--semantic</code>/<code>--no-semantic</code>: Enable/disable semantic analysis using LSP. Default: enabled. Overrides config.</li> <li><code>--tree</code>/<code>--no-tree</code>: Include/exclude directory tree in output. Overrides config (<code>gen.include_tree</code>).</li> <li><code>--verbose</code>, <code>-v</code>: Enable verbose logging</li> <li><code>--process</code>/<code>--no-process</code>: Process the codebase before generation. Default: enabled.</li> <li><code>--entity-graph</code>/<code>--no-entity-graph</code>: Include/exclude entity relationship graph (Mermaid) in output. Overrides config (<code>gen.include_entity_graph</code>).</li> <li><code>--mermaid-entities</code>: Comma-separated list of entity types (e.g., 'module,class,function'). Overrides config (<code>gen.mermaid_entities</code>).</li> <li><code>--mermaid-relationships</code>: Comma-separated list of relationship types (e.g., 'declares,imports,calls'). Overrides config (<code>gen.mermaid_relationships</code>).</li> <li><code>--mermaid-legend</code>/<code>--no-mermaid-legend</code>: Show/hide the legend in the Mermaid diagram. Overrides config (<code>gen.mermaid_show_legend</code>).</li> <li><code>--mermaid-unconnected</code>/<code>--no-mermaid-unconnected</code>: Remove/keep nodes with no connections in the Mermaid diagram. Overrides config (<code>gen.mermaid_remove_unconnected</code>).</li> </ul>"},{"location":"usage/generate/#examples","title":"Examples","text":"<pre><code># Generate documentation for current directory using defaults\ncodemap gen\n# Or using the alias:\ncm gen\n\n# Generate for a specific path with full detail and no semantic analysis\ncodemap gen /path/to/project --lod full --no-semantic\n\n# Generate docs with signatures only and custom Mermaid settings\ncm gen --lod signatures --mermaid-entities \"class,function\" --mermaid-relationships \"calls\"\n\n# Generate only directory tree (implicitly disables entity graph)\ncodemap gen --tree --no-entity-graph\n\n# Custom output location and content length\ncodemap gen -o ./docs/codebase.md --max-content-length 1500\n\n# Use custom configuration file\ncodemap gen --config custom-config.yml\n\n# Verbose mode for debugging\ncodemap gen -v\n</code></pre>"},{"location":"usage/generate/#output-structure","title":"Output Structure","text":"<p>The generated documentation includes: 1. Project overview and structure 2. Directory tree visualization 3. Token-optimized code summaries 4. File relationships and dependencies 5. Rich markdown formatting with syntax highlighting</p>"},{"location":"usage/generate/#file-processing","title":"File Processing","text":"<p>The generator: - Respects <code>.gitignore</code> patterns by default - Intelligently analyzes code structure - Optimizes content for token limits - Generates well-structured markdown - Handles various file types and languages </p>"},{"location":"usage/llm-support/","title":"LLM Provider Support","text":"<p>CodeMap supports multiple LLM providers through LiteLLM.</p> <p>You can specify the desired model using the <code>--model</code> option in the <code>commit</code> and <code>pr</code> commands, or set a default in the Configuration.</p>"},{"location":"usage/llm-support/#examples","title":"Examples","text":"<pre><code># Using OpenAI (default)\ncodemap commit --model openai/gpt-4o-mini\n# Or using the alias:\ncm commit --model openai/gpt-4o-mini\n\n# Using Anthropic\ncodemap commit --model anthropic/claude-3-sonnet-20240229\n\n# Using Groq (recommended for speed)\ncodemap commit --model groq/llama-3.1-8b-instant\n\n# Using OpenRouter\ncodemap commit --model openrouter/meta-llama/llama-3-8b-instruct\n</code></pre>"},{"location":"usage/llm-support/#environment-variables","title":"Environment Variables","text":"<p>The following environment variables are needed to authenticate with the respective LLM providers. You can set these in your system environment or place them in a <code>.env</code> or <code>.env.local</code> file in your project root.</p> <pre><code># LLM Provider API Keys\nOPENAI_API_KEY=your_key_here\nANTHROPIC_API_KEY=your_key_here\nGROQ_API_KEY=your_key_here\nMISTRAL_API_KEY=your_key_here\nCOHERE_API_KEY=your_key_here\nTOGETHER_API_KEY=your_key_here\nOPENROUTER_API_KEY=your_key_here\n\n# Optional: Custom API Base URLs (for proxies or self-hosted models)\nOPENAI_API_BASE=your_custom_url\nANTHROPIC_API_BASE=your_custom_url\n# ... add others as needed ...\n</code></pre>"},{"location":"usage/pr/","title":"Pull Requests (<code>pr</code>)","text":"<p>The <code>codemap pr</code> command helps you create and manage pull requests with ease. It integrates with the existing <code>codemap commit</code> command to provide a seamless workflow from code changes to pull request creation.</p>"},{"location":"usage/pr/#pr-command-features","title":"PR Command Features","text":"<ul> <li>Create branches with intelligent naming based on your current changes</li> <li>Support for multiple Git workflow strategies (GitHub Flow, GitFlow, Trunk-Based)</li> <li>Rich branch visualization with metadata and relationships</li> <li>Smart base branch selection based on branch type</li> <li>Automatic content generation for different PR types (feature, release, hotfix)</li> <li>Workflow-specific PR templates based on branch type</li> <li>Interactive PR content editing with previews</li> <li>Update existing PRs with new commits</li> <li>Configurable via <code>.codemap.yml</code> for team-wide settings (see Configuration)</li> </ul>"},{"location":"usage/pr/#pr-command-requirements","title":"PR Command Requirements","text":"<ul> <li>Git repository with a remote named <code>origin</code></li> <li>GitHub CLI (<code>gh</code>) installed for PR creation and management</li> <li>Valid GitHub authentication for the <code>gh</code> CLI</li> </ul>"},{"location":"usage/pr/#creating-a-pr","title":"Creating a PR","text":"<pre><code>codemap pr create [PATH] [OPTIONS]\n# Or using the alias:\ncm pr create [PATH] [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>PATH</code>: Path to the codebase to analyze (defaults to current directory)</li> </ul> <p>Options:</p> <ul> <li><code>--branch</code>, <code>-b</code>: Target branch name</li> <li><code>--type</code>, <code>-t</code>: Branch type (e.g., feature, release, hotfix, bugfix). Valid types depend on workflow strategy.</li> <li><code>--base</code>: Base branch for the PR (defaults to repo default or workflow-defined default)</li> <li><code>--title</code>: Pull request title</li> <li><code>--desc</code>, <code>-d</code>: Pull request description (file path or text)</li> <li><code>--no-commit</code>: Skip the commit process before creating PR</li> <li><code>--force-push</code>, <code>-f</code>: Force push the branch</li> <li><code>--workflow</code>, <code>-w</code>: Git workflow strategy (github-flow, gitflow, trunk-based). Overrides config (<code>pr.strategy</code>).</li> <li><code>--non-interactive</code>: Run in non-interactive mode</li> <li><code>--model</code>, <code>-m</code>: LLM model for content generation (overrides config <code>llm.model</code>).</li> <li><code>--verbose</code>, <code>-v</code>: Enable verbose logging</li> </ul>"},{"location":"usage/pr/#updating-a-pr","title":"Updating a PR","text":"<pre><code>codemap pr update [PATH] [OPTIONS]\n# Or using the alias:\ncm pr update [PATH] [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>PATH</code>: Path to the codebase to analyze (defaults to current directory)</li> </ul> <p>Options:</p> <ul> <li><code>--pr</code>: PR number to update (required if not updating PR for current branch)</li> <li><code>--title</code>: New PR title</li> <li><code>--desc</code>, <code>-d</code>: New PR description (file path or text)</li> <li><code>--force-push</code>, <code>-f</code>: Force push the branch (use with caution)</li> <li><code>--non-interactive</code>: Run in non-interactive mode</li> <li><code>--verbose</code>, <code>-v</code>: Enable verbose logging</li> </ul> <p>Warning</p> <p>--no-commit is NOT an option for 'update'</p>"},{"location":"usage/pr/#git-workflow-strategies","title":"Git Workflow Strategies","text":"<p>The PR command supports multiple Git workflow strategies:</p> <ol> <li>GitHub Flow (default)</li> <li>Simple, linear workflow</li> <li> <p>Feature branches merge directly to main</p> </li> <li> <p>GitFlow</p> </li> <li>Feature branches \u2192 develop</li> <li>Release branches \u2192 main</li> <li> <p>Hotfix branches \u2192 main (with back-merge to develop)</p> </li> <li> <p>Trunk-Based Development</p> </li> <li>Short-lived feature branches</li> <li>Emphasizes small, frequent PRs</li> </ol>"},{"location":"usage/pr/#pr-template-system","title":"PR Template System","text":"<p>CodeMap includes a robust PR template system that automatically generates appropriate titles and descriptions based on the selected workflow strategy, branch type, and changes being made. See the Configuration page for details on customizing templates.</p>"},{"location":"usage/pr/#examples","title":"Examples","text":"<pre><code># Create PR using workflow-specific templates (GitFlow)\ncodemap pr create --workflow gitflow --type feature\n\n# Create PR with custom title but workflow-based description\ncodemap pr create --title \"My Custom Title\" --workflow trunk-based\n\n# Override both the workflow template and use custom description\ncodemap pr create --desc \"Custom description with **markdown** support\"\n\n# Non-interactive PR creation with defined template usage\ncodemap pr create --non-interactive --workflow gitflow --type release\n</code></pre>"}]}